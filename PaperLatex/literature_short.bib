% This file was created with JabRef 2.9.2.
% Encoding: UTF8

@STRING{Test = {Test1}}

@INPROCEEDINGS{Bode2010a,
  author = {Stephan Bode and Qurat-Ul-Ann Farooq and Matthias Riebisch},
  title = {Evolution Support for Model-Based Development and Testing -- {S}ummary},
  booktitle = {Proceedings of the IWK2010 Workshops: International Workshop on Design,
	Evaluation and Refinement of Intelligent Systems (DERIS2010) and
	the First International Workshop on Evolution Support for Model-Based
	Development and Testing (EMDT2010)},
  year = {2010},
  publisher = {CEUR-WS.org},
  note = {online CEUR-WS.org/Vol-646/EMDT2010paper5.pdf},
  crossref = {Atzmueller2010},
  file = {:./literature/EMDT2010paper5.pdf:PDF},
  owner = {Stephan},
  timestamp = {2011.02.10}
}

@inproceedings{Weinreich2013,
 author = {Miesbauer, Cornelia and Weinreich, Rainer},
 title = {Classification of Design Decisions: An Expert Survey in Practice},
 booktitle = {Proceedings of the 7th European Conference on Software Architecture},
 series = {ECSA'13},
 year = {2013},
 isbn = {978-3-642-39030-2},
 location = {Montpellier, France},
 pages = {130--145},
 numpages = {16},
 url = {http://dx.doi.org/10.1007/978-3-642-39031-9_12},
 doi = {10.1007/978-3-642-39031-9_12},
 acmid = {2525640},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {capturing design decisions, design decision classification, design decisions, software architecture knowledge management},
}

@ARTICLE{Kazman2013, 
author={Cervantes, H. and Velasco-Elizondo, P. and Kazman, R.}, 
journal={Software, IEEE}, 
title={A Principled Way to Use Frameworks in Architecture Design}, 
year={2013}, 
month={March}, 
volume={30}, 
number={2}, 
pages={46-53}, 
keywords={software architecture;Mexico City;Quarksoft;abstract concepts;architecture design codification;architecture design support;bottom-up concepts;software architects;technical design primitives;Computer architecture;Design methodology;Mechanical factors;Runtime;Software architecture;Software development;Specifications;design concepts;design tools and techniques;patterns;requirements;software architectures;specifications}, 
doi={10.1109/MS.2012.175}, 
ISSN={0740-7459},}

@ARTICLE{Chung1996,
  author = {Lawrence Chung and Brian A. Nixon and Eric S. K. Yu},
  title = {Dealing with Change: An Approach Using Non-functional Requirements},
  journal = {Requirements Engineering},
  year = {1996},
  volume = {1},
  pages = {238-260},
  number = {4},
  month = {Dec},
  abstract = {Non-functional requirements (or quality requirements, NFRs) such as
	confidentiality, performance and timeliness are often crucial to
	a software system. Concerns for such NFRs are often the impetus for
	change. To systematically support system evolution, this paper adapts
	the lsquoNFR Frameworkrsquo, which treats NFRs as goals to be achieved
	during development. Throughout the process, consideration of design
	alternatives, analysis of trade-offs and rationalisation of design
	decisions are all carried out in relation to the stated goals, and
	captured in historical records. We show how such historical records
	of treating NFRs as goals also system-atically support system evolution.
	This approach is illustrated by a study of changes in loan policies
	at Barclays Bank. The study considered changes in NFRs, and associated
	changes in priorities, workload and functionality. The study's historical
	records helped quickly determine the impact of changes. We also present
	guidelines for consistently managing historical records, and address
	tool support for the change process.},
  comment = {This is an extended and revised edition of a paper [Chung1995] appearing
	in the Proceedings of the Second International Symposium on Requirements
	Engineering. York, England, March 1995. A draft of that paper was
	prepared when all three authors were at the Department of Computer
	Science, University of Toronto.},
  crossref = {Chung1995},
  file = {:./literature/dealingwithchange.pdf:PDF},
  keywords = {change, non-functional requirements},
  owner = {Stephan},
  review = {see book concerning NFR Framework},
  timestamp = {2008.05.27},
  url = {http://www.springerlink.com/content/h7k8787142t48813/}
}

@INPROCEEDINGS{Cleary2006,
  author = {Brendan Cleary and Chris Exton},
  title = {The Cognitive Assignment Eclipse Plug-in},
  booktitle = {14th IEEE International Conference on Program Comprehension, ICPC},
  year = {2006},
  pages = {241-244},
  month = {June},
  abstract = {Concept assignment approaches assist software engineers to comprehend
	software by localising problem domain concepts to source code elements.
	This paper presents an implementation of a concept assignment approach
	we call cognitive assignment which combines cognitive mapping of
	expert software engineers and Bayesian classification to help engineers
	tasked with understanding unfamiliar systems to localise a concepts
	implementation in the systems source.},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  crossref = {DBLP:conf/iwpc/2006},
  doi = {10.1109/ICPC.2006.46},
  ee = {http://doi.ieeecomputersociety.org/10.1109/ICPC.2006.46},
  file = {:./literature/01631127.pdf:PDF},
  keywords = {program comprehension},
  owner = {Robert},
  timestamp = {2008.07.15}
}

@INCOLLECTION{Constantine2001,
  author = {Larry L. Constantine and Lucy A. D. Lockwood},
  title = {Structure and Style in Use Cases for User Interface Design},
  booktitle = {Object Modeling and User Interface Design: Designing Interactive
	Systems},
  publisher = {Addison-Wesley},
  year = {2001},
  editor = {van Harmelen, Mark},
  chapter = {7},
  pages = {245-279},
  address = {Boston, MA, USA},
  abstract = {Although widely employed in both object-oriented software engineering
	and user interface design, use cases are not well-defined. Relatively
	little attention has been paid to the various styles for writing
	the narratives that define use cases and their consequences for user
	interface design and software usability. Common narrative styles
	are presented with examples and discussions of their relative advantages
	and disadvantages. Essential use cases, a variant employed within
	usage-centered design, are contrasted with conventional use cases
	and scenarios. For the most efficient support of user interface design
	and particularly for large, complex projects, a highly-structured
	form of use case has evolved. New narrative elements and relationships
	among use cases are introduced. These include means for expressing
	partial or flexible ordering of interaction, relationships with business
	rules, as well as a clarification of the often misunderstood concept
	of extension that recognizes two distinct forms: synchronous and
	asynchronous extensions.},
  book = {Object modeling and user interface design: designing interactive systems},
  crossref = {Harmelen2001},
  file = {:./literature/structurestyle2.pdf:PDF},
  isbn = {0-201-65789-9},
  keywords = {use cases, essential models, task modeling, user interface design,
	usage-centered design},
  owner = {Stephan},
  timestamp = {2008.08.01},
  url = {http://www.foruse.com/articles/structurestyle2.pdf}
}

@INPROCEEDINGS{Dowson1987,
  author = {Dowson, M.},
  title = {Iteration in the software process; review of the 3rd International
	Software Process Workshop},
  booktitle = {Proceedings of the 9th international conference on Software Engineering},
  year = {1987},
  series = {ICSE '87},
  pages = {36--41},
  address = {Los Alamitos, CA, USA},
  publisher = {IEEE Computer Society Press},
  acmid = {41770},
  crossref = {Jarke1993},
  isbn = {0-89791-216-0},
  location = {Monterey, California, United States},
  numpages = {6},
  owner = {patrickr},
  review = {Process model classification (see also: Jarke1993):
	
	* Activity-oriented process models
	
	* Product-oriented process models
	
	* Decision-oriented paradigm},
  timestamp = {2012.08.15},
  url = {http://dl.acm.org/citation.cfm?id=41765.41770}
}

@inproceedings{TofanGA11,
  added-at = {2012-01-28T00:00:00.000+0100},
  author = {Tofan, Dan and Galster, Matthias and Avgeriou, Paris},
  biburl = {http://www.bibsonomy.org/bibtex/23c6e300d9f7d6e388a3555a224c567ca/dblp},
  booktitle = {ICSE},
  crossref = {conf/icse/2011},
  editor = {Taylor, Richard N. and Gall, Harald and Medvidovic, Nenad},
  ee = {http://doi.acm.org/10.1145/1985793.1985944},
  interhash = {2e166db3b590b0fe2d982200168a0c21},
  intrahash = {3c6e300d9f7d6e388a3555a224c567ca},
  isbn = {978-1-4503-0445-0},
  keywords = {dblp},
  pages = {916-919},
  publisher = {ACM},
  timestamp = {2012-01-28T00:00:00.000+0100},
  title = {Capturing tacit architectural knowledge using the repertory grid technique.},
  url = {http://dblp.uni-trier.de/db/conf/icse/icse2011.html#TofanGA11},
  year = 2011
}

@inproceedings{ShahinLK09,
  added-at = {2009-10-31T00:00:00.000+0100},
  author = {Shahin, Mojtaba and Liang, Peng and Khayyambashi, Mohammad-Reza},
  biburl = {http://www.bibsonomy.org/bibtex/2c62650400e650eef048fe0c5d30ec90a/dblp},
  booktitle = {WICSA/ECSA},
  crossref = {conf/wicsa/2009},
  date = {2009-10-31},
  description = {dblp},
  ee = {http://dx.doi.org/10.1109/WICSA.2009.5290823},
  interhash = {5e1772acb090b2a06787006a4ebbb261},
  intrahash = {c62650400e650eef048fe0c5d30ec90a},
  keywords = {dblp},
  pages = {293-296},
  publisher = {IEEE},
  timestamp = {2009-10-31T00:00:00.000+0100},
  title = {Architectural design decision: Existing models and tools.},
  url = {http://dblp.uni-trier.de/db/conf/wicsa/wicsa2009.html#ShahinLK09},
  year = 2009
}

@INPROCEEDINGS{Figueiredo2008,
  author = {Eduardo Figueiredo and Cl{\'a}udio Sant'Anna and Alessandro Garcia
	and Thiago T. Bartolomei and Walter Cazzola and Alessandro Marchetto},
  title = {On the Maintainability of Aspect-Oriented Software: A Concern-Oriented
	Measurement Framework},
  booktitle = {Proceedings 12th European Conference on Software Maintenance and
	Reengineering, CSMR},
  year = {2008},
  pages = {183-192},
  month = {April},
  publisher = {IEEE Computer Society},
  abstract = {Aspect-oriented design needs to be systematically assessed with respect
	to modularity flaws caused by the realization of driving system concerns,
	such as tangling, scattering, and excessive concern dependencies.
	As a result, innovative concern metrics have been defined to support
	quantitative analyses of concern's properties. However, the vast
	majority of these measures have not yet being theoretically validated
	and managed to get accepted in the academic or industrial settings.
	The core reason for this problem is the fact that they have not been
	built by using a clearly-defined terminology and criteria. This paper
	defines a concern-oriented framework that supports the instantiation
	and comparison of concern measures. The framework subsumes the definition
	of a core terminology and criteria in order to lay down a rigorous
	process to foster the definition of meaningful and well-founded concern
	measures. In order to evaluate the framework generality, we demonstrate
	the framework instantiation and extension to a number of concern
	measures suites previously used in empirical studies of aspect-oriented
	software maintenance.},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  crossref = {DBLP:conf/csmr/2008},
  doi = {http://dx.doi.org/10.1109/CSMR.2008.4493313},
  file = {:./literature/2008_On_the_Maintainability_Of_Aspect_Oriented_Concern_Oriented_Measurement_csmr08ready.pdf:PDF},
  keywords = {object-oriented programming, software architecture, software maintenance,
	software metricsaspect-oriented software, concern-oriented measurement
	framework, core terminology, scattering, software maintenance, tangling},
  owner = {Robert},
  timestamp = {2008.07.22}
}

@INPROCEEDINGS{Franch1998a,
  author = {Franch, X. and Botella, P.},
  title = {Putting non-functional requirements into software architecture},
  booktitle = {Proceedings. Ninth International Workshop on Software Specification
	and Design},
  year = {1998},
  pages = {60-67},
  month = {April},
  abstract = {This paper presents an approach for incorporating non-functional information
	of software system into software architectures. To do so, components
	present two distinguished slots: their non-functional specification,
	where non-functional requirements on components are placed, and their
	non-functional behaviour with respect to these requirements. Also,
	connector protocols may describe which non-functional aspects are
	relevant to component connections. We propose a notation to describe
	non-functionality in a systematic manner, and we use it to analyse
	two particular aspects of the meeting scheduler case study, user
	interaction and performance.},
  crossref = {Franch1998},
  doi = {10.1109/IWSSD.1998.667920},
  file = {:./literature/00667920.pdf:PDF},
  keywords = {formal specification, software engineeringmeeting scheduler case study,
	non-functional behaviour, non-functional information, non-functional
	requirements, non-functional specification, non-functionality, performance,
	software architectures, user interaction},
  owner = {Stephan},
  review = {NoFun language for describing components and connectors focussing
	on non-functional requirements
	
	
	non-functionality: 3 key conceps:
	
	-NF-attributes: attribute of software describing it
	
	-NF-behaviour: assignment of values to attributes for a particular
	sw unit (e.g. component)
	
	-NF-requirement: constraint reffered to a subset of NF-attributes
	used in a particular sw unit
	
	
	unit: component or connector
	
	
	component: specification and implementation each with functional and
	non-functional part
	
	
	connectors: define interaction between components, also functional
	and non-functional part
	
	
	NF-Attributes:
	
	-belong to a domain
	
	-can be bound to a component
	
	-have a scope
	
	
	NF-Behaviour:
	
	-each implementation of a component should state its behaviour with
	regard to the NF-attributes
	
	question: does the stated behaviour really correspond to the functional
	implementation
	
	
	NF-Requirments
	
	-state conditions for the implementation
	
	-can appear in nf-specifications and nf-implementations},
  timestamp = {2008.04.14},
  url = {http://ieeexplore.ieee.org/iel4/5418/14647/00667920.pdf?tp=&isnumber=&arnumber=667920}
}

@inproceedings{LagoAndAvgeriou2008,
  added-at = {2008-04-18T00:00:00.000+0200},
  author = {Lago, Patricia and Avgeriou, Paris and Capilla, Rafael and Kruchten, Philippe},
  biburl = {http://www.bibsonomy.org/bibtex/230939893da25f521c6e904bb16fc2dd2/dblp},
  booktitle = {WICSA},
  crossref = {conf/wicsa/2008},
  date = {2008-04-18},
  description = {dblp},
  ee = {http://doi.ieeecomputersociety.org/10.1109/WICSA.2008.25},
  interhash = {e2b40c94cea5c540eebc513b16e28e93},
  intrahash = {30939893da25f521c6e904bb16fc2dd2},
  keywords = {dblp},
  pages = {271-274},
  publisher = {IEEE Computer Society},
  timestamp = {2008-04-18T00:00:00.000+0200},
  title = {Wishes and Boundaries for a Software Architecture Knowledge Community.},
  url = {http://dblp.uni-trier.de/db/conf/wicsa/wicsa2008.html#LagoACK08},
  year = 2008
}

@INPROCEEDINGS{Garlan2009,
  author = {Garlan, David and Barnes, Jeffrey M. and Schmerl, Bradley R. and
	Celiku, Orieta},
  title = {Evolution styles: Foundations and tool support for software architecture
	evolution.},
  booktitle = {WICSA/ECSA},
  year = {2009},
  pages = {131-140},
  publisher = {IEEE},
  added-at = {2012-09-05T14:21:39.000+0200},
  biburl = {http://www.bibsonomy.org/bibtex/2e3b624421b3cf272bc2ff7e1bbf93a66/stammel},
  crossref = {conf/wicsa/2009},
  description = {dblp},
  ee = {http://dx.doi.org/10.1109/WICSA.2009.5290799},
  file = {:./literature/garlan2009toolsupport.pdf:PDF},
  interhash = {63ca13f678d6bd3e367e2c9fa5c3d316},
  intrahash = {e3b624421b3cf272bc2ff7e1bbf93a66},
  keywords = {dblp evolution foundations styles support tool},
  owner = {Sebastian},
  timestamp = {2013.06.19},
  url = {http://dblp.uni-trier.de/db/conf/wicsa/wicsa2009.html#GarlanBSC09}
}

@INCOLLECTION{Gulliksen2001,
  author = {Jan Gulliksen and Bengt Göransson and Magnus Lif},
  title = {A User-Centered Approach to Object-Oriented User Interface Design},
  booktitle = {Object Modeling and User Interface: Designing Interactive Systems},
  publisher = {Addison-Wesley},
  year = {2001},
  editor = {van Harmelen, Mark},
  chapter = {8},
  pages = {283-312},
  address = {Boston, MA, USA},
  abstract = {This chapter emphasizes user-centered design as the essential process
	for developing usable systems. User-centered design tries to strengthen
	the creative aspects of user interface design. However, this does
	not ﬁt very well with the more structured, architecture-centered
	nature of object-oriented development methodologies. Several problems
	associated with object-oriented techniques have been observed in
	development projects in practice. In this chapter, realizing the
	increasing commercial market share of such software development processes,
	we set 
	
	out to strengthen the user-centered design aspects of the Rational
	Uniﬁed Process (RUP) and the Dynamic Systems Development Method (DSDM).
	We describe the method of User Interface Modeling (UIM), which is
	based on object-oriented use cases, and establish task requirements
	that are speciﬁc to the user interface design process. We also introduce
	the role of the usability designer in vouching for the usability
	throughout the system development process. Finally, we describe our
	experiences in promoting user-centered design with object-oriented
	interface 
	
	design techniques at the Swedish National Tax Board.},
  crossref = {Harmelen2001},
  file = {:./literature/approach_to_ooui_design.pdf:PDF},
  keywords = {user-centered design, object-oriented user interface design},
  owner = {Stephan},
  timestamp = {2008.08.01}
}

@ARTICLE{Jarke1992,
  author = {Jarke, M. and Mylopoulos, J. and Schmidt, J.W. and Vassiliou, Y.},
  title = {DAIDA: An environment for evolving information systems},
  journal = {ACM Transactions on Information Systems (TOIS)},
  year = {1992},
  volume = {10},
  pages = {1--50},
  number = {1},
  crossref = {Jarke1993a},
  file = {Jarke1992.pdf:literature/Jarke1992.pdf:PDF},
  owner = {patrickr},
  publisher = {ACM},
  review = {Contribution:
	
	* Four worlds framework (4 viewpoints) (DAIDA) applied to information
	system engineering
	
	
	see also: Jarke1993a for an application of DAIDA},
  timestamp = {2012.08.15}
}

@ARTICLE{Jarke1993,
  author = {Jarke, M. and Pohl, K. and Jacobs, S. and Bubenko, J. and Assenova,
	P. and Holm, P. and Wangler, B. and Rolland, C. and Plihon, V. and
	Schmitt, J. and others},
  title = {Requirements engineering: an integrated view of representation, process,
	and domain},
  journal = {Software Engineering—ESEC'93},
  year = {1993},
  pages = {100--114},
  crossref = {Pohl1994a},
  file = {Jarke1993.pdf:literature/Jarke1993.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  review = {Contribution:
	
	* Application of Four-Worlds process modeling framework (subject world,
	usage world, system world, development world) to "Requirements Engineering"},
  timestamp = {2012.08.15}
}

@INPROCEEDINGS{Konersmann2012,
  author = {Konersmann, Marco and Alebrahim, Azadeh and Heisel, Maritta and Goedicke,
	Michael and Kersten, Benjamin},
  title = {Deriving Quality-based Architecture Alternatives with Patterns.},
  booktitle = {Software Engineering},
  year = {2012},
  editor = {Jähnichen, Stefan and Küpper, Axel and Albayrak, Sahin},
  volume = {198},
  series = {LNI},
  pages = {71-82},
  publisher = {GI},
  added-at = {2012-05-10T00:00:00.000+0200},
  biburl = {http://www.bibsonomy.org/bibtex/2243c6121c5787587e4f91d0bc0db6bcc/dblp},
  crossref = {conf/se/2012},
  ee = {http://subs.emis.de/LNI/Proceedings/Proceedings198/article6650.html},
  file = {:./literature/konersmann2012.pdf:PDF},
  interhash = {28af35304aad4b5e6eb375ec48fc0671},
  intrahash = {243c6121c5787587e4f91d0bc0db6bcc},
  isbn = {978-3-88579-292-5},
  keywords = {dblp},
  owner = {Sebastian},
  timestamp = {2013.07.26},
  url = {http://dblp.uni-trier.de/db/conf/se/se2012.html#KonersmannAHGK12}
}

@INCOLLECTION{Kruchten2001,
  author = {Philippe Kruchten and Stefan Ahlqvist and Stefan Bylund},
  title = {User Interface Design in the Rational Unified Process},
  booktitle = {Object Modeling and User Interface Design: Designing Interactive
	Systems},
  publisher = {Addison-Wesley},
  year = {2001},
  editor = {van Harmelen, Mark},
  chapter = {5},
  pages = {161-196},
  address = {Boston, MA, USA},
  book = {Object modeling and user interface design: designing interactive systems},
  crossref = {Harmelen2001},
  isbn = {0-201-65789-9},
  keywords = {user interface design, rational unified process, use case storyboards},
  owner = {Stephan},
  timestamp = {2008.08.01}
}

@INCOLLECTION{Lehman2006,
  author = {Meir Lehman and Juan C. Fern\'{a}ndez Ramil},
  title = {Software Evolution},
  booktitle = {Software Evolution and Feeback: Theory and Practice},
  publisher = {John Wiley \& Sons},
  year = {2006},
  chapter = {1},
  pages = {7-40},
  crossref = {Madhavji2006},
  owner = {Stephan},
  timestamp = {2010.11.19}
}

@ARTICLE{Ocampo2005,
  author = {Ocampo, A. and Bella, F. and M{\"u}nch, J.},
  title = {Software process commonality analysis},
  journal = {Software Process: Improvement and Practice},
  year = {2005},
  volume = {10},
  pages = {273--285},
  number = {3},
  crossref = {Ocampo2003},
  file = {Ocampo2005.PDF:literature/Ocampo2005.PDF:PDF},
  owner = {patrickr},
  publisher = {Wiley Online Library},
  review = {TBD},
  timestamp = {2012.07.20}
}

@TECHREPORT{Ocampo2003,
  author = {Ocampo, Alexis and Münch, Jürgen and Bella, Fabio},
  title = {Software Process Commonality Analysis (IESE-Report No. 090.03/E)},
  institution = {Fraunhofer IESE},
  year = {2003},
  crossref = {Ocampo2005},
  file = {Ocampo2003.PDF:literature/Ocampo2003.PDF:PDF},
  owner = {patrickr},
  timestamp = {2012.07.20}
}

@ARTICLE{Papazoglou2007,
  author = {Papazoglou, M.P. and Traverso, P. and Dustdar, S. and Leymann, F.},
  title = {Service-Oriented Computing: State of the Art and Research Challenges},
  journal = {Computer},
  year = {2007},
  volume = {40},
  pages = {38-45},
  number = {11},
  month = {Nov.},
  abstract = {Service-oriented computing promotes the idea of assembling application
	components into a network of services that can be loosely coupled
	to create flexible, dynamic business processes and agile applications
	that span organizations and computing platforms. An SOC research
	road map provides a context for exploring ongoing research activities.},
  crossref = {Papazoglou2007a, Zdun2007},
  doi = {10.1109/MC.2007.400},
  file = {:./literature/04385255.pdf:PDF},
  issn = {0018-9162},
  keywords = {Web services, business data processing, object-oriented programming,
	software architecture, SOA, SOC research road map, Web services,
	agile applications, application component assembling, dynamic business
	processes, service-oriented computing},
  owner = {Stephan},
  review = {services: autonomous, platform-independent, loosly-coupled entities
	
	any piecs of code or component can be reused and transformed into
	a service
	
	service-oriented approach: compose applications by discovering and
	invoking network-available services
	
	SOA: a logical way of designing a software system
	
	web services: most promising SOC-based technology
	
	
	4 pivotal, inherently related research themes:
	
	- service foundation
	
	- service compositions
	
	- service management and monitoring
	
	- service-oritented engineering
	
	
	extended SOA - three separated planes of functionality
	
	- service foundations
	
	- service compositions
	
	- service management and monitoring
	
	
	+ cross cutting characteristics: semantics, non-functional properties,
	QoS
	
	
	roles: service client, service provider, service aggregator, service
	operator
	
	
	Service Foundation:
	
	------------------------
	
	- provider hosts network-accessible software modules - defines service
	description
	
	- aggregator groups services into value-added services - becomes a
	provider
	
	
	enterprise service bus (ESB)
	
	- open-standards-based message backbone
	
	- supports service, message, and event-based interactions
	
	- integration of different application components behind service-oriented
	facade
	
	-> container model
	
	- provides support and facilitates transactions, security, performance
	metrics, dynamic configuration, services discovery
	
	
	challenges:
	
	- dynamically reconfigurable runtime architectures
	
	- ent-to-end security solutions
	
	- infrastructure support for data and process integration
	
	- semantically enhanced service discovery - explicating semantics
	of provider and requester, adding semantic annotations
	
	
	Service Composition:
	
	--------------------------
	
	- aggregating multiple services into a single composite service by
	aggregator
	
	orchestration: how do services interact at the message level, BPEL4WS
	
	choreography: associated with public message exchanges (between multiple
	business-process), Web Services Choreography Description Language
	(WS-CDL)
	
	-> should be no sharp distinction
	
	
	challenges:
	
	- composability analysis for replaceability, compatibility, and process
	conformance
	
	service comformance: behavioural and semantic conformance
	
	- dynamic and adaptive processes
	
	- QoS-aware service composition
	
	- business-driven automated compositions
	
	
	Service Management and Monitoring:
	
	---------------------------------------------
	
	activities: installation, configuration, collecting metrics, Service
	Level Agrrement (SLA) monitoring
	
	
	Web Services Distributed Management (WSDM) Specification:
	
	-> management channel offering performance management, configuration
	management, ...
	
	-> defines protocol for interoperability of management information
	and capabilities in a distributed environment via Web services
	
	companion specifications: Management Using Web Services (MUWS), Management
	of Web Services (MOWS)
	
	
	challenges:
	
	- self-configuring management services
	
	- self-adapting –
	
	- self-healing –
	
	- self-optimizing –
	
	- self-protecting –
	
	
	Service Design and Development:
	
	----------------------------------------
	
	- SOAs must rely on an evolutionary software engineering approach
	(that partly builds upon earlier processes including component-based
	development and business process modeling)
	
	
	- building a facade via SOAP/WSDL/UDDI over existing applications
	insufficient - serious redesign efforts for proper (commercial-strength)
	delivering
	
	- older paradigms don't address SOA's key elements: services, information
	flows, and components realizing services
	
	
	challenges:
	
	- engineering of service applications - service-oriented engineering
	methodology
	
	- flexible gap-analysis techniques
	
	-> realization strategy possibilies: greenfield development, top-down
	and bottom-up development, meet-in-the-middle development, development
	based on reference models
	
	- service versioning and adaptivity
	
	- service governance: compliance of QoS and policy requirements when
	compositioning across organizational boundaries
	
	
	interesting references:
	
	[16] for service-oriented engineering methodology -> Zdun2007
	
	[6] SOA - Approaches, Technologies and Research Issues -> Papazoglou2007a},
  timestamp = {2008.04.11},
  url = {http://ieeexplore.ieee.org/iel5/2/4385238/04385255.pdf?tp=&isnumber=&arnumber=4385255}
}

@INCOLLECTION{Pinheiro2004,
  author = {Pinheiro, Francisco A. C.},
  title = {Requirements Traceability},
  booktitle = {Perspectives on Software Requirements},
  publisher = {Kluwer},
  year = {2004},
  chapter = {5},
  pages = {91-113},
  abstract = {Requirements tracing is inevitable. We do tracing when we search information
	and it is difficult to imagine a software development environment
	without some tracing aids. For medium to complex systems we should
	have a traceability model and traceability aids should be in place.
	In these systems we have a quite complex web of relationships. It
	is common to have several requirements coming from the same source
	as well as a single requirement having more than one source. It is
	also common to have one requirement deriving several others as well
	as several requirements collapsing into a single one. The diversity
	and huge amount of information dealt with when developing large software
	systems point to the need for automated support to development practices,
	including traceability. This chapter presents the concept of requirements
	tracing and discusses several aspects related to traceability. Particular
	importance is given to the informal aspects of requirements tracing
	and to the non-functional nature of requirements traceability.},
  crossref = {Leite2004},
  file = {:./literature/RequirementsTraceability.pdf:PDF},
  keywords = {requirements traceability},
  owner = {Stephan},
  timestamp = {2009.05.12},
  url = {http://www-di.inf.puc-rio.br/~julio/Chapter%205.pdf}
}

@ARTICLE{Pohl1994a,
  author = {Pohl, K.},
  title = {The three dimensions of requirements engineering: a framework and
	its applications},
  journal = {Information systems},
  year = {1994},
  volume = {19},
  pages = {243--258},
  number = {3},
  crossref = {Jarke1993},
  owner = {patrickr},
  publisher = {Elsevier},
  review = {Contribution:
	
	* Metamodel of requirements engineering process (Development World)
	-> can be seen as phase of software development process},
  timestamp = {2012.08.15}
}

@INPROCEEDINGS{Zhang2011,
  author = {Zhang, Lei and Sun, Yanchun and Song, Hui and Chauvel, Franck and
	Mei, Hong},
  title = {Detecting Architecture Erosion by Design Decision of Architectural
	Pattern.},
  booktitle = {SEKE},
  year = {2011},
  pages = {758-763},
  publisher = {Knowledge Systems Institute Graduate School},
  added-at = {2011-12-09T00:00:00.000+0100},
  biburl = {http://www.bibsonomy.org/bibtex/223f79b34dea5d4cece49cd94b52aa334/dblp},
  crossref = {conf/seke/2011},
  file = {:./literature/zhang2011.pdf:PDF},
  interhash = {b714f8c2f66be31d7da801e02adbfd23},
  intrahash = {23f79b34dea5d4cece49cd94b52aa334},
  isbn = {1-891706-29-2},
  keywords = {dblp},
  owner = {Sebastian},
  timestamp = {2013.07.26},
  url = {http://dblp.uni-trier.de/db/conf/seke/seke2011.html#ZhangSSCM11}
}

@MISC{2009,
  author = {D.P.L. Meij van der},
  title = {A metamodeling approach to incremental model changes},
  month = {July},
  year = {2009},
  abstract = {For the next step in raising the level of abstraction in software
	development, Kent (Kent, 2002) proposed an approach for Model Driven
	Engineering (MDE). With MDE it is possible to raise the level of
	abstraction such that decisions can be made regardless the implementation
	language. Business rules can be defined on a higher level so in fact
	programming happens at the level of models. Model transformations
	allow models to be turned into other models, for instance models
	of source code or other less abstract models. This thesis is about
	model?to?model and model?to?text transformations. Usually modelto?
	text aspects of thoughts are omitted because the text to be generated
	can also be modeled and thus a model?to?model transformation should
	be sufficient. Because in this thesis we focus on incremental model
	changes and also incremental changing the files in the file system,
	we explicitly studied model?to?text transformation approaches to
	keep model and text synchronized. In this thesis we use different
	terms for model?tomodel and model?to?text transformations. We use
	the term transformation when we are dealing with models as logical
	entities, we use the term generation when we are dealing with files
	as physical entities. For instance, in a model?to?text transformation
	the model will be transformed and the output will be generated files;
	the generation of files is due to the transformation of a model.
	We studied the possibilities to perform specific file generation
	and file modification based on a set of changes to a model. In our
	approach we started investigating state of the art modeling environments
	and concluded that they were not able to perform an incremental model
	place, with in?place updates to a model. Also they did not support
	model?to?text transformations so for that reason we presented our
	own approach. The approach we propose in this thesis is an imperative
	approach that is able to perform model?to?model and model?to?text
	transformations in parallel. We also present several implementations
	of our approach and benchmarked them against each other to see which
	implementation is the most efficient when performing different types
	of (straightforward) transformations. Our results show that incremental
	model changes are indeed possible and also in an efficient way, optimized
	to the target platform.},
  file = {:/literature/changeIdentification/scriptie_D_van_der_Meij.pdf:PDF},
  keywords = {Read},
  owner = {Steffen},
  timestamp = {2012.03.01},
  url = {http://essay.utwente.nl/59158/}
}

@MISC{WORKSHOP2005,
  author = {ECMDA-Traceability workshop},
  title = {Future research topics discussion},
  howpublished = {http://www.sintef.no/uploadpages/10558/Future-Research-Topics.pdf},
  year = {2005},
  file = {:./literature/Future-Research-Topics.pdf:PDF},
  owner = {Elke},
  timestamp = {2011.06.10}
}

@INCOLLECTION{Assmann2006,
  author = {A\ssmann, Uwe and Zschaler, Steffen and Wagner, Gerd},
  title = {Ontologies, Meta-models, and the Model-Driven Paradigm},
  booktitle = {Ontologies for Software Engineering and Technologies},
  publisher = {Springer-Verlag},
  year = {2006},
  editor = {Calero, C. and Ruiz, F. and Piattini, M.},
  pages = {49-102},
  file = {:./literature/Paper_240.pdf:PDF},
  journal = {Ontologies for Software Engineering and Technologies},
  owner = {Steffen},
  timestamp = {2012.05.16}
}

@INPROCEEDINGS{Aagedal2002,
  author = {Jan Øyvind Aagedal and Earl F. Ecklund, Jr.},
  title = {Modelling QoS: Towards a UML Profile},
  booktitle = {UML '02: Proceedings of the 5th International Conference on The Unified
	Modeling Language},
  year = {2002},
  pages = {275-289},
  address = {London, UK},
  publisher = {Springer-Verlag},
  abstract = {In this paper, we present a conceptual object model for specifying
	Quality of Service (QoS) that forms a basis for a UML profile for
	QoS. The conceptual model is based on CQML, a lexical language for
	QoS specification. 
	
	A QoS characteristic represents some aspect of the QoS of a system,
	service or resource that can be identified and quantified. A QoS
	statement expresses some QoS by constraining values of QoS characteristics.
	A QoS relation specifies the mutual obligation of an object and its
	environment with respect to QoS. These concepts are related to the
	UML meta-model in order to define a UML profile for QoS. An example
	from a Lecture on Demand (LoD) case study depicts how these concepts
	can be used during enterprise modelling and system design.},
  file = {:./literature/UMLProfileQoS.pdf:PDF},
  isbn = {3-540-44254-5},
  keywords = {QoS, UML profile, quality of service, non-functional properties},
  owner = {Stephan},
  timestamp = {2008.05.15},
  url = {http://heim.ifi.uio.no/~janoa/papers/UMLProfileQoS.pdf}
}

@INPROCEEDINGS{Abadi2008,
  author = {Abadi, A. and Nisenson, M. and Simionovici, Y.},
  title = {A Traceability Technique for Specifications},
  booktitle = {Proceedings of the 16th IEEE International Conference on Program
	Comprehension (ICPC 2008)},
  year = {2008},
  pages = {103-112},
  address = {Amsterdam, Netherlands},
  month = {June},
  file = {:./literature/Paper_273.pdf:PDF},
  owner = {Steffen},
  timestamp = {2014.02.03}
}

@INPROCEEDINGS{Abdi2009a,
  author = {Abdi, M.K. and Lounis, H. and Sahraoui, H.},
  title = {A Probabilistic Approach for Change Impact Prediction in Object-Oriented
	Systems},
  booktitle = {Proceedings of the 2nd Workshop on Artificial Intelligence Techniques
	in Software Engineering (AISEW 2009)},
  year = {2009},
  pages = {189-200},
  address = {Thessaloniki, Greece},
  month = {April},
  file = {:./literature/Paper_122.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- many approaches proposed for IA, but causality relation between
	software still not explained
	
	
	Research Questions:
	
	
	Contribution:
	
	- probalistic IA approach using bayesian networks on source code
	
	
	Solution:
	
	- approach consists of 4 steps:
	
	* graph structure construction
	
	 - produce suitable graph
	
	 - assign probability values to network nodes
	
	* parameter affectation, distinguish between 2 types of variables:
	
	 - entry variables: directly deduced from measurements of these variables
	
	 - intermediate variables: not directly measurable, influenced by
	parent nodes through machine learning
	
	* bayesian inference:
	
	 - update conditional probabilities of all nodes
	
	* results
	
	-> granularity of entities: class
	
	-> granularity of changes: no details given
	
	-> granularity of results: class
	
	
	Open Issues:
	
	- initial probabilities of nodes assigned by experts -> not feasible
	for all projects & time consuming},
  timestamp = {2011.04.01}
}

@INPROCEEDINGS{Abdi2009b,
  author = {Abdi, M.K and Lounis, H. and Sahraoui, H.},
  title = {Predicting Change Impact in Object-Oriented Applications with Bayesian
	Networks},
  booktitle = {Computer Software and Applications Conference, 2009. COMPSAC '09.
	33rd Annual IEEE International},
  year = {2009},
  pages = {234-239},
  address = {Seattle, WA},
  month = {July},
  file = {:./literature/Paper_153.pdf:PDF},
  owner = {Steffen},
  review = {[same as Abdi2009a]},
  timestamp = {2011.04.05}
}

@INPROCEEDINGS{Abdi2006a,
  author = {Abdi, M.K and Lounis, Hakim and Sahraoui, Houari},
  title = {Analyzing Change Impact in Object-Oriented Systems},
  booktitle = {Proceedings of the 32nd EUROMICRO Conference on Software Engineering
	and Advanced Applications (EUROMICRO'06)},
  year = {2006},
  pages = {310-319},
  address = {Cavtat/Dubrovnik (Croatia)},
  month = {August},
  file = {:./literature/Paper_133.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- maintenance more expensive then development
	
	- change effects must be considered by maintainer and developer who
	change a system
	
	
	Research Questions:
	
	- how to reduce effort of maintenance
	
	
	Contribution:
	
	- IA approach for OO software
	
	- new impact calculation method based on meta model
	
	- case study to illustrate approach
	
	
	Solution:
	
	- consider 13 change types for classes, methods, variables (see below)
	
	- use 4 types of links between entities:
	
	* association: class references variables of other classes
	
	* aggregation: definition implies objects of other classes
	
	* inheritance: class inhertits from other class
	
	* invocation: called methods defined in other class
	
	- impact depends on type of link and type of change
	
	- static, code-based IA
	
	- coupling between classes used to conduct IA
	
	- use several couling metrics to detect impacted entities
	
	- use different machine learning techniques to estimate probability
	of change
	
	-> granularity of entities: class, method variable
	
	-> granularity of changes: add/delete, scope change, type change
	
	-> granularity of results: class
	
	
	Open Issues:},
  timestamp = {2011.04.04}
}

@INPROCEEDINGS{Abdi2006b,
  author = {Abdi, M.K and Lounis, Hakim and Sahraoui, Houari},
  title = {Using Coupling Metrics for Change Impact Analysis in Object-Oriented
	Systems},
  booktitle = {Proceedings of the 10th ECOOP Workshop on Quantitative Approaches
	in Object-Oriented Software Engineering (QAOOSE '06)},
  year = {2006},
  pages = {61-70},
  address = {Nantes, France},
  month = {July},
  file = {:./literature/Paper_142.PDF:PDF},
  owner = {Steffen},
  review = {[same as Abdi2006a]},
  timestamp = {2011.04.04}
}

@TECHREPORT{Abowd1997,
  author = {Abowd, G. and Bass, L. and Clements, P. and Kazman, R. and Northrop,
	L. and Zaremski, A.},
  title = {Recommended Best Industrial Practice for Software Architecture Evaluation},
  institution = {CMU/SEI},
  year = {1997},
  number = {CMU/SEI-96-TR-025},
  abstract = {Architectural decisions have a great impact on the consequent quality
	of software systems. As a result, it is important to evaluate how
	a software architecture meets its quality demands. Though much focus
	has been placed on modeling and describing the software architecture
	as a design artifact, we found that relatively little is known about
	the current experience with software architecture evaluation. 
	
	This report details the results of two workshops on software architecture
	evaluation, held at the Software Engineering Institute (SEI) on November
	9-10, 1995 and May 9-10, 1996. The purpose of the workshops was to
	determine the state of industrial practice in the evaluation of software
	architectures with respect to a set of desired quality attributes,
	and to uncover recommendations for best practices. In this report,
	we summarize the findings of the two workshops, define a set of dimensions
	to characterize various software architecture evaluation techniques,
	and make concrete recommendations for implementing architecture evaluation
	practices.},
  file = {:./literature/tr025.96.pdf:PDF},
  keywords = {Software Architecture Evaluation},
  owner = {Matthias},
  timestamp = {2008.09.25},
  url = {http://www.sei.cmu.edu/pub/documents/96.reports/pdf/tr025.96.pdf}
}

@INPROCEEDINGS{Abrahao2006,
  author = {Silvia Abrahao and Emilio Insfran},
  title = {Early Usability Evaluation in Model Driven Architecture Environments},
  booktitle = {Sixth International Conference on Quality Software, 2006. QSIC 2006.},
  year = {2006},
  pages = {287-294},
  month = {Oct.},
  publisher = {IEEE Computer Society},
  abstract = {Due to the increasing interest in the model driven architecture (MDA)
	paradigm, the conceptual models have become the backbone of the software
	development process. So far some methods exist to develop a user
	interface according to a MDA-compliant method, none of them explicitly
	connects usability to their process activities. In this paper, we
	present a framework which incorporates usability as part of a MDA
	development process. In particular, a usability model for early evaluation
	is proposed. Using this model, the usability of a software system
	is evaluated and improved at the platform independent model (PIM)
	level. It focuses on the correspondences between the abstract user
	interface elements and the final user interface elements in a specific
	platform (CM). This framework has been successfully applied to an
	industrial MDA tool},
  doi = {10.1109/QSIC.2006.26},
  file = {:./literature/04032297.pdf:PDF},
  issn = {1550-6002},
  keywords = {formal specification, software architecture, software quality, user
	interfacesMDA-compliant method, conceptual models, model driven architecture,
	platform independent model, quality models, software development,
	software system usability evaluation, user interface},
  owner = {Stephan},
  timestamp = {2008.04.02}
}

@ARTICLE{Abramson1996,
  author = {D. Abramson and R. Sosic and Kessels Rd Brisbane},
  title = {A Debugging and Testing Tool for Supporting Software Evolution},
  journal = {Journal of Automated Software Engineering},
  year = {1996},
  volume = {3},
  pages = {369---390},
  file = {:/literature/RegressionTesting/A Debugging and Testing Tool for supporting software evolution.pdf:PDF},
  keywords = {code based, interesting},
  owner = {Annie},
  timestamp = {2011.01.04},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.17.4007}
}

@ARTICLE{Abran2004,
  author = {Alain Abran and James W. Moore},
  title = {SWEBOK - Guide to the Software Engineering Body of Knowledge},
  year = {2004},
  volume = {The Institute of Electrical and Electronics Engineers, IEEE Computer
	Society, ISBN 0-7695-2330-7},
  file = {:./literature/SWEBOK_Guide_2004.pdf:PDF},
  keywords = {software engineering},
  language = {english},
  owner = {Stephan},
  timestamp = {2008.07.16},
  url = {http://www.swebok.org/}
}

@ARTICLE{Acuna2001,
  author = {Acu{\~n}a, S.T. and Ferr{\'e}, X.},
  title = {Software process modelling},
  journal = {Proc. World Multiconf. on Systemics, Cybernetics and Informatics,
	Orlando, FL},
  year = {2001},
  pages = {237--242},
  file = {Acuna2001.pdf:literature/Acuna2001.pdf:PDF},
  owner = {patrickr},
  review = {Contribution:
	
	
	* literature review on:
	
	** software process definition
	
	** software process modeling definition
	
	** process modelling elements
	
	** process modelling approaches},
  timestamp = {2012.08.15}
}

@TECHREPORT{Adamer2012,
  author = {Adamer, J. and Heindl, M. and Mastnak, C. and P{\"o}tscher, K.},
  title = {Traceability-a systematic literature survey},
  institution = {Technische Universit\"{a}t Wien, Institut f\"{u}r Softwaretechnik
	und Interaktive Systeme, Business Informatics Group},
  year = {2012},
  __markedentry = {[Steffen:]},
  file = {Adamer2012 - traceability - a systematic literature survey.pdf:literature/detep/Adamer2012 - traceability - a systematic literature survey.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.03.21}
}

@MISC{Adams,
  author = {Rob J. Adams and Len Bass and Bonnie E. John},
  title = {Applying general usability scenarios to the design of the software
	architecture of a collaborative workspace},
  howpublished = {Human-Centered Software Engineering: Frameworks for HCI/HCD and Software
	Engineering Integration, Kluwer Academic Publishers},
  abstract = {Architecturally-sensitive usability scenarios are important usability
	concerns that require early consideration in software design so that
	architectural support can render them easy and cost-effective to
	implement. Examples include providing the ability to cancel a command,
	undo commands, aggregate data, etc. This chapter reports on our experiences
	applying these scenarios to the design of MERBoard, a wall-sized
	interactive system developed by NASA to assist Mars Rover science
	teams with collaborative data analysis. We applied the scenarios
	during a major redesign of the software architecture that introduced
	usability as a valued quality attribute. In the process, we found
	that the scenarios were well-received by developers who readily understood
	how they related to MERBoard, that they applied to a collaborative
	workspace despite having been initially developed for a single-user
	desktop system, that they had a real impact on the architecture redesign,
	and that the scenario consideration process was quick and not too
	onerous for any of the team members.},
  file = {:./literature/MERBoardExperienceChapter.pdf:PDF},
  keywords = {software architecture, usability},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://www.cs.cmu.edu/~bej/usa/publications/MERBoardExperienceChapter.pdf}
}

@INPROCEEDINGS{Adikari2007,
  author = {Sisira Adikari and Craig McDonald and Neil Lynch},
  title = {Design Science-Oriented Usability Modelling for Software Requirements},
  booktitle = {Human-Computer Interaction. Interaction Design and Usability, 12th
	International Conference, HCI International 2007},
  year = {2007},
  editor = {Julie A. Jacko},
  volume = {4550/2007},
  series = {LNCS},
  pages = {373-382},
  publisher = {Springer},
  abstract = {An identified key reason for degraded usability in software systems
	is the deficiencies of current RE practice to incorporate usability
	perspectives effectively into SRS. The explicit expression of user
	and usability aspects in SRS benefits designers, developers, and
	testers in ensuring optimal usability in software products. This
	paper presents the results of a design-science oriented user interface
	design study to validate the proposition that incorporating user
	modelling and usability modelling in SRS improves design.},
  doi = {10.1007/978-3-540-73105-4},
  file = {:./literature/adikari2007.pdf:PDF},
  keywords = {User modelling, usability modelling},
  owner = {Stephan},
  timestamp = {2008.04.02}
}

@INPROCEEDINGS{Agrawal1993,
  author = {Agrawal, Hiralal and Horgan, Joseph R. and Krauser, Edward W. and
	London, Saul},
  title = {Incremental Regression Testing},
  booktitle = {Proceedings of the Conference on Software Maintenance},
  year = {1993},
  series = {ICSM '93},
  pages = {348--357},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[qurat:]},
  acmid = {658149},
  file = {:/literature/RegressionTesting/incremental regression testing.pdf:PDF},
  isbn = {0-8186-4600-4},
  keywords = {Read, RegressionTesting, CodeBased, Relevant, approach},
  numpages = {10},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=645542.658149}
}

@CONFERENCE{Ahmad2007,
  author = {Ahmad, A. and Ghazali, M.A.},
  title = {Documenting Requirements Traceability Information for Small Projects},
  booktitle = {Multitopic Conference, 2007. INMIC 2007. IEEE International},
  year = {2007},
  pages = {1 -5},
  month = {dec.},
  abstract = {Software engineering literature lists many benefits of requirements
	traceability (RT) and strongly suggests that it should be practiced
	for software projects. However, available literature concentrates
	on the development of complex and large systems that have thousands
	of requirements. Companies that develop small software systems, with
	only approximately a hundred requirements, have limited budgets and
	they face the challenge to define what traceability information to
	document and how. Goals of this paper are to find problems of RT
	faced in small projects and to offer guidelines for documenting traceability
	information for such projects.},
  doi = {10.1109/INMIC.2007.4557711},
  file = {:./literature/04557711.pdf:PDF},
  keywords = {requirements traceability;software engineering literature;software
	projects;software development management;systems analysis;},
  owner = {Elke},
  timestamp = {2011.06.06}
}

@ARTICLE{Aizenbud-Reshef2006,
  author = {N. Aizenbud-Reshef and B. T. Nolan and J. Rubin and Y. Shaham-Gafni},
  title = {Model traceability},
  journal = {IBM Systems Jounal},
  year = {2006},
  volume = {45},
  pages = {515-526},
  number = {3},
  month = {July},
  abstract = {Traceability relationships help stakeholders understand the many associations
	and dependencies that exist among software artifacts created during
	a software development project. The extent of traceability practice
	is viewed as a measure of system quality and process maturity and
	is mandated by many standards. This paper introduces model traceability,
	reviews the current state of the art, and highlights open problems.
	One issue that impedes wide adoption of traceability is the overhead
	incurred in manually creating and maintaining relationships. We review
	the latest research advancements that address this issue through
	the automatic discovery of trace relationships. Model Driven Development™
	provides new opportunities for establishing and using traceability
	information. We discuss automatic generation of trace information
	through transformations and the use of traceability relationships
	to maintain consistency and synchronize model artifacts. We conclude
	with a discussion of the implementation and utilization challenges
	that lie ahead.},
  address = {Riverton, NJ, USA},
  file = {:./literature/aizenbud.pdf:PDF},
  issn = {0018-8670},
  keywords = {traceability, model driven development, traceability relationships},
  owner = {Stephan},
  publisher = {IBM Corp.},
  review = {comprehensive state-of-the-art overview about traceability approaches
	
	
	classification of traceability relationships
	
	- by nature/origin and by automation
	
	- imposed/inferred (rule-based) links
	
	- manual/computed (by derivation or analysis) links
	
	
	interconnection between traceability and model-driven development
	discussed
	
	-> MDD helping automation
	
	
	challenges for traceability research:
	
	- standard traceability metamodel with reference objects representing
	traceable artifacts
	
	- different types of links with standardized semantics
	
	- unique identifiers for artifacts
	
	- automatic link establishment
	
	- relationship between traceability and software development process
	and methodology},
  timestamp = {2008.07.01},
  url = {http://www.research.ibm.com/journal/sj/453/aizenbud.pdf}
}

@INPROCEEDINGS{Aizenbud-Reshef2005,
  author = {Aizenbud-Reshef, N. and Paige, R. F. and Rubin, J. and Shaham-Gafni,
	Y. and Kolovos, D. S.},
  title = {Operational Semantics for Traceability},
  booktitle = {Proceedings of the 1st ECMDA Workshop on Traceability},
  year = {2005},
  pages = {7-14},
  address = {Nurnberg, Germany},
  __markedentry = {[Steffen:]},
  file = {:./literature/ostraceability.pdf:PDF},
  journal = {ECMDA-TW'05: Proceedings of 1st Workshop on Traceability, Nurnberg,
	Germany. SINTEF,},
  owner = {elkeb},
  timestamp = {2012.01.05}
}

@INPROCEEDINGS{Akerholm2004,
  author = {Akerholm, Mikael and Fredriksson, Johan and Sandstrom, Kristian and
	Crnkovic, Ivica},
  title = {Quality Attribute Support in a Component Technology for Vehicular
	Software},
  booktitle = {Fourth Conference on Software Engineering Research and Practice in
	Sweden},
  year = {2004},
  address = {Linkoping, Sweden},
  month = {October},
  abstract = {The electronics in vehicles represents a class of systems where quality
	attributes, such as safety, reliability, and resource usage, leaven
	all through development. Vehicular manufacturers are interested in
	developing their software using a component based approach, supported
	by a component technology, but commercial component technologies
	are too resource demanding, complex and unpredictable. In this paper
	we provide a vehicular domain specific classification of the importance
	of different quality attributes for software, and a discussion of
	how they could be facilitated by a component technology. The results
	can be used as guidance and evaluation for research aiming at developing
	component technologies suitable for vehicular systems.},
  file = {:./literature/0771.pdf:PDF},
  keywords = {quality attributes, component technology},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://www.mrtc.mdh.se/publications/0771.pdf}
}

@MISC{Akerman2005,
  author = {Richard Akerman},
  title = {Service-Oriented Architecture Methods to Develop Networked Library
	Services},
  howpublished = {SOA Symposium 2005},
  month = {Dec},
  year = {2005},
  note = {Presentation},
  file = {:./literature/akerman.pdf:PDF},
  keywords = {service oriented architecture, enterprise architecture, methodology},
  owner = {Stephan},
  review = {presentation sheets alone relativ useless},
  timestamp = {2008.04.02},
  url = {http://www.umanitoba.ca/uts/ltc/soa/presentations/akerman.ppt}
}

@CONFERENCE{Alexander2002,
  author = {Alexander, I.},
  title = {Towards Automatic Traceability in Industrial Practice},
  booktitle = {Proceedings of the 1st International Workshop on Traceability in
	Emerging Forms of Software Engineering (TEFSE 2002), Edinburgh, UK,},
  year = {2002},
  abstract = {Traceability is agreed to be essential but it is
	
	avoided on many industrial projects both
	
	through unfamiliarity and because it is
	
	burdensome. Semi-automatic traceability tools
	
	promise the beginnings of a solution to these
	
	twin problems. This paper describes
	
	experience with a toolkit that helped to reduce
	
	the burden of installing traces and allowed
	
	readers to view traces with familiar tools.
	
	Three traceability tools were used: an analyser
	
	that can automatically link Use Case
	
	references to Use Cases; a dictionary builder
	
	that links and if need be creates definitions
	
	from marked-up terms; and an exporter that
	
	translates a database of Use Cases into a fullynavigable
	
	 and fully-indexed hypertext. The
	
	advantages and limitations of this toolkit are
	
	discussed in the context of a railway control
	
	system project.},
  file = {:./literature/10.1.1.135.1774.pdf:PDF},
  owner = {Elke},
  review = {bringt konkrete Beispiele (Elke)},
  timestamp = {2011.06.01}
}

@INPROCEEDINGS{Ali2007a,
  author = {A. Ali and A. Nadeem and M.Z.Z.Iqbal and M. Usman},
  title = {Regression Testing Based on UML Design Models},
  booktitle = {PRDC 2007. 13th Pacific Rim International Symposium on Dependable
	Computing,2007.},
  year = {2007},
  pages = {85--88},
  abstract = {This paper presents a methodology for identifying changes and test
	case selection based on the {UML} designs of the system. Design artifacts
	used for this purpose are {UML} class diagram and sequence diagrams,
	which are used to generate an extended concurrent control flow graph
	{(ECCFG)} which is further used for regression testing, i.e., change
	identification and test case selection. A proof- of-concept tool
	has been developed and used on a case study, which shows that our
	approach selects a precise set of test cases from an existing test
	suite.},
  doi = {10.1109/PRDC.2007.53},
  file = {:/literature/RegressionTesting/Regression Testing based on UML Design Models.pdf:PDF},
  keywords = {design artifacts, extended concurrent control flow graph, program
	testing, regression testing, sequence diagrams, {UML} class diagram,
	{UML} design models, Unified Modeling Language, MBRT},
  owner = {Annie},
  review = {artifacts: class diagram, sequence diagram
	
	
	No specific change type, modifictification in properties
	
	
	casestudy, yes, 6 testcases, atm system
	
	tool support: no
	
	
	traceability, bulitin in eccfg, no explicit traceability
	
	
	testcase representation, (path)},
  timestamp = {2011.01.04}
}

@INPROCEEDINGS{Al-Naeem2005,
  author = {Al-Naeem, T. and Gorton, I. and Babar, M.A. and Rabhi, F. and Benatallah,
	B.},
  title = {A quality-driven systematic approach for architecting distributed
	software applications},
  booktitle = {Proceedings 27th International Conference on Software Engineering,
	(ICSE 2005)},
  year = {2005},
  pages = { 244-253},
  month = {May},
  publisher = {IEEE},
  abstract = {Architecting distributed software applications is a complex design
	activity. It involves making decisions about a number of inter-dependent
	design choices that relate to a range of design concerns. Each decision
	requires selecting among a number of alternatives; each of which
	impacts differently on various quality attributes. Additionally,
	there are usually a number of stakeholders participating in the decision-making
	process with different, often conflicting, quality goals, and project
	constraints, such as cost and schedule. To facilitate the architectural
	design process, we propose a quantitative quality-driven approach
	that attempts to find the best possible fit between conflicting stakeholders'
	quality goals, competing architectural concerns, and project constraints.
	The approach uses optimization techniques to recommend the optimal
	candidate architecture. Applicability of the proposed approach is
	assessed using a real system.},
  doi = {10.1109/ICSE.2005.1553567},
  file = {:./literature/ArchDesigner.pdf:PDF},
  issn = { },
  keywords = { distributed processing, software architecture, software quality distributed
	software application architecting, optimization, quality-driven systematic
	approach, software architecture design, software quality},
  owner = {Stephan},
  review = {interesting approach using the decision making method analytical hierarchy
	process (AHP) for valuing alternative design decisions
	
	
	gloabal optimization problem of weighted quality attributes and weighted
	design alternatives solved using integer programming},
  timestamp = {2009.12.04}
}

@ARTICLE{Alter1999,
  author = {Alter, S.},
  title = {A general, yet useful theory of information systems},
  journal = {Communications of the AIS},
  year = {1999},
  volume = {1},
  pages = {3},
  number = {3es},
  file = {Alter1999.pdf:literature/Alter1999.pdf:PDF},
  owner = {patrickr},
  publisher = {Association for Information Systems},
  timestamp = {2012.10.18}
}

@ARTICLE{Altmanninger2009,
  author = {Altmanninger, Kerstin and Seidl, Martina and Wimmer, Manuel},
  title = {A survey on model versioning approaches},
  journal = {International Journal of Web Information Systems},
  year = {2009},
  volume = {5},
  pages = {271-304},
  number = {3},
  abstract = {Purpose – The purpose of this paper is to provide a feature-based
	characterization of version control systems (VCSs), providing an
	overview about the state-of-the-art of versioning systems dedicated
	to modeling artifacts.
	
	
	Design/methodology/approach – Based on a literature study of existing
	approaches, a description of the features of versioning systems is
	established. Special focus is set on three-way merging which is an
	integral component of optimistic versioning. This characterization
	is employed on current model versioning systems, which allows the
	derivation of challenges in this research area.
	
	
	Findings – The results of the evaluation show that several challenges
	need to be addressed in future developments of VCSs and merging tools
	in order to allow the parallel development of model artifacts.
	
	
	Practical implications – Making model-driven engineering (MDE) a success
	requires supporting the parallel development of model artifacts as
	is done nowadays for text-based artifacts. Therefore, model versioning
	capabilities are a must for leveraging MDE in practice.
	
	
	Originality/value – The paper gives a comprehensive overview of collaboration
	features of VCSs for software engineering artifacts in general, discusses
	the state-of-the-art of systems for model artifacts, and finally,
	lists urgent challenges, which have to be considered in future model
	versioning system for realizing MDE in practice.},
  doi = {10.1108/17440080910983556},
  file = {:./literature/Altmanninger2009.pdf:PDF},
  keywords = {versioning control systems, VCS, model versioning},
  owner = {Stephan},
  timestamp = {2010.12.14}
}

@ARTICLE{Amyot2003,
  author = {Daniel Amyot},
  title = {Introduction to the User Requirements Notation: Learning by Example},
  journal = {Computer Networks},
  year = {2003},
  volume = {42},
  pages = {285-301},
  number = {3},
  month = {June},
  abstract = {Recognizing the need for a notation that would be used in the very
	first and often informal stages of the development cycle, the International
	Telecommunication Union (ITU-T) initiated a question on a User Requirements
	Notation (URN), which will be standardized as the Z.150 series of
	Recommendations. URN supports the development, description, and analysis
	of requirements for telecommunications systems and services, as well
	as for other types of complex reactive, distributed, and dynamic
	systems. Through a wireless telephony example, this paper gives an
	overview of the core elements and typical usage of the two complementary
	notations comprised in URN. The Goal-oriented Requirement Language
	(GRL) is used to describe business goals, non-functional requirements,
	alternatives, and rationales, whereas Use Case Map (UCM) enables
	the description of functional requirements as causal scenarios. This
	paper also briefly explores methodology elements and the complementarity
	between URN and the existing ITU-T languages.},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1016/S1389-1286(03)00244-5},
  file = {:./literature/IntroductionToURN.pdf:PDF},
  issn = {1389-1286},
  keywords = {Goals; GRL; ITU-T languages; Requirements engineering; Scenarios;
	UCM; User requirements notation},
  owner = {Stephan},
  publisher = {Elsevier North-Holland, Inc.},
  timestamp = {2009.01.26}
}

@TECHREPORT{Amyot1999,
  author = {Amyot, Daniel},
  title = {Use Case Maps Quick Tutorial},
  institution = {SITE, University of Ottawa},
  year = {1999},
  month = {September},
  note = {Version 1.0},
  file = {:./literature/UCMtutorial.pdf:PDF},
  keywords = {use case maps, URN, requirements},
  owner = {Stephan},
  timestamp = {2009.07.27},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.38.9896&rep=rep1&type=pdf}
}

@ARTICLE{Amyot2003a,
  author = {Daniel Amyot and Armin Eberlein},
  title = {An Evaluation of Scenario Notations and Construction Approaches for
	Telecommunication Systems Development},
  journal = {Telecommunication Systems},
  year = {2003},
  volume = {24},
  pages = {61-94},
  number = {1},
  abstract = {The elicitation, modeling and analysis of requirements have consistently
	been one of the main challenges during the development of complex
	systems. Telecommunication systems belong to this category of systems
	due to the worldwide distribution and the heterogeneity of today's
	telecommunication networks. Scenarios and use cases have become popular
	for capturing and analyzing requirements. However, little research
	has been done that compares different approaches and assesses their
	suitability for the telecommunications domain. This paper defines
	evaluation criteria and then reviews fifteen scenario notations.
	In addition, twenty-six approaches for the construction of design
	models from scenarios are briefly compared.},
  doi = {10.1023/A:1025890110119},
  file = {:./literature/Amyot2003a.pdf:PDF},
  keywords = {use case, use case maps, design model, requirements, scenario, synthesis,
	telecommunications},
  owner = {Stephan},
  timestamp = {2010.11.15}
}

@INPROCEEDINGS{Anacleto2004,
  author = {Anacleto, A. and von Wangenheim, C.G. and Salviano, C.F. and Savi,
	R.},
  title = {Experiences gained from applying ISO/IEC 15504 to small software
	companies in Brazil},
  booktitle = {4th International SPICE Conference on Process Assessment and Improvement,
	Lisbon, Portugal},
  year = {2004},
  pages = {33--37},
  file = {Anacleto2004.PDF:literature/Anacleto2004.PDF:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@INPROCEEDINGS{Anda2007,
  author = {Bente Anda},
  title = {Assessment of Software System Evolvability},
  booktitle = {Proceedings of the Ninth International Workshop on Principles of
	Software Evolution (IWPSE'07)},
  year = {2007},
  pages = {71-74},
  address = {New York, NY, USA},
  organization = {ACM},
  abstract = {The evolvability, the ease of further development, of a software systems
	is difficult to assess, but may have large economic consequences.
	Many studies have investigated the relations between particular software
	metrics and effort on evolving individual classes, but little attention
	has been given to methods for assessing and measuring evolvability
	of complete software systems. This paper discusses such methods,
	and motivates that they should use a combination of structural code
	measures and expert assessments. This is exemplified in a case study
	assessing the evolvability of four functionally equivalent systems.
	The paper also gives with directions for future work on evolvability
	assessments.},
  doi = {10.1145/1294948.1294966},
  file = {:./literature/AssessmentSoftwareSystemEvolvability2007-p71-anda.pdf:PDF},
  keywords = {software system evolvability, evolvability assessment},
  owner = {Stephan},
  timestamp = {2009.03.30}
}

@TECHREPORT{Anderson1972,
  author = {James P. Anderson},
  title = {Computer Security Technology Planning Study},
  institution = {U.S. Air Force, Electronic Systems Division, Deputy for Command and
	Management Systems, HQ Electronic Systems Division (AFSC)},
  year = {1972},
  number = {ESD-TR-73-51},
  address = {L. G. Hanscom Field, Bedford, MA 01730 USA},
  month = {Oct.},
  abstract = {The results of a planning study for USAF computer security requirements
	are presented. The study recommends research and development urgently
	needed to provide secure information processing systems for command
	and control and support systems for the Air Force.},
  file = {:./literature/ande72a.pdf:PDF},
  keywords = {data processing, air force, computers, protection, military requirements,
	time sharing, command and control systems, computer hardware, computer
	systems, computer systems management and standards, security, reference
	monitoring},
  owner = {Stephan},
  timestamp = {2008.10.13},
  url = {http://nob.cs.ucdavis.edu/history/CD/ande72a.pdf}
}

@BOOK{Anderson2001,
  title = {Security Engineering: A Guide to Building Dependable Distributed
	Systems},
  publisher = {John Wiley \& Sons},
  year = {2001},
  author = {Ross J. Anderson},
  file = {:./literature/AndersonSecurityEngineering2001.pdf:PDF},
  owner = {Stephan},
  timestamp = {2010.10.29}
}

@ARTICLE{Anquetil2010,
  author = {Anquetil, N. and Kulesza, U. and Mitschke, R. and Moreira, A. and
	Royer, J.C. and Rummler, A. and Sousa, A.},
  title = {A model-driven traceability framework for software product lines},
  journal = {Software and Systems Modeling},
  year = {2010},
  volume = {9},
  pages = {427--451},
  number = {4},
  file = {Anquetil2010.pdf:literature/Anquetil2010.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.07.19}
}

@INPROCEEDINGS{Anton1998,
  author = {Ant{\'o}n, A.I. and Potts, C.},
  title = {The use of goals to surface requirements for evolving systems},
  booktitle = {Software Engineering, 1998. Proceedings of the 1998 International
	Conference on},
  year = {1998},
  pages = {157--166},
  organization = {IEEE},
  file = {Anton1998.pdf:literature/Anton1998.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.12.18}
}

@INPROCEEDINGS{Antoniol2000,
  author = {Antoniol, G. and Canfora, G. and Casazza, G. and De Lucia, A.},
  title = {Identifying the Starting Impact Set of a Maintenance Request: A Case
	Study},
  booktitle = {Proceedings of the Fourth European Conference on Software Maintenance
	and Reengineering},
  year = {2000},
  pages = {227-230},
  address = {Zurich, Switzerland},
  month = {February},
  file = {:./literature/Paper_101.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- identification of the starting impact set is a crucial part for
	all IA approaches
	
	- change request which cause IA often formulated in natural language
	
	- therefore hard to determine what is initially effected by a request
	
	
	Research Questions:
	
	- how to determine those parts of a system that are directly affected
	by a change request / change (starting impact set)
	
	
	Contribution:
	
	- IR method to trace a maintenance request to components which are
	initially affected by this request
	
	- method based on traceability links between source code and documentation
	
	
	Solution:
	
	- apply 2 IR techniques to score documents associated with the software
	
	* vector-space approach
	
	* probalistic approach
	
	- extract "meaningful" words from documents and try to match them
	with code entities / components
	
	- rank documents to retrieve only the relevant ones
	
	- whole process consists of 2 steps:
	
	* identify set of high-level documents
	
	* use documentation-2-code traceability links to identify source code
	components
	
	 -> intially affected components
	
	-> granularity of entities: not specified
	
	-> granularity of changes: maintenance request
	
	-> granularity of results: not specified
	
	
	Open Issues:
	
	- usual problem with lack of precision as soon as IR is involved},
  timestamp = {2011.02.24}
}

@ARTICLE{Antoniol2002,
  author = {Giuliano Antoniol and Gerardo Canfora and Gerardo Casazza and Andrea
	De Lucia and Ettore Merlo},
  title = {Recovering Traceability Links between Code and Documentation},
  journal = {IEEE Trans. Softw. Eng.},
  year = {2002},
  volume = {28},
  pages = {970-983},
  number = {10},
  month = {Oct},
  abstract = {Software system documentation is almost always expressed informally
	in natural language and free text. Examples include requirement specifications,
	design documents, manual pages, system development journals, error
	logs, and related maintenance reports. We propose a method based
	on information retrieval to recover traceability links between source
	code and free text documents. A premise of our work is that programmers
	use meaningful names for program items, such as functions, variables,
	types, classes, and methods. We believe that the application-domain
	knowledge that programmers process when writing the code is often
	captured by the mnemonics for identifiers; therefore, the analysis
	of these mnemonics can help to associate high-level concepts with
	program concepts and vice-versa. We apply both a probabilistic and
	a vector space information retrieval model in two case studies to
	trace C++ source code onto manual pages and Java code to functional
	requirements. We compare the results of applying the two models,
	discuss the benefits and limitations, and describe directions for
	improvements.},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/TSE.2002.1041053},
  file = {:./literature/01041053.pdf:PDF},
  issn = {0098-5589},
  keywords = {redocumentation, traceability, program comprehension, object orientation,
	information retrieval},
  owner = {Robert},
  publisher = {IEEE Press},
  timestamp = {2008.07.14}
}

@ARTICLE{Antoniol2001,
  author = {Antoniol, Guiliano and Caprile, B. and Potrich, A. and Tonella, Paolo},
  title = {Design-code traceability recovery: selecting the basic linkage properties},
  journal = {Science of Computer Programming},
  year = {2001},
  volume = {40},
  pages = {213-234},
  file = {:./literature/Paper_269.pdf:PDF},
  owner = {Steffen},
  timestamp = {2013.10.22}
}

@INPROCEEDINGS{Antoniol2005,
  author = {Antoniol, Giuliano and Rollo, Vincenzo Fabio and Venturi, Gabriele},
  title = {Detecting groups of co-changing files in {CVS} repositories},
  booktitle = {Proceedings of the Eighth International Workshop on Principles of
	Software Evolution (IWPSE'05)},
  year = {2005},
  pages = {23-32},
  address = {Lisbon, Portugal},
  month = {September},
  file = {:./literature/Paper_109.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- CVS system keep track of almost all changes done to software
	
	- co-changing files gathered from CVS contain non-trivial dependencies
	which are otherwise not to spot
	
	
	Research Questions:
	
	
	Contribution:
	
	- definition of co-change suitable for practise
	
	- new approach relying on dynamic time warping to detect co-changing
	files
	
	
	Solution:
	
	- basic steps of approach:
	
	* extract file histories from CVS, according to time window of interest
	
	 - start backwards with most recent version 
	
	 - increase time window by 1 evolution history in each step until
	all are covered 
	
	* use Dynamic Time Warping (DTW) to compute distances between pairs
	of histories
	
	 - DTW computes non-linear mapping of one "signal" to another by minizing
	the distance between them
	
	* use distance to group and filter similar evolution histories
	
	 - detect groups in windows
	
	 - trace groups among windows
	
	-> granularity of entities: files
	
	-> granularity of changes: change records from CVS (line-based)
	
	-> granularity of results: files
	
	
	==> same as [Bouktif2006]
	
	
	Open Issues:
	
	- usual problems of history-based approaches: time & order of commit
	as well as content of commit influence results},
  timestamp = {2011.04.01}
}

@INPROCEEDINGS{Apel2005,
  author = {Sven Apel and Thomas Leich and Marko Rosenmüller and Gunter Saake},
  title = {Combining Feature-Oriented and Aspect-Oriented Programming to Support
	Software Evolution},
  booktitle = {Proceedings of the 2nd ECOOP Workshop on Reflection, AOP and Meta-Data
	for Software Evolution (RAM-SE’05)},
  year = {2005},
  editor = {Walter Cazzola and Shigeru Chiba and Gunter Saake and Tom Tourwé},
  pages = {3-16},
  address = {Glasgow, UK},
  month = {July},
  publisher = {Fakultät für Informatik, Universität Magdeburg},
  abstract = {Starting from the advantages of using Feature-Oriented Programming
	(FOP) and program families to support software evolution, this paper
	discusses the drawbacks of current FOP techniques. In particular
	we address the insufficient crosscutting modularity that complicates
	software evolution. To overcome this tension we propose the integration
	of concepts of Aspect-Oriented Programming (AOP) into existing FOP
	solutions. As study object we utilize FeatureC++, a proprietary extension
	to C++ that supports FOP. After a short introduction to basic language
	features of FeatureC++, we summarize the problems regarding the crosscutting
	modularity. In doing so, we point to the strengths of AOP that can
	help. Thereupon, we introduce three approaches that combine FOP and
	AOP concepts: Multi Mixins, Aspectual Mixins, and Aspectual Mixin
	Layers. Furthermore, we discuss their benefits for software evolution.},
  citeseerurl = {http://citeseer.ist.psu.edu/734327.html},
  file = {:./literature/ECOOP-RAMSE2005.pdf:PDF},
  keywords = {FOP, feature oriented programming, AOP, aspect oriented programming,
	software evolution},
  owner = {Stephan},
  timestamp = {2008.07.10},
  url = {http://wwwiti.cs.uni-magdeburg.de/iti_db/fcc/publications/ECOOP-RAMSE2005.pdf}
}

@INPROCEEDINGS{Apiwattanapong2005,
  author = {Apiwattanapong, Taweesup and Orso, Alessandro and Harrold, Mary Jean},
  title = {Efficient and Precise Dynamic Impact Analysis Using Execute-After
	Sequences},
  booktitle = {Proceedings of the International Conference on Software Engineering
	(ICSE 2005)},
  year = {2005},
  pages = {432-441},
  address = {St. Louis, MO},
  month = {May},
  file = {:./literature/Paper_29.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- static IA is too conservative and identifies the whole system as
	effected
	
	- existing dynamic approaches (PathImpact and CoverageImpact) too
	expensive or inprecise
	
	
	Research Questions:
	
	- perform IA on dynamic software data such as execution data (exe.
	on operational profile, exe. of tests, program part exe.)
	
	- find approach for long-running programs which is more precise than
	CoverageImpact
	
	
	Contribution:
	
	- dynamic IA technique which is as precise and efficient as static
	IA
	
	- new algorithm collecting only required data
	
	
	Solution:
	
	- use traces like PathImpact but simplify them by removing method-returns,
	instead replace them with method-return-into-events
	
	* A calls B, B calls C, A calls C would result in (PathImpact)-trace:
	Aentry Bentry, Centry, Creturn, Breturn, Centry, Creturn, Areturn
	
	* replace with method-return-into-events: Aentry, Bentry, Centry,
	A*return, A*return, Centry, A*return, A*return
	
	- consider only first and last events for each method, called Execution-After-sequence
	
	- note timestamps in EA-sequences during program execution
	
	- perform IA on element F like the following:
	
	* get first timestamp for F
	
	* search for all methods whose last timestamp is >= the first timestamp
	of F ("all methods executed after F")
	
	= possible impacted methods
	
	-> granularity of entities: methods
	
	-> granularity of changes: changes to methods
	
	-> granularity of results: methods
	
	
	Open Issues:
	
	- increase granularity to the level of statements (not just method
	calls)},
  timestamp = {2011.02.02}
}

@ELECTRONIC{Appelton,
  author = {Brad Appelton},
  title = {Blog: Brad Appleton's ACME Blog; Categorie Traceability},
  howpublished = {http://bradapp.blogspot.com/search/label/Traceability},
  note = {last vitit 01/2012},
  owner = {elkeb},
  timestamp = {2012.01.04}
}

@ELECTRONIC{Appleton2005,
  author = {Brad Appleton},
  year = {2005},
  title = {Website: The Trouble with Tracing: Traceability Dissected},
  howpublished = {http://www.cmcrossroads.com/agile-scm/6685-the-trouble-with-tracing-traceability-dissected},
  note = {last visite 01.2012},
  url = {http://www.cmcrossroads.com/agile-scm/6685-the-trouble-with-tracing-traceability-dissected},
  owner = {elkeb},
  timestamp = {2012.01.04}
}

@ARTICLE{April2005,
  author = {April, Alain and Huffman Hayes, Jane and Abran, Alain and Dumke,
	Reiner},
  title = {Software Maintenance Maturity Model (SMMM): The software maintenance
	process model},
  journal = {Journal of Software Maintenance and Evolution: Research and Practice},
  year = {2005},
  volume = {17},
  pages = {197-223},
  number = {3},
  month = {May},
  abstract = {We address the assessment and improvement of the software maintenance
	function by proposing a maturity model for daily software maintenance
	activities: the Software Maintenance Maturity Model (SMmm). The software
	maintenance function suffers from a scarcity of management models
	to facilitate its evaluation, management, and continuous improvement.
	The SMmm addresses the unique activities of software maintenance
	while preserving a structure similar to that of the Capability Maturity
	Model integration (CMMi). It is designed to be used as a complement
	to that model. The SMmm is based on practitioners' experience, international
	standards, and the seminal literature on software maintenance. We
	present the model's purpose, scope, foundation, and architecture,
	followed by its initial validation.},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1002/smr.v17:3},
  file = {:./literature/April2005.pdf:PDF},
  issn = {1532-060X},
  keywords = {software maintenance, software maintenance maturity model, maintenance
	process, process improvement, process model, maturity model},
  owner = {Stephan},
  publisher = {John Wiley \& Sons, Inc.},
  timestamp = {2009.04.28}
}

@ARTICLE{Arisholm2004,
  author = {Arisholm, E. and Briand, L. C. and Foyen, A.},
  title = {Dynamic coupling measurement for object-oriented software},
  journal = {IEEE Transactions on Software Engineering},
  year = {2004},
  volume = {30},
  pages = {491-506},
  number = {8},
  file = {:./literature/Paper_172.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- many OO coupling metrics do not capture all aspects of OO like dynamic
	binding, dead code etc.
	
	- current coupling metrics do not consider dynamic information
	
	
	Research Questions:
	
	- how to use dynamic information to improve coupling measures
	
	
	Contribution:
	
	- new dynamic coupling measure for OO software
	
	- experiment, which suggest that dyn. coupling measures complement
	trad. static ones
	
	
	Solution:
	
	- gather coupling measures by measuring runtime object interactions
	
	- use a simple metamodel / datamodel for OO software, containing classes,
	methods and messages
	
	- monitor message exchanges and method invocations
	
	- define a set of 12 coupling measures based on rules
	
	-> granularity of entities: classes
	
	-> granularity of changes:
	
	-> granularity of results: classes
	
	
	Open Issues:
	
	- use developed tool and measures to detect dead code
	
	- use tool to gain understanding of software (which component does
	what?)uff},
  timestamp = {2011.07.26}
}

@CONFERENCE{Arkley2002,
  author = {Arkley, P. and Mason, P. and Riddle, S.},
  title = {Position Paper: Enabling Traceability},
  booktitle = {Proceedings of 1st International Workshop on Traceability in Emerging
	Forms of Software Engineering},
  year = {2002},
  pages = {61-65},
  file = {:./literature/ArkleyMasonRiddleEnablingTraceabilityFinal.pdf:PDF},
  owner = {Elke},
  review = {beschreibt auch Studie (Elke)},
  timestamp = {2011.06.01},
  url = {http://www.soi.city.ac.uk/~zisman/WSProgramme.html}
}

@INPROCEEDINGS{Arkley2006,
  author = {Arkley, P. and Riddle, S.},
  title = {Tailoring traceability information to business needs},
  booktitle = {Requirements Engineering, 14th IEEE International Conference},
  year = {2006},
  pages = {239--244},
  organization = {IEEE},
  file = {Arkley2006 - tailoring traceability information to business needs.pdf:literature//detep//Arkley2006 - tailoring traceability information to business needs.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.02.29}
}

@INPROCEEDINGS{Arkley2005,
  author = {Arkley, P. and Riddle, S.},
  title = {Overcoming the traceability benefit problem},
  booktitle = {Proceedings 13th IEEE International Conference on Requirements Engineering,
	2005},
  year = {2005},
  pages = {385-389},
  abstract = {To modify complex computer-based systems requires a detailed understanding
	of their functionality. Requirements traceability can help the engineer
	to gain that understanding, but several surveys have observed that
	traceability information is poorly recorded. We argue that the cause
	is the lack of direct perceived benefit to the main development process.
	As a consequence traceability information is incomplete, inaccurate
	and out-of-date. We propose a method of recording traceability information,
	a traceable development contract (TDC), as a means of reducing this
	problem by tackling the issue of an upstream functional development
	team imposing changes on a downstream development team. The contract
	makes the recording of traceability information beneficial to both
	development teams.},
  doi = {10.1109/RE.2005.49},
  file = {:./literature/Arkley2005.pdf:PDF},
  keywords = {functional development; requirements traceability; traceability benefit
	problem; traceability information recording; traceable development
	contract; software engineering; systems analysis;},
  owner = {Stephan},
  review = {Elke
	
	Paper beschreibt eine Praxisstudie!},
  timestamp = {2010.12.09}
}

@ARTICLE{Armbrust2008,
  author = {Armbrust, O. and Ebell, J. and Hammerschall, U. and M{\"u}nch, J.
	and Thoma, D.},
  title = {Experiences and results from tailoring and deploying a large process
	standard in a company},
  journal = {Software Process: Improvement and Practice},
  year = {2008},
  volume = {13},
  pages = {301--309},
  number = {4},
  file = {Armbrust2008.pdf:literature/Armbrust2008.pdf:PDF},
  keywords = {Test},
  owner = {patrickr},
  publisher = {Wiley Online Library},
  timestamp = {2012.07.20}
}

@BOOK{Arnold1993a,
  title = {Software Reengineering},
  publisher = {IEEE Computer Society Press},
  year = {1993},
  author = {Arnold, Robert S.},
  address = {Los Alamitos, CA, USA},
  owner = {Stephan},
  timestamp = {2010.11.19}
}

@INPROCEEDINGS{Arnold1993b,
  author = {Arnold, Robert S. and Bohner, Shawn A.},
  title = {Impact Analysis - Towards a Framework for Comparison},
  booktitle = {Proceedings of the Conference on Software Maintenance (CSM '93)},
  year = {1993},
  pages = {292-301},
  address = {Montreal, Que., Canada},
  month = {September},
  file = {:./literature/Paper_73.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- the term IA is used with many meanings
	
	- no structured classification of approaches available
	
	
	Research Questions:
	
	- how does an approach accomplish IA
	
	- how does an approch perform IA internally
	
	- how effective is an approach
	
	
	Contribution:
	
	- framework for classifying IA approaches
	
	- comparison and classification of 5 approches
	
	
	Solution:
	
	- evaluation framework consists of 3 parts:
	
	* IA Application: examins how the approch accomplishs IA
	
	 - explains what items might be affected
	
	 - suggested change strategies
	
	* IA Parts: examines nature of internal parts and methods used to
	perform IA
	
	 - what does the approach do
	
	 - how does it do...
	
	 - duties of involved tools and agents
	
	* IA Effectiveness: examines how well approaches accomplish goals
	of IA
	
	 - use different measurements to reason about effectiveness, e.g.
	ratio between:
	
	 * starting impact set (SIS)
	
	 * estimated impact set (EIS)
	
	 * actual impact set (AIS)
	
	- apply this categorization onto 5 IA approaches:
	
	* program slicing
	
	* generic manual cross referencing
	
	* traceability approach 
	
	* documenting system
	
	* control flow analyzer
	
	
	Open Issues:},
  timestamp = {2011.02.17}
}

@INPROCEEDINGS{Aryani2010,
  author = {Aryani, Amir and Peake, Ian D. and Hamilton, Margaret},
  title = {Domain-based change propagation analysis: An enterprise system case
	study},
  booktitle = {Proceedings of the IEEE International Conference on Software Maintenance
	(ICSM '10)},
  year = {2010},
  pages = {1-9},
  address = {Timisoara},
  month = {September},
  file = {:./literature/Paper_145.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- most IA approaches not applicable if no history and code available
	
	- technique must be developed which detects impacts based on domain
	information
	
	
	Research Questions:
	
	- how to accomplish IA based on domain information
	
	- how to enable domain experts to judge impact of change / cost of
	change without help of developers
	
	- is there a correlation between evolutionary (history-based) and
	conceptual coupling
	
	
	Contribution:
	
	- IA approach relying on domain-analysis
	
	- compared results to history-mining
	
	
	Solution:
	
	- use conceptual coupling to detect related elements
	
	- predict change propagation based on detected couplings
	
	- distinguish between:
	
	* domain variables
	
	* domain functions
	
	* user interface components
	
	- information about these 3 entities derived from users manual and
	expert knowlegde
	
	- information stored in dependency matrix (dependency graph)
	
	- extract information about groups of dependent entities from matrix
	
	- assign probabilities to discovered groups of dependent entities
	
	-> granularity of entities: domain variables, domain functions, user
	interface components
	
	-> granularity of changes: no details given
	
	-> granularity of results: domain variables, domain functions, user
	interface components
	
	= program dependencies + probabilistic model
	
	
	Open Issues:
	
	- conduct larger case study
	
	- include information mined from bug reports and support records},
  timestamp = {2011.04.04}
}

@INPROCEEDINGS{Aryani2009,
  author = {Aryani, Amir and Peake, Ian D. and Hamilton, Margaret and Schmidt,
	Heinz},
  title = {Change Propagation Analysis Using Domain Information},
  booktitle = {Australian Software Engineering Conference 2009},
  year = {2009},
  pages = {34-43},
  address = {Gold Coast, Australia},
  month = {April},
  file = {:./literature/Paper_125.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- current IA techniques rely on source code, or documented source
	code and / or architectural representations
	
	- this data is not available for all software systems
	
	
	Research Questions:
	
	- how can domain knowlegde be of use for impact analysis / change
	prediction without requiring source code / architecure
	
	
	Contribution:
	
	- new methodology for IA based on information visible and understandable
	to domain experts
	
	- method build upon connection graph of conceptual relationships between
	user interface components
	
	- approach depends on visibility of change for domain user
	
	
	Solution:
	
	- proposed approach distinguishs between 2 types of relations:
	
	* relations resulting from domain functionality
	
	* relations resulting from architectural dependencies
	
	- provide 5 definitions:
	
	* domain variable: data with clear meaning at domain level (e.g. a
	date)
	
	* domain functionality: function the system provides to its users
	
	* user interface component (UIC): contains at least 1 domain functionality
	
	* architectural component: unit of source code or library
	
	* architectural dependencies: reference between 2 architectural components
	
	- propose relies on analyses of information visible to domain users
	to capture logical relationships
	
	- build a graph of dependencies
	
	- weight each dependency and only select relevant dependencies (threshold)
	
	 * results in weighted dependency graph
	
	-> granularity of entities: components (in component-based architecture)
	
	-> granularity of changes: no details given
	
	-> granularity of results: components (in component-based architecture)
	
	
	Open Issues:
	
	- resulting weighted graph even for small case study too dense
	
	- not yet implemented and only tested with small case study
	
	- authors of paper took role as domain expert in study},
  timestamp = {2011.04.01}
}

@INPROCEEDINGS{Aschauer2009,
  author = {Aschauer, T. and Dauenhauer, G. and Pree, W.},
  title = {Multi-level Modeling for Industrial Automation Systems},
  booktitle = {35th Euromicro Conference on Software Engineering and Advanced Applications
	(SEAA '09)},
  year = {2009},
  pages = {490-496},
  abstract = {Model-driven engineering of software intensive systems requires adequate
	means for describing their essential properties. For the domain of
	testbed automation systems, conventional modeling formalisms fall
	short due to the inadequacy of a fixed meta-level hierarchy. In this
	paper we identify the core problems by examining real-world examples.
	As a solution, we propose using a unification of classes and objects,
	known as clabjects. We propose extensions to the basic clabject notion
	for handling connector inheritance and instantiation, which are essential
	for bridging the gap between theoretical foundations and industrial
	applications.},
  doi = {10.1109/SEAA.2009.46},
  file = {:./literature/Multi-Level_Modeling_for_Industrial_Automation_Systems.pdf:PDF},
  keywords = {multi-level modeling; automation systems; clabjects},
  owner = {gerlach},
  timestamp = {2013.05.14},
  url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true&arnumber=5350019}
}

@INPROCEEDINGS{Ash1994,
  author = {Ash, Dan and Alderete, John and Oman, Paul W. and Lowther, Bruce},
  title = {Using Software Maintainability Models to Track Code Health},
  booktitle = {Proceedings of the International Conference on Software Maintenance},
  year = {1994},
  series = {ICSM '94},
  pages = {154--160},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid = {655707},
  file = {:/literature/RegressionTesting/Using Software Maintainability Models to Track Code Health.pdf:PDF},
  isbn = {0-8186-6330-8},
  keywords = {Maintainability, NotRelevant},
  numpages = {7},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=645543.655707}
}

@INPROCEEDINGS{Askari2006,
  author = {Askari, Mina and Holt, Ric},
  title = {Information Theoretic Evaluation of Change Prediction Models for
	Large-Scale Software},
  booktitle = {Proceedings of the 3rd International Workshop on Mining Software
	Repositories (MSR’06)},
  year = {2006},
  pages = {126-132},
  address = {New York},
  file = {:./literature/Paper_50.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- data in software repositories follows a Zipf distribution (http://de.wikipedia.org/wiki/Zipf-Verteilung)
	
	
	Research Questions:
	
	- how much information of repositories is of use and how to extract
	them
	
	- how to predict bugs and changes from extracted data
	
	
	Contribution:
	
	- 3 probalistic models to predict changes:
	
	* Maximum Likelihood Estimation (MLE)
	
	* Reflexive Exponential Decay (RED)
	
	* RED-Co-Change
	
	- evaluation of all 3 models
	
	
	Solution:
	
	- obtain data from CVS logs
	
	- count number of modifications for each file and sort them into a
	list (can access "rank" of a file)
	
	- create a sequence of file changes from that data (use this sequence
	for prediction)
	
	- Most Likely Estimation (MLE) Model:
	
	* count the number of occurrences of a file "Count(f)" to compute
	the probality P(f) = Count(f) / N
	
	* improved formula P(f) = Count(f)+1/ N + d (aka Laplace estimation)
	
	- Reflexive Exponential Decay (RED):
	
	* if a change occured, more changes are likely
	
	* however, this effect decreases periodically with time if no change
	happens (sort of half life measure)
	
	- RED-Co-Change (REDCC)
	
	* improved RED model
	
	* update probability not just in changed files, also for co-changed
	files likewise (co-change = changed together)
	
	-> granularity of entities: files
	
	-> granularity of changes: atomic change sets
	
	-> granularity of results: files
	
	
	Open Issues:},
  timestamp = {2011.02.09}
}

@INPROCEEDINGS{Asuncion2007,
  author = {Asuncion, H.U. and Fran{\c{c}}ois, F. and Taylor, R.N.},
  title = {An end-to-end industrial software traceability tool},
  booktitle = {Proceedings of the the 6th joint meeting of the European software
	engineering conference and the ACM SIGSOFT symposium on The foundations
	of software engineering},
  year = {2007},
  pages = {115--124},
  organization = {ACM},
  file = {Asuncion2007 - An end-to-end industrial software traceability tool.pdf:literature/Asuncion2007 - An end-to-end industrial software traceability tool.pdf:PDF},
  owner = {tobiask},
  timestamp = {2012.03.05}
}

@TECHREPORT{Atkinson2003,
  author = {Colin Atkinson and Holger Bär and Joachim Bayer and Christian Bunse
	and Jean-Francois Girard and Hans-Gerhard Gross and Stefan Kettermann
	and Ronny Kolb and Thomas Kühne and Tim Romberg and Olaf Seng and
	Peter Sody and Enno Tolzmann},
  title = {Handbuch zur komponentenbasierten Softwareentwicklung},
  institution = {Fraunhofer IESE und FZI},
  year = {2003},
  month = {Jan},
  file = {:./literature/cbse_handbuch.pdf:PDF},
  keywords = {komponentenbasierte Entwicklung, Softwarearchitektur, Wiederverwendung,
	ADD, KobrA},
  owner = {Stephan},
  timestamp = {2009.04.02},
  url = {http://app2web.fzi.de/themen/ap4/cbse_handbuch.pdf}
}

@INPROCEEDINGS{Avgeriou2005,
  author = {Paris Avgeriou and Uwe Zdun},
  title = {Architectural patterns revisited -- a pattern language},
  booktitle = {Proceedings 10th European Conference on Pattern Languages of Programs
	(EuroPlop 2005), Irsee},
  year = {2005},
  pages = {1-39},
  abstract = {Architectural patterns are a key concept in the field of software
	architecture: they offer well-established solutions to architectural
	problems, help to document the architectural design decisions, facilitate
	communication between stakeholders through a common vo- cabulary,
	and describe the quality attributes of a software system as forces.
	Regrettably, finding and applying the appropriate architectural patterns
	in practice still remains largely ad-hoc and unsystematic. This is
	due to the lack of consensus in the community with respect to the
	“philosophy” and granularity of architectural patterns, as well as
	the lack of a coherent pattern language. In this paper we attempt
	to establish common ground in the architectural patterns community
	by proposing a pattern language that acts as a super- set of the
	existing architectural pattern collections and categorizations. This
	language is particularly focused on establishing the relationships
	between the patterns and performs a categorization based on the concept
	of “architectural views”.},
  file = {:./literature/Avgeriou2005.pdf:PDF},
  keywords = {architectural patterns, design patterns, patterns language},
  owner = {Stephan},
  timestamp = {2009.11.27}
}

@INPROCEEDINGS{Ayala2005,
  author = {Claudia P. Ayala and Carlos Cares and Juan P. Carvallo and Gemma
	Grau and Mariela Haya and Guadalupe Salazar and Xavier Franch and
	Enric Mayol and Carme Quer},
  title = {A Comparative Analysis of i*-Based Agent-Oriented Modeling Languages},
  booktitle = {Proceedings of the International Workshop on Agent-Oriented Software
	Development Methodology (AOSDM'05) at the 7th International Conference
	on Software Engineering and Knowledge Engineering (SEKE'05)},
  year = {2005},
  pages = {43-50},
  publisher = {KSI Press},
  abstract = {Agent-oriented models are frequently used in disciplines such as requirements
	engineering and organizational process modelling. i * is currently
	one of the most widespread notations used for this purpose. Due to
	its strategic nature, instead of a single definition, there exist
	several versions and variants, often not totally defined and even
	contradictory. In this paper we present a comparative study of the
	three most widespread i* variants: Eric Yu’s seminal proposal, the
	Goal-oriented Requirement Language (GRL) and the language used in
	the TROPOS method. Next, we propose a generic conceptual model to
	be used as reference framework of these three variants and we show
	its use for generating specific models for the three mentioned variants,
	as well as for other existing proposals.},
  file = {:./literature/AOSDM'05-ComparativeAnalysis.pdf:PDF},
  keywords = {i*, GRL, TROPOS, goal-oriented modeling, non-functional requirements,
	agent-oriented modeling},
  owner = {Stephan},
  review = {compares the i* variants original i*, GRL and TROPOS},
  timestamp = {2009.03.25},
  url = {http://www.ideaciona.com/PhD/publications/AOSDM%2705-ComparativeAnalysis.pdf}
}

@INPROCEEDINGS{Bezivin2004a,
  author = {B\'{e}zivin, Jean and Jouault, Fr\'{e}d\'{e}ric and Valduriez, Patrick},
  title = {First Experiments with a ModelWeaver},
  booktitle = {Proceedings of the OOPSLA and GPCE Workshop},
  year = {2004},
  address = {Vancouver, Canada},
  file = {:./literature/Paper_238.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.05.16}
}

@INPROCEEDINGS{Bezivin2004b,
  author = {B\'{e}zivin, Jean and Jouault, Fr\'{e}d\'{e}ric and Valduriez, Patrick},
  title = {On the Need for Megamodels},
  booktitle = {Proceedings of the OOPSLA and GPCE Workshop},
  year = {2004},
  address = {Vancouver, Canada},
  file = {:./literature/Paper_237.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.05.16}
}

@BOOK{Babar2009,
  title = {Software Architecture Knowledge Management},
  publisher = {Springer Science \& Business Media},
  year = {2009},
  author = {Babar, M.A.},
  file = {:./literature/Software_Architecture_Knowledge_Management_barbar2009.pdf:PDF},
  isbn = {9783642023750},
  owner = {Sebastian},
  timestamp = {2013.07.26},
  url = {http://books.google.de/books?id=KddoEVXgkAAC}
}

@ARTICLE{Baccarini1996,
  author = {Baccarini, D.},
  title = {The concept of project complexity—a review},
  journal = {International Journal of Project Management},
  year = {1996},
  volume = {14},
  pages = {201--204},
  number = {4},
  file = {Baccarini1996.pdf:literature/Baccarini1996.pdf:PDF},
  keywords = {Project complexity},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.17}
}

@TECHREPORT{Bachmann2003,
  author = {Felix Bachmann and Len Bass and Mark Klein},
  title = {Deriving Architectural Tactics: A Step Toward Methodical Architectural
	Design},
  institution = {CMU/SEI},
  year = {2003},
  number = {CMU/SEI-2003-TR-004},
  month = {Mar},
  abstract = {This is one of several reports that provide the current status on
	the work being done by the Software Engineering Institute (SEISM)
	to understand the relationship between quality requirements and architectural
	design. The ultimate objective of this work is to provide analysis-based
	guidance to designers so that the quality attributes of generated
	designs are more predictable and better understood.
	
	Currently, four distinct problems must be solved to achieve that objective:
	(1) the precise specification of quality attribute requirements,
	(2) the enumeration of architectural decisions that can be used to
	achieve desired quality attribute requirements, (3) a means of coupling
	one quality attribute requirement to the relevant architectural decisions,
	and (4) a means of composing the relevant architectural decisions
	into a design. Embodying the solutions to these four problems into
	a design method that is sensitive to business priorities is an additional
	problem. This report deals with the third problem—coupling one quality
	attribute requirement to architectural decisions that achieve it.
	
	This report provides initial evidence that there is, in fact, a systematic
	relationship between general scenarios, concrete scenarios, architectural
	tactics, and design fragments. It examines, in detail, two concrete
	scenarios—one for performance and one for modifiability—and describes
	how to move from each scenario, through tactics, to design fragments
	that satisfy the scenario.},
  file = {:./literature/03tr004.pdf:PDF},
  keywords = {architectural design, quality requirement, architectural decisions,
	performance, modifiability},
  owner = {Stephan},
  review = {System-specific quality attribute requirements—called concrete scenarios—are
	instances of general scenarios
	
	
	architectural tactic introduced as characteristic of architectural
	decision to achieve a quality attribute
	
	
	in this report derivation of a set of architectural tactics (further
	a set of design fragments) for a concrete scenario
	
	
	concrete scenario examples examined: performance and modifiability},
  timestamp = {2008.04.14},
  url = {http://www.sei.cmu.edu/pub/documents/03.reports/pdf/03tr004.pdf}
}

@ARTICLE{Bachmann2005,
  author = {Bachmann, F. and Bass, L. and Klein, M. and Shelton, C.},
  title = {Designing software architectures to achieve quality attribute requirements},
  journal = {IEE Proceedings Software},
  year = {2005},
  volume = {152},
  pages = { 153-165},
  number = {4},
  month = {Aug.},
  abstract = {In order to have a software architecture design method that achieves
	quality attribute requirements several aspects of the method must
	be in place. First there must be some way to specify quality attribute
	requirements so that it can be determined whether the designed architecture
	can achieve them. Secondly, there must be some way for modularising
	the knowledge associated with quality attributes so that the design
	method does not need to know how to reason about all of the multiplicity
	of quality attributes that exist. Finally, there must be some way
	for managing the interactions among the quality attributes so that
	either the requirements can be satisfied or the ones that cannot
	be satisfied are identified. The authors describe a structure called
	a 'reasoning framework' as a modularisation of quality attribute
	knowledge. The requirements that the architecture must satisfy are
	specified as concrete quality attribute scenarios. Each reasoning
	framework provides mechanisms that will transform the architecture
	with respect to a given quality attribute theory. Within a reasoning
	framework, the authors distinguish between an architectural model
	and a quality attribute model and characterise the actions that a
	reasoning framework undertakes as basic architectural transformations.
	Finally, the process of identifying interactions among reasoning
	frameworks is begun so that conflicting requirements can be managed.
	The use of reasoning frameworks is situated inside an existing architectural
	design method so that a useful method exists while the open issues
	of designing to achieve quality attribute requirements are resolved.},
  doi = {10.1049/ip-sen:20045037},
  file = {:./literature/Bachmann2005.pdf:PDF},
  issn = {1462-5970},
  keywords = { formal specification, software architecture, software quality quality
	attribute knowledge, quality attribute requirements, reasoning framework
	interaction, software architectural design method},
  owner = {Stephan},
  review = {detailed description how tactics are used for architectural transformations
	concerning performance and modifiability},
  timestamp = {2009.11.27}
}

@TECHREPORT{Bachmann2007,
  author = {Bachmann, F. and Bass, L. and Nord, R.},
  title = {Modifiability Tactics},
  institution = {CMU/SEI},
  year = {2007},
  number = {CMU/SEI-2007-TR-002},
  month = {September},
  abstract = {An architectural tactic is a design decision that affects how well
	a software architecture addresses a particular quality attribute.
	This report describes how tactics are based on the parameters of
	quality attribute models. Tactics provide an architectural means
	of adjusting those parameters, which, in turn, can improve the quality-attribute-specific
	behavior of the resulting system.
	
	This report justifies the tactics for modifiability, using established
	concepts of coupling, cohesion, and cost motivations as the means
	of identifying parameters of interest. Various tactics are then described
	based on their ability to control these parameters. The report also
	describes a standard set of architectural patterns and their variants
	in terms of the use of these tactics.},
  file = {:./literature/Bachmann2007.pdf:PDF},
  keywords = {modifiability, architectural tactics, architectural patterns},
  owner = {Stephan},
  timestamp = {2009.11.27},
  url = {http://www.dia.uniroma3.it/~cabibbo/asw/altrui/07tr002-modifiability.pdf}
}

@INPROCEEDINGS{Badri2005,
  author = {Badri, L. and Badri, M. and St-Yves, D.},
  title = {Supporting predictive change impact analysis: a control call graph
	based technique},
  booktitle = {Proceedings of the 12th Asia-Pacific Conference on Software Engineering
	(APSEC '05)},
  year = {2005},
  pages = {9},
  month = {December},
  file = {:./literature/Paper_110.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- IA important part of software maintenance
	
	- trad. IA methods based on call graphs lack required precision
	
	
	Research Questions:
	
	- how to improve call-graph based IA approaches to increase precision
	while keeping costs for performing IA low
	
	
	Contribution:
	
	- new static technique for IA combining call graphs and control flow
	information (control call graphs)
	
	. method generates control flow paths to predict impacted entities
	
	
	Solution:
	
	- new static IA approach CCGImpact 
	
	- combines static call graphs with static control flow
	
	- method captures control flow between method calls to increase precision
	of prediction
	
	* gain information about the order of calls and exluded calls
	
	- method comprised of three steps:#
	
	* analysis of source code and construction of CCG
	
	 - ignore all statements and instructions which do not lead to a method-call
	
	* construct compacted sequences
	
	 - removes infeasible paths
	
	 - adds sequence information to the control call graphs
	
	* change prediction
	
	-> granularity of artifacts: methods
	
	-> granularity of changes: changes to methods
	
	-> granularity of results: affected methods
	
	
	Open Issues:
	
	- adopt proposed method to OO specific software
	
	- approach not tested with OO software (tested with trad. procedural
	programs)},
  timestamp = {2011.03.14}
}

@INPROCEEDINGS{Bagheri2007a,
  author = {Bagheri, Hamid},
  title = {Injecting security as aspectable NFR into Software Architecture},
  booktitle = {Asia-Pacific Software Engineering Conference, APSEC 2007},
  year = {2007},
  pages = {310-317},
  month = {Dec.},
  abstract = {Complexity of the software development process is often increased
	by actuality of crosscutting concerns in software requirements; moreover,
	Software security as a particular non-functional requirement of software
	systems is often addressed late in the software development process.
	Modeling and analyzing of these concerns and especially security
	in the software architecture facilitate detecting architectural vulnerabilities,
	decrease costs of the software maintenance, and reduce finding tangled
	and complex components in the ultimate design. Aspect oriented ADLs
	have emerged to overcome this problem; however, imposing radical
	changes to existing architectural modeling methods is not easily
	acceptable by architects. In this paper, we present a method to enhance
	conventional software architecture description languages through
	utilization of aspect features with special focuses on security.
	To achieve the goal, aspectable NFRs have been clarified; then, for
	their description in the software architecture, an extension to xADL
	2.0 [5] has been proposed; finally, we illustrate this material along
	with a case study.},
  doi = {10.1109/APSEC.2007.65},
  file = {:./literature/04425869.pdf:PDF},
  issn = {1530-1362},
  keywords = {aspect oriented, non-functional requirements, security, software architecture,
	ADL},
  owner = {Stephan},
  review = {presentation of the extended architectural modeling language xADL
	2.0 for aspectable NFRs
	
	
	acpectable NFR:
	
	- some dimensions of it potentially replicated among architectural
	elements
	
	- can be satisfied by addition of crosscutting functionality to the
	system
	
	
	modifiability and testability are internal quality attributes -> not
	aspectable
	
	
	performance crosscuts whole system but not achieved in isolation,
	instead through trade-offs between availability, security, modifiability
	-> not aspectable
	
	
	but security aspectable NFR
	
	
	addition of one aspectual component not sufficient (or not allowed)
	with respect to different architectural layers
	
	-> introduction of aspectual hyper-layer
	
	-> acpectual components of aspectual hyper-layer weaved into base
	architecture
	
	
	aspectual component
	
	- can be considered as library of one primary NFR's methods
	
	- packaging of methods corresponding to one NFR
	
	-> subcomponents for methods of dimensions of the NFR
	
	- a weaver for each component -> defined in XML
	
	
	- further description of XML specification for weaving},
  timestamp = {2008.04.21}
}

@INPROCEEDINGS{Bagheri2007,
  author = {Bagheri, Hamid and Mirian-Hosseinabadi, Seyed-Hassan and Esfahani,
	Hesam Chiniforooshan},
  title = {An Aspect Enhanced Method of NFR Modeling in Software Architecture},
  booktitle = {10th International Conference on Information Technology, (ICIT 2007)},
  year = {2007},
  pages = {240-242},
  month = {Dec.},
  abstract = {Existence of crosscutting concerns in software requirements often
	intensifies complexity of software development process. Modeling
	and analyzing of these concerns in the software architecture decrease
	possibility of finding tangled and complex components in the ultimate
	design. Aspect oriented ADLs have emerged to overcome this problem;
	however, imposing radical changes to existing architectural modeling
	methods is not easily acceptable by architects. In this paper, we
	present a method to enhance conventional software architecture description
	languages through utilization of aspect features with special focuses
	on non-functional requirements (NFRs).},
  doi = {10.1109/ICOIT.2007.4418305},
  file = {:./literature/04418305.pdf:PDF},
  keywords = {aspect oriented, method, NFR, non-functional requirements, software
	architecture},
  owner = {Stephan},
  review = {extension of xADL 2.0 proposed for NFR aspects
	
	
	focused on achieving higher quality for internal quality attributes
	modifiability and testability (as not "aspectable NFRs"
	
	- cannot be explicitly replicated by architectural elements
	
	- there are also no mechanisms for performance that can be extracted
	from architectural components in a separate component
	
	
	- for usability there are strategies (like help on user demand) which
	can be replicated in many components -> increase complexity of design
	(?)
	
	
	- logging for security purpose -> crosscutting
	
	
	- aspectual hyper-layer for "aspectual components" on top of basic
	architecture model
	
	-> enhancement for supporting aspectual components (indiependent of
	architectural styles)
	
	
	aspectual component:
	
	- responsible for encapsulation of a crosscutting NFR
	
	- associated weavers responsible for mapping methods of NFR to underlying
	architecture model
	
	- "library" of one primary NFR's methods
	
	
	xADL 2.0:
	
	- extensible, XML based, and modular architecture description language
	
	- core: component, connector, and configuration
	
	-> extended by "AspectWeaver.xsd"},
  timestamp = {2008.04.21}
}

@ARTICLE{Bakker2010,
  author = {Bakker, R.M.},
  title = {Taking stock of temporary organizational forms: A systematic review
	and research agenda},
  journal = {International Journal of Management Reviews},
  year = {2010},
  volume = {12},
  pages = {466--486},
  number = {4},
  file = {Bakker2010.pdf:literature/Bakker2010.pdf:PDF},
  owner = {patrickr},
  publisher = {Wiley Online Library},
  timestamp = {2012.10.19}
}

@ARTICLE{Bakker2011,
  author = {Bakker, R.M. and Knoben, J. and De Vries, N. and Oerlemans, L.A.G.},
  title = {The nature and prevalence of inter-organizational project ventures:
	Evidence from a large scale field study in the Netherlands 2006--2009},
  journal = {International Journal of Project Management},
  year = {2011},
  volume = {29},
  pages = {781--794},
  number = {6},
  file = {Bakker2011.pdf:literature/Bakker2011.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.18}
}

@INPROCEEDINGS{Balasubramaniam2007,
  author = {Balasubramaniam, D. and Morrison, R. and Greenwood, R.M. and Warboys,
	B.},
  title = {Flexible Software Development: From Software Architecture to Process},
  booktitle = {Software Architecture, 2007. WICSA'07. The Working IEEE/IFIP Conference
	on},
  year = {2007},
  pages = {14--14},
  organization = {IEEE},
  file = {Balasubramaniam2007.pdf:literature/Balasubramaniam2007.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.23}
}

@INPROCEEDINGS{Baldassarre2002,
  author = {Baldassarre, M.T. and Caivano, D. and Visaggio, C.A. and Visaggio,
	G.},
  title = {ProMisE: A framework for process models customization to the operative
	context},
  booktitle = {Empirical Software Engineering, 2002. Proceedings. 2002 International
	Symposium n},
  year = {2002},
  pages = {103--110},
  organization = {IEEE},
  file = {Baldassarre2002.pdf:literature/Baldassarre2002.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.23}
}

@BOOK{Baldwin2000,
  title = {Design Rules: The Power of Modularity},
  publisher = {MIT Press},
  year = {2000},
  author = {Baldwin, Carliss Y. and Clark, Kim B.},
  address = {Cambridge, MA, USA},
  file = {:./literature/ModularOperators.pdf:PDF},
  keywords = {modularity, modular operators},
  owner = {Stephan},
  timestamp = {2011.01.14}
}

@BOOK{Balzert2000,
  title = {Objecktorientierung in 7 Tagen: Vom UML-Modell zur fertigen Web Anwendung},
  publisher = {Lehrbücher der Informatik, Spektrum Akademischer Verlag},
  year = {2000},
  author = {Heide Balzert},
  keywords = {OOA, OOD, Objektorientierung, UML, Electronic Commerce},
  owner = {Robert},
  timestamp = {2006.09.18}
}

@ARTICLE{Banerjee2005,
  author = {Somo Banerjee and Chris A. Mattmann and Nenad Medvidovic and Leana
	Golubchik},
  title = {Leveraging architectural models to inject trust into software systems},
  journal = {SIGSOFT Softw. Eng. Notes},
  year = {2005},
  volume = {30},
  pages = {1-7},
  number = {4},
  abstract = {Existing software systems have become increasingly durable and their
	lifetimes have significantly lengthened. They are increasingly distributed
	and decentralized. Our dependence on them has grown tremendously.
	As such, the issues of trustworthiness and security have become prime
	concerns in designing, constructing, and evolving software systems.
	However, the exact meanings of these concepts are not universally
	agreed upon, nor is their role in the different phases of the software
	development lifecycle. In this paper, we argue that trustworthiness
	is a more broadly encompassing term than security, and that the two
	are often interdependent. We then identify a set of dimensions of
	trustworthiness. Finally, we analyze how the key elements of a software
	system's architecture can be leveraged in support of those trustworthiness
	dimensions. Our ultimate goal is to apply these ideas in the context
	of a concrete software architecture project. The goal of this paper
	is more modest: to understand the problem area and its relation to
	software architecture.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1082983.1083213},
  file = {:./literature/Banerjee2005-ArchitecturalModelsToInjectTrust.pdf:PDF},
  issn = {0163-5948},
  keywords = {software architecture, thrustworthiness, security, availability, reliability,
	fault-tolerance, survivability},
  owner = {Stephan},
  publisher = {ACM},
  review = {thrustwothiness broader scope than more used term security
	
	- must be considered in software development early
	
	
	dimensions of thrustworthiness
	
	-> security, reliability, availability, fault-tolerance, survivability
	
	
	security -> 7 dimensions [Bashir et al.]
	
	- authentication
	
	- access control
	
	- audit trail
	
	- confidentiality
	
	- integrity
	
	- availability
	
	- non-repudiation
	
	security in SWA -> UMLSec
	
	
	reliability sub-dimensions
	
	- error prevention
	
	- failure detection and removal
	
	- measurements to maximize reliability -> reliability models
	
	reliability models:
	
	- state-based
	
	- path-based
	
	- additive models
	
	
	availability -> 6 categories
	
	- caching
	
	- hoarding
	
	- queueing RPCs
	
	- deployment and redeployment
	
	- replication and replica reconciliation
	
	- code mobility
	
	
	fault-tolerance
	
	types of faults:
	
	- in system's environment
	
	- in components
	
	- in connectors
	
	- component connector mismatches
	
	
	survivability
	
	- ability to resist, recognize, recover from, adapt to threats
	
	3 kinds of threats:
	
	- attacks
	
	- failures
	
	- accidents},
  timestamp = {2008.07.18}
}

@TECHREPORT{Barbacci1995,
  author = {Mario Barbacci and Mark H. Klein and Thomas A. Longstaff and Charles
	B. Weinstock},
  title = {Quality Attributes},
  institution = {CMU/SEI},
  year = {1995},
  month = {Dec},
  abstract = {Computer systems are used in many critical applications where a failure
	can have serious consequences (loss of lives or property). Developing
	systematic ways to relate the software quality attributes of a system
	to the system's architecture provides a sound basis for making objective
	decisions about design tradeoffs and enables engineers to make reasonably
	accurate predictions about a system's attributes that are free from
	bias and hidden assumptions. The ultimate goal is the ability to
	quantitatively evaluate and trade off multiple software quality attributes
	to arrive at a better overall system. The purpose of this report
	is to take a small step in the direction of developing a unifying
	approach for reasoning about multiple software quality attributes.
	In this report, we define software quality, introduce a generic taxonomy
	of attributes, discuss the connections between the attributes, and
	discuss future work leading to an attribute- based methodology for
	evaluating software architectures.},
  file = {:./literature/tr021.95.pdf:PDF},
  keywords = {quality attributes, software engineering, quality assurance, computer
	program reliability, methodology, predictions, computer architecture,
	trade off analysis, taxonomy},
  owner = {Stephan},
  review = {description of the quality attributes performance, dependability,
	security and safety including trade-offs
	
	
	described taxonomy for quality attributes
	
	------------------------------------------------
	
	concerns: parameters by which the attributes of a system are judged,
	specified and measured
	
	attribut-specific factors: properties of the system and its environment
	that have an impact on the concerns
	
	methods: how to address the concerns
	
	
	performance
	
	---------------
	
	- refers to responsiveness (time required to respond to a specific
	event or the number of events processed in a given time)
	
	- not equal to speed
	
	- degree to which a system or component accomplishes its designated
	functions within given constraints, such as speed, accuracy, or memory
	usage (IEEE 610.12)
	
	
	concerns:
	
	- latency (response window, precedence, jitter, criticality)
	
	- throughput (observation interval, processing rate, crititcality)
	
	- capacity (utilization, schedulable utilization, spare capacity)
	
	- modes (reduced capacity or overload)
	
	
	factors:
	
	- demand (arrival pattern, execution time) - how much is a resource
	needed
	
	- system (type of resource, software services, resource allocation)
	
	
	methods:
	
	- synthesis
	
	- analysis (scheduling theory, queuing theory, formal methods)
	
	
	dependability
	
	----------------
	
	property of a computer system such that reliance can justifiably be
	placed on the services it delivers
	
	
	attributes (concerns):
	
	- availability
	
	- reliability
	
	- safety
	
	- confidentiality
	
	- integrity
	
	- maintainability
	
	
	impairments (factors):
	
	- faults (adjudged or hypothesized cause of an error)
	
	- errors (a system state that is liable to lead to a failure if not
	corrected)
	
	- failures (a system fails when its behaviour differs from that which
	was intended)
	
	
	means (methods):
	
	- fault prevention
	
	- fault tolerence (error processing [detection, diagnosis, recovery],
	fault treatment [diagnosis, passivation, reconfiguration])
	
	- fault removal (verification [static, dynamic], diagnosis, correction)
	
	- fault forecasting (qualitative forecasting, quantitative forecasting)
	
	
	security
	
	---------
	
	depends on the context (government and military, banking and finance,
	academic and scientific)
	
	
	protection of data against disclosure, modification, or destruction
	
	protection from unauthorized use of resources
	
	
	concerns:
	
	- confidentiality
	
	- integrity
	
	- availability
	
	
	factors:
	
	- interface (authentication, encryption, auditing and analysis)
	
	- internal (access control, auditing and logging, kernelization)
	
	
	methods:
	
	- synthesis (process models, security models, secure protocols)
	
	- analysis (formal methods, penetration analysis, covert-channel analysis)
	
	
	safety
	
	-------
	
	property of a system such that reliance can justifiably be placed
	in the absence of accidents
	
	
	concerns:
	
	- interaction complexity (linear interaction, complex interaction)
	- understandability, predictability
	
	- coupling strength (tight or loose coupling) - loose coupling to
	prevent cascading of failures
	
	
	factors:
	
	- hazard (a condition that can lead to a mishap)
	
	- mishap (unplanned events that result in death, injury, illness,
	damage, or loss of property)
	
	
	methods:
	
	- hazard identification (brainstorming, consensus building, hazard
	and operability analysis)
	
	- hazard analysis (fault tree analysis, event tree analysis, failure
	modes and effects analysis)
	
	- implementation methodologies (formal methods, transformation, version
	management)
	
	- implementation mechanisms (lockins, lockouts, interlocks)
	
	
	relationship
	
	--------------
	
	security depends on reliability (an attribute of dependability)
	
	safety depends on security
	
	
	safety -> security -> dependability},
  timestamp = {2008.04.02},
  url = {http://www.sei.cmu.edu/pub/documents/95.reports/pdf/tr021.95.pdf}
}

@TECHREPORT{Barbacci1997,
  author = {Mario R. Barbacci and Mark H. Klein and Charles B. Weinstock},
  title = {Principles for Evaluating the Quality Attributes of a Software Architecture},
  institution = {CMU/SEI},
  year = {1997},
  month = {May},
  abstract = {Software quality is the degree to which software possesses a desired
	combination of attributes (e.g., reliability, interoperability).
	In this paper we describe a few principles for analyzing a software
	architecture to determine if it exhibits certain quality attributes.
	We show how analysis techniques indigenous to the various quality
	attribute communities can provide a foundation for performing software
	architecture evaluation. We also show how the principles provide
	a context for existing evaluation approaches such as scenarios, questionnaires,
	checklists, and measurements. Our immediate goal in identifying these
	principles for attribute-based architecture evaluation is to better
	integrate existing techniques and metrics into software architecture
	practice, not necessarily to invent new attribute-specific techniques
	and metrics. A longer-term goal is to codify these principles into
	systematic procedures or methods for architecture evaluation. This
	paper is an initial step towards identifying the ingredients of such
	methods.},
  citeseerurl = {http://citeseer.ist.psu.edu/barbacci97principles.html},
  file = {:./literature/tr036.96.pdf:PDF},
  keywords = {quality attributes, software architecture, reliability, evaluation},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://www.sei.cmu.edu/pub/documents/96.reports/pdf/tr036.96.pdf}
}

@INPROCEEDINGS{Barbero2008,
  author = {Barbero, Mika\"{a}l and B\'{e}zivin, Jean},
  title = {Model Driven Management of Complex Systems: Implementing the Macroscope’s
	vision},
  booktitle = {Proceedings of the 15th Annual IEEE International Conference on the
	Engineering of Computer Based Systems},
  year = {2008},
  pages = {277-286},
  month = {March},
  file = {:./literature/Paper_236.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.05.16}
}

@INPROCEEDINGS{Bardram2004,
  author = {Jakob Eyvind Bardram and Henrik Bærbak Christensen and Klaus Marius
	Hansen},
  title = {Architectural Prototyping: An Approach for Grounding Architectural
	Design and Learning},
  booktitle = {In Proceedings of the 4th Working IEEE/IFIP Conference on Software
	Architecture (WICSA 2004},
  year = {2004},
  pages = {15--24},
  publisher = {IEEE Computer Society},
  file = {:./literature/bardram2004.pdf:PDF},
  owner = {Sebastian},
  timestamp = {2013.07.25}
}

@INPROCEEDINGS{Barros1995,
  author = {Barros, S. and Bodhuin, T. and Escudie, A. and Queille, J.P. and
	Voidrot, J.F.},
  title = {Supporting impact analysis: a semi-automated technique and associated
	tool},
  booktitle = {Proceedings of the 11th International Conference on Software Maintenance
	(ICSM'95)},
  year = {1995},
  pages = {42-51},
  address = {Opio (Nice), France},
  month = {October},
  file = {:./literature/Paper_135.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- some domain require extensive change analysis before conducting
	any change
	
	- IA is a requirement prior to any maintenance, therefore IA has to
	be reliable
	
	
	Research Questions:
	
	- when to conduct IA
	
	
	Contribution:
	
	- approach for IA rely on dependency graphs and propagation rules
	
	
	Solution:
	
	- static analysis seen as only possible chance as it can also include
	other documents (-> history mining was no issue back then)
	
	- model dependencies between entities as graph
	
	- tool must be adaptable concerning its granularity, i.e. low-level
	or high-level analysis
	
	- define rules which state what is affected when a change of certain
	type is conducted on a certain entitiy
	
	- dependency graph and rules are used by propagation engine
	
	- distinguish between rules which have impact and rules which have
	potential impact
	
	- assign virtual order to potential impacts and potential rules to
	distinguish them from "strict" impacts when propagating recursivly
	
	- tool is interactive, i.e. allowing developers to invalidate proposed
	impact; allow him to edit the graph (IA reacts on it)
	
	- paper provides steps for interactive IA process
	
	- implemented in IAS tool
	
	-> granularity of entities:
	
	-> granularity of changes:
	
	-> granularity of results:
	
	
	Open Issues:
	
	- integrate IAS with traceability platform
	
	- implement some cost estimation functions},
  timestamp = {2011.04.04}
}

@INCOLLECTION{Basili1994,
  author = {Victor R. Basili and Gianluigi Caldiera and H. Dieter Rombach},
  title = {The Goal Question Metric Approach},
  booktitle = {Encyclopedia of Software Engineering},
  publisher = {John Wiley \& Sons},
  year = {1994},
  editor = {J. Marciniak},
  pages = {528-532},
  file = {:./literature/Paper_189.pdf:PDF},
  keywords = {GQM},
  owner = {Steffen},
  timestamp = {2011.11.14}
}

@BOOK{Bass2003,
  title = {Software Architecture in Practice},
  publisher = {Addison-Wesley Longman Publishing Co., Inc.},
  year = {2003},
  author = {Bass, Len and Clements, Paul and Kazman, Rick},
  address = {Boston, MA, USA},
  edition = {2},
  file = {:./literature/Bass2003.pdf:PDF},
  isbn = {0321154959},
  keywords = {software architecture, architectural tactics},
  owner = {Stephan},
  timestamp = {2011.01.15}
}

@INPROCEEDINGS{Bass2002,
  author = {Leonard J. Bass and Mark Klein and Felix Bachmann},
  title = {Quality Attribute Design Primitives and the Attribute Driven Design
	Method},
  booktitle = {Revised Papers from the 4th International Workshop on Software Product-Family
	Engineering},
  year = {2002},
  volume = {2290},
  series = {LNCS},
  pages = {169-186},
  address = {Berlin, Heidelberg, Germany},
  publisher = {Springer-Verlag},
  abstract = {This paper discusses the understanding of quality attributes and their
	application to the design of a software architecture. We present
	an approach to characterizing quality attributes and capturing architectural
	patterns that are used to achieve these attributes. For each pattern,
	it is important not only how the pattern achieves a quality attribute
	goal but also what impact the pattern has on other attributes. We
	embody this investigation of quality into the Attribute Driven Design
	Method for designing software architecture.},
  doi = {10.1007/3-540-47833-7_17},
  file = {:./literature/AttributeDrivenDesign.pdf:PDF},
  isbn = {3-540-43659-6},
  keywords = {quality attributes, attribute driven design, ADD, non-functional requirements,
	design method},
  owner = {Stephan},
  timestamp = {2009.01.26}
}

@INPROCEEDINGS{Bates1993,
  author = {Bates, Samuel and Horwitz, Susan},
  title = {Incremental program testing using program dependence graphs},
  booktitle = {Proceedings of the 20th ACM SIGPLAN-SIGACT symposium on Principles
	of programming languages},
  year = {1993},
  series = {POPL '93},
  pages = {384--396},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[qurat:]},
  acmid = {158694},
  doi = {http://doi.acm.org/10.1145/158511.158694},
  file = {:/literature/RegressionTesting/incremental program testing using program dependance graph.pdf:PDF},
  isbn = {0-89791-560-7},
  keywords = {relevant, read, regressionTesting, codebased, app},
  location = {Charleston, South Carolina, United States},
  numpages = {13},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://doi.acm.org/10.1145/158511.158694}
}

@INPROCEEDINGS{Bauer2002,
  author = {Markus Bauer and Thomas Genßler and Volker Kuttruff and Olaf Seng},
  title = {Werkzeugunterstützung für evolutionäre Softwareentwicklung},
  booktitle = {Proceedings of the fourth German Workshop on Software-Reengineering},
  year = {2002},
  address = {Bad Honnef},
  month = {April},
  abstract = {Moderne Softwaresysteme zeichnen sich durch steigende Komplexität
	aus. Aus diesem Grund wird es immer schwieriger, Systeme von vornherein
	gut zu entwerfen. Softwaresysteme weisen daher von Anfang an gewisse
	Entwurfsmängel auf, zu denen sich im weiteren Verlauf des Entwicklungs-
	und Lebenszyklus weitere gesellen: Software muss allzu oft hastig
	an neue Anforderungen angepasst werden. Dabei geht die ursprüngliche
	Struktur der Systeme langsam verloren und es entstehen zerwartete
	Systeme. Deshalb müssen Softwaresysteme während ihres gesamten Lebenszyklus
	systematisch auf Schwachstellen in Entwurf und Implementierung untersucht
	werden. Die gefundenen Schwachstellen müssen mit Hilfe von Restrukturierungen
	möglichst unmittelbar behoben werden. Unser Ziel ist die durchgängige
	Methoden- und Werkzeugunterstützung bei der Durchführung dieser Aktivitäten,
	die durch den heutigen Stand der Technik nicht gewährleistet ist.},
  file = {:./literature/BauerGensslerKuttruffSeng.pdf:PDF},
  keywords = {evolutionäre Softwareentwicklung, Evolution, Werkzeugunterstützung},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://www.uni-koblenz.de/fb4/publikationen/gelbereihe/RR-9-2002/abstracts/BauerGensslerKuttruffSeng.pdf}
}

@ARTICLE{Bechky2006,
  author = {Bechky, B.A.},
  title = {Gaffers, gofers, and grips: Role-based coordination in temporary
	organizations},
  journal = {Organization Science},
  year = {2006},
  volume = {17},
  pages = {3--21},
  number = {1},
  file = {Bechky2006.pdf:literature/Bechky2006.pdf:PDF},
  owner = {patrickr},
  publisher = {INFORMS},
  timestamp = {2012.10.19}
}

@BOOK{Beck1999,
  title = {Extreme Programming Explained: Embrace Change},
  publisher = {{Addison-Wesley Professional}},
  year = {1999},
  author = {Kent Beck},
  pages = {190},
  address = {Boston, MA, USA},
  month = {October},
  abstract = {{Kent Beck's eXtreme Programming eXplained provides an intriguing
	high-level overview of the author's Extreme Programming (XP) software
	development methodology. Written for IS managers, project leaders,
	or programmers, this guide provides a glimpse at the principles behind
	XP and its potential advantages for small- to mid-size software development
	teams. The book intends to describe what XP is, its guiding principles,
	and how it works. Simply written, the book avoids case studies and
	concrete details in demonstrating the efficacy of XP. Instead, it
	demonstrates how XP relies on simplicity, unit testing, programming
	in pairs, communal ownership of code, and customer input on software
	to motivate code improvement during the development process. As the
	author notes, these principles are not new, but when they're combined
	their synergy fosters a new and arguably better way to build and
	maintain software. Throughout the book, the author presents and explains
	these principles, such as "rapid feedback" and "play to win," which
	form the basis of XP. Generally speaking, XP changes the way programmers
	work. The book is good at delineating new roles for programmers and
	managers who Beck calls "coaches." The most striking characteristic
	of XP is that programmers work in pairs, and that testing is an intrinsic
	part of the coding process. In a later section, the author even shows
	where XP works and where it doesn't and offers suggestions for migrating
	teams and organizations over to the XP process. In the afterword,
	the author recounts the experiences that led him to develop and refine
	XP, an insightful section that should inspire any organization to
	adopt XP. This book serves as a useful introduction to the philosophy
	and practice of XP for the manager or programmer who wants a potentially
	better way to build software. --Richard Dragan Topics covered: Extreme
	Programming (XP) software methodology, principles, XP team roles,
	facilities design, testing, refactoring, the XP software lifecycle,
	and adopting XP.} {Software development projects can be fun, productive,
	and even daring. Yet they can consistently deliver value to a business
	and remain under control. Extreme Programming (XP) was conceived
	and developed to address the specific needs of software development
	conducted by small teams in the face of vague and changing requirements.
	This new lightweight methodology challenges many conventional tenets,
	including the long-held assumption that the cost of changing a piece
	of software necessarily rises dramatically over the course of time.
	XP recognizes that projects have to work to achieve this reduction
	in cost and exploit the savings once they have been earned. Fundamentals
	of XP include: * Distinguishing between the decisions to be made
	by business interests and those to be made by project stakeholders.
	* Writing unit tests before programming and keeping all of the tests
	running at all times. * Integrating and testing the whole system-several
	times a day. * Producing all software in pairs, two programmers at
	one screen. * Starting projects with a simple design that constantly
	evolves to add needed flexibility and remove unneeded complexity.
	* Putting a minimal system into production quickly and growing it
	in whatever directions prove most valuable. Why is XP so controversial?
	Some sacred cows don't make the cut in XP: * Don't force team members
	to specialize and become analysts, architects, programmers, testers,
	and integrators-every XP programmer participates in all of these
	critical activities every day. * Don't conduct complete up-front
	analysis and design-an XP project starts with a quick analysis of
	the entire system, and XP programmers continue to make analysis and
	design decisions throughout development. * Develop infrastructure
	and frameworks as you develop your application, not up-front-delivering
	business value is the heartbeat that drives XP projects. * Don't
	write and maintain implementation documentation-communication in
	XP projects occurs face-to-face, or through efficient tests and carefully
	written code. You may love XP or you may hate it, but Extreme Programming
	Explained will force you to take a fresh look at how you develop
	software.}},
  citeulike-article-id = {149388},
  comment = {http://books.google.de/books?id=G8EL4H4vf7UC&dq=Extreme+Programming+Explained:+Embrace+Change&pg=PP1&ots=j7tJrsfWyq&sig=G9mO2Ia_RhbdkfKl2NnOIfr5b3Q&hl=de&sa=X&oi=book_result&resnum=1&ct=result#PPP1,M1},
  howpublished = {Paperback},
  isbn = {0201616416},
  keywords = {xp},
  owner = {Robert},
  priority = {2},
  timestamp = {2008.07.14},
  url = {http://www.amazon.de/Extreme-Programming-Explained-Embrace-Change/dp/0201616416/ref=sr_11_1?ie=UTF8&qid=1216050753&sr=11-1}
}

@INPROCEEDINGS{Becker2007,
  author = {Becker, Steffen and Koziolek, Heiko and Reussner, Ralf},
  title = {Model-based performance prediction with the {P}alladio component
	models},
  booktitle = {Proceedings of the 6th International Workshop on Software and Performance},
  year = {2007},
  series = {WOSP '07},
  pages = {54--65},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1217006},
  doi = {http://doi.acm.org/10.1145/1216993.1217006},
  file = {:./literature/Becker2007.pdf:PDF},
  isbn = {1-59593-297-6},
  keywords = {component-based software engineering, performance prediction, software
	architecture},
  location = {Buenes Aires, Argentina},
  numpages = {12},
  owner = {Stephan},
  timestamp = {2011.02.09}
}

@TECHREPORT{Beer2012,
  author = {Beer, Mathis and Konrad, Daniel and Sch\"{a}fer, Marvin},
  title = {{Analyzing tools for the application of traceability (in German:
	Untersuchung von Werkzeugen f\"{u}r den Einsatz von Traceability)}},
  institution = {Ilmenau University of Technology},
  year = {2012},
  type = {Projektseminar},
  file = {:./literature/ToolsTraceability.pdf:PDF},
  owner = {elkeb},
  timestamp = {2012.04.04}
}

@PHDTHESIS{Belle2004,
  author = {Theodore B. Van Belle},
  title = {Modularity and the Evolution of Software Evolvability},
  school = {University of New Mexico},
  year = {2004},
  type = {Dissertation for PhD in Computer Science},
  address = {Albuquerque, New Mexico},
  month = {Dec},
  abstract = {Drawing on models of the evolution of living systems, this dissertation
	explores the principle of modularity, both biological and in software,
	and its role in creating structures that are easy to change. These
	ideas are captured in the Software Evolvability Change Optimization
	(SECO) model, a framework for investigating how modularity can enhance
	evolvability in software. 
	
	SECO abstracts software history by dividing the code into non-overlapping
	elements that are linked together by a series of changes. These changes
	are either gathered from the recorded histories of real software,
	or modeled using evolutionary computation, change propagation among
	elements, or correlations in changes between elements. 
	
	The dissertation uses SECO in both an analytic and synthetic role,
	investigating aspects of modularity such as encapsulation and code
	factoring, and using automatic techniques to optimize the modular
	structure of real code. 
	
	The dissertation contributes to the further understanding of modularity
	as a means of improving software evolvability by adding the dimension
	of time to the analysis. In this way, it can discover dependency
	links between software elements that are not evident from a static
	analysis of the program.},
  file = {:./literature/Modularity_and_Evolution_of_Evolvability.pdf:PDF},
  keywords = {modularity, modularization, software evolution, software evolvability},
  owner = {Stephan},
  timestamp = {2008.07.11},
  url = {http://www.cs.unm.edu/~vanbelle/RA/dissertation/dissertation.pdf}
}

@ARTICLE{Bendraou2010,
  author = {Bendraou, Reda and J\'{e}z\'{e}quel, Jean-Marc and Gervais, Marie-Pierre
	and Blanc, Xavier},
  title = {A Comparison of Six UML-Based Languages for Software Process Modeling},
  journal = {Software Engineering, IEEE Transactions on},
  year = {2010},
  volume = {36},
  pages = {662 -675},
  number = {5},
  month = {September},
  doi = {10.1109/TSE.2009.85},
  file = {05593045.pdf:literature/05593045.pdf:PDF},
  issn = {0098-5589},
  keywords = {UML based SPML;UML based language;metamodeling approach;software development
	process;software process modeling language;Unified Modeling Language;software
	engineering;},
  owner = {Stephan},
  timestamp = {2010.12.31}
}

@ARTICLE{Benedusi1998,
  author = {Benedusi},
  title = {post maintenance activities based on path change analysis, code based},
  year = {1998},
  __markedentry = {[qurat:]},
  file = {:/literature/RegressionTesting/post maintinance testing based on path change analysis.pdf:PDF},
  owner = {Annie},
  timestamp = {2011.10.06}
}

@ARTICLE{Bengtsson2004,
  author = {PerOlof Bengtsson and Nico Lassing and Jan Bosch and Hans van Vliet},
  title = {Architecture-level modifiability analysis ({ALMA})},
  journal = {J. Syst. Softw.},
  year = {2004},
  volume = {69},
  pages = {129-147},
  number = {1-2},
  abstract = {Several studies have shown that 50-70% of the total lifecycle cost
	for a software system is spent on evolving the system. Organizations
	aim to reduce the cost of these adaptations, by addressing modifiability
	during the system's development. The software architecture plays
	an important role in achieving this, but few methods for architecture-level
	modifiability analysis exist. Independently, the authors have been
	working on scenario-based software architecture analysis methods
	that focus exclusively on modifiability. Combining these methods
	led to architecture-level modifiability analysis (ALMA), a unified
	architecture-level analysis method that focuses on modifiability,
	distinguishes multiple analysis goals, has explicit assumptions and
	provides repeatable techniques for performing the steps. ALMA consists
	of five main steps, i.e. goal selection, software architecture description,
	change scenario elicitation, change scenario evaluation and interpretation.
	The method has been validated through its application in several
	cases, including software architectures at Ericsson Software Technology,
	DFDS Fraktarna, Althin Medical, the Dutch Department of Defense and
	the Dutch Tax and Customs Administration.},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1016/S0164-1212(03)00080-3},
  file = {:./literature/alma.pdf:PDF},
  issn = {0164-1212},
  keywords = {Software architecture; Architecture analysis; Modifiability; Scenarios},
  owner = {Robert},
  publisher = {Elsevier Science Inc.},
  timestamp = {2008.07.14},
  url = {http://www.math.vu.nl/~hans/publications/y2004/alma.pdf}
}

@ARTICLE{Bennett1990,
  author = {Keith H. Bennett},
  title = {An introduction to software maintenance},
  journal = {Information and Software Technology},
  year = {1990},
  volume = {12},
  pages = {257-264},
  number = {4},
  owner = {Steffen},
  timestamp = {2011.10.12}
}

@INPROCEEDINGS{Bennett2000,
  author = {Keith H. Bennett and V\'{a}clav T. Rajlich},
  title = {Software maintenance and evolution: a roadmap},
  booktitle = {Proceedings of the Conference on The Future of Software Engineering,
	ICSE '00},
  year = {2000},
  pages = {73-87},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Software maintenance and evolution are characterised by their huge
	cost and slow speed of implementation. Yet they are inevitable activities
	– almost all software that is useful and successful stimulates user-generated
	requests for change and improvements. Our aim is to describe a landscape
	for research in software maintenance and evolution over the next
	ten years, in order to improve the speed and accuracy of change while
	reducing costs, by identifying key problems, promising solution strategies
	and topics of importance. The aims are met, by taking two approaches.
	Firstly current trends and practices are projected forward using
	a new model of software evolution called the staged model. Both strategic
	problems and research to solve particular tactical problems are described
	within this framework. Secondly, a longer term, and much more radical
	vision of software evolution is presented. Both general principles
	and specific research topics are provided, both within an overall
	strategy of engineering research and rationale.},
  doi = {http://doi.acm.org/10.1145/336512.336534},
  file = {:./literature/finalbennett.pdf:PDF},
  isbn = {1-58113-253-0},
  keywords = {software maintenance, evolution, staged model},
  location = {Limerick, Ireland},
  owner = {Stephan},
  review = {description of staged model for software maintenance
	
	- maintenance refers to general post-delivery activities
	
	- evolution is a particular stage
	
	
	four classes of maintenance activities: adaptive, perfective, corrective,
	preventive
	
	
	staged model stages: initial development, evolution, servicing, phase-out,
	close-down
	
	alternative: versioned staged model: all substantial changes in the
	functionality are implemented in future versions, no servicing for
	outdated versions
	
	-> staged model reference: Rajlich2000
	
	
	evolution: adaption of the application to the ever-changing user requirements
	and operating environment
	
	prerequisites: an architecture that will persist, knowledge of the
	development team
	
	
	if one aspect disappears (e.g. architectural integrity destroyed,
	or team members with knowledge leave) evolution ends -> servicing
	
	
	key challange: find ways that software can be more easily changed
	in subsequent phases
	
	
	keep a system within a particular stage for as long as possible
	
	
	central aim of flexibility: assist the next (evolution) stage, not
	subsequent stages
	
	
	evolution: major changes
	
	servicing: tactical changes
	
	
	challanges:
	
	- evolution: architectures which themselves can evolve in controlled
	ways, partitioning architectures into independently evolving subsystems
	
	- program comprehension
	
	- migration
	
	- restructuring to remove unnecessary complexity
	
	
	"Software change is the basic operation of both software evolution
	and software servicing."
	
	
	change is a process, either introducing new requirements, or modifying
	the system, or moving system into new environment
	
	
	change mini-cycle:
	
	-request for change
	
	-planning phase
	
	 - program comprehension
	
	 - change impact analysis
	
	-change implementation
	
	 - restructuring for change
	
	 - change propagation
	
	-verification and validation
	
	-re-documentation
	
	
	program comprehension consumes more than 50% of all maintenance resources
	
	
	if change has influence on delocalized components -> behaviour preserving
	transformation
	
	- first transform architecture
	
	- second perform change itsself
	
	--> less change propagation},
  timestamp = {2008.04.17},
  url = {http://www.cs.ucl.ac.uk/staff/A.Finkelstein/fose/finalbennett.pdf}
}

@TECHREPORT{Bennicke2004,
  author = {M. Bennicke and H. Rust},
  title = {Programmverstehen und statische Analysetechniken im Kontext des Reverse
	Engineering und der Qualitätssicherung},
  institution = {ViSEK/025/D},
  year = {2004},
  month = {Feb},
  abstract = {Über Jahre gewachsene Software-Systeme bereiten Unternehmen häufig
	Schwierigkeiten: Im Interesse des Bestandsschutzes war es häufig
	notwendig, die Systeme immer wieder an neue Anforderungen anzupassen.
	Andererseits erfolgte die Dokumentation der vorgenommenen Änderungen
	nur sehr nachlässig, was dazu führte, dass die Umsetzung neuer Änderungen
	immer schwieriger wurde. 
	
	Seit Jahren werden daher statische Analysetechniken mit zumindest
	zwei Zielen eingesetzt: Statische Analysen liefern einerseits das
	notwendige Datenmaterial über die Systemstrukturen, um ein Reverse
	Engineering und das Programmverstehen wieder zu ermöglichen. Andererseits
	liefern die gleichen Methoden greifbare Ansatzpunkte, um bereits
	während der Systemerstellung Qualitätssicherung betreiben zu können.
	
	
	Dieses Dokument liefert einen Überblick über den Stand der Technik
	hinsichtlich der Tätigkeiten Programmverstehen, Reverse Engineering
	und Qualitätssicherung hinsichtlich des Einsatzes statischer Analysen
	in diesen Bereichen. Es werden sowohl theoretische Grundlagen als
	auch konkrete statische Analysetechniken, Beispiele und Werkzeuge
	diskutiert.},
  file = {:./literature/StatischeAnalyse_20040204.pdf:PDF},
  keywords = {statische Analyse, Programmverstehen, Reverse Engineering, Reengineering,
	Software-Qualität},
  owner = {Robert},
  timestamp = {2007.04.21},
  url = {http://www.informatik.tu-cottbus.de/~rust/ss2004/sa/lit/StatischeAnalyse_20040204.pdf}
}

@ARTICLE{Bensaou1996,
  author = {Bensaou, M. and Venkatraman, N.},
  title = {Interorganizational relationships and information technology: A conceptual
	synthesis and a research framework},
  journal = {European Journal of Information Systems},
  year = {1996},
  volume = {5},
  pages = {84-91},
  booktitle = {In Proceedings of the Second European Conference on Information Systems},
  file = {Bensaou1996.pdf:literature/Bensaou1996.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.10.11}
}

@INPROCEEDINGS{vandenBerg2006,
  author = {van den Berg, Klaas},
  title = {Change Impact Analysis of Crosscutting in Software Architectural
	Design},
  booktitle = {Proceedings of the Workshop on Architecture-Centric Evolution (ACE
	2006)},
  year = {2006},
  pages = {1-15},
  address = {Nantes},
  month = {July},
  file = {:./literature/Paper_48.pdf:PDF},
  owner = {Steffen},
  review = {"crosscutting":
	
	- a traceability-link between A and B
	
	- A is related to many other elements (including B)
	
	- many other elements are related to B (including A)
	
	-> A crosscuts B (standard situation in traces or dependency graphs)
	
	
	Problem:
	
	- software architectures also affected by changes
	
	- dependencies between architecture elements epxressed through traceability
	links
	
	
	Research Questions:
	
	- how can crosscutting contribute to IA on an architectural level
	
	
	Contribution:
	
	- IA through crosscutting of software architectures
	
	
	Solution:
	
	- matrix representation of dependencies
	
	- derive crosscutting matrix from dep.-matrix
	
	- allow for multiple levels of dependencies, therefore multiple matrices
	
	- traces between matrices can be computed by multiplying both matrices
	(backwards: multiply and then transpose)
	
	- identify impacted elements by crosscut/tangling/scattering and injection-relations
	
	-> granularity of entities: adaptable
	
	-> granularity of changes: no details given
	
	-> granularity of results: adaptable
	
	
	Open Issues:
	
	- not yet evaluated
	
	- conflicts in change propagation: "change t while preserving t"},
  timestamp = {2011.02.09}
}

@INPROCEEDINGS{Berg2006,
  author = {Klaas van den Berg and Jos'{e} Mar'{i}a Conejero and Juan Hern'{a}ndez},
  title = {Analysis of crosscutting across software development phases based
	on traceability},
  booktitle = {EA '06 Proceedings of the 2006 international workshop on Early aspects
	at ICSE},
  year = {2006},
  pages = {43-50},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[Steffen:]},
  abstract = {Traceability of requirements and concerns enhances the quality of
	software development. We use trace relations to define crosscutting.
	As starting point, we set up a dependency matrix to capture the relationship
	between elements at two levels, e.g. concerns and representations
	of concerns. The definition of crosscutting is formalized in terms
	of linear algebra, and represented with matrices and matrix operations.
	In this way, crosscutting can be clearly distinguished from scattering
	and tangling. We apply this approach to the identification of crosscutting
	across early phases in the software life cycle, based on the transitivity
	of trace relations. We describe an illustrative case study to demonstrate
	the applicability of the analysis.},
  doi = {http://doi.acm.org/10.1145/1137639.1137647},
  file = {:./literature/vandenberg2006Crosscutting.pdf:PDF},
  isbn = {1-59593-405-7},
  keywords = {aspect orientated software development, traceability, scattering,
	tangling, crosscutting, crosscutting concerns},
  location = {Shanghai, China},
  owner = {Robert},
  timestamp = {2008.07.22}
}

@INPROCEEDINGS{Berg2009,
  author = {van den Berg, Mark and Tang, Antony and Farenhorst, Rik},
  title = {{A Constraint-Oriented Approach to Software Architecture Design}},
  booktitle = {2009 Ninth International Conference on Quality Software},
  year = {2009},
  pages = {396--405},
  month = aug,
  publisher = {IEEE},
  abstract = {Software architecture design constraints exist and they bound the
	solution space in some ways. However,in research and practice little
	is known about the characteristics of these constraints and how they
	influence decision making. In this paper we report our findings on
	design constraint characteristics based on case studies in two countries.
	We discovered how constraints typically manifest themselves in the
	architecture design process, and how they impact the architectural
	decisions taken. Based on these insights we suggest a number of implications
	and strategies to support architectural design.},
  doi = {10.1109/QSIC.2009.59},
  file = {:./literature/Berg2009.pdf:PDF},
  isbn = {978-1-4244-5912-4},
  issn = {1550-6002},
  mendeley-groups = {Reading list},
  owner = {Sebastian},
  timestamp = {2014.03.17},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5381394}
}

@ARTICLE{Berggren2001,
  author = {Berggren, C. and S{\"o}derlund, J. and Anderson, C.},
  title = {Clients, contractors, and consultants-The consequences of organizational
	fragmentation in contemporary project environments},
  journal = {International Journal of Project Management},
  year = {2001},
  volume = {32},
  pages = {39--48},
  number = {3},
  file = {Berggren2001.pdf:literature/Berggren2001.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.10.22}
}

@ARTICLE{Bergmann2009,
  author = {G\{'a}bor Bergmann and Istv\'{a}n R\'{a}th and D\'{a}niel Varr\'{o}},
  title = {Parallelization of Graph Transformation Based on Incremental Pattern
	Matching},
  journal = {ECEASST},
  year = {2009},
  volume = {18},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  ee = {http://eceasst.cs.tu-berlin.de/index.php/eceasst/article/view/265},
  file = {:/literature/changeIdentification/265-780-1-PB.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.03.01}
}

@ARTICLE{Bergmans2001,
  author = {Bergmans, Lodewijk and Aksit, Mehmet},
  title = {Composing crosscutting concerns using composition filters},
  journal = {Commun. ACM},
  year = {2001},
  volume = {44},
  pages = {51-57},
  number = {10},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/383845.383857},
  file = {:./literature/filters.pdf:PDF},
  issn = {0001-0782},
  keywords = {aspect-oriented development, composition filters},
  owner = {Stephan},
  publisher = {ACM},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Bernaras1996,
  author = {Bernaras, A. and Laresgoiti, I. and Corera, J.},
  title = {Building and reusing ontologies for electrical network applications},
  booktitle = {Proceedings European Conference on Artificial Intelligence (ECAI'96)},
  year = {1996},
  pages = {298-302},
  address = {Budapest, Hungary},
  keywords = {Ontology Engineering},
  owner = {Stephan},
  timestamp = {2011.03.15}
}

@INPROCEEDINGS{Bernstein1994,
  author = {Bernstein, D.V.},
  title = {A practitioner's approach to software reliability},
  booktitle = {Proceedings. Annual Reliability and Maintainability Symposium, 1994},
  year = {1994},
  pages = {349-358},
  month = {Jan},
  publisher = {IEEE Computer Society},
  abstract = {The purpose of this analysis is to formulate a set of software development
	procedures which improve the reliability of the software as it is
	being built. The premise for this concept is that careful attention
	to the design of the process of developing software can have significant
	effect on the level of reliability in the completed software product.
	Specific approaches to improving the level of software characteristics
	which contribute to the process of achieving reliability can be implemented
	during the development process.},
  comment = {correspondence to Software Quality Characteristics Tree [Boehm76]},
  doi = {10.1109/RAMS.1994.291133},
  file = {:./literature/Bernstein1994PractitionersApproach.pdf:PDF},
  keywords = {software engineering, software reliabilitydesign process, software
	characteristics, software development, software engineering, software
	reliability},
  owner = {Matthias},
  timestamp = {2008.07.19}
}

@ARTICLE{Bertolino2003,
  author = {Antonia Bertolino and Raffaela Mirandola},
  title = {Modeling and Analysis of Non-functional Properties in Component-based
	Systems},
  journal = {Electronic Notes in Theoretical Computer Science},
  year = {2003},
  volume = {82},
  pages = {158-168},
  number = {6},
  month = {September},
  abstract = {This paper discusses methodologies for the specification and analysis
	of performance related properties of components and assemblies of
	components, and outlines an original approach, called the CB-SPE,
	for component-based software performance engineering. The proposed
	approach relies on, and adapts to a CB framework, the concepts and
	steps of the SPE technology, and uses for modeling the standard RT-UML
	profile, reshaped according to the CB principles.},
  doi = {10.1016/S1571-0661(04)81034-X},
  file = {:./literature/BM03a.pdf:PDF},
  keywords = {non-functional properties, component-based, modeling},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://www.iei.pi.cnr.it/~antonia/publications/BM03a.pdf}
}

@INPROCEEDINGS{Beszedes2007b,
  author = {Besz\'{e}des, \'{A}rp\'{a}d and Gergely, Tam\'{a}s and Farag\'{o},
	Szabolcs and Gyim\'{o}thy, Tibor and Fischer, Ferenc},
  title = {The Dynamic Function Coupling Metric and Its Use in Software Evolution},
  booktitle = {Proceedings of the 11th European Conference on Software Maintenance
	and Reengineering (CSMR'07)},
  year = {2007},
  pages = {103-112},
  address = {Amsterdam, the Netherlands},
  month = {March},
  file = {:./literature/Paper_165.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- most IA techniques sacrifice precision and recall for efficiency
	
	- current dynamic IA is too conservative and therefore imprecise
	
	
	Research Questions:
	
	- how to exploit couplings between methods for IA
	
	
	Contribution:
	
	- new coupling measure for IA "Dynamic Function Coupling" (DFC)
	
	- evaluation resulted in doubled precision for DFC-IA
	
	
	Solution:
	
	- take both directions of Execute After relation into account
	
	- DFC uses "closeness" of two functions
	
	- compute this closeness for each pair of functions
	
	- use the DFC to select function-pairs which meet a threshold
	
	- build dynamic call tree from method entry and method exit behaviour
	to gather DFC values
	
	- use DFC values to select possible impacted methods
	
	-> granularity of entities: method
	
	-> granularity of changes:
	
	-> granularity of results: method
	
	
	Open Issues:
	
	- verify scalability of proposed method for practice},
  timestamp = {2011.07.25}
}

@INPROCEEDINGS{Beszedes2007a,
  author = {Besz\'{e}des, \'{A}rp\'{a}d and Gergely, Tam\'{a}s and J\'{a}sz,
	Judit and T\'{o}th, Gabriella and Gyim\'{o}thy, Tibor and Rajlich,
	V\'{a}clav},
  title = {Computation of Static Execute After Relation with Applications to
	Software Maintenance},
  booktitle = {Proceedings of the IEEE International Conference on Software Maintenance
	(ICSM 2007)},
  year = {2007},
  pages = {295-304},
  address = {Paris},
  month = {October},
  file = {:./literature/Paper_164.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- static slicing is safe, but lacks precision (too many impacts) and
	too costly
	
	- hidden dependencies hard to spot and existing algorithms are not
	scalable
	
	
	Research Questions:
	
	- obtain high recall as with static slicing but with increased precision
	and reduced costs
	
	
	Contribution:
	
	- use of Static Execution After relations (SEA) to approximate static
	slicing with less costs
	
	- SEA gathers explicit and hidden dependencies with low costs
	
	- case study to demonstrate precision and performance gain of SEA
	
	
	
	Solution:
	
	- compute SEAs from class methods to unveil hidden dependencies between
	classes
	
	- Component Control Flow Grapg (CCFG) collect method calls
	
	* one entry-node for each method
	
	* one component node for each method
	
	* "control flow" connections between both
	
	- algorithm computes SEA as follows:
	
	* determine transitive calls for each procedure
	
	* all procedures processed again to compute SEAs
	
	 - order components topologically
	
	 - determine set of procedures called in each component
	
	-> granularity of entities: class, method
	
	-> granularity of changes:
	
	-> granularity of results: class
	
	
	Open Issues:
	
	- validation with real case study
	
	- yet only compare with static slicing and no other techniques},
  timestamp = {2011.07.25}
}

@INPROCEEDINGS{Beus-Dukic2000,
  author = {L. Beus-Dukic},
  title = {Non-functional requirements for COTS software components},
  booktitle = {Proceedings of the 2nd Workshop on COTS Software},
  year = {2000},
  address = {Limerick, Ireland},
  month = {June},
  abstract = {Commercially available software components come with the built-in
	functionality often offering end-user more than they need. A fact
	that end-user has no or very little influence on component’s functionality
	promoted nonfunctional requirements which are getting more attention
	than ever before. In this paper, we identify some of the problems
	encountered when non-functional requirements for COTS software components
	need to be defined.},
  citeseerurl = {citeseer.ist.psu.edu/beus-dukic00nonfunctional.html},
  file = {:./literature/cotsw00.pdf:PDF},
  keywords = {Requirements engineering, non-functional requirements, COTS software
	component},
  owner = {Stephan},
  review = {discussion of what requirements (FR and NFR) are relevant for COTS
	
	
	points out open questions on non-functional requirements for components
	
	- how to prioritize
	
	- how to describe, measure, quantify components' ilities
	
	
	no solutions},
  text = {L. Beus-Dukic. Non-functional requirements for COTS software components.
	Position Paper. Proc. ICSE},
  timestamp = {2008.04.14},
  url = {http://users.cscs.wmin.ac.uk/~beusdul/papers/cotsw00.pdf}
}

@ARTICLE{Beydeda2000,
  author = {Sami Beydeda and Volker Gruhn},
  title = {Integrating White- and Black-Box Techniques for Class-Level Regression
	Testing},
  year = {2000},
  file = {:/literature/RegressionTesting/integrating whiteand black box testing for class level regression testing.pdf:PDF},
  keywords = {MBRT},
  owner = {Annie},
  review = {CSIG, similer to a state machine
	
	
	Casestudy: Small Example},
  timestamp = {2011.01.04},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.23.3355}
}

@INPROCEEDINGS{Beyer2005,
  author = {Beyer, Dirk and Noack, Andreas},
  title = {Clustering Software Artifacts Based on Frequent Common Changes},
  booktitle = {Proceedings of the 13th International Workshop on Program Comprehension
	(IWPC'05)},
  year = {2005},
  pages = {259-268},
  file = {:./literature/Paper_111.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- clusters of artifacts which frequently change together are good
	candidates to form / be grouped in subsystems / submodels
	
	- documentation and abstract design can get lost or outdated, but
	can be recovered from low-level structure
	
	
	Research Questions:
	
	- how to gain abstract desgin documents (i.e. architecture, components)
	from source code
	
	
	Contribution:
	
	- two-step method for identifying artifacts which should form a subsystem
	based on their change behavior
	
	- derive requirements for co-change layouts and introduce model to
	produce layouts which meet requirements
	
	
	Solution:
	
	- two-step approach consists of following steps:
	
	* extract co-change graph for software artifacts from version control
	repository
	
	 - vertices: artifacts (files, functions etc.)
	
	 - edges: change transactions (commits) of verioning system
	
	* compute layout of graph to reveal clusters of co-change artifacts
	
	 - related artifacts are placed in close distance, whereas unrelated
	ones are placed far away from cluster
	
	 - distance between nodes is computed as degree of their common change
	
	 - each edge in the graph is labeled with the degree of co-change
	
	- use "energy-based" graph layout algorithm to compute clusters:
	
	* assign real-numbers to each graph layout
	
	* search for a layout with minimal energy
	
	* use the "Edge-Repulsion LinLog Energy"-model
	
	* use Barnes-Hut algorithm to compute layout
	
	-> granularity of entities: files
	
	-> granularity of changes: change records from version control system
	
	-> granularity of results: files
	
	
	Open Issues:
	
	- improve clustering of artifacts which were rarely changed},
  timestamp = {2011.04.01}
}

@INPROCEEDINGS{Bezivin2005,
  author = {Jean Bezivin and Frederic Jouault and Peter Rosenthal and Patrick
	Valduriez},
  title = {Modeling in the Large and Modeling in the Small},
  booktitle = {Model Driven Architecture},
  year = {2005},
  editor = {Uwe Assmann and Mehmet Akcsit and A. Rensink},
  number = {3599},
  series = {LNCS},
  pages = {33-46},
  publisher = {Springer},
  file = {:./literature/Bezivin2005.pdf:PDF},
  owner = {matthias},
  timestamp = {2013.10.02}
}

@CONFERENCE{Bianchi2000,
  author = {Bianchi, Alessandro and Fasolino,Anna Rita and Visaggio, Giuseppe},
  title = {An Exploratory Case Study of the Maintenance Effectiveness of Traceability
	Models},
  booktitle = {Proceedings of 8th International Workshop on Program Comprehension
	(IWPC'00)},
  year = {2000},
  pages = {149 - 158},
  organization = {IEEE},
  abstract = {Analysing the role of traceability models in software maintenance
	and comprehension is an important research issue. An exploratory
	case study evaluating the relationship between the granularity of
	the traceability model adopted and the effectiveness of the maintenance
	process is presented in this paper. Two maintenance effectiveness
	aspects were taken into account: efficiency and accuracy. The analysis
	was carried out in an object-oriented environment, with the support
	of an integrated platform of software tools. The preliminary results
	show that some aspects of the effectiveness of the maintenance process
	can be improved by modifying the degree of granularity of the model.
	These results encourage further research into this topic, while some
	additional side-effects that emerged from the study are also investigated.},
  file = {:./literature/00852489.pdf:PDF},
  owner = {Elke},
  review = {experimentelle Studie: mit experimenteller Umgebung - nicht aus der
	Praxis},
  timestamp = {2011.06.06},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=852489&tag=1}
}

@ARTICLE{Bible2001,
  author = {Bible, John and Rothermel, Gregg and Rosenblum, David S.},
  title = {A comparative study of coarse- and fine-grained safe regression test-selection
	techniques},
  journal = {ACM Trans. Softw. Eng. Methodol.},
  year = {2001},
  volume = {10},
  pages = {149--183},
  month = {April},
  __markedentry = {[qurat:]},
  acmid = {367015},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/367008.367015},
  file = {:/literature/RegressionTesting/ACOmparativeStudyOfCOarseAndFineGrained.pdf:PDF},
  issn = {1049-331X},
  issue = {2},
  keywords = {regression test selection, regression testing, analysis},
  numpages = {35},
  owner = {Annie},
  publisher = {ACM},
  timestamp = {2011.10.20},
  url = {http://doi.acm.org/10.1145/367008.367015}
}

@ARTICLE{Biffl2006,
  author = {Biffl, S. and Winkler, D. and H{\"o}hn, R. and Wetzel, H.},
  title = {Software process improvement in Europe: potential of the new V-modell
	XT and research issues},
  journal = {Software Process: Improvement and Practice},
  year = {2006},
  volume = {11},
  pages = {229--238},
  number = {3},
  file = {Biffl2006.pdf:literature/Biffl2006.pdf:PDF},
  owner = {patrickr},
  publisher = {Wiley Online Library},
  timestamp = {2012.07.20}
}

@ARTICLE{Bigley2001,
  author = {Bigley, G.A. and Roberts, K.H.},
  title = {The incident command system: High-reliability organizing for complex
	and volatile task environments.},
  journal = {Academy of Management Journal},
  year = {2001},
  volume = {44},
  pages = {1281--1299},
  number = {6},
  file = {Bigley2001.pdf:literature/Bigley2001.pdf:PDF},
  owner = {patrickr},
  publisher = {Academy of Management},
  timestamp = {2012.10.22}
}

@INPROCEEDINGS{Bilal2006,
  author = {Bilal, Haider and Black, Sue},
  title = {Computing Ripple Effect for Object Oriented Software},
  booktitle = {Proceedings of the 10th ECOOP Workshop on Quantitative Approaches
	in Object-Oriented Software Engineering (QAOOSE '06)},
  year = {2006},
  pages = {51-60},
  address = {Nantes, France},
  month = {July},
  file = {:./literature/Paper_142.PDF:PDF},
  owner = {Steffen},
  review = {useful stuff:
	
	"Therefore, many software systems are never really complete until
	their function in the organization becomes obsolete"
	
	
	Problem:
	
	- detection of ripple effects is important in evolution
	
	- existing ripple effect algorithm can be improved
	
	(required due to size of today's systems with several mLOC)
	
	
	Research Questions:
	
	- increase clearity of ripple effect algorithm (for the algorithm
	and the measurement of ripple effect)
	
	
	Contribution:
	
	- improved ripple effect algorithm, based on improved ripple effect
	metric
	
	- ripple effect metric as software complexity metric
	
	
	Solution:
	
	- two types of change propagation are used to calculate ripple effects:
	
	* intramodule change propagation
	
	* intermodule change propagation
	
	- 4 different metrics implemented:
	
	* concat all code within class (omit local calls) and calc. ripple
	effect between this class and others
	
	* ripples across methods and classes, ignoring propagation within
	methods
	
	* ripples across methods and classes, computing ripples in methods,
	between methods and between classes
	
	* ripples across methods within each class, ignore propagation between
	classes
	
	-> granularity of entities: class, method
	
	-> granularity of changes:
	
	-> granularity of results: class, method
	
	
	Open Issues:},
  timestamp = {2011.07.25}
}

@BOOK{Binder2000,
  title = {Testing Object-Or\-ien\-ted Systems - Models, Patterns, and Tools},
  publisher = {Addison Wesley Longman},
  year = {2000},
  author = {Binder, Robert V.},
  pages = {1191},
  keywords = {software test},
  owner = {Robert},
  timestamp = {2008.07.14},
  url = {http://books.google.de/books?hl=de&lr=&id=EVkEMahB2MUC&oi=fnd&pg=PR25&ots=P0pIjjdkOY&sig=Co8654m3_jdZawWjf3jgsNi4OCk#PPP1,M1}
}

@INPROCEEDINGS{Binkley1995,
  author = {Binkley, D.},
  title = {Reducing the cost of regression testing by semantics guided test
	case selection},
  booktitle = {Proceedings of the International Conference on Software Maintenance},
  year = {1995},
  series = {ICSM '95},
  pages = {251--},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[qurat:]},
  acmid = {853227},
  file = {:/literature/RegressionTesting/Reducing the Cost of Regression Testing by Semantics Guided Test Case Selection.pdf:PDF},
  isbn = {0-8186-7141-6},
  keywords = {code based, calling context slice, common execution patterns, cost,
	interprocedural slice, language semantics, program testing, regression
	testing, semantic differences, semantics guided test case selection,
	software cost estimation, software maintenance},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=850946.853227}
}

@INPROCEEDINGS{Binkley1992,
  author = {Binkley, D.},
  title = {Using semantic differencing to reduce the cost of regression testing},
  booktitle = {Software Maintenance, 1992. Proceerdings., Conference on},
  year = {1992},
  pages = {41 -50},
  month = {nov},
  doi = {10.1109/ICSM.1992.242560},
  file = {:/literature/RegressionTesting/using semantic differencing to reduce the cost of regression testing.pdf:PDF},
  keywords = {Read, Relevant, CodeBased, app},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@INPROCEEDINGS{Binkley2005,
  author = {Binkley, David and Harman, Mark},
  title = {Locating dependence clusters and dependence pollution},
  booktitle = {Proceedings of the 21st International Conference on Software Maintenance
	(ICSM'05)},
  year = {2005},
  pages = {177-186},
  month = {September},
  file = {:./literature/Paper_167.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- dependence clusters difficult to maintaine as change to one statement
	may affect many others too
	
	
	Research Questions:
	
	
	Contribution:
	
	- defined concept of dependence cluster and dependence pollution
	
	- visualization technique to quickly locate such clusters
	
	
	Solution:
	
	- use a "size of slice" approach
	
	* create slices for each variable
	
	* check if slices have same size
	
	* if so, such variables contribute to a cluster
	
	- use "Monotone Slice-size Graph" (MSG) to visualize clusters
	
	-> granularity of entities: variable
	
	-> granularity of changes:
	
	-> granularity of results: variable
	
	
	Open Issues:
	
	- more case studies and categorization of programs according to their
	MSGs},
  timestamp = {2011.07.26}
}

@INCOLLECTION{Binkley2010,
  author = {Binkley, David and Lawrie, Dawn},
  title = {Information Retrieval Applications in Software Maintenance and Evolution},
  booktitle = {Encyclopedia of Software Engineering},
  publisher = {Taylor \& Francis LLC},
  year = {2010},
  editor = {P. Laplante},
  chapter = {2},
  file = {:./literature/Paper_175.PDF:PDF},
  owner = {Steffen},
  review = {good summary of IR techniques (+ basic algorithms and definitions)
	and how they are applied in various SWE applications},
  timestamp = {2011.08.02}
}

@TECHREPORT{Biolchi2005,
  author = {Biolchi, Jorge and Mian, Paul Gomes and Natali, Ana Candida Cruz
	and Travassos, Guilherme Horta},
  title = {Systematic Review in Software Engineering},
  institution = {Systems Engineering and Computer Science Department, University of
	Rio de Janeiro},
  year = {2005},
  number = {RT - ES 679/05},
  month = {May},
  file = {:./literature/Paper_197.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.03.01}
}

@MASTERSTHESIS{Bishop2004,
  author = {Bishop, Luke},
  title = {Incremental impact analysis for object-oriented software},
  school = {Iowa State University},
  year = {2004},
  file = {:./literature/Master_3.pdf:PDF},
  owner = {Steffen},
  review = {- first compute dependency graph of program, then propagate ripple
	effect of proposed change
	
	* method input/output mapping is base for dependency graph
	
	* this mapping can be reused as it must be changed in case of changes
	which affect the method only
	
	* compute static data flow within method
	
	- store results of each IA process to enable incremental IA search
	later
	
	
	- scope of analysis: code
	
	- tool: Incremental Impact Analyzer
	
	- language: Java
	
	- scalability: -
	
	- granularity
	
	* changes: +/- method
	
	* artifacts: variable, method
	
	* results: class
	
	- technique: dependency graph
	
	- analysis style:
	
	- evaluation
	
	* size: 9 KLOC
	
	* precision:
	
	* recall:
	
	* time: 350ms},
  timestamp = {2011.02.10}
}

@ARTICLE{Biswas2009,
  author = {Biswas, Swarnendu and Mall, Rajib and Satpathy, Manoranjan and Sukumaran,
	Srihari},
  title = {A model-based regression test selection approach for embedded applications},
  journal = {SIGSOFT Software Engineering Notes},
  year = {2009},
  volume = {34},
  pages = {1--9},
  month = {July},
  acmid = {1543413},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1543405.1543413},
  file = {:/literature/RegressionTesting/A Model-Based Regression Test Selection Approach for Embedded Applications.pdf:PDF},
  issn = {0163-5948},
  issue = {4},
  keywords = {embedded software, real-time, regression test optimization, regression
	test selection, regression testing, safety critical,model baseds},
  numpages = {9},
  owner = {Annie},
  publisher = {ACM},
  review = {orignal source code is involved
	
	extended Class Dependence Graph ECIDG
	
	
	state charts
	
	
	Dependencies: Control dependence, data dependence, control flow and
	message sequence
	
	
	Code is necessary to exercise the approach, so platform independence
	is low
	
	
	Tool support: No
	
	Case study: Small Example
	
	
	Classification: yes obsolete, redundent, regression and optimized},
  timestamp = {2011.01.04},
  url = {http://doi.acm.org/10.1145/1543405.1543413}
}

@INPROCEEDINGS{Bjerknes2000,
  author = {Bjerknes, G. and Mathiassen, L.},
  title = {Improving the customer-supplier relation in IT development},
  booktitle = {System Sciences, 2000. Proceedings of the 33rd Annual Hawaii International
	Conference on},
  year = {2000},
  pages = {10--pp},
  file = {Bjerknes2000.pdf:literature/Bjerknes2000.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@ARTICLE{Black2001,
  author = {Black, Sue},
  title = {Computing ripple effect for software maintenance},
  journal = {Journal of Software Maintenance and Evolution: Research and Practice},
  year = {2001},
  volume = {13},
  pages = {263-279},
  file = {:./literature/Paper_177.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- existing ripple-effect algorithm troublesome, i.e. too expensive
	
	
	Research Questions:
	
	- how to improve existing r.-e. algorithm
	
	
	Contribution:
	
	- reformulation of Yau's and Collofello's ripple-effetc algorithm
	
	- implemented in ripple-effect and stability tool, REST for C programs
	
	
	Solution:
	
	- build dependency matrices of program
	
	- REST uses matrices to compute ripple effects and stability measures
	
	- algorithm based on McCabe complexity measure
	
	-> granularity of entities: variable
	
	-> granularity of changes:
	
	-> granularity of results: variable
	
	
	Open Issues:
	
	- make REST more robust (right now only up to 160 variables)
	
	- extend ripple-effect analysis for OO software},
  timestamp = {2011.07.26}
}

@ARTICLE{Blackburn1996,
  author = {Blackburn, J.D. and Scudder, G.D. and Van Wassenhove, L.N.},
  title = {Improving speed and productivity of software development: a global
	survey of software developers},
  journal = {Software Engineering, IEEE Transactions on},
  year = {1996},
  volume = {22},
  pages = {875--885},
  number = {12},
  file = {Blackburn1996.pdf:literature/Blackburn1996.pdf:PDF},
  owner = {patrickr},
  publisher = {IEEE},
  timestamp = {2013.01.02}
}

@INPROCEEDINGS{Blanc:2009:IDM:1573487.1573497,
  author = {Blanc, Xavier and Mougenot, Alix and Mounier, Isabelle and Mens,
	Tom},
  title = {Incremental Detection of Model Inconsistencies Based on Model Operations},
  booktitle = {Proceedings of the 21st International Conference on Advanced Information
	Systems Engineering},
  year = {2009},
  series = {CAiSE '09},
  pages = {32--46},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  acmid = {1573497},
  doi = {10.1007/978-3-642-02144-2_8},
  file = {:/literature/IncrementalCAISE09.pdf:PDF},
  isbn = {978-3-642-02143-5},
  location = {Amsterdam, The Netherlands},
  numpages = {15},
  url = {http://dx.doi.org/10.1007/978-3-642-02144-2_8}
}

@INPROCEEDINGS{Blowers2006,
  author = {Blowers, R. and Richardson, I.},
  title = {The Capability Maturity Model (SW and Integrated) Tailored in Small
	Indigenous Software Industries},
  booktitle = {Proceedings of the First International Research Workshop for Process
	Improvement in Small Settings},
  year = {2006},
  file = {Blowers2005.pdf:literature/Blowers2005.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@INPROCEEDINGS{Blumenberg2008,
  author = {Blumenberg, S. and Beimborn, D. and Koenig, W.},
  title = {Determinants of IT outsourcing relationships: a conceptual model},
  booktitle = {Hawaii International Conference on System Sciences, Proceedings of
	the 41st Annual},
  year = {2008},
  pages = {12--12},
  organization = {IEEE},
  file = {Blumenberg2008.pdf:literature/Blumenberg2008.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.10.11}
}

@INPROCEEDINGS{Bodart1995,
  author = {François Bodart and Anne-Marie Hennebert and Jean-Marie Leheureux
	and Isabelle Provot and Benoît Sacré and Jean Vanderdonckt},
  title = {Towards a Systematic Building of Software Architecture: the TRIDENT
	Methodological Guide},
  booktitle = {Proceedings of Eurographics Workshop on Design, Specification, Verification
	of Interactive Systems DSV-IS'95},
  year = {1995},
  editor = {R. Bastide and Ph. Palanque},
  series = {Eurographics Series},
  pages = {237-253},
  month = {June},
  abstract = {When designers are facing the question how to build an application
	architecture practically, they often have to consider various arguments
	and factors coming from different perspectives: decomposition criteria
	in architecture design, dialog independence in user interface (UI)
	design, methodology to follow in a development team. These factors
	are not easy to conciliate, forcing designers to make trade offs
	or unbalanced choices. In this paper, we discuss an architecture
	model, which is part of TRIDENT project, that addresses these issues.
	It consists of a generic architecture model for highly interactive
	business oriented applications. It is accompanied with a practical
	task-based methodology for building an architecture that automatically
	preserves desired criteria. Assumptions made for the architecture
	model, its content and the semantics of relationships are explained.
	The systematic approach is exemplified by a complete architecture
	case throughout the paper. Software Architecture Analysis Method
	(SAAM) is finally applied to prove the benefits of this architecture
	and to evaluate it with respect to relevant criteria. This paper
	suggest first steps towards a systematic building of a software architecture.},
  file = {:./literature/Bodart-DSVIS95.pdf:PDF},
  keywords = {generic architecture model, task-based methodology, SAAM, systematic
	software architecture},
  owner = {Stephan},
  timestamp = {2008.04.14},
  url = {http://www.isys.ucl.ac.be/bchi/members/jva/pub/Bodart-DSVIS95.pdf}
}

@PHDTHESIS{Bode2011b,
  author = {Stephan Bode},
  title = {Quality goal oriented architectural design and traceability for evolvable
	software systems},
  school = {Ilmenau University of Technology},
  year = {2011},
  month = {April},
  file = {:./literature/PhD_10.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.10.17}
}

@INPROCEEDINGS{Bode2009b,
  author = {Bode, Stephan},
  title = {On the Role of Evolvability for Architectural Design},
  booktitle = {Workshop Modellierung und Beherrschung der Komplexit\"at, Informatik
	2009},
  year = {2009},
  series = {LNI},
  pages = {3256-3263},
  address = {Bonn},
  publisher = {Koellen},
  abstract = {Today software systems have to face frequent requests for change during
	their whole lifetime. It is very important that they can adapt to
	the frequently changing needs and are flexible for new features in
	order to remain useful and to conserve business value. This ability
	of software systems, known as evolvability, does still not gain the
	attention it deserves. This paper discusses, why evolvability has
	to be explicitly considered during the design of software architectures
	and why the current practice with focus on maintainability during
	software evolution is insufficient. Furthermore, some advice for
	tackling the problem is given.},
  file = {:./literature/OnTheroleOfEvolvability090630.pdf:PDF},
  keywords = {software evolution, software evolvability, maintainability, architectural
	design},
  owner = {Stephan},
  timestamp = {2009.10.15}
}

@MASTERSTHESIS{Bode2008,
  author = {Stephan Bode},
  title = {{Traceability und Entwurfsentscheidungen f\"ur Softwarearchitekturen
	mit der Quasar-Methode}},
  school = {Ilmenau University of Technology},
  year = {2008},
  type = {Diploma Thesis},
  address = {Ilmenau, Germany},
  abstract = {Zusammenfassung:
	
	Die Wartung von Software spielt heutzutage eine wichtige Rolle, da
	bestehende Systeme häufig an sich ändernde Bedürfnisse und Anforderungen
	angepasst werden müssen. Mit dem Konzept der Traceability können
	Entwicklungsschritte eines Softwaresystems nachvollzogen werden,
	indem die Artefakte der verschiedenen Schritte über Traceability-Links
	miteinander verknüpft werden.In der vorliegenden Arbeit wird das
	Vorgehen nach der Architekturentwurfsmethode Quasar kritisch untersucht.
	Quasar bietet unzureichende Unterstützung für die Erstellung von
	graphischen Benutzerschnittstellen und wird diesbezüglich erweitert.
	Die einzelnen Aktivitäten von Quasar werden außerdem durch zusätzliche
	Aktivitäten verfeinert, um ein präzise beschriebenes Vorgehen zu
	erreichen. Zusätzlich wird Quasar um eine Zuordnung von Traceability-Links
	ergänzt. Die Architektur der grafischen Benutzerschnittstelle der
	Beispielanwendung eines betrieblichen Informationssystems wird unter
	Verwendung der erweiterten Quasar-Methode sowie auf Basis des SalesPoint-Frameworks
	neu entwickelt. Die getroffenen Entwurfsentscheidungen werden dokumentiert
	und Traceability-Links erstellt. Besondere Beachtung bei der Erstellung
	der Benutzerschnittstelle wird auch der Einhaltung von softwareergonomischen
	Richtlinien geschenkt, um gute Ergonomie zu erreichen. Die weiterentwickelte
	Methode wird bei der Entwicklung dieser Beispielanwendung eingesetzt
	und dabei evaluiert.
	
	
	Abstract:
	
	Today software maintenance plays an important role for the success
	of software development projects, because existing systems have to
	be adapted to frequently changing needs and requirements. The concept
	of traceability helps to understand the development activities during
	the changes of a software system by linking the different artifacts
	via traceability links. However, traceability has to be integrated
	into the design methods.In this thesis the development steps of the
	architectural design method Quasar are evaluated. The Quasar method
	provides only a low support for the design of graphical user interfaces
	and therefore, it is extended concerning this aspect. The activities
	of Quasar are refined by additional activities to fill the gaps in
	the method and to facilitate traceability. The extended Quasar method
	is applied for the development of the architecture and the graphical
	user interface of a business information system. The design decisions
	in this process are described and the corresponding traceability
	links are established. A special emphasis while designing the user
	interface is also placed on the consideration of usability guidelines
	and principles. The extended method is evaluated during the development
	activities for the business information system.},
  file = {:./literature/Traceability_und_Entwurfsentscheidungen_mit_Quasar.pdf:PDF},
  keywords = {software architecture, categories, usability, traceability, Quasar,
	software engineering, architectural design, GUI, graphical user interface;
	Softwareentwicklung, Softwarewartung, Betriebliches Informationssystem,
	Rückverfolgbarkeit, Graphische Benutzeroberfläche},
  owner = {Stephan},
  timestamp = {2008.07.16},
  url = {http://www.db-thueringen.de/servlets/DocumentServlet?id=10073}
}

@INPROCEEDINGS{Bode2009a,
  author = {Bode, Stephan and Fischer, Anja and K\"uhnhauser, Winfried E. and
	Riebisch, M.},
  title = {Software Architectural Design meets Security Engineering},
  booktitle = {Proceedings 16th International Conference and Workshop on the Engineering
	of Computer Based Systems (ECBS 2009)},
  year = {2009},
  pages = {109-118},
  month = {April},
  publisher = {IEEE},
  abstract = {Security requirements strongly influence the architectural design
	of complex IT systems in a similar way as other non-functional requirements.
	Both security engineering as well as software engineering provide
	methods to deal with such requirements. However, there is still a
	critical gap concerning the integration of the methods of these separate
	fields. 
	
	In this paper we close this gap with respect to security requirements
	by proposing a method that combines software engineering approaches
	with state-of-the-art security engineering principles. This method
	establishes an explicit alignment between the non-functional goal,
	the principles in the field of security engineering, and the implementation
	of a security architecture. The method aims at designing a system's
	security architecture based on a small, precisely defined, and application-specific
	trusted computing base. We illustrate this method by means of a case
	study which describes distributed enterprise resource planning systems
	using web services to implement business processes across company
	boundaries.},
  file = {:./literature/bode_SWADesignSecurityEng.pdf:PDF},
  keywords = {software architecture, architectural design, security engineering,
	non-functional requirement, goal solution scheme},
  owner = {Stephan},
  timestamp = {2009.04.29},
  url = {http://www.theoinf.tu-ilmenau.de/~sbode/publications/bode_SWADesignSecurityEng.pdf}
}

@INPROCEEDINGS{Bode2011a,
  author = {Stephan Bode and Steffen Lehnert and Matthias Riebisch},
  title = {Comprehensive Model Integration for Dependency Identification with
	{EMFTrace}},
  booktitle = {1st Intl. Workshop on Model-Driven Software Migration (MDSM 2011)
	and the 5th Intl. Workshop on Software Quality and Maintainability
	(SQM 2011)},
  year = {2011},
  pages = {17-20},
  file = {:./literature/Bode_ModelIntegrationEMFTrace.pdf:PDF},
  keywords = {model dependencies, model integration, model repository, meta model,
	traceability},
  owner = {Stephan},
  timestamp = {2011.02.07}
}

@INPROCEEDINGS{BabarICSE2005, 
author={Al-Naeem, T. and Gorton, I. and Babar, M.A. and Rabhi, F. and Benatallah, B.}, 
booktitle={Software Engineering, 2005. ICSE 2005. Proceedings. 27th International Conference on}, 
title={A quality-driven systematic approach for architecting distributed software applications}, 
year={2005}, 
month={May}, 
pages={244-253}, 
keywords={distributed processing;software architecture;software quality;distributed software application architecting;optimization;quality-driven systematic approach;software architecture design;software quality;Application software;Australia;Computer architecture;Costs;Design engineering;Design optimization;Process design;Software architecture;Software design;Software quality}, 
doi={10.1109/ICSE.2005.1553567},}

@INPROCEEDINGS{Bode2010,
  author = {Bode, Stephan and Riebisch, Matthias},
  title = {Impact Evaluation for Quality-Oriented Architectural Decisions regarding
	Evolvability},
  booktitle = {Proceedings 4th European Conference on Software Architecture, ECSA
	2010},
  year = {2010},
  editor = {Babar, Muhammad and Gorton, Ian},
  volume = {6285},
  series = {LNCS},
  pages = {182-197},
  publisher = {Springer Berlin / Heidelberg},
  note = {(acceptance rate: 25\%)},
  abstract = {Quality goals have to be under a special consideration during software
	architectural design. Evolvability constitutes a quality goal with
	a special relevance for business critical systems. Architectural
	patterns can significantly contribute to the satisfaction of quality
	goals. But architectural design decisions regarding these goals have
	to be made in a systematic, methodical way and concerning the patterns’
	influence on quality properties. Unfortunately, pattern catalogs
	do not well support quality goal-oriented design decisions. This
	paper presents a systematic refinement and mapping of the quality
	goal evolvability to properties for good architectural design. A
	set of architectural patterns is evaluated regarding these properties.
	Furthermore, a calculation scheme is provided that enables the evaluation
	of the patterns to support design decisions. The results have been
	developed, revised, and evaluated in a series of applications based
	on industrial expertise.},
  affiliation = {Ilmenau University of Technology, P.O. Box 10 05 65, 98684 Ilmenau,
	Germany},
  doi = {10.1007/978-3-642-15114-9_15},
  file = {:./literature/BodeECSA2010.pdf:PDF},
  keywords = {evolvability, architectural design, goal-oriented, impact evaluation,
	architectural pattern},
  owner = {Stephan},
  timestamp = {2010.10.04},
  url = {http://dx.doi.org/10.1007/978-3-642-15114-9_15}
}

@INPROCEEDINGS{Bode2009,
  author = {Bode, Stephan and Riebisch, M.},
  title = {Tracing Quality-Related Design Decisions in a Category-Driven Software
	Architecture.},
  booktitle = {Software Engineering 2009},
  year = {2009},
  editor = {Peter Liggesmeyer and Gregor Engels and J\"{u}rgen M\"{u}nch and
	J\"{o}rg D\"{o}rr and Norman Riegel},
  volume = {P-143},
  series = {LNI},
  pages = {87-98},
  address = {Bonn},
  publisher = {K\"{o}llen},
  abstract = {Quality properties, so-called non-functional ones, have a fundamental
	influence on the development of software systems because they constitute
	the decisive factors for the design of a system's software architecture.
	They earn a similar consideration like functional properties. For
	a high evolvability of the software systems, traceability supports
	changes by facilitating design decisions, software comprehension
	and coverage checks. In this paper a method for design traceability
	is presented, in which links both for functional and quality properties
	are established in similar ways. A software category based design
	method is used for a better alignment between requirements and design.
	As a consequence, the method leads to a reduced number of traceability
	links. The method has been successfully applied in the development
	and partial reengineering of an e-commerce system.},
  file = {:./literature/bode_SE2009.pdf:PDF},
  keywords = {traceability, non-functional requirement, quality requirements, usability,
	Quasar, design decisions, architectural design, software categories,
	goal solution scheme},
  owner = {Stephan},
  timestamp = {2009.04.29},
  url = {http://www.theoinf.tu-ilmenau.de/~sbode/publications/bode_SE2009.pdf}
}

@INCOLLECTION{Bode2011,
  author = {Stephan Bode and Matthias Riebisch},
  title = {Tracing the Implementation of Non-Functional Requirements},
  booktitle = {Non-Functional Properties in Service-Oriented Architecture: Requirements,
	Models and Methods},
  publisher = {IGI Global},
  year = {2011},
  editor = {Nikola Milanovic},
  month = {to appear},
  owner = {Stephan},
  timestamp = {2010.11.01}
}

@INPROCEEDINGS{Bode2008a,
  author = {Stephan Bode and Matthias Riebisch},
  title = {Usability-Focused Architectural Design for Graphical User Interface
	Components},
  booktitle = {Proceedings International Conference on Innovation in Software Engineering
	(ISE08)},
  year = {2008},
  pages = {1236-1241},
  publisher = {IEEE},
  file = {:./literature/bode-GUIComponentDesign.pdf:PDF},
  owner = {Stephan},
  timestamp = {2011.02.10}
}

@INPROCEEDINGS{Boehm2006,
  author = {Boehm, Barry},
  title = {A view of 20th and 21st century software engineering},
  booktitle = {Proceedings of the 28th international conference on Software engineering},
  year = {2006},
  series = {ICSE '06},
  pages = {12--29},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {10.1145/1134285.1134288},
  file = {:./literature/Viewof20thand21stCenturySE-Boehm2006.pdf:PDF},
  isbn = {1-59593-375-1},
  keywords = {software engineering, software futures, software history},
  location = {Shanghai, China},
  numpages = {18},
  owner = {matthias},
  timestamp = {2013.05.28},
  url = {http://sunset.usc.edu/events/2006/CSSE_Convocation/publications/BoehmViewof20thand21stCenturySE.pdf}
}

@BOOK{Boehm1978,
  title = {Characteristics of Software Quality},
  publisher = {North-Holland},
  year = {1978},
  author = {B.W. Boehm and J.R. Brown and M. Lipow and G.J. MacLeod and M.J.
	Merritt},
  address = {Amsterdam},
  keywords = {software quality, quality attributes},
  owner = {Stephan},
  timestamp = {2008.10.31}
}

@ARTICLE{Boehm1996,
  author = {Boehm, B. and In, H.},
  title = {Identifying quality-requirement conflicts},
  journal = {IEEE Software},
  year = {1996},
  volume = {13},
  pages = {25-35},
  number = {2},
  month = {Mar},
  abstract = {Without a well-defined set of quality-attribute requirements, software
	projects are vulnerable to failure. The authors have developed QARCC,
	a knowledge-based tool that helps users, developers, and customers
	analyze requirements and identify conflicts among them.},
  doi = {10.1109/52.506460},
  file = {:./literature/00506460.pdf:PDF;non-published layout, better quality:./literature/icre96v5.5-1.pdf:PDF},
  issn = {0740-7459},
  keywords = {formal specification, knowledge based systems, project management,
	software development management, software quality, software tools,
	systems analysis QARCC, knowledge-based tool, project failure, quality-attribute
	requirements, quality-requirement conflicts, requirements engineering,
	software projects},
  owner = {Stephan},
  timestamp = {2008.06.05},
  url = {http://courses.cs.tamu.edu/cpsc689/hohin/cpsc608/notes/icre96v5.5.pdf}
}

@ARTICLE{Boehm1988,
  author = {Boehm, B.W. and Papaccio, P.N.},
  title = {Understanding and controlling software costs},
  journal = {Software Engineering, IEEE Transactions on},
  year = {1988},
  volume = {14},
  pages = {1462--1477},
  number = {10},
  file = {Boehm1988.pdf:literature/Boehm1988.pdf:PDF},
  owner = {patrickr},
  publisher = {IEEE},
  timestamp = {2013.01.02}
}

@INPROCEEDINGS{Boehm1976,
  author = {B. W. Boehm and J. R. Brown and M. Lipow},
  title = {Quantitative evaluation of software quality},
  booktitle = {Proceedings of the 2nd international Conference on Software Engineering,
	(ICSE '76)},
  year = {1976},
  pages = {592-605},
  publisher = {IEEE},
  abstract = {The study reported in this paper establishes a conceptual framework
	and some key initial results in the analysis of the characteristics
	of software quality. Its main results and conclusions are: • Explicit
	attention to characteristics of software quality can lead to significant
	savings in software life-cycle costs. • The current software state-of-the-art
	imposes specific limitations on our ability to automatically and
	quantitatively evaluate the quality of software. • A definitive hierarchy
	of well-defined, well-differentiated characteristics of software
	quality is developed. Its higher-level structure reflects the actual
	uses to which software quality evaluation would be put; its lower-level
	characteristics are closely correlated with actual software metric
	evaluations which can be performed. • A large number of software
	quality-evaluation metrics have been defined, classified, and evaluated
	with respect to their potential benefits, quantifiability, and ease
	of automation. •Particular software life-cycle activities have been
	identified which have significant leverage on software quality. Most
	importantly, we believe that the study reported in this paper provides
	for the first time a clear, well-defined framework for assessing
	the often slippery issues associated with software quality, via the
	consistent and mutually supportive sets of definitions, distinctions,
	guidelines, and experiences cited. This framework is certainly not
	complete, but it has been brought to a point sufficient to serve
	as a viable basis for future refinements and extensions.},
  file = {:./literature/Boehm1976QuantitativeEvaluationOfSoftwareQuality.pdf:PDF},
  keywords = {software engineering, quality assurance, software quality, software
	measurement and evaluation, quality metrics, quality characteristics,
	management by objectives, software standards, software reliability},
  location = {San Francisco, California, United States},
  owner = {Stephan},
  timestamp = {2008.07.19},
  url = {http://portal.acm.org/citation.cfm?id=807736}
}

@INPROCEEDINGS{deBoer2005,
  author = {de Boer, F.S. and Bonsangue, M.M. and Groenewegen, L.P.J. and Stam,
	A.W. and Stevens, S. and van der Torre, L.},
  title = {Change Impact Analysis of Enterprise Architectures},
  booktitle = {Proceedings of the IEEE International Conference on Information Reuse
	and Integration (IRI)},
  year = {2005},
  pages = {177-181},
  month = {August},
  file = {:./literature/Paper_119.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- enterprise architecture combine organization structure, business
	procesess and architecture
	
	- single change affect many domains of enterprise architecture
	
	
	Research Questions:
	
	- how can architect master ripple-effects which spread across all
	domains
	
	
	Contribution:
	
	- approach which allows architect to assess effect of change on enterprise
	architecture
	
	- allows to identify potential impacts before change takes place
	
	
	Solution:
	
	- approach based on ArchiMate-model which provides descriptions
	
	* mix of Testbed (business language) and UML concepts at a very general
	level
	
	* use business layer, application layer and technology layer
	
	- distinguish between different kinds of change
	
	- propagate changes through the graph (relations between artifacts
	= edges), possible nodes:
	
	* role = collection of respomsibilities
	
	* process = assign roles to processes which fullfil them
	
	* component = processes are realized by software components
	
	- propagation depends on type of change and type of relation
	
	-> granularity of entities: component, process, data object
	
	-> granularity of changes: remove, add, modify
	
	-> granularity of results: component, process, data object
	
	
	Open Issues:
	
	- refine specification of change for better understanding of riplpe-effects
	
	- combination of IA with temporal logics to reason about impact on
	process},
  timestamp = {2011.04.01}
}

@ARTICLE{Boger2003,
  author = {Boger, Marko and Sturm, Thorsten and Fragemann, Per},
  title = {Refactoring Browser for {UML}},
  journal = {Lecture Notes in Computer Science},
  year = {2003},
  volume = {2591},
  pages = {366-377},
  file = {:./literature/Paper_187.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.11.01}
}

@INPROCEEDINGS{Bohner2002a,
  author = {Bohner, Shawn A.},
  title = {Extending Software Change Impact Analysis into {COTS} Components},
  booktitle = {Proceedings of the Annual NASA Goddard Software Engineering Workshop},
  year = {2002},
  pages = {175-182},
  file = {:./literature/Paper_1.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- no IA for middleware and commercial-off-the-shelf software (COTS)
	
	- IA must be expanded on those since new software consists of many
	reused parts/components
	
	
	Research Questions:
	
	- perform structural analysis on components to identify dependencies
	
	- how to cope with impact explosion after IA
	
	
	Contribution:
	
	- examine / expand existing reearch into IA for distributed / composed
	systems
	
	
	Solution:
	
	- build a dependency graph which connects entities
	
	- use reachability matrix for dependencies
	
	- introduce distance measure for impacts to reduce false positives
	
	-> granularity of entities: no details
	
	-> granularity of changes: no details
	
	-> granularity of results: no details
	
	
	Open Issues:
	
	- impact visualization
	
	- utilizing 3D techniques seems most promising},
  timestamp = {2011.01.01}
}

@INPROCEEDINGS{Bohner2002b,
  author = {Bohner, S. A.},
  title = {Software change impacts-an evolving perspective},
  booktitle = {Proceedings of the International Conference on Software Maintenance},
  year = {2002},
  pages = {263-272},
  file = {:./literature/Paper_134.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- distributed software composed of components, middleware introduce
	new challenge for IA
	
	- current IA techniques not helpful for such environments
	
	- dependency graphs of such software systems are beyond comprehension
	
	
	Research Questions:
	
	- how to extend current IA techniques into COTS/middleware based systems
	
	- how to visualize the large dependency webs of such software
	
	
	Contribution:
	
	- literature review on IA for software composed of components, middleware
	etc.
	
	- exploration of 3D vizualization for better comprehension
	
	
	Solution:
	
	==> same as [Bohner2002a]
	
	- use semantics between code entities to guide impact propagation
	
	- utilize XML to conduct IA on COTS and web services
	
	-> granularity of entities: no details
	
	-> granularity of changes: no details
	
	-> granularity of results: no details
	
	
	Open Issues:
	
	- implement 3D technique into IA approach},
  timestamp = {2011.04.04}
}

@INPROCEEDINGS{Bohner1996b,
  author = {Bohner, Shawn A.},
  title = {Impact analysis in the software change process: a year 2000 perspective},
  booktitle = {Proceedings of the 12th International Conference on Software Maintenance
	(ICSM'96)},
  year = {1996},
  pages = {42-51},
  address = {Monterey, CA},
  month = {November},
  file = {:./literature/Paper_146.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- larger software with more dependencies inbetween
	
	- change efforts plaqued with different estimations of changes etc.
	
	
	Research Questions:
	
	- where is IA applied during evolution
	
	- how is IA addressed in software process
	
	
	Contribution:
	
	- examination of where and how IA is applied during software evolution
	
	- developed model for software change process
	
	
	Results of "literature review":
	
	- changing requirements are standard
	
	- software has to change to adopt
	
	- without IA, changes can have unpredictable affects
	
	- several maintenance models developed
	
	-> model to understand software change process
	
	-> model to manage software change
	
	-> model to understand impact determination
	
	-> model to understand impact identification
	
	-> model to design software change
	
	-> model to implement software change
	
	-> model to test affected software
	
	
	Open Issues:},
  timestamp = {2011.04.04}
}

@PHDTHESIS{Bohner1995,
  author = {Bohner, Shawn A.},
  title = {A graph traceability approach for software change impact analysis},
  school = {George Mason University},
  year = {1995},
  address = {Fairfax, VA, USA},
  owner = {Steffen},
  timestamp = {2011.03.14}
}

@BOOK{Bohner1996a,
  title = {Software Change Impact Analysis},
  publisher = {IEEE Computer Society Publications Tutorial Series},
  year = {1996},
  author = {Bohner, Shawn A. and Arnold, Robert S.},
  pages = {376},
  address = {Los Alamitos, CA, USA},
  owner = {Steffen},
  timestamp = {2011.02.17}
}

@INPROCEEDINGS{Bohner2003,
  author = {Bohner, Shawn A. and Gracanin, Denis},
  title = {Software Impact Analysis in a Virtual Environment},
  booktitle = {Proceedings of the 28th Annual NASA Goddard Software Engineering
	Workshop},
  year = {2003},
  pages = {143-151},
  month = {December},
  file = {:./literature/Paper_88.pdf:PDF},
  owner = {Steffen},
  review = {/*
	
	 paper names some interesting IA examples:
	
	- year 2000 date conversion
	
	- Euro currency conversion
	
	*/
	
	
	--> this paper highlights research questions and state-of-the-art
	so there is no "solution" / "own contribution" in that sense
	
	
	Problem:
	
	- automated support for visualizing software inevitable for (modern)
	large scale software systems
	
	- increasing amount of packaged software / components decreases efficiency
	of trad. IA approaches due to too large "dependency webs"
	
	
	Research Questions:
	
	- incorporate architecture dependeny into IA
	
	- involve entire development process into IA (requirements, design,
	test)
	
	- visualization of software
	
	
	Contribution:
	
	- introduction to software change, change impact, impact analysis
	and software visualization
	
	- standard 2D techniques for visualization not suitable for large
	systems
	
	* additions like zoom and fisheye do not help that much
	
	- 3D techniques considered useful for large scale software
	
	- virtual environments offer additional support for visualization
	and they provide new concepts (landscapes, cities -> well known to
	humans)
	
	
	Solution:
	
	- extend IA across major software lifecyle objects
	
	- use 3D visualization and navigation to model dependencies
	
	- combine architecture / component information with source code dependencies
	and traceability
	
	- apply slicing algorithms on this dependency network
	
	- implemented in 3D prototype
	
	-> granularity of entities: no details given
	
	-> granularity of changes: no details given
	
	-> granularity of results: no details given},
  timestamp = {2011.02.23}
}

@PHDTHESIS{Boellert2002,
  author = {Kai Böllert},
  title = {Objektorientierte Entwicklung von Software-Produktlinien zur Serienfertigung
	von Software-Systemen},
  school = {Technische Universität Ilmenau},
  year = {2002},
  file = {:./literature/DissertationKaib.pdf:PDF},
  keywords = {software product line, FeatuRSEB, Hyperspace, Hyper/J, Hyper/UML},
  owner = {Stephan},
  timestamp = {2009.02.11}
}

@INPROCEEDINGS{Bondi2000,
  author = {Andr\'{e} B. Bondi},
  title = {Characteristics of scalability and their impact on performance},
  booktitle = {Proceedings of the 2nd International Workshop on Software and Performance
	(WOSP '00)},
  year = {2000},
  pages = {195-203},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Scalability is a desirable attribute of a network, system, or process.
	Poor scalability can result in poor system performance, necessitating
	the reengineering or duplication of systems. While scalability is
	valued, its characteristics and the characteristics that undermine
	it are usually only apparent from the context. Here, we attempt to
	define different aspects of scalability, such as structural scalability
	and load scalability. Structural scalability is the ability of a
	system to expand in a chosen dimension without major modifications
	to its architecture. Load scalability is the ability of a system
	to perform gracefully as the offered traffic increases. It is argued
	that systems with poor load scalability may exhibit it because they
	repeatedly engage in wasteful activity, because they are encumbered
	with poor scheduling algorithms, because they cannot fully take advantage
	of parallelism, or because they are algorithmically inefficient.
	We qualitatively illustrate these concepts with classical examples
	from the literature of operating systems and local area networks,
	as well as an example of our own. Some of these areaccompanied by
	rudimentary delay analysis.},
  doi = {http://doi.acm.org/10.1145/350391.350432},
  file = {:./literature/ScalabilityPerformance-p195-bondi.pdf:PDF},
  isbn = {1-58113-195-X},
  keywords = {quality attributes, scalability, performance},
  location = {Ottawa, Ontario, Canada},
  owner = {Stephan},
  timestamp = {2008.10.09}
}

@BOOK{Booch1994,
  title = {Object Oriented Analysis and Design With Applications},
  publisher = {{Addison-Wesley} Longman, Amsterdam},
  year = {1994},
  author = {Grady Booch},
  edition = {2nd},
  month = {October},
  file = {:./literature/Book_1.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.06.11}
}

@INPROCEEDINGS{Borg2013a,
  author = {Borg, Markus and Gotel, Orlena and Wnuk, Krzysztof},
  title = {Enabling traceability reuse for impact analyses - A feasibility study
	in a safety context},
  booktitle = {Proceedings of the 7th International Workshop on Traceability in
	Emerging Forms of Software Engineering (TEFSE 2013)},
  year = {2013},
  file = {:./literature/Paper_262.pdf:PDF},
  owner = {Steffen},
  timestamp = {2013.03.19}
}

@INPROCEEDINGS{Bosch2004,
  author = {Bosch, Jan},
  title = {Software Architecture: The Next Step.},
  booktitle = {EWSA},
  year = {2004},
  editor = {Oquendo, Flávio and Warboys, Brian and Morrison, Ronald},
  volume = {3047},
  series = {Lecture Notes in Computer Science},
  pages = {194-199},
  publisher = {Springer Berlin Heidelberg},
  ee = {http://dx.doi.org/10.1007/978-3-540-24769-2_14},
  interhash = {ee4c75f466c12c720dbf017c47a0f216},
  intrahash = {4539851c8fc944af58caa0cc7cccb3e5},
  isbn = {3-540-22000-3},
  keywords = {dblp},
  owner = {Sebastian},
  timestamp = {2011-07-07T00:00:00.000+0200},
  url = {http://dblp.uni-trier.de/db/conf/ewsa/ewsa2004.html#Bosch04}
}

@BOOK{Bosch2000,
  title = {Design and use of software architectures: Adopting and evolving a
	product-line approach},
  publisher = {ACM Press/Addison-Wesley},
  year = {2000},
  author = {Jan Bosch},
  pages = {354},
  address = {New York, NY, USA},
  isbn = {0-201-67494-7},
  keywords = {software architecture, software design, functional requirements, non-functional
	requirements, product-line},
  owner = {Stephan},
  timestamp = {2008.07.03},
  url = {http://books.google.de/books?hl=de&lr=&id=FDfyWknLvMYC&oi=fnd&pg=PP11&ots=KQP2lipY0_&sig=AfKzOFZ4Z-Wl6PAXSkpoFIN7nUA}
}

@book{BassBook2012,
 author = {Bass, Len and Clements, Paul and Kazman, Rick},
 title = {Software Architecture in Practice},
 year = {2012},
 isbn = {0321815734, 9780321815736},
 edition = {3rd},
 publisher = {Addison-Wesley Professional},
}

@ARTICLE{LagoConcerns, 
author={Lago, P. and Avgeriou, P. and Hilliard, R.}, 
journal={Software, IEEE}, 
title={Guest Editors' Introduction: Software Architecture: Framing Stakeholders' Concerns}, 
year={2010}, 
month={Nov}, 
volume={27}, 
number={6}, 
pages={20-24}, 
keywords={Investments;Product life cycle management;Software architecture;Software development;Special issues and sections;architecture;framework;software development;software life cycle;stakeholder concerns;viewpoints}, 
doi={10.1109/MS.2010.142}, 
ISSN={0740-7459},}



@INPROCEEDINGS{AvgeriouForces, 
author={van Heesch, U. and Avgeriou, P. and Hilliard, R.}, 
booktitle={Software Architecture (WICSA) and European Conference on Software Architecture (ECSA), 2012 Joint Working IEEE/IFIP Conference on}, 
title={Forces on Architecture Decisions - A Viewpoint}, 
year={2012}, 
month={Aug}, 
pages={101-110}, 
keywords={software architecture;system documentation;architecture decision;decision force viewpoint;documentation approach;standard ISO/IEC/IEEE 42010;Computer architecture;Documentation;Force;IEC standards;ISO;Software;Software architecture;ISO/IEC/IEEE 42010;Software architecture;architecture decisions;forces}, 
doi={10.1109/WICSA-ECSA.212.18},}

@book{seidman2006interviewing,
  title={Interviewing as Qualitative Research: A Guide for Researchers in Education and the Social Sciences},
  author={Seidman, I.},
  isbn={9780807746660},
  lccn={90028645},
  url={http://books.google.de/books?id=pk1Rmq-Y15QC},
  year={2006},
  publisher={Teachers College Press}
}

@INPROCEEDINGS{Bosch2003,
  author = {Bosch, J. and Juristo, N.},
  title = {Designing software architectures for usability},
  booktitle = {Proceedings. 25th International Conference on Software Engineering},
  year = {2003},
  pages = {757-758},
  month = {3-10 May},
  publisher = {IEEE Xplore},
  abstract = {Usability is increasingly recognized as a quality attribute that one
	has to design for. The conventional alternative is to measure usability
	on a finished system and improve it. The disadvantage of this approach
	is, obviously, that the cost associated with implementing usability
	improvements in a fully implemented system are typically very high
	and prohibit improvements with architectural impact. In this tutorial,
	we present the insights gained, techniques developed and lessons
	learned in the EU-IST project STATUS (SofTware Architectures That
	supports USability). These include a forward-engineering perspective
	on usability, a technique for specifying usability requirements,
	a method for assessing software architectures for usability and,
	finally, for improving software architectures for usability. The
	topics are extensively illustrated by examples and experiences from
	many industrial cases.},
  doi = {10.1109/ICSE.2003.1201273},
  file = {:./literature/01201273.pdf:PDF},
  issn = {0270-5257 },
  keywords = {formal specification, software architecture, software process improvement,
	software quality, software reusability EU-IST project, requirements
	specification, software architecture, software quality, software
	usability},
  owner = {Stephan},
  review = {- states that usability is important for software architecture
	
	- should be seen as other quality attributes, too
	
	-> techniques required for including usability in forward engineering
	
	
	interesting: STATUS project},
  timestamp = {2008.04.02}
}

@INPROCEEDINGS{Bosch1999,
  author = {Jan Bosch and Peter Molin and Jan Bosch and Peter Molin},
  title = {Software Architecture Design: Evaluation and Transformation},
  booktitle = {In 1999 IEEE Engineering of Computer Based Systems Symposium. IEEE
	Computer Based Systems},
  year = {1999},
  pages = {4--10},
  file = {:./literature/bosch1999.pdf:PDF},
  owner = {Sebastian},
  timestamp = {2013.07.24}
}

@MISC{Bouillon,
  author = {Elke Bouillon},
  title = {Umfrage zur Bestimmung von Nutzerszenarien f\"ur den Einsatz von
	Traceability},
  howpublished = {http://www.tu-ilmenau.de/fileadmin/media/sspi/Forschung/Umfrage.pdf},
  year = {2011},
  file = {:literature/UmfrageTraceability.pdf:PDF},
  owner = {elkeb},
  timestamp = {2011.12.14}
}

@ARTICLE{Bouillon2012,
  author = {Bouillon, E. and Philippow, I.},
  title = {Requirements-Traceability in der industriellen Praxis - Ziele und
	Einsatz},
  journal = {Softwaretechnik-Trends},
  year = {2012},
  volume = {32},
  number = {3},
  month = {August},
  file = {:literature/bouillon1.pdf:PDF},
  owner = {elkeb},
  timestamp = {2012.12.07},
  url = {http://pi.informatik.uni-siegen.de/stt/32_3/index.html}
}

@INPROCEEDINGS{Bouktif2006,
  author = {Bouktif, Salah and Gu\'{e}h\'{e}neuc, Yann-Ga\"{e}l and Antoniol,
	Giuliano},
  title = {Extracting Change-patterns from {CVS} Repositories},
  booktitle = {Proceedings of the 13th Working Conference on Reverse Engineering
	(WCRE '06)},
  year = {2006},
  pages = {221-230},
  address = {Benevento},
  month = {October},
  file = {:./literature/Paper_80.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- ofter there is no other information as the source code and version
	history
	
	- however, information stored in version control systems is vast
	
	
	Research Questions:
	
	- given a file under modification, what other files must change too
	
	
	Contribution:
	
	- approach for detecting change-patterns through dynamic time warping
	(based on pattern-recognition)
	
	- method proposes files that should co-change with a given change
	
	- definitions of change-patterns
	
	
	Solution:
	
	- use technique called "Dynamic TIme Warping" (DTW) [from pattern
	recognition] to identify groups of co-changing files
	
	- preprocess CVS data to gain windows of interest (time windows)
	
	- compute distance between files within window
	
	- use distance to filter unlikely files
	
	= clustering
	
	- change patterns embody relationships among changes
	
	* required for guiding maintainers (complete, consistent changes)
	
	- basic assumption of approach:
	
	* if two files often change together at the "same time", they are
	likely to change together in future as well
	
	- use "second" as finest granularity of time and "files" as artifacts
	under consideration
	
	- change pattern extraction consists of 3 steps:
	
	* extraction of data from CVS
	
	 - produce a detailed change log in XML
	
	 - each log is list of moments in time where files were added/removed/changed
	
	* transform data by computing appropriate time window to limit the
	effect of past changes
	
	 - length of window can be determined in 2 ways:
	
	 * impose a fixed distance in time ("changes not older than...")
	
	 * impose a fixed number of past changes ("the last X changes")
	
	* use DTW to identify change-patterns
	
	 - aligns each possible pair of file histories
	
	 - group histories together having a distance below a given threshold
	
	-> granularity of entities: files
	
	-> granularity of changes: changes to files
	
	-> granularity of results: files
	
	
	Open Issues:
	
	- use alternative clustering/grouping techniques
	
	- case study performed with files which were changed between 5 - 7
	times, larger histories truncated -> could miss frequent changing
	files},
  timestamp = {2011.02.23}
}

@INPROCEEDINGS{Bouwers2009,
  author = {E. Bouwers and J. Visser and A. van Deursen},
  title = {Criteria for the Evaluation of Implemented Architectures},
  booktitle = {Proceedings of the 25th International Conference on Software Maintenance
	(ICSM 2009)},
  year = {2009},
  editor = {Tao Xie and Kostas Kontogiannis},
  pages = {73-82},
  publisher = {IEEE},
  abstract = {Software architecture evaluation methods aim at identi- fying potential
	maintainability problems for a given archi- tecture. Several of these
	methods exist, which typically pre- scribe the structure of the evaluation
	process. Often left im- plicit, however, are the concrete system
	attributes that need to be studied in order to assess the maintainability
	of imple- mented architectures.
	
	To determine this set of attributes, we have performed an empirical
	study on over 40 commercial architectural eval- uations conducted
	during the past two years as part of a systematic “Software Risk
	Assessment”. We present this study and we explain how the identified
	attributes can be projected on various architectural system properties,
	which provides an overview of criteria for the evaluation of the
	maintainability of implemented software architectures.},
  file = {:./literature/Bouwers2009.pdf:PDF},
  group = {SE},
  keywords = {architectural maintainability, maintainability evaluation, architectural
	evaluation, industrial study},
  owner = {Stephan},
  project = {Reconstructor},
  review = {industrial case study on what are important architectural attributes
	for maintainability
	
	
	maintainability model based on ISO 9126 --> limited, not sufficient
	for evolution},
  timestamp = {2009.10.06},
  topic = {Software Evolution},
  url = {http://swerl.tudelft.nl/twiki/pub/Main/TechnicalReports/TUD-SERG-2009-018.pdf}
}

@ARTICLE{Bowers2002,
  author = {Bowers, J. and May, J. and Melander, E. and Baarman, M. and Ayoob,
	A.},
  title = {Tailoring XP for large system mission critical software development},
  journal = {Extreme Programming and Agile Methods—XP/Agile Universe 2002},
  year = {2002},
  pages = {269--301},
  file = {Bowers2002.pdf:literature/Bowers2002.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@ARTICLE{Gomaa1996,
  author = {Gomaa, H. and Menasce, D. and Kerschberg, A.},
  title = {Software Architectural Design Method for Large-Scale Distributed Information Systems},
  journal = {Journal of Distributed Systems Engineering},
  year = {1996},
  pages = {162--172},
  file = {Bowers2002.pdf:literature/Bowers2002.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@inproceedings{ZimmermanWebServiceRest,
 author = {Pautasso, Cesare and Zimmermann, Olaf and Leymann, Frank},
 title = {Restful Web Services vs. "Big"' Web Services: Making the Right Architectural Decision},
 booktitle = {Proceedings of the 17th International Conference on World Wide Web},
 series = {WWW '08},
 year = {2008},
 isbn = {978-1-60558-085-2},
 location = {Beijing, China},
 pages = {805--814},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1367497.1367606},
 doi = {10.1145/1367497.1367606},
 acmid = {1367606},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {HTTP, REST, SOAP, WS-* vs. REST, WSDL, architectural decision modeling, resource oriented architectures, service oriented architectures, technology comparison, web services},
}

@ARTICLE{CloudComparison, 
author={Ekanayake, J. and Gunarathne, T. and Qiu, J.}, 
journal={Parallel and Distributed Systems, IEEE Transactions on}, 
title={Cloud Technologies for Bioinformatics Applications}, 
year={2011}, 
month={June}, 
volume={22}, 
number={6}, 
pages={998-1011}, 
keywords={bioinformatics;cloud computing;message passing;scheduling;Apache Hadoop;MPI implementation;Microsoft DryadLINQ;bioinformatics;cloud technologies;expressed sequence tag;intertask communication;job schedulers;sequence assembly program;Bioinformatics;Clouds;Instruction sets;Matrix decomposition;Pipelines;Programming;Runtime;Distributed programming;parallel systems;performance;programming paradigms.}, 
doi={10.1109/TPDS.2010.178}, 
ISSN={1045-9219},}

@incollection{ZdunMiddelwareEv,
year={2001},
isbn={978-3-540-41792-7},
booktitle={Engineering Distributed Objects},
volume={1999},
series={Lecture Notes in Computer Science},
editor={Emmerich, Wolfgang and Tai, Stefan},
doi={10.1007/3-540-45254-0_3},
title={A Key Technology Evaluation Case Study: Applying a New Middleware Architecture on the Enterprise Scale},
url={http://dx.doi.org/10.1007/3-540-45254-0_3},
publisher={Springer Berlin Heidelberg},
author={Goedicke, Michael and Zdun, Uwe},
pages={8-26},
language={English}
}

@incollection{BigDataMedvidovic,
year={2011},
isbn={978-1-4614-1414-8},
booktitle={Handbook of Data Intensive Computing},
editor={Furht, Borko and Escalante, Armando},
doi={10.1007/978-1-4614-1415-5_2},
title={Architecting Data-Intensive Software Systems},
url={http://dx.doi.org/10.1007/978-1-4614-1415-5_2},
publisher={Springer New York},
author={Mattmann, ChrisA. and Crichton, DanielJ. and Hart, AndrewF. and Goodale, Cameron and Hughes, J.Steven and Kelly, Sean and Cinquini, Luca and Painter, ThomasH. and Lazio, Joseph and Waliser, Duane and Medvidovic, Nenad and Kim, Jinwon and Lean, Peter},
pages={25-57},
language={English}
}

@article{Ariyachandra2010200,
title = "Key organizational factors in data warehouse architecture selection ",
journal = "Decision Support Systems ",
volume = "49",
number = "2",
pages = "200 - 212",
year = "2010",
issn = "0167-9236",
doi = "http://dx.doi.org/10.1016/j.dss.2010.02.006",
url = "http://www.sciencedirect.com/science/article/pii/S0167923610000436",
author = "Thilini Ariyachandra and Hugh Watson",
}

@inproceedings{TangBiasing,
 author = {Tang, Antony},
 title = {Software Designers, Are You Biased?},
 booktitle = {Proceedings of the 6th International Workshop on SHAring and Reusing Architectural Knowledge},
 series = {SHARK '11},
 year = {2011},
 isbn = {978-1-4503-0596-9},
 location = {Waikiki, Honolulu, HI, USA},
 pages = {1--8},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1988676.1988678},
 doi = {10.1145/1988676.1988678},
 acmid = {1988678},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {cognitive bias, decisions, reasoning, software design},
}

@ARTICLE{TangReasoningStrategy, 
author={Tang, A. and van Vliet, H.}, 
journal={Software, IEEE}, 
title={Design Strategy and Software Design Effectiveness}, 
year={2012}, 
month={Jan}, 
volume={29}, 
number={1}, 
pages={51-55}, 
keywords={software engineering;breadth-first approach;depth-first approach;design strategy;design-space exploration;problem-driven approach;software design effectiveness;solution-driven approach;Complexity theory;Planning;Product development;Software design;Software engineering;design concepts;design tools and techniques;software engineering}, 
doi={10.1109/MS.2011.130}, 
ISSN={0740-7459},}

@MISC{Bowring01astudy,
  author = {James (Jim) Bowring and Jim Bowring},
  title = {A Study of the Impact of Implementation Quality on Regression Testing
	Both Conventional and Metacontent-Based},
  year = {2001},
  owner = {Steffen},
  timestamp = {2012.03.01}
}

@ARTICLE{Brady2004,
  author = {Brady, T. and Davies, A.},
  title = {Building project capabilities: from exploratory to exploitative learning},
  journal = {Organization Studies},
  year = {2004},
  volume = {25},
  pages = {1601--1621},
  number = {9},
  file = {Brady2004.pdf:literature/Brady2004.pdf:PDF},
  owner = {patrickr},
  publisher = {Sage Publications},
  timestamp = {2012.10.22}
}

@PHDTHESIS{Brcina2011,
  author = {Robert Brcina},
  title = {{Zielorientierte Erkennung und Behebung von Qualit\"atsdefiziten
	in Software-Systemen am Beispiel der Weiterentwicklungsf\"ahigkeit}},
  school = {Ilmenau University of Technology},
  year = {2011},
  note = {(to appear)},
  file = {:./literature/PhD_11.pdf:PDF},
  keywords = {evolvability, reengineering, quality deficiency},
  owner = {Stephan},
  timestamp = {2011.02.21}
}

@ARTICLE{Brcina2007,
  author = {Robert Brcina},
  title = {{T}raceability and {A}spects of a {T}raceability {P}rocess ({A}rbeiten
	zur {V}erfolgbarkeit und {A}spekte des {V}erfolgbarkeitsprozesses)},
  journal = {Softwaretechnik Trends},
  year = {2007},
  volume = {27},
  pages = {3-8},
  number = {1},
  abstract = {Verfolgbarkeitsmodelle spielen in bisherigen Arbeiten eine wichtige
	Rolle. So werden zum Beispiel Verfolgbarkeitsmodelle beschrieben,
	die unterschiedliche Projektanforderungen adressieren. Aus praktischer
	Sicht kann dabei die Wiederverwendung von Modellen die Effizienz
	des Verfolgbarkeitsprozesses steigern. Deswegen wird im Vergleich
	zu bisherigen Arbeiten die Nutzung von existierenden Konzepten als
	eigenständige Aktivität berücksichtigt. Bei komplexen Entwicklungspro
	jekten werden in der Regel Modelle verwendet, um Zusammenh¨ange sinnvoll
	darzustellen und das gemeinsame Verst¨andnis im Projekt zu fördern.
	Dies gilt auch für Verfolgbarkeitsmodelle. Es wird erläutert, welche
	Aufgaben Verfolgbarkeitsmodelle im Projekt haben und der bisher bekannte
	Verfolgbarkeitsprozess wird detailiert betrachtet und um Aktivitäten
	erweitert.},
  file = {:./literature/20060128_brcina_paper_traceability.pdf:PDF},
  issn = {0720-8928},
  keywords = {traceability},
  owner = {Robert},
  timestamp = {2006.11.01}
}

@INPROCEEDINGS{Brcina2009,
  author = {Brcina, Robert and Bode, Stephan and Riebisch, M.},
  title = {Optimization Process for Maintaining Evolvability during Software
	Evolution},
  booktitle = {Proceedings 16th International Conference and Workshop on the Engineering
	of Computer Based Systems (ECBS 2009)},
  year = {2009},
  pages = {196-205},
  month = {April},
  publisher = {IEEE},
  abstract = {Software systems have to be changed continuously and evolutionarily
	throughout the whole time of their development and usage. Meanwhile,
	the software systems have to remain flexible in order to retain the
	ability to be extended by additional new features or to be changed.
	To maintain this ability, known as evolvability, the architecture
	of such software systems and its evolution must be continuously controlled
	and, if necessary improved. Existing design methodologies do not
	provide sufficient support for controlling the evolvability. One
	reason for this is, that in comparison with software maintainability,
	evolvability characteristics are hardly defined. This paper discusses
	evolvability, and introduces a quality model for it. Furthermore,
	a meta-model-based process for controlling and optimising the evolvability
	characteristics of software baselines is presented. The feasibility
	of this approach is shown by a case study based on the results from
	its implementation in large industrial projects.},
  file = {:./literature/brcina_ecbs09_final.pdf:PDF},
  keywords = {software maintenance, maintainability, evolvability, software evolution,
	software process, metrics},
  owner = {Stephan},
  timestamp = {2009.04.29},
  url = {http://www.theoinf.tu-ilmenau.de/~sbode/publications/brcina_ecbs09_final.pdf}
}

@ARTICLE{Brcina2006,
  author = {Robert Brcina and Markus Prechtel},
  title = {{F}eature {D}riven {P}latform {D}evelopment and {T}raceability (in
	german: {F}eature-orientierte {P}lattformentwicklung und {V}erfolgbarkeit)},
  journal = {Softwaretechnik Trends},
  year = {2006},
  volume = {26},
  pages = {3-8},
  number = {4},
  abstract = {Der Gewinn durch Wiederverwendung bei der Softwareentwicklung ist
	ein wichtiger Aspekt für Unternehmen. Dieser wird oftmals anhand
	von Produktlinien- oder Plattformstrategien erhöht. Charakteristisch
	für solche Plattformansätze ist eine hohe Anzahl von Anforderungen,
	da unterschiedlichste Unternehmensanwendungen unterstützt werden
	müssen. Die Umsetzung der daraus abgeleiten Anforderungen an die
	Plattform erfordert ein intensives Management der Verfolgbarkeit.
	Häufig genutzt werden "Feature-Modelle", welche die Verfolgbarkeit
	der Anforderungen und Features berücksichtigen. In diesen Modellen
	wird allerdings oftmals die Integration von Features in Plattformen
	als wichtiges Glied zwischen Kunden und Entwicklungsteam nicht berücksichtigt.
	In dieser Arbeit werden ein erweitertes Feature-Modell und ein Konzept
	zur Verfolgbarkeit eingeführt, welche die Integration von Plattformen
	berücksichtigen. Darin wird aufgezeigt, welche Beziehungen zwischen
	verschiedenen Ebenen des Entwicklungsprozesses bestehen und die Auswirkungen
	auf Entwicklung und Test werden erörtert.},
  file = {:./literature/brcina-final.pdf:PDF},
  keywords = {feature-driven development, traceability},
  owner = {Robert},
  timestamp = {2006.11.01}
}

@INPROCEEDINGS{Breech2004,
  author = {Breech, B. and Danalis, A. and Shindo, Stacey and Pollock, Lori},
  title = {Online Impact Analysis via Dynamic Compilation Technology},
  booktitle = {Proceedings of the 20th IEEE International Conference of Software
	Maintenance},
  year = {2004},
  pages = {453-457},
  month = {September},
  file = {:./literature/Paper_40.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- static IA too expensive (both time & space)
	
	- dynamic IA without overhead useful for online IA "on the fly"
	
	
	Research Questions:
	
	- how to avoid extensive memory usage by computing traces as PathImpact
	does
	
	- utilize dynamic compiler technology to gather insights on program
	during execution
	
	
	Contribution:
	
	- approach for whole-program path based online IA
	
	
	Solution:
	
	- basic assumption: changes to methods will propagate down (as with
	all dynamic IA)
	
	- implemented into DynamoRIO (dyn. Compiler) and (Virtual Java Machine,
	JRVM) -> use dynamic compiler
	
	-> granularity of entities: methods
	
	-> granularity of changes: changes to methods
	
	-> granularity of results: methods
	
	
	Open Issues:
	
	- approach doesn't work for exceptions or abnormal termination (since
	no function calls to trace)},
  timestamp = {2011.02.04}
}

@INPROCEEDINGS{Breech2006,
  author = {Breech, Ben and Tegtmeyer, Mike and Pollock, Lori},
  title = {Integrating Influence Mechanisms into Impact Analysis for Increased
	Precision},
  booktitle = {Proceedings of the 22nd IEEE International Conference on Software
	Maintenance (ICSM '06)},
  year = {2006},
  pages = {55-65},
  address = {Philadelphia, PA},
  month = {December},
  file = {:./literature/Paper_56.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- fine-grained IA techniques to expensive (time & space) whereas coarse-grained
	techniques are to imprecise
	
	
	Research Questions:
	
	- achieve precision of static techniques while keeping speed of dynamic
	techniques
	
	
	Contribution:
	
	- new static and dynamic IA algorithms operating on method-level that
	increase precision while keeping costs low
	
	- take care of changes propagating through scoping and parameter passing
	
	
	Solution:
	
	- use static analysis to estimate propagation of change (while taking
	scoping, global variables and function signatures into account)
	
	- changes can only propagate through return values, parameters and
	global variables
	
	- establish a influence graph based on such changes (nodes provides
	egdes, whereas influences between functions are displayed as edges)
	
	- supports 3 kinds of edges:
	
	* value: passing values in or out
	
	* reference: passing ref. in or out
	
	* external: global variable access
	
	- perform static IA by computing the closure on the influence graph
	when starting from a certain point (i.e. function)
	
	- perform dynamic IA on influence graphs, i.e. maintain a influence
	set for each function; use this sets to propagate changes between
	method calls
	
	- improve dynamic IA by placed egdes between nodes effected by global
	variables (speedup, but decrease of precision)
	
	- algorithm is safe
	
	-> granularity of entities: methods
	
	-> granularity of changes: changes to methods
	
	-> granularity of results: methods
	
	
	Open Issues:
	
	- not evaluated with OOP designs, evaluated system have max. 25KLOC
	
	- CoverageImpact (which is better than PathImpact) not considered
	
	- gain of precision of only 3-5 %},
  timestamp = {2011.02.10}
}

@INPROCEEDINGS{Breech2005,
  author = {Breech, Ben and Tegtmeyer, Mike and Pollock, Lori},
  title = {A Comparison of Online and Dynamic Impact Analysis Algorithms},
  booktitle = {Proceedings of the European Conference on Software Maintenance and
	Reengineering},
  year = {2005},
  pages = {143-152},
  month = {March},
  file = {:./literature/Paper_31.pdf:PDF},
  owner = {Steffen},
  review = {goal of paper:
	
	- comparison of 2 online and 2 dynamic IA algorithms in terms of memory,
	computation time etc.
	
	
	dynamic:
	
	- path impact
	
	- coverage impact
	
	
	online:
	
	- instrumented path impact
	
	- dynamic compilation [see Breech2004]
	
	
	-> online = IA performed concurrent to program execution
	
	-> dynamic = IA information gathered while running entire program
	once
	
	
	cirteria for evaluation:
	
	- scalability
	
	- precision
	
	- recall
	
	- memory consumption
	
	- execution time},
  timestamp = {2011.02.04}
}

@PHDTHESIS{Breivold2011,
  author = {Breivold, H. P.},
  title = {Software Architecture Evolution through Evolvability Analysis},
  school = {Mälardalen University, Sweden},
  year = {2011},
  file = {:./literature/PHDThesis_hongyu_pei_breivold_2011.pdf:PDF},
  owner = {Sebastian},
  timestamp = {2013.07.26}
}

@INPROCEEDINGS{Breivold2009a,
  author = {Hongyu Pei Breivold and Ivica Crnkovic},
  title = {Analysis of Software Evolvability in Quality Models},
  booktitle = {35th Euromicro Conference on Software Engineering and Advanced Applications
	(SEAA), Software Process and Product Improvement (SPPI) Track},
  year = {2009},
  month = {August},
  publisher = {IEEE},
  abstract = {For long-lived systems, there is a need to address evolvability explicitly.
	For this purpose, we have in our earlier work developed a software
	evolvability framework based on industrial case studies. With this
	as input in this paper we analyze several existing quality models
	for the purpose of evaluating how software evolvability is addressed
	in these models. The goal of the analysis is to investigate if the
	elements of the evolvability framework can be systematically managed
	or integrated into different existing quality models. Our conclusion
	is that although none of the existing quality models is dedicated
	to the analysis of software evolvability, we can enrich respective
	quality model through integrating the missing elements, and adapt
	each quality model for software evolvability analysis purpose.},
  file = {:./literature/Breivold09a.pdf:PDF},
  keywords = {software evolvability, quality models},
  owner = {Stephan},
  review = {study if/how existing quality models can be extended with evolvabiltiy
	characteristics},
  timestamp = {2009.11.27},
  url = {http://www.mrtc.mdh.se/index.php?choice=publications&id=1646}
}

@TECHREPORT{Breivold2009b,
  author = {Hongyu Pei Breivold and Ivica Crnkovic},
  title = {A Survey of Software Architecture Evolvability},
  institution = {M{\"{a}}lardalen University},
  year = {2009},
  type = {{T}echnical {R}eport},
  number = {ISSN 1404-3041 ISRN MDH-MRTC-239/2009-1-SE},
  month = {September},
  abstract = {For long-lived systems, there is a need to address evolvability (i.e.
	a system’s ability to easily accommodate changes) explicitly during
	the entire lifecycle. In this report, we undertake a systematic review
	to obtain an overview of the existing studies in promoting software
	evolvability at architectural level. The search strategy identified
	3036 studies, of which 54 were catalogued as primary studies for
	this review after using multi-step selection process. The studies
	are classified into five main categories of themes, including techniques
	that support quality considerations during software architecture
	design, architectural quality evaluation, economic valuation, architectural
	knowledge management and modeling techniques. Four dimensions of
	factors are identified that exert influence on software evolvability.
	To cope with these diverse influencing factors, combination of appropriate
	techniques becomes necessary.},
  file = {:./literature/Breivold09b.pdf:PDF},
  keywords = {software evolvability, systematic literature review, survey, software
	evolution},
  owner = {Stephan},
  review = {systematic literature review concerning contributions to software
	eovlution and evolvability
	
	
	good source for references},
  timestamp = {2009.11.27},
  url = {http://www.mrtc.mdh.se/index.php?choice=publications&id=1772}
}

@INPROCEEDINGS{Breivold2007,
  author = {Breivold, Hongyu Pei and Crnkovic, Ivica and Eriksson, Peter},
  title = {Evaluating Software Evolvability},
  booktitle = {Proceedings of the 7th Conference on Software Engineering Research
	and Practice in Sweden (SERPS'07)},
  year = {2007},
  editor = {Thomas Arts},
  number = {2007:02},
  series = {Software Engineering and Management},
  pages = {96-103},
  address = {G\"oteborg, Sweden},
  month = {Oct},
  organization = {IT University of G\"oteborg, Department of Applied Information Technology},
  abstract = {Software evolution is characterized by inevitable changes of software
	and increasing software complexities, which in turn may lead to huge
	cost unless rigorously taking into account change accommodations.
	This has intensified the need on evolvable software systems that
	can correspond to changes in a cost-effective way. Nevertheless,
	although software evolvability is one of the most important quality
	attributes of software, it is not precisely defined today. Besides,
	the lack of evolvability model hinders us from analyzing, evaluating
	and comparing software systems in terms of evolvability. To address
	these issues, we distinguish software evolvability from maintainability
	in this paper and outline a suggestion for an evolvability model
	which analyzes software evolvability from various perspectives, as
	well as an evolvability evaluation method. The model and the method
	are evaluated through its application in an industrial automation
	system. The contribution of this paper is the initial establishment
	of an explicit definition of software evolvability, an evolvability
	model and an evolvability evaluation method that can be applied for
	large complex software-intensive systems.},
  file = {:./literature/Art07p.pdf:PDF},
  keywords = {Software evolvability, maintainability, quality model},
  owner = {Stephan},
  review = {- definition and characterization of evolvability
	
	- comparison between evolvability and maintainability
	
	-> different focus in several characteristics:
	
	change stimuli
	
	- business model, business objectives, technologies, new standards
	vs. defects, requirements from customer
	
	type of change
	
	- coarse-grained, long term, higher level vs. fine-grained, short
	term, localized change
	
	focus activity
	
	- cope with changes vs. keep system perform functions
	
	software structure
	
	- structural change vs. relatively constant
	
	architecture integrity
	
	- conformance required vs. conformance preservation
	
	
	evolvability subcharacteristics:
	
	- analysability
	
	- changeability: correlated to extensibility and portability, closely
	related to coupling, cohesion, modularity, software complexity
	
	- integrity: mostly related to understanding and coherence
	
	- extensibility: characteristic of evolvability but not of maintainability
	
	- portability: essential for evolvability but not for maintenance
	
	- testability
	
	
	- analyzability and integrity center subcharacteristics
	
	- during evolution process focus may be shifted among portability
	and extensibility
	
	- other characteristics always required
	
	
	evaluation method:
	
	- 2 phases with 7 steps
	
	
	phase 1: analyzation of implactions of change stimuli on SWA
	
	step 1: identify requirements on SWA
	
	step 2: prioritize requirements
	
	
	phase 2: analyzation and preparation of SWA to accomodate change stimuli
	and potential future changes
	
	step 3: extract architectural constructs related to identified issues
	from phase 1
	
	step 4: identify refactoring components
	
	step 5: identify potential refactoring solutions
	
	step 6: identify and define test cases
	
	step 7: present analysis results
	
	
	open issues:
	
	- further establishment of evaluation model
	
	- further derivation of subcharacteristics -> enable quantification
	and appropriate reasoning
	
	- catalog of guidelines and checkpoints for each subcharacteristic},
  timestamp = {2008.07.11},
  url = {http://www.ituniv.se/program/sem_research/Publications/2007/Art07/Art07p.pdf}
}

@INPROCEEDINGS{Breivold2008,
  author = {Hongyu Pei Breivold and Ivica Crnkovic and Peter Eriksson},
  title = {Analyzing Software Evolvability},
  booktitle = {IEEE International Computer Software and Applications Conference
	(COMPSAC 2008)},
  year = {2008},
  pages = {327-330},
  address = {Turku, Finland},
  month = {July},
  publisher = {IEEE},
  abstract = {Software evolution is characterized by inevitable changes of software
	and increasing software complexities, which in turn may lead to huge
	costs unless rigorously taking into account change accommodations.
	This is in particular true for long-lived systems in which changes
	go beyond maintainability. For such systems, there is a need to address
	evolvability explicitly during the entire lifecycle. Nevertheless,
	there is a lack of a model that can be used for analyzing, evaluating
	and comparing software systems in terms of evolvability. In this
	paper, we describe the initial establishment of an evolvability model
	as a framework for analysis of software evolvability. We motivate
	and exemplify the model through an industrial case study of a software-intensive
	automation system.},
  doi = {http://doi.ieeecomputersociety.org/10.1109/COMPSAC.2008.50},
  file = {:./literature/1478.pdf:PDF},
  keywords = {evolvability characteristics, evolvability model, analyzability, integrity,
	changeability, portability, testability, extensibility},
  owner = {Stephan},
  review = {confer [Breivold2007]},
  timestamp = {2008.08.05},
  url = {http://www.mdh.se/index.php?choice=publications&id=1478}
}

@INPROCEEDINGS{Breivold2008b,
  author = {Breivold, Hongyu Pei and Crnkovic, Ivica and Land, Rikard and Larsson,
	Magnus},
  title = {Analyzing Software Evolvability of an Industrial Automation Control
	System: A Case Study},
  booktitle = {The Third International Conference on Software Engineering Advances,
	2008. ICSEA '08.},
  year = {2008},
  pages = {205-213},
  month = {Oct.},
  publisher = {IEEE},
  abstract = {Evolution of software systems is characterized by inevitable changes
	of software and increasing software complexity, which in turn may
	lead to huge maintenance and development costs. For long-lived systems,
	there is a need to address evolvability (i.e. a system’s ability
	to easily accommodate changes) explicitly in the requirements and
	early design phases, and maintain it during the entire lifecycle.
	This paper describes our work in analyzing and improving the evolvability
	of an industrial automation control system, and presents 1) evolvability
	subcharacteristics based on the problems in the case and available
	literature; 2) a structured method for analyzing evolvability at
	the architectural level - the ARchitecture Evolvability Analysis
	(AREA) method. This paper includes also the main analysis results
	and our observations during the evolvability analysis process in
	the case study. The evolvability subcharacteristics and the method
	should be generally applicable, and they are being validated within
	another domain at the time of writing.},
  doi = {10.1109/ICSEA.2008.16},
  file = {:./literature/4668110.pdf:PDF},
  keywords = {software evolvability, case study, software evolution},
  owner = {Stephan},
  review = {subcharacteristics of evolvability defined in [Breivold2008] are examined
	in a case study
	
	
	introduction of the ARchitecture Evolvability Analysis (AREA) method
	
	Phase1:
	
	- analyzation of impact of change stimuli for the SWA
	
	- identification and prioritization of potential requirements
	
	- check against evolvability subcharacteristics
	
	
	Phase2:
	
	- analyse existing architecture and its constructs
	
	-> conceptual view of original architecture
	
	- identify refactoring components for the change requirements
	
	-> revised architectural view of SWA
	
	- identify and assess possible solutions
	
	- define test cases
	
	
	Phase3:
	
	- present evaluation},
  timestamp = {2009.01.06}
}

@INPROCEEDINGS{Breivold2008a,
  author = {Breivold, Hongyu Pei and Crnkovic, Ivica and Land, Rikard and Larsson,
	Stig},
  title = {Using Dependency Model to Support Software Architecture Evolution},
  booktitle = {23rd IEEE/ACM International Conference on Automated Software Engineering
	- Workshops, 2008 (ASE Workshops 2008)},
  year = {2008},
  pages = {82-91},
  month = {Sept.},
  publisher = {IEEE},
  abstract = {Evolution of software systems is characterized by inevitable changes
	of software and increasing software complexity, which in turn may
	lead to huge maintenance and development costs. For long-lived systems,
	there is a need to address and maintain evolvability (i.e. a system’s
	ability to easily accommodate changes) during the entire lifecycle.
	As designing software for ease of extension and contraction depends
	on how well the software structure is organized, this paper explores
	the relationships between evolvability, modularity and inter-module
	dependency. Through a case study of an industrial power control and
	protection system, we describe our work in managing its software
	architecture evolution, guided by the dependency analysis at the
	architectural level. The paper includes also the main analysis results,
	our experiences and reflections during the dependency analysis process
	in the case study.},
  doi = {10.1109/ASEW.2008.4686324},
  file = {:./literature/breivold08.pdf:PDF},
  keywords = {evolvability subcharacteristics, evolvability model, software archtecture
	evolution},
  owner = {Stephan},
  review = {interplay between modularity and evolvability and inter-module dependencies
	is discussed
	
	
	Design Structure Matrix (DSM) as a dependency model is utilized for
	the analysis of inter-module dependencies
	
	
	case study with discussion how to use DSM, how to reduce dependencies},
  timestamp = {2009.01.06}
}

@ARTICLE{Breivold2012,
  author = {Breivold, Hongyu Pei and Crnkovic, Ivica and Larsson, Magnus},
  title = {A systematic review of software architecture evolution research},
  journal = {Inf. Softw. Technol.},
  year = {2012},
  volume = {54},
  pages = {16--40},
  number = {1},
  month = jan,
  acmid = {2051698},
  address = {Newton, MA, USA},
  doi = {10.1016/j.infsof.2011.06.002},
  file = {:./literature/breivold2012.pdf:PDF},
  issn = {0950-5849},
  issue_date = {January, 2012},
  keywords = {Architecture analysis, Architecture evolution, Evolvability analysis,
	Software architecture, Software evolvability, Systematic review},
  numpages = {25},
  owner = {Sebastian},
  publisher = {Butterworth-Heinemann},
  timestamp = {2013.06.03},
  url = {http://dx.doi.org/10.1016/j.infsof.2011.06.002}
}

@ARTICLE{Bresnen2004,
  author = {Bresnen, M. and Goussevskaia, A. and Swan, J.},
  title = {Embedding new management knowledge in project-based organizations},
  journal = {Organization studies},
  year = {2004},
  volume = {25},
  pages = {1535--1555},
  number = {9},
  file = {Bresnen2004.pdf:literature/Bresnen2004.pdf:PDF},
  owner = {patrickr},
  publisher = {Sage Publications},
  timestamp = {2012.10.22}
}

@INPROCEEDINGS{Briand2002,
  author = {Briand, L. and Labiche, Y. and Buist, K. and Soccar, G.},
  title = {Automating Impact Analysis and Regression Test Selection Based on
	{UML} Designs},
  booktitle = {Proceedings of the 18th IEEE International Conference on Software
	Maintenance (ICSM'02)},
  year = {2002},
  pages = {252-261},
  address = {Montreal, Quebec, Canada},
  month = {October},
  file = {:./literature/Paper_157.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- re-executing all test cases not feasible in practice
	
	- regression test selection based on code too expensive due to large
	size of code
	
	- no means to derive affected tests from architecture yet
	
	
	Research Questions:
	
	- how to efficiently detect test cases to rerun, delete and ignore
	
	
	Contribution:
	
	- methodology for automated regression test selection based on IA
	
	- formal mapping between UML design changes and diff. classes of regression
	tests
	
	
	Solution:
	
	- 3 classes of regression tests
	
	* reusable: still valid and no need for rerun
	
	* retestable: still valid, but must be rerun
	
	* obsolete: test case cannot be run with new version; either update
	or remove
	
	- test selection based on differences between 2 versions of architecture
	
	* assess design of last version by comparing what would be in new
	design
	
	* then assess impact of change and decide whether to implement or
	not
	
	* determine test cases through traceability (connecting architecture
	and test cases)
	
	- associate each use case with a unique sequence diagram describing
	object interaction
	
	* split complicated sequence diagrams into several smaller ones
	
	* splitted diagrams "communicate" via messages
	
	-> granularity of entities: attribute, method, class, sequence, use
	case
	
	-> granularity of changes: add/delete/change class, attribute, method,
	sequence diagram, use cases
	
	-> granularity of results: regression tests
	
	- traceability-based IA on architectures
	
	- implemented by Regression Test Selection Tool (RTSTool)
	
	
	[Seite 6, 2. Abschnitt]
	
	
	Open Issues:},
  timestamp = {2011.05.03}
}

@INPROCEEDINGS{Briand2003a,
  author = {Briand, L. and Labiche, Y. and O'Sullivan, L.},
  title = {Impact analysis and change management of {UML} models},
  booktitle = {Proceedings of the 19th International Conference on Software Maintenance},
  year = {2003},
  pages = {256-265},
  eid = {IEEEComputer Society Press},
  file = {:./literature/Paper_5.pdf:PDF},
  journal = {Proceedings of 19th International Conference on Software Maintenance},
  owner = {Steffen},
  review = {same as Briand2006, but more examples, rules, etc.
	
	
	- provides 115 consistency rules for UML
	
	- provides 5 bad smells for UML},
  timestamp = {2011.01.01}
}

@ARTICLE{Briand2006,
  author = {Briand, L. and Labiche, Y. and O'Sullivan, L. and S\'{o}wka, M.},
  title = {Automated impact analysis of {UML} models},
  journal = {Journal of Systems and Software},
  year = {2006},
  volume = {79},
  pages = {339-352},
  file = {:./literature/Paper_2.PDF:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- large number of UML diagrams during software lifecyle
	
	- changes should propagate through all models
	
	- no support for model based IA yet
	
	
	Research Questions:
	
	- maintenance of models
	
	- keep usefulness of models after implementation
	
	
	Contribution:
	
	- rules for change detection among models
	
	- provide means for IA on UML models before any coding takes place
	
	- utilize distance measure to estimate impacts
	
	- empirical studies to evaluate approach
	
	- provide strict definitions for change, impacted elements and change
	operations
	
	
	Solution:
	
	- synchronize models
	
	- detect and classify changes in models
	
	- use rules (defined with OCL) to react on changes and implement them
	in models
	
	- implemented in prototype tool (iACMTool)
	
	-> granularity of entities: entire UML
	
	-> granularity of changes: fine-grained changes
	
	-> granularity of results: entire UML
	
	
	Open Issues:
	
	- associate probalities with IA rules
	
	- improve ranking of impacted elements},
  timestamp = {2011.01.01}
}

@ARTICLE{Briand1999b,
  author = {Briand, Lionel C. and Daly, John W. and Wuest, Juergen K.},
  title = {A uniﬁed framework for coupling measurement in object-oriented systems},
  journal = {IEEE Transactions on Software Engineering},
  year = {1999},
  volume = {25},
  pages = {91-121},
  number = {1},
  file = {:./literature/Paper_168.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	
	Research Questions:
	
	
	Contribution:
	
	
	Solution:
	
	-> granularity of entities:
	
	-> granularity of changes:
	
	-> granularity of results:
	
	
	Open Issues:},
  timestamp = {2011.07.26}
}

@ARTICLE{Briand2009a,
  author = {L. C. Briand and Y. Labiche and S. He},
  title = {Automating regression test selection based on {UML} designs},
  journal = {Information and Software Technology.},
  year = {2009},
  volume = {51},
  pages = {16--30},
  number = {1},
  abstract = {This paper presents a methodology and tool to support test selection
	from regression test suites based on change analysis in object-oriented
	designs. We assume that designs are represented using the Unified
	Modeling Language {(UML)} 2.0 and we propose a formal mapping between
	design changes and a classification of regression test cases into
	three categories: Reusable, Retestable, and Obsolete. We provide
	evidence of the feasibility of the methodology and its usefulness
	by using our prototype tool on an industrial case study and two student
	projects.},
  file = {:/literature/RegressionTesting/automating impact analysis an regression test selection based on uml diagrams.pdf:PDF},
  keywords = {object-oriented software engineering, regression testing, test selection,
	uml},
  owner = {Annie},
  timestamp = {2011.01.04},
  url = {http://portal.acm.org/citation.cfm?id=1465742.1466092&coll=GUIDE&dl=GUIDE&CFID=54491404&CFTOKEN=93053143}
}

@ARTICLE{Briand2009,
  author = {Briand, Lionel C. and Labiche, Yvan and Yue, Tao},
  title = {Automated traceability analysis for {UML} model refinements},
  journal = {Information and Software Technology},
  year = {2009},
  volume = {51},
  pages = {512-527},
  __markedentry = {[Steffen:]},
  file = {:./literature/Paper_218.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.30}
}

@INPROCEEDINGS{Briand1999a,
  author = {Briand, Lionel C. and Wuest, Juergen and Lounis, Hakim},
  title = {Using Coupling Measurement for Impact Analysis in Object-Oriented
	Systems},
  booktitle = {Proceedings of the IEEE International Conference on Software Maintenance
	(ICSM '99)},
  year = {1999},
  pages = {475-482},
  address = {Oxford , UK},
  file = {:./literature/Paper_54.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- collaboration of system objects is most complex in OO software
	
	- this leads to an explosion of possible impacts computed by dependency
	analysis due to large number of dependencies
	
	- cause for ripple effects
	
	
	Research Questions:
	
	- investigate whether coupling measurement (capturing all sorts of
	class collaborations) is able to assist IA
	
	
	Contribution:
	
	- discover influence of couplings between objects in OO systems on
	IA
	
	- provide a classification of all sorts of class collaborations
	
	
	Solution:
	
	- definition of coupling taxonomy (e.g. "A calls B", "A has data of
	type B" etc.) -> set of measurements
	
	- perfrom regression analyis for each measurement to evaluate its
	likelyhood to detect ripple-effects
	
	- rank each class to other classes based on their couple measure
	
	-> granularity of entities: classes
	
	-> granularity of changes: no details given
	
	-> granularity of results: classes
	
	
	Open Issues:
	
	- many ripple effects of higly coupled classes cannot be detected
	
	- current coupling classification does not cover everything},
  timestamp = {2011.02.09}
}

@BOOK{Brooks1995,
  title = {The Mythical Man-Month : Essays on Software Engineering},
  publisher = {Addison-Wesley},
  year = {1995},
  author = {Frederick P. Brooks},
  pages = {200},
  owner = {Matthias},
  timestamp = {2008.07.14},
  url = {http://portal.acm.org/citation.cfm?doid=540031}
}

@ARTICLE{Brooks1983,
  author = {Ruven E. Brooks},
  title = {Towards a Theory of the Comprehension of Computer Programs},
  journal = {International Journal of Man-Machine Studies},
  year = {1983},
  volume = {18},
  pages = {543-554},
  number = {6},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  citeseerurl = {http://citeseerx.ist.psu.edu/showciting;jsessionid=CDBECB385AFB540EB89CDB3F697D55B3?cid=60510},
  keywords = {program comprehension},
  owner = {Robert},
  timestamp = {2008.07.14}
}

@MISC{Brosch,
  author = {Brosch, Petra and Seidl, Martina and Wimmer, Manuel},
  title = {Mining of Model Repositories for Decision Support in Model Versioning},
  citeulike-article-id = {5089512},
  citeulike-linkout-0 = {http://publik.tuwien.ac.at/files/PubDat\_176009.pdf},
  file = {:/literature/changeIdentification/PubDat_176009.pdf:PDF},
  keywords = {Read},
  owner = {Steffen},
  posted-at = {2009-07-07 19:43:21},
  priority = {3},
  timestamp = {2012.03.01},
  url = {http://publik.tuwien.ac.at/files/PubDat\_176009.pdf}
}

@INPROCEEDINGS{Brown2007,
  author = {Alan W. Brown and John A. McDermid},
  title = {The Art and Science of Software Architecture},
  booktitle = {Proceedings First European Conference on Software Architecture (ECSA
	2007)},
  year = {2007},
  editor = {F. Oquendo},
  volume = {4758},
  series = {LNCS},
  pages = {237-256},
  month = {September},
  publisher = {Springer},
  abstract = {The past 20 years has seen significant investments in the theory and
	practice of software architecture. However, architectural deficiencies
	are frequently cited as a key factor in the shortcomings and failures
	that lead to unpredictable delivery of complex operational systems.
	Here, we consider the art and science of software architecture: we
	explore the current state of software architecture, identify key
	architectural trends and directions in academia and industry, and
	highlight some of the architectural research challenges which need
	to be addressed. The paper proposes an agenda of research activities
	to be carried out by a partnership between academia and industry.
	While challenges exist in many domains, for this paper we draw examples
	from one area of particular concern: safety-critical systems.},
  doi = {10.1007/978-3-540-75132-8},
  file = {:./literature/Brown2007.pdf:PDF},
  keywords = {software architecture, software engineering, system engineering, research
	challenges},
  owner = {Stephan},
  review = {good overview of state-of-the-art and practice research challenges
	
	
	good reference for introductions' motivation part},
  timestamp = {2010.02.10}
}

@BOOK{Brown1998,
  title = {AntiPatterns - Refactoring Software, Architectures, and Projects
	in Crisis},
  publisher = {John Wiley \& Sons, Inc.},
  year = {1998},
  author = {William J. Brown and Raphael C. Malveau and Hays W. McCormick III
	and Thomas J. Mowbray},
  file = {:./literature/BrownAntiPatterns1998.pdf:PDF},
  owner = {matthias},
  timestamp = {2013.04.08}
}

@INPROCEEDINGS{Broy2006,
  author = {Manfred Broy and Florian Deissenboeck and Markus Pizka},
  title = {Demystifying Maintainability},
  booktitle = {Proceedings of the 2006 International Workshop on Software Quality,
	WoSQ '06},
  year = {2006},
  pages = {21-26},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Due to its economic impact "maintainability" is broadly accepted as
	an important quality attribute of software systems. But in contrast
	to attributes such as performance and correctness, there is no common
	understanding of what maintainability actually is, how it can be
	achieved, measured, or assessed. In fact, every software organization
	of significant size seems to have its own definition of maintainability.
	We address this problem by defining an unique two-dimensional quality
	model that associates maintenance activities with system properties
	including the capabilities of the organization. The separation of
	activities and properties facilitates the identification of sound
	quality criteria and allows to reason about their interdependencies.
	The resulting quality controlling process enforces these criteria
	through tool-supported measurements as well as manual inspections.
	We report on our experiences with the incremental development of
	the quality model and its application to large scale commercial software
	projects. Among the positive effects are a slowdown of decay and
	a significantly increased awareness for long-term quality aspects.},
  citeseerurl = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.8241},
  doi = {http://doi.acm.org/10.1145/1137702.1137708},
  file = {:./literature/DemystifyingMaintainabilityBroy2006.pdf:PDF},
  isbn = {1-59593-399-9},
  keywords = {maintainability, quality models, quality assessment},
  location = {Shanghai, China},
  owner = {Stephan},
  review = {no common understanding of maintainability -> no maintainability checking
	used in practice
	
	
	to assess maintainability it has to be decomposed into "checkable"
	properties
	
	
	related works
	
	- metrics-based approaches
	
	- quality modeling -> factor-criteria-metrics (-> Boehm's Software
	Quality Characteristics Tree)
	
	- processes and process models (ISO 9000, CMM)
	
	-> some flaws:
	
	- overall maintainability value cannot be evaluated
	
	- several properties are difficult to measure
	
	- quality of product not only depends on development process
	
	
	difficulty to maintain interdependencies between different maintainability
	criteria when building FCM tree bottom up
	
	-> due to mixing up activities and characteristics, no clear meaning
	of edges in tree
	
	
	2-dimensional model developed
	
	- activities and properties seperated
	
	- decomposition in distinct trees -> clear meaning of edges - refine
	
	- then combination of tree leafs in maintainability matrix using a
	relativ weight of each leaf between 0 and 1 so that all sum up to
	1
	
	
	there is no maintainability of a software system
	
	-> influencing factors of maintainability always depend on context
	with activities},
  timestamp = {2008.08.01}
}

@ARTICLE{Brun2008,
  author = {Brun, C and Pierantonio, A},
  title = {Model Differences in the Eclipse Modelling Framework},
  journal = {UPGRADE The European J for the Informatics Professional},
  year = {2008},
  volume = {IX(2)},
  pages = {29--34},
  number = {2},
  file = {:/literature/changeIdentification/2008-II-pierantonio.pdf:PDF},
  keywords = {Read},
  owner = {Steffen},
  timestamp = {2012.03.01},
  url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3004169&tool=pmcentrez&rendertype=abstract}
}

@ARTICLE{Brunard1994,
  author = {Brunard, V. and Kleiner, BH},
  title = {Developing trustful and cooperative relationships},
  journal = {Leadership and Organization Development Journal},
  year = {1994},
  volume = {15},
  pages = {16--19},
  number = {2},
  owner = {patrickr},
  timestamp = {2012.10.30}
}

@ARTICLE{Bryman1987,
  author = {Bryman, A. and Bresnen, M. and Beardsworth, AD and Ford, J. and Keil,
	ET},
  title = {The concept of the temporary system: the case of the construction
	project},
  journal = {Research in the Sociology of Organizations},
  year = {1987},
  volume = {5},
  pages = {253--283},
  owner = {patrickr},
  publisher = {JAI Press Greenwich, CT},
  timestamp = {2012.10.19}
}

@ARTICLE{Bryman1987a,
  author = {Bryman, A. and Bresnen, M. and Ford, J. and Beardsworth, A. and Keil,
	T.},
  title = {Leader orientation and organizational transience: an investigation
	using Fiedler's LPC scale},
  journal = {Journal of occupational psychology},
  year = {1987},
  volume = {60},
  pages = {13--19},
  number = {1},
  owner = {patrickr},
  publisher = {Cambridge University Press},
  timestamp = {2012.10.19}
}

@INPROCEEDINGS{Bu2009,
  author = {Bu, Wanfeng and Tang, Antony and Han, Jun},
  title = {An analysis of decision-centric architectural design approaches},
  booktitle = {Proceedings of the 2009 ICSE Workshop on Sharing and Reusing Architectural
	Knowledge},
  year = {2009},
  series = {SHARK '09},
  pages = {33--40},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid = {1556975},
  doi = {10.1109/SHARK.2009.5069113},
  file = {:./literature/bu2009.pdf:PDF},
  isbn = {978-1-4244-3726-9},
  numpages = {8},
  owner = {Sebastian},
  timestamp = {2013.07.26},
  url = {http://dx.doi.org/10.1109/SHARK.2009.5069113}
}

@ARTICLE{Buckley2005,
  author = {Buckley, Jim and Mens, Tom and Zenger, Matthias and Rashid, Awais
	and Kniesel, G\"{u}nter},
  title = {Towards a taxonomy of software change: Research Articles},
  journal = {Journal of Software Maintenance and Evolution},
  year = {2005},
  volume = {17},
  pages = {309-332},
  number = {5},
  month = {September},
  acmid = {1090746},
  address = {New York, NY, USA},
  doi = {10.1002/smr.v17:5},
  file = {:/literature/changeIdentification/10.1.1.65.3667.pdf:PDF},
  issn = {1532-060X},
  issue = {5},
  keywords = {Read, CVS, characterization, eLiza, refactoring browser, software
	evolution tools},
  numpages = {24},
  owner = {Steffen},
  publisher = {John Wiley \& Sons, Inc.},
  review = {changes
	
	
	change texonomy
	
	
	time of change 
	
	change type 
	
	change history 
	
	degree of automation 
	
	activeness 
	
	change frequency 
	
	anticipation 
	
	artifact
	
	granularity 
	
	impact 
	
	change propagation 
	
	availability 
	
	openness
	
	safety 
	
	degree of formality
	
	
	
	
	change types
	
	+ structural
	
	+addition (adding new elements to the software),
	
	+subtraction (removing elements from the software), 
	
	+alteration (modifying an existing element in the software, e.g.,
	renaming).
	
	+semantic
	
	+semantics-modifying
	
	+semantics-preserving changes
	
	+restructuring activities [11], such as the replacement of a for loop
	by a while loop, or the removal of goto statements in spaghetti code
	[59]. (refactoring operations)},
  timestamp = {2012.03.01},
  url = {http://dl.acm.org/citation.cfm?id=1090744.1090746}
}

@ARTICLE{Buckley2005a,
  author = {Buckley, Jim and Mens, Tom and Zenger, Matthias and Rashid, Awais
	and Kniesel, Günter},
  title = {Towards a taxonomy of software change},
  journal = {Journal of Software Maintenance and Evolution: Research and Practice},
  year = {2005},
  volume = {17},
  pages = {309-332},
  month = {September},
  booktitle = {JOURNAL OF SOFTWARE MAINTENANCE AND EVOLUTION: RESEARCH AND PRACTICE},
  file = {:./literature/Paper_32.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	
	Research Questions:
	
	
	Contribution:
	
	
	Solution:
	
	
	Open Issues:},
  timestamp = {2011.02.04}
}

@INPROCEEDINGS{Buckner2005,
  author = {Buckner, Jonathan and Buchta, Joseph and Petrenko, Maksym and Rajlich,
	V\'{a}clav},
  title = {{JRipples}: A tool for program comprehension during incremental change},
  booktitle = {Proceedings of the 13th International Workshop on Program Comprehension
	(IWPC ’05)},
  year = {2005},
  pages = {149-151},
  month = {May},
  file = {:./literature/Paper_169.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- incremental change due to frequent updates is large problem for
	most software
	
	
	Research Questions:
	
	- provide tool support to cope with problem
	
	
	Contribution:
	
	- interactive tool JRipples proposed
	
	
	~ tool paper, not really "research"},
  timestamp = {2011.07.26}
}

@TECHREPORT{Budlong1996,
  author = {Budlong, Faye C. and Szulewski, Paul A. and Ganska, Ralph J.},
  title = {Process Tailoring for Software Project Plans},
  institution = {The Software Technology Support Center (STSC) of the U.S. Air Force},
  year = {1996},
  file = {Budlong1996.pdf:literature/Budlong1996.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.24}
}

@TECHREPORT{Burge2002,
  author = {Janet E. Burge and David C. Brown},
  title = {NFRs: fact or fiction},
  institution = {Artificial Intelligence in Design Research Group, Computer Science
	Department, WPI, Worcester, MA 01609, USA},
  year = {2002},
  number = {WPI-CS-TR-02-01},
  abstract = {Requirements, derived from the customers' needs and desires, are used
	to guide software development and to determine if the completed system
	is what the customer needs. Require-ments Engineering (RE) captures
	and repre-sents system requirements so that they can be traced through
	to both implementation and testing to ensure that the resulting system
	does what the customer has requested. The primary focus of RE has
	been on the functional requirements: ensuring that the necessary
	functionality of the system is delivered to the user. The non-functional
	requirements (NFRs), however, are also important since they contribute
	to the overall quality of the resulting system. RE has treated NFRs
	as something separate and distinct from the functional requirements.},
  file = {:./literature/NFRsFactOrFiction.pdf:PDF},
  keywords = {non-functional requirements},
  owner = {Stephan},
  timestamp = {2008.07.31},
  url = {ftp://ftp.cs.wpi.edu/pub/techreports/pdf/02-01.pdf}
}

@BOOK{Buschmann1996,
  title = {{Pattern-Oriented} Software Architecture: A System of Patterns},
  publisher = {John Wiley \& Sons},
  year = {1996},
  author = {Frank Buschmann and Regine Meunier and Hans Rohnert and Peter Sommerlad
	and Michael Stal},
  edition = {1},
  month = Jul,
  isbn = {0471958697},
  keywords = {architectural patterns, design patterns, pattern catalog},
  owner = {Stephan},
  timestamp = {2010.03.02}
}

@INPROCEEDINGS{Bustard2005,
  author = {Bustard, D.W. and Keenan, F.},
  title = {Strategies for systems analysis: Groundwork for process tailoring},
  booktitle = {Engineering of Computer-Based Systems, 2005. ECBS'05. 12th IEEE International
	Conference and Workshops on the},
  year = {2005},
  pages = {357--362},
  file = {Bustard2005.pdf:literature/Bustard2005.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@INPROCEEDINGS{Cachero2007,
  author = {Cristina Cachero and Geert Poels and Coral Calero},
  title = {Towards a Quality-Aware Web Engineering Process},
  booktitle = {Proceedings of the EMMSAD'07 Workshop, CAISE'07},
  year = {2007},
  address = {Norway},
  month = {June},
  abstract = {Evidence-Based Web Engineering (WE) is necessary in order to (1) help
	industry practitioners in making rational decisions about technology
	adoption and (2) increase the acceptability of WE methodologies.
	Particularly, empirical data should be provided to support traditional
	WE claims such as increased productivity or better quality of the
	applications deployed using a WE methodology. Unfortunately the WE
	community is not yet familiar with either systematic quality evaluation
	issues or empirical research, and therefore tools and guidelines
	to ease this shift are necessary. In this paper we extend the traditional
	WE Development Process with quality evaluation and assurance activities
	that are compliant with the ISO/IEC 14598 set of standards and guarantee
	that Web applications developed with WE approaches fulfill certain
	quality criteria. This extension follows the MDA paradigm in order
	to ensure that the development productivity is not hampered by the
	additional focus on quality aspects.},
  file = {:./literature/EMMSAD07.pdf:PDF},
  keywords = {Web Engineering methodologies, Web Engineering process, quality evaluation,
	quality assurance, model-driven development},
  owner = {Stephan},
  review = {introduces a development process enriched with the use of quality
	models
	
	
	standard development steps for web engineering
	
	---------------------------------------------------------
	
	requirements workflow leads to use case model
	
	
	-> transformation through analysis workflow into domain model
	
	
	-> transformation through conceptual design workflow
	
	models: navigational model, presentation model
	
	
	-> transformation through platform and technology specific design
	workflow
	
	result: model for J2EE platform odr .Net platform
	
	
	-> code transformation
	
	
	new quality-aware web engineering process
	
	----------------------------------------------------
	
	encapsulation of different quality models for the several steps of
	the process
	
	quality models:
	
	- requirements coverage quality model
	
	- representation faithfulness quality model
	
	- navigability quality model
	
	- attractiveness quality model
	
	
	but
	
	----
	
	interesting pieces left out
	
	no futher description of the quality models},
  timestamp = {2008.04.02},
  url = {http://www.dlsi.ua.es/~ccachero/papers/EMMSAD07.pdf}
}

@INPROCEEDINGS{Cai2000,
  author = {Xia Cai and M.R. Lyu and Kam-Fai Wong and Roy Ko},
  title = {Component-based software engineering: technologies, development frameworks,
	and quality assurance schemes},
  booktitle = {Seventh Asia-Pacific Software Engineering Conference (APSEC'00)},
  year = {2000},
  volume = {0},
  pages = {372},
  address = {Los Alamitos, CA, USA},
  publisher = {IEEE Computer Society},
  abstract = {Component-based software development approach is based on the idea
	to develop software systems by selecting appropriate of-the-shey
	components and then to assemble them with a well-defined software
	architecture. Because the new software development paradigm is much
	diferent ?om the traditional approach, quality assurance (QA) for
	component-based software development is a new topic in the software
	engineering community. In this papec we survey current component-based
	software technologies, describe their advantages and disadvantages,
	and discuss the features they inherit. We also address QA issues
	for component-based soffware. As a major contribution, we propose
	a QA model for component-based software development, which covers
	component requirement analysis, component development, component
	certification, component customization, and system architecture design,
	integration, testing, and maintenanceshelf (COTS) components can
	be developed by different developers using different languages and
	different platforms. This can be shown in Figure 1, where COTS components
	can be checked out from a component repository, and assembled into
	a target software system.},
  doi = {http://doi.ieeecomputersociety.org/10.1109/APSEC.2000.896722},
  file = {:./literature/00896722.pdf:PDF},
  issn = {1530-1362},
  keywords = {subroutines; software architecture; software quality; certification;
	program testing; software maintenance; object-oriented programming;
	component-based software engineering; software development frameworks;
	software quality assurance schemes; off-the-shelf components; software
	architecture; software development paradigm; component requirement
	analysis; component development; component certification; component
	customization; system architecture design; system integration; system
	testing; system maintenance},
  owner = {Stephan},
  timestamp = {2008.04.17}
}

@ARTICLE{Calder2003,
  author = {Muffy Calder and Mario Kolberg and Evan H. Magill and Stephan Reiff-Marganiec},
  title = {Feature interaction: a critical review and considered forecast},
  journal = {Comput. Networks},
  year = {2003},
  volume = {41},
  pages = {115-141},
  number = {1},
  abstract = {The state of the art of the field of feature interactions in telecommunications
	services is reviewed, concentrating on three major research trends:
	software engineering approaches, formal methods, and on line techniques.
	Then, the impact of the new, emerging architectures on the feature
	interaction problem is considered. A forecast is made about how research
	in feature interactions needs to readjust to address the new challenges
	posed by the emerging architectures.},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1016/S1389-1286(02)00352-3},
  file = {:./literature/calder-kolberg-magill-reiff.pdf:PDF},
  issn = {1389-1286},
  keywords = {Feature interaction; Telecommunications services; Incompatibility},
  owner = {Matthias},
  publisher = {Elsevier North-Holland, Inc.},
  timestamp = {2008.07.15},
  url = {http://www.dcs.gla.ac.uk/publications/PAPERS/6421/calder-kolberg-magill-reiff.pdf}
}

@INPROCEEDINGS{Calvo-Manzano2006,
  author = {Calvo-Manzano, J. A. and Agustin, C. G. and Pacheco, I. G. and Gilabert,
	T. S. F. and Serrano, A.},
  title = {Software Process Improvement Solution for Small and Medium-Size Enterprises},
  booktitle = {Proceedings of the First International Research Workshop for Process
	Improvement in Small Settings},
  year = {2006},
  file = {:literature/Blowers2005.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@INPROCEEDINGS{Canfora2010,
  author = {Canfora, Gerardo and Ceccarelli, Michele and Cerulo, Luigi and Di
	Penta, Massimiliano},
  title = {Using Multivariate Time Series and Association Rules to Detect Logical
	Change Coupling: an Empirical Study},
  booktitle = {Proceedings of the 26th IEEE International Conference on Software
	Maintenance (ICSM 2010)},
  year = {2010},
  file = {:./literature/Paper_35.pdf:PDF},
  owner = {Steffen},
  review = {-> detailed version of [Ceccarelli2010]
	
	
	- performed empirical comparison on four projects to evaluate approach
	presented in [Ceccarelli2010]},
  timestamp = {2011.02.04}
}

@INPROCEEDINGS{Canfora2006,
  author = {Canfora, Gerardo and Cerulo, Luigi},
  title = {Fine Grained Indexing of Software Repositories to Support Impact
	Analysis},
  booktitle = {Proceedings of the International Workshop on Mining Software Repositories
	(MSR'06)},
  year = {2006},
  pages = {105-111},
  file = {:./literature/Paper_12.PDF:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- versioned/bug-tracked software provides huge amount of historical
	data
	
	- natural language wide used in many software artifacts
	
	- use of this information for IA
	
	
	Research Questions:
	
	- provide IA for change requests based on historical data
	
	- learn from history how past requests have been solved and what they
	effected
	
	- how to utilize free text stored in version repositories
	
	
	Contribution:
	
	- build textual representations of code entities at different levels
	of abstraction
	
	- use IR techniques to perform IA on them
	
	
	Solution:
	
	- recover history of souce code modifications (added/removed/changed
	lines) from version history
	
	- create a line history table stating when which LOC was added/removed/changed
	
	- represent each LOC together with related free text (from revision
	history, e.g. comments) 
	
	- index process generates ranked list of code entities (from the step
	above) through IR:
	
	* subdivide free texts into sequence of index terms
	
	* apply word stemming on indexed terms
	
	* remove stop words
	
	- build descriptors for source files, consisting of:
	
	* description of change request
	
	* description of the source file
	
	-> granularity of entities: file to statement level
	
	-> granularity of changes: atomic changes
	
	-> granularity of results: file to statement level
	
	
	Open Issues:
	
	- max. 50% recall, average way below 20%
	
	- results dependent on quality of text
	
	- indexes can be build for mature projects only},
  timestamp = {2011.01.05}
}

@INPROCEEDINGS{Canfora2005,
  author = {Canfora, Gerardo and Cerulo, Luigi},
  title = {Impact Analysis by Mining Software and Change Request Repositories},
  booktitle = {Proceedings of the 11th IEEE International Software Metrics Symposium
	(METRICS'05)},
  year = {2005},
  pages = {29-38},
  address = {Como, Italy},
  month = {September},
  file = {:./literature/Paper_113.pdf:PDF},
  journal = {Proceedings of the IEEE International Symposium on Software Metrics},
  owner = {Steffen},
  review = {Problem:
	
	- many useful information about projects and changes are stored in
	different repositories / systems
	
	- bugtrackers and version control systems provide rich information
	about change history of software
	
	
	Research Questions:
	
	- how to obtain IA information from version control and bug-tracking
	systems to assist in maintenance
	
	
	Contribution:
	
	- information retrieval technique to link change requests with source
	files which are most likely to change
	
	- combine data from CVS with data stored in Bugzilla
	
	
	Solution:
	
	- basic assumption is:
	
	* commit report and previous change request which focus on a certain
	file are a good indicator for further changes concerning this file
	
	- compute similarity between old and new change requests based on
	textual similarity
	
	* texts are: bug reports, feature proposal, commit reports, change
	requests
	
	- use standard IR procedures: stemming, stop word eleminating
	
	- use probalistic IR comparison algorithm
	
	- present ranked list of affected files to developer
	
	-> granularity of artifacts: source files
	
	-> granularity of changes: no details ("change request" -> can be
	anything)
	
	-> granularity of results: affected source files
	
	- developed a toolkit
	
	
	Open Issues:
	
	- same issue as with all IR approaches: lack of precision
	
	- granularity of files to coarse-grained to be really useful
	
	- approach only useful when bug/change data already exists},
  timestamp = {2011.03.14}
}

@ARTICLE{Canfora2011,
  author = {Canfora, Gerardo and Di Penta, Massimiliano and Cerulo, Luigi},
  title = {Achievements and challenges in software reverse engineering},
  journal = {Commun. ACM},
  year = {2011},
  volume = {54},
  pages = {142--151},
  number = {4},
  month = apr,
  abstract = {Deeply understanding the intricacies of software must always come
	before any considerations for modifying it.},
  address = {New York, NY, USA},
  doi = {10.1145/1924421.1924451},
  file = {:./literature/canfora2011.pdf:PDF},
  issn = {0001-0782},
  issue_date = {April 2011},
  numpages = {10},
  owner = {matthias},
  publisher = {ACM},
  review = {Reviewer: Richard John Botting 
	
	Reverse engineering is now recognized as the vital discipline in supporting
	software maintenance. Documentation is always incomplete and out
	of date, so one relies on the code. Even the cleanest code, however,
	fails to identify all of the requirements, assumptions, and dependencies
	involved.
	
	In the last two decades, many novel tools and techniques have been
	developed to help programmers analyze code. One of the strengths
	of this paper is the categorization of the types of tools and their
	desirable features. The list of nearly 50 recent references is a
	good starting point for researchers. An older annotated bibliography
	[1] gives a historical perspective.
	
	The paper has a few spelling mistakes and grammatical errors, but
	is still clear and accurate. Though it is a good survey of reverse
	engineering tools, the figures in the virtual extension of the magazine
	ruined it for me. One figure is a bandwidth-consuming computer-generated
	image with no visible relation to the topic being discussed. The
	other figure is a visual summary of the ontology that the authors
	developed from Chikofsky and Cross's taxonomy [2]. This diagram claims
	to use the unified modeling language (UML), but is full of novice-type
	errors, such as roles at the wrong ends of associations and incorrect
	arrowheads. Researchers would be wise to get the Hypertext Markup
	Language (HTML) version that omits the figures. The tables of tools,
	however, will be valuable to practitioners, and these are only in
	the PDF version of the paper.},
  timestamp = {2013.01.10},
  url = {http://doi.acm.org/10.1145/1924421.1924451}
}

@INPROCEEDINGS{Cao2004,
  author = {Cao, L. and Mohan, K. and Xu, P. and Ramesh, B.},
  title = {How extreme does extreme programming have to be? Adapting XP practices
	to large-scale projects},
  booktitle = {System Sciences, 2004. Proceedings of the 37th Annual Hawaii International
	Conference on},
  year = {2004},
  pages = {10--pp},
  file = {Cao2004.pdf:literature/Cao2004.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@INPROCEEDINGS{Capilla2007a,
  author = {Capilla, Rafael and Nava, Francisco and Due\~{n}as, Juan Carlos},
  title = {{Modeling and Documenting the Evolution of Architectural Design Decisions}},
  booktitle = {Second Workshop on Sharing and Reusing Architectural Knowledge -
	Architecture, Rationale, and Design Intent (SHARK/ADI'07: ICSE Workshops
	2007)},
  year = {2007},
  month = may,
  publisher = {IEEE},
  doi = {10.1109/SHARK-ADI.2007.9},
  file = {:./literature/Capilla2007.pdf:PDF},
  isbn = {0-7695-2951-8},
  owner = {Sebastian},
  timestamp = {2014.03.18},
  url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4273349 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4273349}
}

@ARTICLE{Capilla2006,
  author = {Capilla, Rafael and Nava, Francisco and P\'{e}rez, Sandra and Due\~{n}as,
	JC},
  title = {{A web-based tool for managing architectural design decisions}},
  journal = {SIGSOFT Softw. Eng. Notes},
  year = {2006},
  volume = {31},
  number = {5},
  annote = {ADDSS},
  doi = {10.1145/1163514.1178644},
  file = {:./literature/Capilla2006.pdf:PDF},
  keywords = {architecture design decisions,patterns,requirements,software,software
	architecture,traceability},
  mendeley-groups = {Architecture Knowledge/Models/ADDSS},
  owner = {Sebastian},
  timestamp = {2014.03.18},
  url = {http://dl.acm.org/citation.cfm?id=1178644}
}

@INPROCEEDINGS{KruchtenEmperical2008, 
author={Falessi, D. and Cantone, G. and Kruchten, P.}, 
booktitle={Software Architecture, 2008. WICSA 2008. Seventh Working IEEE/IFIP Conference on}, 
title={Value-Based Design Decision Rationale Documentation: Principles and Empirical Feasibility Study}, 
year={2008}, 
month={Feb}, 
pages={189-198}, 
keywords={decision making;design;software engineering;system documentation;design decision rationale documentation;inhibitors;value-based software engineering;Application software;Computer architecture;Computer industry;Costs;Documentation;Inhibitors;Software architecture;Software design;Software engineering;Software testing;Design decision rationale documentation;empirical software engineering;value based software engineering}, 
doi={10.1109/WICSA.2008.8},}

@incollection{LagoMindset,
year={2007},
isbn={978-3-540-77617-8},
booktitle={Software Architectures, Components, and Applications},
volume={4880},
series={Lecture Notes in Computer Science},
editor={Overhage, Sven and Szyperski, ClemensA. and Reussner, Ralf and Stafford, JudithA.},
doi={10.1007/978-3-540-77619-2_14},
title={The Architectâs Mindset},
url={http://dx.doi.org/10.1007/978-3-540-77619-2_14},
publisher={Springer Berlin Heidelberg},
keywords={software architecture; architectural knowledge},
author={Clerc, Viktor and Lago, Patricia and van Vliet, Hans},
pages={231-249},
language={English}
}

@INPROCEEDINGS{Capilla2007,
  author = {Capilla, R. and Nava, F. and Tang, A.},
  title = {Attributes for Characterizing the Evolution of Architectural Design
	Decisions},
  booktitle = {Third International IEEE Workshop on Software Evolvability, 2007},
  year = {2007},
  pages = {15-22},
  month = {Oct.},
  publisher = {IEEE},
  abstract = {Software architecture has been widely used to describe the design
	of a software system. Its maintenance over time can be costly, especially
	when maintainers have to recover software architecture knowledge
	due to poor design documentation. Capturing design decisions is one
	important aspect in documenting design and even though there has
	been some work in this area, there has been little emphasis on the
	evolution of design decisions. In this paper, we analyze design decision
	models and the issues of not capturing evolving decisions. To tackle
	these issues, we propose a set of decision attributes that can be
	used to support evolving decision models.},
  doi = {10.1109/SE.2007.17},
  file = {:./literature/04383092.pdf:PDF},
  keywords = {decision making, design, software architecture, software maintenance,
	system documentationarchitectural design decision evolution, design
	documentation, software architecture, software maintenance},
  owner = {Stephan},
  review = {design decisions important --> document them, record design rationale
	
	
	recently: design decisions as first class entities
	
	--> decision view added to Rational's 4+1 views
	
	already design decision models exisitent - several types of decision
	links
	
	but: dealing with evolutio of decisions insufficient
	
	
	tool support for design decisions:
	
	- Archium
	
	- PAKME
	
	- ADDSS
	
	- AREL / eAREL (better support for evolution)
	
	
	evolutionary information described by attributes
	
	--> further attributes to design decision artifacts must be added
	
	- links between decisions also must be adapted
	
	--> versioning of links
	
	--> trace the evolution of links},
  timestamp = {2008.10.01}
}

@article{HarrisonA10,
  added-at = {2010-09-07T00:00:00.000+0200},
  author = {Harrison, Neil B. and Avgeriou, Paris},
  biburl = {http://www.bibsonomy.org/bibtex/2d6a06f6a9b7d95519b23f948bb8ad0bc/dblp},
  ee = {http://dx.doi.org/10.1016/j.jss.2010.04.067},
  interhash = {b1d79e7d20ff2083512a6907748ba10b},
  intrahash = {d6a06f6a9b7d95519b23f948bb8ad0bc},
  journal = {Journal of Systems and Software},
  keywords = {dblp},
  number = 10,
  pages = {1735-1758},
  timestamp = {2010-09-07T00:00:00.000+0200},
  title = {How do architecture patterns and tactics interact? A model and annotation.},
  url = {http://dblp.uni-trier.de/db/journals/jss/jss83.html#HarrisonA10},
  volume = 83,
  year = 2010
}

@inproceedings{KamalA10,
  added-at = {2010-08-30T00:00:00.000+0200},
  author = {Kamal, Ahmad Waqas and Avgeriou, Paris},
  biburl = {http://www.bibsonomy.org/bibtex/2fa99156bd95317ffc84e9ba10ae5e01b/dblp},
  booktitle = {ECSA},
  crossref = {conf/ecsa/2010},
  editor = {Babar, Muhammad Ali and Gorton, Ian},
  ee = {http://dx.doi.org/10.1007/978-3-642-15114-9_34},
  interhash = {aa7e6d7b9a28d52c3e91b1278b4d61a8},
  intrahash = {fa99156bd95317ffc84e9ba10ae5e01b},
  isbn = {978-3-642-15113-2},
  keywords = {dblp},
  pages = {401-408},
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  timestamp = {2010-08-30T00:00:00.000+0200},
  title = {Mining Relationships between the Participants of Architectural Patterns.},
  url = {http://dblp.uni-trier.de/db/conf/ecsa/ecsa2010.html#KamalA10},
  volume = 6285,
  year = 2010
}


@inproceedings{AvgeriouZ05,
  added-at = {2010-03-02T00:00:00.000+0100},
  author = {Avgeriou, Paris and Zdun, Uwe},
  biburl = {http://www.bibsonomy.org/bibtex/2632ca18db20ea04d5420de0b7385f159/dblp},
  booktitle = {EuroPLoP},
  crossref = {conf/europlop/2005},
  date = {2010-03-02},
  description = {dblp},
  editor = {Longshaw, Andy and Zdun, Uwe},
  interhash = {9d5a39ca35f0e8e303e51e5ae8c8c4a6},
  intrahash = {632ca18db20ea04d5420de0b7385f159},
  isbn = {978-3-87940-805-4},
  keywords = {dblp},
  pages = {431-470},
  publisher = {UVK - Universitaetsverlag Konstanz},
  timestamp = {2010-03-02T00:00:00.000+0100},
  title = {Architectural Patterns Revisited - A Pattern Language.},
  url = {http://dblp.uni-trier.de/db/conf/europlop/europlop2005.html#AvgeriouZ05},
  year = 2005
}

@inproceedings{Zimmermann12,
  added-at = {2012-12-06T00:00:00.000+0100},
  author = {Zimmermann, Olaf},
  biburl = {http://www.bibsonomy.org/bibtex/200dfe37e19911ce068e0af0a2ad2ba56/dblp},
  booktitle = {WICSA/ECSA Companion Volume},
  crossref = {conf/wicsa/2012c},
  editor = {M�nnist�, Tomi and Babar, Muhammad Ali and Cuesta, Carlos E. and Savolainen, Juha Erik},
  ee = {http://doi.acm.org/10.1145/2361999.2362021},
  interhash = {b65c575df10cfd9901d47a04fd52856f},
  intrahash = {00dfe37e19911ce068e0af0a2ad2ba56},
  isbn = {978-1-4503-1568-5},
  keywords = {dblp},
  pages = {96-103},
  publisher = {ACM},
  series = {ACM International Conference Proceeding Series},
  timestamp = {2012-12-06T00:00:00.000+0100},
  title = {Architectural decision identification in architectural patterns.},
  url = {http://dblp.uni-trier.de/db/conf/wicsa/wicsac2012.html#Zimmermann12},
  volume = 704,
  year = 2012
}

@INCOLLECTION{Capilla2011,
  author = {Capilla, Rafael and Zimmermann, Olaf and Zdun, Uwe and K\"{u}ster,
	Jochen M.},
  title = {An enhanced architectural knowledge metamodel linking architectural
	design decisions to other artifacts in the software engineering lifecycle},
  booktitle = {Software Architecture},
  publisher = {Springer Berlin Heidelberg},
  year = {2011},
  pages = {303-318},
  annote = {- extends ADkwik to counter the shortcomings - shortcoming of ADkwik,
	ADDSS and The Knowledge Architect related to traceability links --
	only coarse-grained traces, i.e. not pssoible to trace attributes
	of class model -- no attention on history and evolution von decisions
	-- deferring decisions to runtime is not supported - key findings
	after conducting user survey in respecto ADkwik metamodel: -- decisions
	have to be visited multiple times -- lifetime of decisions transcends
	indentification, making and enforcement -> evaluation after system
	is implemented to see if they fulfill the requirements},
  doi = {10.1007/978-3-642-23798-0\_33},
  file = {:Users/gerdes/Documents/daten/doc/paper/mendeley/Capilla et al/ldots Architecture/Capilla et al._2011_An enhanced architectural knowledge metamodel linking architectural design decisions to other artifacts in the softw.pdf:PDF},
  keywords = {Traceability,architectural design decisions,architectural knowledge,evolution,metamodel,runtime
	decisions,traceability},
  mendeley-tags = {Traceability},
  owner = {Sebastian},
  timestamp = {2014.03.17},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-23798-0\_33}
}

@MASTERSTHESIS{Carimo2006,
  author = {Rossana Abdul Carimo},
  title = {Evaluation of UML Profile for Quality of Service from the User Perspective},
  school = {School of Engineering, Blekinge Institute of Technology, Ronneby,
	Sweden},
  year = {2006},
  abstract = {Addressing Quality of Service and specification of quality attributes
	has been gaining a growing importance in the software engineering
	area. The research presented in this study investigates different
	approaches to specification of Quality of Service. UML profile for
	Quality of Service is one of the standards of the Quality of Service
	specification and is described in the QoS specification context.
	
	The research aim of this thesis is the evaluation of the UML profile
	for Quality of Service against the following criteria: expressiveness,
	reusability, understandability, applicability and tool support, as
	well as further comparison of the profile with other Quality of Service
	specification languages. To perform that, several tasks and activities
	were conducted, such as a survey on different QoS specification languages,
	an examination of the UML profile for Quality of Service, the formulation
	of the evaluation criteria, and the appliance of the criteria in
	the evaluation and comparison processes. 
	
	This study is performed from the perspective of readers and users
	of the profile that are not UML experts but have sufficient knowledge
	of UML in terms of software systems analysis and design. 
	
	The context of the UML profile and Quality of Service aspects include
	basic concepts of the UML 2.0 and Quality of Service which will be
	described along the thesis. 
	
	The main contribution of the thesis is the evaluation of the UML profile
	for Quality of Service against a set of criteria, followed by explanations
	on the contents of the profile and how Quality of Service is specified
	within it. 
	
	The presented comparison of the UML profile and other Quality of Service
	specification languages could be the basis for a user to decide what
	language to use in a particular situation. 
	
	This study can be comprehended as a starting point for further evaluation
	of the UML profile and its comparison with other quality specification
	languages.},
  file = {:./literature/Carimo_mse_2007_03_Final.pdf:PDF},
  keywords = {QoS, UML profile, modeling language, evaluation, comparison, QoS specification,
	meta-models, profile, stereotypes},
  owner = {Stephan},
  timestamp = {2008.05.15},
  url = {http://www.bth.se/fou/cuppsats.nsf/all/3ac77eb62128e695c125729e0047fefd/$file/Carimo_mse_2007_03_Final.pdf}
}

@INPROCEEDINGS{Carlshamre2001,
  author = {Carlshamre, P. and Sandahl, K. and Lindvall, M. and Regnell, B. and
	Natt och Dag, J.},
  title = {An industrial survey of requirements interdependencies in software
	product release planning},
  booktitle = {Proceedings of the Fifth IEEE International Symposium on Requirements
	Engineering},
  year = {2001},
  pages = {84-91},
  owner = {Steffen},
  timestamp = {2012.12.05}
}

@INPROCEEDINGS{Carriere1999,
  author = {Carriere, S.J. and Kazman, R. and Woods, S.G.},
  title = {Assessing and maintaining architectural quality},
  booktitle = {Proceedings of the Third European Conference on Software Maintenance
	and Reengineering},
  year = {1999},
  pages = {22-30},
  publisher = {IEEE},
  abstract = {Software architecture analysis is a cost effective means of controlling
	risk and maintaining system quality throughout the processes of software
	design, development and maintenance. The paper presents a sequence
	of steps that maps architectural quality goals into scenarios that
	measure the goals, mechanisms that realize the scenarios and analytic
	models that measure the results. This mapping ensures that design
	decisions and their rationale are documented in such a fashion that
	they can be systematically explored, varied, and potentially traded
	off against each other. As systems evolve, the analytic models can
	be used to assess the impact of architectural changes, relative to
	the system's changing quality goals},
  doi = {10.1109/CSMR.1999.756679},
  file = {:./literature/Carriere1999.pdf:PDF},
  keywords = {risk management, software architecture, software maintenance, software
	qualityanalytic models, architectural changes, architectural quality
	assessment, architectural quality goals, design decisions, quality
	goals, risk control, scenarios, software architecture analysis, software
	design, system quality maintenance},
  owner = {Stephan},
  review = {general description of steps for quality realization
	
	
	generic qualities mapped to
	
	abstract scenarios (optional) to
	
	derived/specific scenarios to
	
	generic mechanisms (optional) to
	
	specific mechanisms to
	
	analytic model},
  timestamp = {2009.12.04}
}

@ARTICLE{Casey2004,
  author = {Casey, V. and Richardson, I.},
  title = {A practical application of the IDEAL model},
  journal = {Software Process: Improvement and Practice},
  year = {2004},
  volume = {9},
  pages = {123--132},
  number = {3},
  file = {Casey2004.pdf:literature/Casey2004.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@INPROCEEDINGS{Cass2002,
  author = {Cass, A. and Volcker, C. and Sutter, P. and Dorling, A. and Stienen,
	H.},
  title = {SPiCE in action-experiences in tailoring and extension},
  booktitle = {Euromicro Conference, 2002. Proceedings. 28th},
  year = {2002},
  pages = {352--360},
  organization = {IEEE},
  file = {Cass2002.pdf:literature/Cass2002.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.23}
}

@ARTICLE{Castor2008,
  author = {A. Castor and R. Pinto and C. Silva and J. Castro},
  title = {Towards Requirement Traceability in TROPOS},
  year = {2008},
  abstract = {Abstract. If we are to be successful in the development of the next
	generation of agent oriented systems we must deal with the critical
	issue of requirements traceability. Failure to do so will imply in
	higher costs and longer corrective and adaptable maintenance. Unfortunately
	most agent-oriented methodologies are not addressing this issue.
	Requirement traceability is intended to ensure continued alignment
	between stakeholders ’ requirements and various outputs of the system
	development process. In this paper we show how traceability could
	be applied to agent oriented development paradigm. In fact, software
	developers have used agents as a way to understand, model, and develop
	more naturally an important class of complex system. The growth of
	interest in software agents has recently led to the development of
	new methodologies based on agent concepts. However, few agent-oriented
	methodologies are requirement driven, or recognize traceability as
	an important issue to be supported. In this paper we argue that requirement
	traceability must be considered in agent-oriented methodologies.
	In particular we show how a general-purpose traceability approach
	can be used in the context of the Tropos framework. An e-commerce
	case study is used to demonstrate the applicability of the approach.
	Key words: requirements traceability, agent-oriented development.
	1},
  file = {:./literature/A_Castor.pdf:PDF},
  institution = {CiteSeerX - Scientific Literature Digital Library and Search Engine
	[http://citeseerx.ist.psu.edu/oai2] (United States)},
  location = {http://www.scientificcommons.org/43467702},
  owner = {Elke},
  timestamp = {2011.06.17},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.84.7222}
}

@INPROCEEDINGS{Cater-Steel2004,
  author = {Cater-Steel, A.P.},
  title = {Low-rigour, rapid software process assessments for small software
	development firms},
  booktitle = {Software Engineering Conference, 2004. Proceedings. 2004 Australian},
  year = {2004},
  pages = {368--377},
  file = {Cater-Steel2004.pdf:literature/Cater-Steel2004.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@ARTICLE{Cater-Steel2006,
  author = {Cater-Steel, A. and Toleman, M. and Rout, T.},
  title = {Process improvement for small firms: An evaluation of the RAPID assessment-based
	method},
  journal = {Information and Software Technology},
  year = {2006},
  volume = {48},
  pages = {323--334},
  number = {5},
  file = {Cater-Steel2006.pdf:literature/Cater-Steel2006.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@INPROCEEDINGS{Cavnar1994,
  author = {Cavnar, William B. and Trenkle, John M.},
  title = {N-Gram-Based Text Comparison},
  booktitle = {Proceedings of the 3rd Annual Symposium on document Analysis and
	Information Retrieval (SDAIR-94)},
  year = {1994},
  pages = {161-175},
  file = {:./literature/Cavnar1994.pdf:PDF},
  keywords = {n-gram},
  owner = {Stephan},
  timestamp = {2011.02.03}
}

@INPROCEEDINGS{Ceccarelli2010,
  author = {Ceccarelli, Michele and Cerulo, Luigi and Canfora, Gerardo and Di
	Penta, Massimiliano},
  title = {An Eclectic Approach for Change Impact Analysis},
  booktitle = {Proceedings of the 32nd ACM/IEEE International Conference on Software
	Engineering},
  year = {2010},
  pages = {163-166},
  file = {:./literature/Paper_34.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- existing approaches for association rules have problems when spread
	over large interval of time
	
	
	Research Questions:
	
	- improve forecasting of changes by examing previous changes
	
	- decide which change is useful for prediction and which not
	
	
	Contribution:
	
	- new approach for IA using statistical learning approach (using Granger
	causality) to infer mutual relations between software objects
	
	- Granger causality test helps learning consequent changes
	
	
	Solution:
	
	- use of Vector Auto-Regression (VAR) model to capture evolution and
	interdependencies between multiple time series
	
	- use Granger test to identify changes that are useful for forecasting
	changes to other software artifacts
	
	-> granularity of entities: source files
	
	-> granularity of changes: change records from version control systems
	
	-> granularity of results: source files
	
	
	Open Issues:
	
	- Granger test depends on carefully chosen variables, tweaking them
	is an issue},
  timestamp = {2011.02.04}
}

@ARTICLE{Cepeda2005,
  author = {Cepeda, S.L.},
  title = {CMMI{\textregistered}-Staged or Continuous?},
  journal = {Cepeda Systems and Software Analysis, Inc. Luettavissa: http://www.
	sei. cmu. edu/library/assets/cepeda-cmmi. pdf. Luettu},
  year = {2005},
  volume = {10},
  pages = {2009},
  file = {Cepeda2005.pdf:literature/Cepeda2005.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.19}
}

@ARTICLE{Chakrabarti2006,
  author = {Sujit Kumar Chakrabarti and Y.N. Srikant},
  title = {Specification Based Regression Testing Using Explicit State Space
	Enumeration},
  journal = {Software Engineering Advances, International Conference on},
  year = {2006},
  volume = {0},
  pages = {20},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/ICSEA.2006.65},
  file = {:/literature/RegressionTesting/specification based regression test selection using explicit state space enumerations.pdf:PDF},
  isbn = {0-7695-2703-5},
  keywords = {SpecificationBased, Read, Relevant},
  owner = {Annie},
  publisher = {IEEE Computer Society},
  review = {specifications are written in API language which is a textual specification
	language.},
  timestamp = {2011.10.20}
}

@ARTICLE{Chan2007,
  author = {Kenneth Chan and Iman Poernomo},
  title = {QoS-aware model driven architectture through the UML and CIM},
  journal = {Information Systems Frontiers},
  year = {2007},
  volume = {9},
  pages = {209-224},
  number = {2-3},
  month = {July},
  abstract = {The specification of Quality of Service (QoS) constraints over software
	design requires measures that ensure such requirements are met by
	the delivered product. Achieving this goal is non-trivial, as it
	involves, at least, identifying how QoS constraint specifications
	should be checked at the runtime. In this paper we present an implementation
	of a Model Driven Architecture (MDA) based framework for the runtime
	monitoring of QoS properties. We incorporate the UML2 superstructure
	and the UML profile for Quality of Service to provide abstract descriptions
	of component-and-connector systems. We then define transformations
	that refine the UML2 models to conform with the Distributed Management
	Taskforce (DMTF) Common Information Model (CIM) (Distributed Management
	Task Force Inc. 2006), a schema standard for management and instrumentation
	of hardware and software. Finally, we provide a mapping the CIM metamodel
	to a .NET-based metamodel for implementation of the monitoring infrastructure
	utilising various .NET features including the Windows Management
	Instrumentation (WMI) interface.},
  doi = {10.1007/s10796-007-9033-8},
  file = {:./literature/QoSawareMDA.pdf:PDF},
  keywords = {model driven architecture, QoS, monitoring, instrumentation},
  owner = {Stephan},
  timestamp = {2008.05.15}
}

@ARTICLE{Chapin2001,
  author = {Ned Chapin and Joanne E. Hale and Khaled Md. Kham and Juan F. Ramil
	and Wui-Gee Tan},
  title = {Types of software evolution and software maintenance},
  journal = {Journal of Software Maintenance},
  year = {2001},
  volume = {13},
  pages = {3-30},
  number = {1},
  abstract = {The past two decades have seen increasing sophistication in software
	work. Now and in the future, the work of both practitioners and researchers
	would be helped by a more objective and finer granularity recognition
	of types of software evolution and software maintenance activities
	as actually done. To these ends, this paper proposes a clarifying
	redefinition of the types of software evolution and software maintenance.
	The paper bases the proposed classification not on people's intentions
	but upon objective evidence of maintainers' activities ascertainable
	from observation of activities and artifacts, and/or a before and
	after comparison of the software documentation. The classification
	includes taking into account in a semi-hierarchical manner evidence
	of the change or lack thereof in: (1) the software, (2) the documentation,
	(3) the properties of the software, and (4) the customer-experienced
	functionality. A comparison is made with other classifications and
	typologies. The paper provides a classified list of maintenance activities
	and a condensed decision tree as a summary guide to the proposed
	evidence-based classification of the types of software evolution
	and software maintenance.},
  address = {New York, NY, USA},
  file = {:./literature/types-of-software-evolution-and-maintenance.pdf:PDF},
  issn = {1040-550X},
  keywords = {software evolution management; software maintenance management; maintainer
	activities; maintenance terminology; evolution terminology; software
	support; empirical studies},
  owner = {Stephan},
  publisher = {John Wiley \& Sons, Inc.},
  review = {classification of the types of different maintenance and evolution
	activities
	
	
	substitutes for software maintenance: "operational support", "continous
	development"
	
	
	intention-based approach
	
	- perfective maintenance
	
	- adaptive maintenance
	
	- corrective maintenance
	
	-> intentions not reliable and not consistently determainable
	
	
	-> here evidence-based approach
	
	- evidence in form of performed activities resulting in changes
	
	- changes concerning: software, code, or customer-experienced functionality
	
	
	12 types of software maintenance and evolution in 4 clusters with
	increasing impact on software
	
	- e.g. enhancing software with new functionality has more impact than
	changing non-code documentation
	
	
	support interface:
	
	- training
	
	- consultive
	
	- evaluative*
	
	
	documentation:
	
	- reformative
	
	- updative*
	
	
	software properties:
	
	- groomative
	
	- preventive
	
	- performance
	
	- adaptive*
	
	
	business rules:
	
	- reductive
	
	- corrective
	
	- enhancive*
	
	
	how to decide which type
	
	- was software changed? no -> support interface
	
	yes: was source code changed? no -> documentation
	
	yes: was function changed? no -> software properties
	
	yes: -> buisness rules
	
	
	if mixture of types present -> dominating type (*) decisive
	
	
	- all types applicable with maintenance
	
	- evolution only: enhansive, corrective, reductive, adaptive, performance},
  timestamp = {2008.06.16},
  url = {http://www.few.vu.nl/~steven/sam/types-of-software-evolution-and-maintenance.pdf}
}

@BOOK{Chappell2004,
  title = {Enterprise Service Bus},
  publisher = {O'Reilly Media},
  year = {2004},
  author = {David. A. Chappell},
  address = {USA},
  edition = {1},
  keywords = {SOA, ESB, Enterprise Service Bus},
  owner = {Stephan},
  timestamp = {2010.10.29}
}

@CONFERENCE{Charrada2011,
  author = {Charrada, Eya Ben and Caspar, David and Jeanneret, C\'{e}dric and
	Glinz, Martin},
  title = {Towards a Benchmark for Traceability},
  booktitle = {Proceedings of the 12th International Workshop on Principles of Software
	Evolution and the 7th annual ERCIM Workshop on Software Evolution},
  year = {2011},
  pages = {21-30},
  address = {Szeged, Hungary},
  month = {September},
  file = {:./literature/p21.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.09.12}
}

@INPROCEEDINGS{Chaumun1999,
  author = {Chaumun, M. Ajmal and Kabaili, Hind and Keller, Rudolf K. and Lustman,
	Francois},
  title = {A change impact model for changeability assessment in object-oriented
	software systems},
  booktitle = {Proceedings of the Third European Conference on Software Maintenance
	and Reengineering},
  year = {1999},
  pages = {130-149},
  file = {:./literature/Paper_92.pdf:PDF},
  owner = {Steffen},
  review = {important stuff: combination of changes types and dependency types
	
	
	Problem:
	
	- growing maintenance costs become a major concern for developers
	and users
	
	- changeability is important, especially when changes are frequent
	
	
	Research Questions:
	
	- what is the influence of high-level design on maintainability
	
	- how do inter-class dependencies influence changeability
	
	
	Contribution:
	
	- approach computing the impact of changes on classes
	
	- change impact model defined at conceptual level and mapped on C++
	
	
	Solution:
	
	- the conceptual models comprised of the following definitions
	
	* consider classes, methods and variables as objects of interest (called
	"Components" in this paper)
	
	* consider changes to any of these "Components"
	
	 - add/remove
	
	 - signature/type/visibility/scope change
	
	 - structure change
	
	 -> list of 66 types of changes (12 variable, 35 method, 19 class)
	
	* consider 4 types of links between "Components" association, aggregation,
	inheritance and invocation
	
	- impact of a change depends on 2 main factors:
	
	* type of change
	
	* link-type between involved classes
	
	- use impact model to predict changes to classes
	
	* only consider syntax of software
	
	* compute impact based on the 66 change types and links between classes
	etc.
	
	-> prepare "truth"-tables stating which change has impact ~> explicit
	rules
	
	-> granularity of entities: class, method, variable
	
	-> granularity of changes: atomic changes (add/remove, signature/type/visibility
	change)
	
	-> granularity of results: class, method, variable
	
	
	Open Issues:
	
	- very bad assumption made (CRITICAL !!!!!!): if the system re-compiles
	after a change, there is no impact (as approach only based on syntax)},
  timestamp = {2011.02.23}
}

@ARTICLE{Che2012,
  author = {Che, Meiru and Perry, Dewayne E.},
  title = {Managing architectural design decisions documentation and evolution},
  journal = {International Journal of Computers},
  year = {2012},
  volume = {6},
  pages = {137-148},
  number = {2},
  file = {:./literature/Paper_274.pdf:PDF},
  owner = {Steffen},
  timestamp = {2014.03.14}
}

@ARTICLE{Satu2007,
  author = {Elo, Satu and Kyngas, Helvi},
  title = {The qualitative content analysis process},
  journal = {Journal of Advanced Nursing},
  year = {2007},
  volume = {62(1)},
  pages = {107-115},
  number = {2},
  owner = {Mohamed},
  timestamp = {2014.04.10}
}

@INPROCEEDINGS{Chen2001,
  author = {Chen, Kunrong and Rajlich, V\'{a}clav},
  title = {{RIPPLES}: Tool for Change in Legacy Software},
  booktitle = {Proceedings of the IEEE International Conference on Software Maintenance},
  year = {2001},
  pages = {230-239},
  address = {Florence, Italy},
  month = {November},
  file = {:./literature/Paper_178.PDF:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- concept location and change propagation are basic problems of software
	development
	
	- not all dependencies between code components are captured by static
	analysis
	
	
	Research Questions:
	
	- support developer activity while changing software with solid tool
	support
	
	
	Contribution:
	
	- RIPPLES tool using a "Abstract System Dependency Graph" (ASDG) for
	estimating change propagation
	
	
	Solution:
	
	- combine dependencies obtained through static analysis with conceptual
	dependencies
	
	- variables, methods and types supply the graph's nodes whereas data
	and control flow support the edges
	
	- remove statements with no function call or variable modification
	(e.g. set value)
	
	- ASDG can be used for concept location, e.g. bottom-up/top-down or
	backward data flow strategy
	
	- for change propagation, vertices are marked:
	
	* unmarked (default)
	
	* candidate
	
	* changed
	
	- egdes are marked as:
	
	* unmarked (default)
	
	* foward
	
	* backward
	
	-> granularity of entities: method, variable
	
	-> granularity of changes:
	
	-> granularity of results:
	
	
	Open Issues:
	
	- improvement of precision of approach
	
	- improve detection of conceptual dependencies},
  timestamp = {2011.08.12}
}

@INPROCEEDINGS{Chen2011,
  author = {Chen, Xiaofan and Grundy, John},
  title = {Improving Automated Documentation to Code Traceability by Combining
	Retrieval Techniques},
  booktitle = {Proceedings of the 2011 IEEE/ACM International Conference on Automated
	Software Engineering},
  year = {2011},
  pages = {223-232},
  month = {November},
  file = {:./literature/Paper_234.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.05.10}
}

@PHDTHESIS{Chen2002a,
  author = {Chen, Yapping},
  title = {Specification-based Regression Testing Measurement with Risk Analysis},
  school = {School of Graduate Studies and Research, Carleton University},
  year = {2002},
  file = {:/literature/RegressionTesting/MasterThesis.pdf:PDF},
  owner = {Annie},
  timestamp = {2011.05.03}
}

@INPROCEEDINGS{Chen2003,
  author = {Yanping Chen and Robert Probert},
  title = {A Risk-based Regression Test Selection Strategy},
  booktitle = {ISSRE 2003: Proceeding of the 14th IEEE International Symposium on
	Software Reliability Engineering},
  year = {2003},
  pages = {305--306},
  address = {Denver, Colorado, {USA}},
  month = nov,
  file = {:/literature/RegressionTesting/A Risk-based Regression Test Selection Strategy.pdf:PDF},
  keywords = {specification based, interesting, must read},
  owner = {Annie},
  timestamp = {2011.01.04}
}

@INPROCEEDINGS{Chen2002,
  author = {Yanping Chen and Robert L. Probert and D. Paul Sims},
  title = {Specification-based regression test selection with risk analysis},
  booktitle = {Proceedings of the 2002 conference of the Centre for Advanced Studies
	on Collaborative research},
  year = {2002},
  pages = {1},
  address = {Toronto, Ontario, Canada},
  publisher = {{IBM} Press},
  abstract = {Regression testing is essential to ensure software quality. The test
	team applies a regression test suite to ensure that new or modified
	features do not regress (make worse) existing features. Although
	existing research has addressed many problems and put forward solutions,
	most regression test techniques are code-based. Code-based regression
	test selection is good for unit testing, but it has a scalability
	problem. When the size of the subject under test grows, it becomes
	hard to manage all the information and to create corresponding traceability
	matrices. In this paper, we describe a specification-based method
	for regression test {selection.The} basic model we use for describing
	requirements based on customer features or behaviors is the activity
	diagram, which is a notation of the Unified Modeling Language {(UML).}
	A process for identifying the affected test cases is presented. To
	summarize our approach, we select two kinds of regression tests:
	i) Targeted Tests, which ensure that important current customer features
	are still supported adequately in the new release and ii) Safety
	Tests, which are risk-directed, and ensure that potential problem
	areas are properly handled. Our test selection technique will be
	based on a practical risk analysis model.},
  file = {:/literature/RegressionTesting/specification based regression test selection with risk analysis.pdf:PDF},
  owner = {Annie},
  review = {Artifacts: Activity daigarm
	
	Risk Analysyis
	
	
	Traceability matrix is used
	
	
	Test case representations: Pathss(sequence of edges)
	
	TC Classification: Affacted tests and prioritised safety tests
	
	
	Case study: Yes (3 IBM WEB SPHERE Components, 306 test cases)
	
	
	Tool support : No},
  timestamp = {2011.01.04},
  url = {http://portal.acm.org/citation.cfm?id=782115.782116&coll=GUIDE&dl=GUIDE&CFID=54491404&CFTOKEN=93053143}
}

@ARTICLE{Chen2009,
  author = {Yanping Chen and Robert L. Probert and Hasan Ural},
  title = {Regression test suite reduction based on SDL models of system requirements},
  journal = {Journal of Software Maintenance and Evolution: Research and Practice},
  year = {2009},
  volume = {21},
  pages = {379--405},
  number = {6},
  annote = {Abstract 10.1002/smr.415.abs This paper proposes a model-based regression
	test suite reduction method. The proposed method considers an {SDL}
	model representing the requirements of a system under test and a
	set of modifications on this model, applies dependence analysis to
	identify interaction patterns related to each type of modifications,
	i.e., adding, deleting, and changing transitions in the {SDL} model,
	and reduces the size of a given regression test suite by examining
	interaction patterns covered by each test case in the test suite.
	Results of empirical studies are reported. Copyright Ã‚Â© 2009 John
	Wiley \& Sons, Ltd.},
  file = {:/literature/RegressionTesting/ainee.pdf:PDF},
  issn = {1532-0618},
  keywords = {control dependence, data dependence, regression test suite reduction,
	requirements-based regression testing},
  owner = {Annie},
  review = {Models: 6 SDL models
	
	max No of testcase: 1691},
  timestamp = {2011.01.04},
  url = {http://dx.doi.org/10.1002/smr.415}
}

@INPROCEEDINGS{Chen2007,
  author = {Chen, Yanping and Probert, Robert L. and Ural, Hasan},
  title = {Regression test suite reduction using extended dependence analysis},
  booktitle = {Fourth international workshop on Software quality assurance: in conjunction
	with the 6th ESEC/FSE joint meeting},
  year = {2007},
  series = {SOQUA '07},
  pages = {62--69},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1295086},
  doi = {http://doi.acm.org/10.1145/1295074.1295086},
  file = {:/literature/RegressionTesting/Regression Test Suite Reduction Using Extended Dependence Analysis.pdf:PDF},
  isbn = {978-1-59593-724-7},
  keywords = {control dependence, data dependence, extended finite state machine,
	regression test suite reduction, regression testing},
  location = {Dubrovnik, Croatia},
  numpages = {8},
  owner = {Annie},
  review = {Model, EFSM
	
	
	additional: Data and Control Dependence
	
	
	change types Considered: Addition and deletion, change
	
	
	Impact analysis to detect side effects is performed
	
	
	Dependencies types: 12 model specific
	
	
	(In the analysis take care of inter model dependencies and sidde effects
	plus intra model dependencies and side effects)
	
	
	Case study not reported
	
	tool support no
	
	
	there is another journal paper after this work, obtain it some how
	to get the actual results},
  timestamp = {2011.01.04},
  url = {http://doi.acm.org/10.1145/1295074.1295086}
}

@INPROCEEDINGS{Chen1994,
  author = {Chen, Yih-Farn and Rosenblum, David S. and Vo, Kiem-Phong},
  title = {TestTube: a system for selective regression testing},
  booktitle = {Proceedings of the 16th international conference on Software engineering},
  year = {1994},
  series = {ICSE '94},
  pages = {211--220},
  address = {Los Alamitos, CA, USA},
  publisher = {IEEE Computer Society Press},
  acmid = {257769},
  file = {:/literature/RegressionTesting/test tube A system for selective regression testing.pdf:PDF},
  isbn = {0-8186-5855-X},
  keywords = {Read, Relevant, code based, for C programs},
  location = {Sorrento, Italy},
  numpages = {10},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=257734.257769}
}

@ARTICLE{Cheng2009,
  author = {Cheng, C.K. and Permadi, R.B.},
  title = {Towards an Evaluation Framework for Software Process Improvement},
  journal = {School of Computing, Blekinge Institute of Technology, Blekinge},
  year = {2009},
  volume = {149},
  file = {Cheng2009.pdf:literature/Cheng2009.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@ARTICLE{Chikofsky1990,
  author = {Chikofsky, E.J. and Cross, J.H., II},
  title = {Reverse engineering and design recovery: a taxonomy},
  journal = {IEEE Software},
  year = {1990},
  volume = {7},
  pages = {13-17},
  number = {1},
  month = {Jan},
  abstract = {The key to applying computer-aided software engineering to the maintenance
	and enhancement of existing systems lies in applying reverse-engineering
	approaches. However, there is considerable confusion over the terminology
	used in both technical and marketplace discussions. The authors define
	and relate six terms: forward engineering, reverse engineering, redocumentation,
	design recovery, restructuring, and reengineering. The objective
	is not to create new terms but to rationalize the terms already in
	use. The resulting definitions apply to the underlying engineering
	processes, regardless of the degree of automation applied.},
  doi = {10.1109/52.43044},
  file = {:./literature/00043044.pdf:PDF},
  issn = {0740-7459},
  keywords = {nomenclature, software engineeringcomputer-aided software engineering,
	design recovery, enhancement, existing systems, forward engineering,
	maintenance, redocumentation, reengineering, restructuring, reverse-engineering
	approaches, taxonomy},
  owner = {Stephan},
  review = {definition and relation of the terms: forward engineering, reverse
	engineering, redocumentation, design discovery, restructuring, and
	reengineering
	
	
	software maintenance
	
	--------------------------
	
	- modification of a software product after delivery to correct faults,
	to improve performance or other attributes, or to adapt the product
	to a changed environment [ANSI/IEEE Std 720-1983]
	
	- reverse engineering is a part of
	
	
	3 dependent concepts to describe forward and reverse engineering
	
	- existence of a life-cycle model
	
	- presence of a subject system
	
	- identification of abstraction levels
	
	
	in life-cycle model:
	
	- early stages: more general, implementation independent concepts
	
	- later stages: emphasis of implementation details
	
	
	distinction between levels and degrees of abstraction:
	
	- levels: crossing of conceptual stages of design
	
	- degrees: within a single stage
	
	- represent information in any single life-cycle stage in detailed
	form -> lower degree of abstraction
	
	- in more summarized or global form -> higher degree of abstraction
	
	
	forward engineering
	
	------------------------
	
	- traditional process of moving from high-level abstractions to the
	physical implementation
	
	- subject system is the result of the development process
	
	- sequence: requirements -> design -> implementation
	
	
	reverse engineering
	
	-----------------------
	
	- process of analyzing a subject system (often the starting point,
	but from any level of abstraction possible)
	
	- identify system components and relationships
	
	- create representations of system in form of higher level abstraction
	
	- a process of examination
	
	subareas:
	
	- redocumentation: creation or revision of a semantically equivalent
	representation within the same relative abstraction level -> pretty
	printers, diagram generators, cross-reference listing generators
	
	- design recovery: identification of meaningful higher level abstractions
	beyond direct examination -> use of domain knowledge, external information,
	fuzzy reasoning
	
	
	restructuring
	
	---------------
	
	- transformation from one representation form to another at the same
	relative abstraction level
	
	- preservation of system's external behaviour (functionality and semantics)
	
	- reshaping of data models, design plans, requirements structures
	(e.g. data normalization)
	
	- no modifications because of new requirements
	
	
	reengineering
	
	----------------
	
	- also: renovation, reclamation
	
	- examination and alteration of a subject system to reconstitute it
	in a new form
	
	- includes reverse engineering followed by forward engineering or
	restructuring
	
	- may include modificaitons for new requirements
	
	
	objectives
	
	------------
	
	- primary purpose of reverse engineering: increase of the overall
	comprehension of the system
	
	6 key objectives:
	
	- cope with complexity
	
	- generate alternate views
	
	- recover lost information
	
	- detect side effects (and anomalies)
	
	- synthesize higher abstractions
	
	- facilitate reuse},
  timestamp = {2008.04.29}
}

@ARTICLE{Chittimalli2009,
  author = {Chittimalli, Pavan Kumar and Harrold, Mary Jean},
  title = {Recomputing Coverage Information to Assist Regression Testing},
  journal = {IEEE Trans. Softw. Eng.},
  year = {2009},
  volume = {35},
  pages = {452--469},
  month = {July},
  __markedentry = {[qurat:]},
  acmid = {1592341},
  address = {Piscataway, NJ, USA},
  doi = {10.1109/TSE.2009.4},
  file = {:/literature/RegressionTesting/Re-computing Coverage Information to Assist Regression Testing.pdf:PDF},
  issn = {0098-5589},
  issue = {4},
  keywords = {code based; Regression testing, regression test selection, testing,
	maintenance.},
  numpages = {18},
  owner = {Annie},
  publisher = {IEEE Press},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=1591903.1592341}
}

@INPROCEEDINGS{Chittimalli2008,
  author = {Chittimalli, Pavan Kumar and Harrold, Mary Jean},
  title = {Regression test selection on system requirements},
  booktitle = {Proceedings of the 1st India software engineering conference},
  year = {2008},
  series = {ISEC '08},
  pages = {87--96},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1342229},
  doi = {http://doi.acm.org/10.1145/1342211.1342229},
  file = {:/literature/RegressionTesting/Regression Test Selection on System Requirements.pdf:PDF},
  isbn = {978-1-59593-917-3},
  keywords = {regression test selection, regression testing, requirements, test
	case prioritization, traceability},
  location = {Hyderabad, India},
  numpages = {10},
  owner = {Annie},
  timestamp = {2011.01.04},
  url = {http://doi.acm.org/10.1145/1342211.1342229}
}

@ARTICLE{Chiu2004,
  author = {Chiu, D.K.W. and Cheung, S.C. and Till, S. and Karlapalem, K. and
	Li, Q. and Kafeza, E.},
  title = {Workflow view driven cross-organizational interoperability in a web
	service environment},
  journal = {Information Technology and Management},
  year = {2004},
  volume = {5},
  pages = {221--250},
  number = {3},
  file = {Chiu2004.pdf:literature/Chiu2004.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.10.10}
}

@ARTICLE{Christensen2010,
  author = {Christensen, Henrik Bærbak and Hansen, Klaus Marius},
  title = {An empirical investigation of architectural prototyping.},
  journal = {Journal of Systems and Software},
  year = {2010},
  volume = {83},
  pages = {133-142},
  number = {1},
  added-at = {2010-01-12T00:00:00.000+0100},
  biburl = {http://www.bibsonomy.org/bibtex/2bc2ba0cb9b37cdfa631cd05161f8989a/dblp},
  date = {2010-01-12},
  description = {dblp},
  ee = {http://dx.doi.org/10.1016/j.jss.2009.07.049},
  file = {:./literature/christensen2010.pdf:PDF},
  interhash = {93563ad30db41cb42508b1192722a451},
  intrahash = {bc2ba0cb9b37cdfa631cd05161f8989a},
  keywords = {dblp},
  owner = {Sebastian},
  timestamp = {2013.07.23},
  url = {http://dblp.uni-trier.de/db/journals/jss/jss83.html#ChristensenH10}
}

@INPROCEEDINGS{Christensen1999,
  author = {Christensen, M. and Damm, C.H. and Hansen, K.M. and Sandvad, E. and
	Thomsen, M.},
  title = {Design and evolution of software architecture in practice},
  booktitle = {Proceedings Technology of Object-Oriented Languages and Systems,
	1999. TOOLS 32},
  year = {1999},
  pages = {2-15},
  publisher = {IEEE Xplore},
  abstract = {With special focus on software architectural issues, we report from
	the first two major phases of a software development project. Our
	experience suggests that explicit focus on software architecture
	in these phases was an important key to success. More specifically:
	Demands for stability, flexibility and proper work organisation in
	an initial prototyping phase of a project are facilitated by having
	an explicit architecture. However, the architecture should also allow
	for certain degrees of freedom for experimentation. Furthermore,
	in a following evolutionary development phase, architectural redesign
	is necessary and should be firmly based on experience gained from
	working within the prototype architecture. Finally, to get it right,
	the architecture needs to be prototyped, or iterated upon, throughout
	evolutionary development cycles. In this architectural prototyping
	process, we address the difficult issue of identifying and evolving
	functional components in the architecture and point to an architectural
	strategy a set of architectures, their context and evolution-that
	was helpful in this respect.},
  doi = {10.1109/TOOLS.1999.809410},
  file = {:./literature/christensen1999.pdf:PDF},
  keywords = {software architecture, software prototypingarchitectural prototyping,
	evolutionary development cycles, iterative development, object-oriented
	development, software architecture, software development project},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://www.cit.dk/COT/reports/reports/Case5/11/cot-5-11.pdf}
}

@INBOOK{Chung1999,
  pages = {545-564},
  title = {Architectural Design to meet Stakeholder Requirements},
  publisher = {Kluwer Academic Publishers},
  year = {1999},
  editor = {Donohoe, Patrick},
  author = {Chung, Lawrence and Gross, Daniel and Yu, Eric},
  abstract = {Architectural design occupies a pivotal position in software engineering.
	It is during architectural design that crucial requirements such
	as performance, reliability, costs, etc., must be addressed. Yet
	the task of achieving these properties remains a difficult one. Senior
	architects with many years of experience have to make difficult choices
	to meet competing requirements. This task is made even more difficult
	with the shift in software engineering paradigm from monolithic,
	stand-alone, built-from-scratch systems to componentized, evolvable,
	standards-based, and product line oriented systems. Many well-established
	design strategies need to be reconsidered as new requirements such
	as evolvability, reusability, time-to-market, etc., are becoming
	more important. These requirements do not come from a single source,
	but result from negotiations among many stakeholders. A systematic
	framework is needed to help architects achieve quality requirements
	during architectural design. This paper outlines an approach that
	formulates architectural properties such as modifiability and performance
	as “softgoals” which are incrementally refined. Tradeoffs are made
	as conflicts and synergies are discovered. Architectural decisions
	are traced to stakeholders and their dependency relationships. Knowledge-based
	tool support for the process would provide guidance during design
	as well as records of design rationales to facilitate understanding
	and change management.},
  file = {:./literature/ChungGrossYu_WICSA99.pdf:PDF},
  keywords = {software architecture, rationale, stakeholders, organization modeling,
	requirements, quality attributes, architectural properties, non-functional
	requirements, process-oriented, softgoal, satisficing, design reasoning},
  owner = {Stephan},
  timestamp = {2009.02.10},
  url = {http://www.utdallas.edu/~chung/ftp/WICSA99.pdf}
}

@inproceedings{TangReasoning2008,
 author = {Tang, Antony and Tran, Minh H. and Han, Jun and Vliet, Hans},
 title = {Design Reasoning Improves Software Design Quality},
 booktitle = {Proceedings of the 4th International Conference on Quality of Software-Architectures: Models and Architectures},
 series = {QoSA '08},
 year = {2008},
 isbn = {978-3-540-87878-0},
 location = {Karlsruhe, Germany},
 pages = {28--42},
 numpages = {15},
 url = {http://dx.doi.org/10.1007/978-3-540-87879-7_2},
 doi = {10.1007/978-3-540-87879-7_2},
 acmid = {1478071},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {Design Reasoning, Software Architecture Design, Usability},
}

@incollection{BabarAK,
year={2006},
isbn={978-3-540-30997-0},
booktitle={Rationale Management in Software Engineering},
editor={Dutoit, AllenH. and McCall, Raymond and MistrÃ­k, Ivan and Paech, Barbara},
doi={10.1007/978-3-540-30998-7_11},
title={A Framework for Supporting Architecture Knowledge and Rationale Management},
url={http://dx.doi.org/10.1007/978-3-540-30998-7_11},
publisher={Springer Berlin Heidelberg},
author={Babar, MuhammadAli and Gorton, Ian and Kitchenham, Barbara},
pages={237-254},
language={English}
}

@incollection{WeinreichSurvey,
year={2014},
isbn={978-3-319-09969-9},
booktitle={Software Architecture},
volume={8627},
series={Lecture Notes in Computer Science},
editor={Avgeriou, Paris and Zdun, Uwe},
doi={10.1007/978-3-319-09970-5_1},
title={A Fresh Look at Codification Approaches for SAKM: A Systematic Literature Review},
url={http://dx.doi.org/10.1007/978-3-319-09970-5_1},
publisher={Springer International Publishing},
keywords={Architecture Knowledge Management (AKM); AKM Codification Approaches; AKM Models; AKM Activities},
author={Weinreich, Rainer and Groher, Iris},
pages={1-16},
language={English}
}

@INPROCEEDINGS{Chung1995,
  author = {Lawrence Chung and Brian A. Nixon and Eric Yu},
  title = {Using Non-Functional Requirements to Systematically Support Change},
  booktitle = {Proceedings of The Second IEEE International Symposium on Requirements
	Engineering, (RE`95)},
  year = {1995},
  pages = {132-139},
  month = {March},
  publisher = {IEEE Computer Society},
  abstract = {Non-functional requirements (or quality requirements, NFRs) such as
	confidentiality, performance and timeliness are often crucial to
	a software system. Our NFR-framework treats NFRs as goals to be achieved
	during the process of system development. Throughout the process,
	goals are decomposed, design tradeoffs are analysed, design decisions
	are rationalised, and goal achievement is evaluated. This paper shows
	how a historical record of the treatment of NFRs during the development
	process can also serve to systematically support evolution of the
	software system. We treat changes in terms: of (i) adding or modifying
	NFRs, or changing their importance, and (ii) changes in design decisions
	or design rationale. This incremental approach is illustrated by
	a study of changes in banking policies at Barclays Bank.},
  doi = {10.1109/ISRE.1995.512554},
  file = {:./literature/RE95.pdf:PDF},
  keywords = {Barclays Bank, banking, formal specification, management of change,
	software engineering, software quality, systems analysis Barclays
	Bank, banking policies, confidentiality, design decisions, design
	tradeoffs, development process, evolution, goal achievement, goal
	decomposition, historical record, nonfunctional requirements, performance,
	quality requirement, software system, system development, systematic
	change support, timeliness},
  owner = {Stephan},
  review = {introduction to requirements engineering (RE) as branch of systems
	engineering
	
	activities: elicitation, modelling and analysing, communicating, agreeing,
	evolving
	
	
	disriptions for different activities: e.g. elicitation techniques,
	modelling approaches
	
	
	key challanges:
	
	- manage inconsistency
	
	- new techniques for modelling and analysing properties of the environment
	- deal with inconsistent, incomplete and evolving models
	
	- bridge the gap between requirements elicitation approaches based
	on contextual enquiry and more formal specification and analysis
	techniques
	
	- better understanding of impact of architectural choices on prioritization
	and evolution of requirements
	
	- training for requirements pratitioners
	
	
	- richer models for non-functional requirements - ilities
	
	- reuse of requirements models},
  timestamp = {2008.04.15},
  url = {http://www.cs.toronto.edu/pub/eric/RE95.pdf}
}

@INPROCEEDINGS{Chung1995a,
  author = {Lawrence Chung and Brian A. Nixon and Eric Yu},
  title = {Using Non-Functional Requirements to Systematically Select Among
	Alternatives in Architectural Design},
  booktitle = {Proc. 1st Int. Workshop on Architectures for Software Systems},
  year = {1995},
  pages = {31-43},
  abstract = {Non-functional requirements, such as modifiability, performance, reusability,
	comprehensibility and security, are often crucial to a software system.
	As such, these non-functional requirements (or NFRs) should be addressed
	as early as possible in a software lifecycle and properly reflected
	in a software architecture before committing to a detailed design.
	The purpose of this paper is to discuss how the treatment of NFRs
	as goals (which may be synergistic or conflicting) serves to systematically
	guide selection among architectural design alternatives. During the
	architectural design process, goals are decomposed, design alternatives
	are analysed with respect to their tradeoffs, design decisions are
	made rationalised, and goal achievement is evaluated. This process
	can be supported by by a body of organised knowledge. This paper
	outlines an approach by which such knowledge can be organized. This
	approach is illustrated by a preliminary study of architectural design
	for a KWIC (Key Word in Context) system.},
  citeseerurl = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.29.2252},
  file = {:./literature/ChungNixonYu_selectAlternatives.pdf:PDF},
  keywords = {non-functional requirements, selection among design alternatives},
  owner = {Stephan},
  review = {alternatives like shared data, abstract data type and implicit invocation
	are rated concerning modifiability, performance, and reusability
	
	-> evaluation and selection with the help of a goal-graph},
  timestamp = {2009.01.09},
  url = {http://www.ics.uci.edu/~andre/ics223w2006/chungnixonyu.pdf}
}

@INPROCEEDINGS{Chung1994,
  author = {Lawrence Chung and Brian A. Nixon and Eric Yu},
  title = {Using Quality Requirements to Systematically Develop Quality Software},
  booktitle = {Proceedings of the Fourth International Conference on Software Quality},
  year = {1994},
  address = {McLean, VA, USA},
  month = {Oct. 3-5},
  abstract = {Although quality issues such as accuracy, security, and performance
	are often crucial to the success of a software system, there has
	been no systematic way to achieve quality requirements during system
	development. We offer a framework and an implemented tool which treat
	quality requirements as goals to be achieved systematically during
	the system development process. We illustrate the process that a
	developer would go through, in building quality into a system. We
	have tested the framework on a number of studies involving a variety
	of quality requirements, organisational settings, and system types.},
  citeseerurl = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.34.7998},
  file = {:./literature/Chung_Nixon_YU_ICSQ4Paper.pdf:PDF},
  keywords = {non-functional requirements, accuracy, security, performance, information
	systems, process, software quality, defect detection, conflicts,
	NFR framework},
  owner = {Stephan},
  review = {preliminary work for NFR framework
	
	
	tool support: NFR assistant
	
	-> interaction between designer and tool is described
	
	
	open issues
	
	- transition from NFR to functiona components
	
	- NFR framework only for RE, nothing for SWA},
  timestamp = {2009.01.09},
  url = {ftp://ftp.cs.toronto.edu/pub/eric/ICSQ4Paper.pdf}
}

@BOOK{Chung2000,
  title = {Non-functional Requirements in Software Engineering},
  publisher = {Kluwer},
  year = {2000},
  author = {Chung, Lawrence and Nixon, Brian A. and Yu, Eric and Mylopoulos,
	John},
  volume = {5},
  pages = {472},
  series = {International Series in Software Engineering},
  abstract = {Non-Functional Requirements in Software Engineering presents a systematic
	and pragmatic approach to `building quality into' software systems.
	Systems must exhibit software quality attributes, such as accuracy,
	performance, security and modifiability. However, such non-functional
	requirements (NFRs) are difficult to address in many projects, even
	though there are many techniques to meet functional requirements
	in order to provide desired functionality. This is particularly true
	since the NFRs for each system typically interact with each other,
	have a broad impact on the system and may be subjective. To enable
	developers to systematically deal with a system's diverse NFRs, this
	book presents the NFR Framework. Structured graphical facilities
	are offered for stating NFRs and managing them by refining and inter-relating
	NFRs, justifying decisions, and determining their impact. Since NFRs
	might not be absolutely achieved, they may simply be satisfied sufficiently
	(`satisficed'). To reflect this, NFRs are represented as `softgoals',
	whose interdependencies, such as tradeoffs and synergy, are captured
	in graphs. The impact of decisions is qualitatively propagated through
	the graph to determine how well a chosen target system satisfices
	its NFRs. Throughout development, developers direct the process,
	using their expertise while being aided by catalogues of knowledge
	about NFRs, development techniques and tradeoffs, which can all be
	explored, reused and customized.
	
	Non-Functional Requirements in Software Engineering demonstrates the
	applicability of the NFR Framework to a variety of NFRs, domains,
	system characteristics and application areas. This will help readers
	apply the Framework to NFRs and domains of particular interest to
	them. Detailed treatments of particular NFRs - accuracy, security
	and performance requirements - along with treatments of NFRs for
	information systems are presented as specializations of the NFR Framework.
	Case studies of NFRs for a variety of information systems include
	credit card and administrative systems. The use of the Framework
	for particular application areas is illustrated for software architecture
	as well as enterprise modelling. Feedback from domain experts in
	industry and government provides an initial evaluation of the Framework
	and some case studies. Drawing on research results from several theses
	and refereed papers, this book's presentation, terminology and graphical
	notation have been integrated and illustrated with many figures.
	
	Non-Functional Requirements in Software Engineering is an excellent
	resource for software engineering practitioners, researchers and
	students.},
  comment = {http://books.google.de/books?hl=de&lr=&id=IgV_nRpf5tUC&oi=fnd&pg=PR9&ots=aLMTsv-uxf&sig=YAEMWn4IJXaqUXmHDAaJ0h8bqYg#PPP1,M1},
  file = {:./literature/134678990.pdf:PDF},
  keywords = {non-functional requirements, software engineering, softgoal, softgoal
	interdependency graph, tradeoffs, operationalizations},
  owner = {Stephan},
  timestamp = {2008.07.03},
  url = {http://www.springer.com/computer/programming/book/978-0-7923-8666-7}
}

@INCOLLECTION{Chung2009,
  author = {Chung, Lawrence and do Prado Leite, Julio},
  title = {{On Non-Functional Requirements in Software Engineering}},
  booktitle = {{Conceptual Modeling: Foundations and Applications}},
  publisher = {Springer Berlin / Heidelberg},
  year = {2009},
  editor = {Borgida, Alexander and Chaudhri, Vinay and Giorgini, Paolo and Yu,
	Eric},
  volume = {5600},
  series = {Lecture Notes in Computer Science},
  pages = {363-379},
  abstract = {Essentially a software system’s utility is determined by both its
	functionality and its non-functional characteristics, such as usability,
	flexibility, performance, interoperability and security. Nonetheless,
	there has been a lop-sided emphasis in the functionality of the software,
	even though the functionality is not useful or usable without the
	necessary non-functional characteristics. In this chapter, we review
	the state of the art on the treatment of non-functional requirements
	(hereafter, NFRs), while providing some prospects for future directions.},
  affiliation = {The University of Texas at Dallas Department of Computer Science},
  file = {:./literature/Chung2009.pdf:PDF},
  keywords = {non-functional requirement engineering, NFR framework, i*},
  owner = {Stephan},
  timestamp = {2010.11.08},
  url = {http://dx.doi.org/10.1007/978-3-642-02463-4_19}
}

@INPROCEEDINGS{Cibulski2011,
  author = {Cibulski, H. and Yehudai, A.},
  title = {Regression Test Selection Techniques for Test-Driven Development},
  booktitle = {Software Testing, Verification and Validation Workshops (ICSTW),
	2011 IEEE Fourth International Conference on},
  year = {2011},
  pages = {115 -124},
  month = {march},
  __markedentry = {[qurat:]},
  doi = {10.1109/ICSTW.2011.28},
  file = {:/literature/RegressionTesting/Regression Test Selection Techniques.pdf:PDF},
  keywords = {code based , prioritization technique, bug detection rate;code change;cost-bounded
	RTS technique;development cycle;dynamic program analysis;natural-language
	analysis;regression fault;regression test selection;test rank tool;test-driven
	development;natural language processing;program debugging;program
	diagnostics;program testing;software fault tolerance;},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@ARTICLE{Ciraci2007,
  author = {Selim Ciraci and Pim Broek van den and Mehmet Aksit},
  title = {A Taxonomy for a Constructive Approach to Software Evolution},
  journal = {Journal of Software},
  year = {2007},
  volume = {2},
  pages = {84-97},
  number = {2},
  abstract = {In many software design and evaluation techniques, either the software
	evolution problem is not systematically elaborated, or only the impact
	of evolution is considered. Thus, most of the time software is changed
	by editing the components of the software system, i.e. breaking down
	the software system. The software engineering discipline provides
	many mechanisms that allow evolution without breaking down the system;
	however, the contexts where these mechanisms are applicable are not
	taken into account. Furthermore, the software design and evaluation
	techniques do not support identifying these contexts. In this paper,
	we provide a taxonomy of software evolution that can be used to identify
	the context of the evolution problem. The identified contexts are
	used to retrieve, from the software engineering discipline, the mechanisms,
	which can evolve the software software without breaking it down.
	To build such a taxonomy, we build a model for software evolution
	and use this model to identify the factors that effect the selection
	of software evolution mechanisms. Our approach is based on solution
	sets, however; the contents of these sets may vary at different stages
	of the software life-cycle. To address this problem, we introduce
	perspectives; that are filters to select relevant elements from a
	solution set. We apply our taxonomy to a parser tool to show how
	it coped with problematic evolution problems.},
  file = {:./literature/taxonomy_for.pdf:PDF},
  keywords = {software evolution, architecture design mechanisms},
  owner = {Stephan},
  publisher = {Academy Publisher},
  review = {approach to improve the selection of appropriate mechanisms for software
	evolution problems concerning the integration of new requirements
	
	
	evolution problem is analyzed according to its context
	
	
	a context consist of three parameters: characteristic, relation, environment
	
	
	characteristic: extension, composition, exception
	
	relation of existing system to new solution: non-overlapping, overlapping
	(specialisation or interpretation)
	
	environment: run-time adatptation, compile-time adaptation, installation
	
	
	--> 24 feasbile contexts for which specific mechanisms can be applied
	
	
	proposed mechanisms are amongst other for example hook methods or
	classic design patterns such as bridge, decorator, observer, command,
	strategy},
  timestamp = {2009.08.05},
  url = {http://doc.utwente.nl/60223/1/taxonomy_for.pdf}
}

@INPROCEEDINGS{Ciraci2006,
  author = {Selim Ciraci and Pim van den Broek},
  title = {Evolvability as a Quality Attribute of Software Architectures},
  booktitle = {Proceedings of the International ERCIM Workshop on Software Evolution
	2006},
  year = {2006},
  editor = {Laurence Duchien, Maja D'Hondt and Kim Mens},
  pages = {29-31},
  address = {LIFL et l'INRIA, Universit\'e des Sciences et Technologies de Lille,
	France},
  month = {April},
  abstract = {We review the definition of evolvability as it appears on the literature.
	In particular, the concept of software evolvability is compared with
	other system quality attributes, such as adaptability, maintainability
	and modifiability.},
  file = {:./literature/0404paper.pdf:PDF;:http\://trese.cs.utwente.nl/publications/files/0404paper.pdf:PDF},
  keywords = {software evolvability, software evolution, quality attribute},
  owner = {Stephan},
  review = {two different uses and so research groups [Lehman et al. Evolution
	as a Noun and Evolution as a Verb]
	
	
	verb:
	
	- "how" to effectively and reliably evolve software systems
	
	- theories, abstractions, languages and methods
	
	
	noun:
	
	- "what" to investigate and learn properties of software evolution
	
	- "what is evolvable"
	
	- evolvability research
	
	
	- old definition of evolvability " the capability of software products
	to be evolved to continue to serve its customer in a cost effective
	way" [Cook et al.] lacks description of scope of changes
	
	-> three sources of software evolution:
	
	- domain
	
	- experience
	
	- process
	
	
	-> new definition for evolvability:
	
	- "a system's ability to survive changes in its environment, requirements
	and implementation technologies"
	
	-> shift in focus: also changes during initial development
	
	
	- evolvability should be considered as quality attribute since it
	is a NFR of a system
	
	
	goals [Bennett2000]:
	
	- SWA must allow changes without damaging the system's integrity
	
	- architectures must be evolvable in a controlled way
	
	
	evaluation of evolvability:
	
	- adapt techniques based on scenarios
	
	but: most of evolvability scenarios may be missed
	
	-> model based evaluation may be more suitable
	
	-> evolvability metrics needed
	
	- GQM
	
	
	following specific viewpoint of the authors:
	
	modifiability definition too broad, also evolvability definition
	
	- changes included for adaptability and maintainability can also be
	fitted to modifiability
	
	- modifiability as superset for all quality attributes that deal with
	changes
	
	- if system modifiable than it's also evolvable},
  timestamp = {2008.07.10},
  url = {ftp://ftp.umh.ac.be/pub/ftp_infofs/2006/ERCIMproceedings.pdf}
}

@INPROCEEDINGS{Clarke2003,
  author = {Clarke, Peter and Malloy, Brian and Gibson, Paul},
  title = {Using a Taxonomy Tool to Identify Changes in OO Software},
  booktitle = {Proceedings of the Seventh European Conference on Software Maintenance
	and Reengineering},
  year = {2003},
  pages = {213--},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid = {873575},
  file = {:/literature/RegressionTesting/Using A Taxonomy Tool To Identify Changes in OO Software.pdf:PDF},
  isbn = {0-7695-1902-4},
  keywords = {NotRelevant, code change},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=872754.873575}
}

@INPROCEEDINGS{Cleland-Huang2006,
  author = {Cleland-Huang, J.},
  title = {Just Enough Requirements Traceability},
  booktitle = {30th Annual International Computer Software and Applications Conference,
	2006 (COMPSAC '06)},
  year = {2006},
  volume = {1},
  pages = {41-42},
  month = {Sept},
  abstract = {Even though traceability is legally required in most safety critical
	software applications and is a recognized component of many software
	process improvement initiatives, organizations continue to struggle
	to implement it in a cost-effective manner. This paper addresses
	the problems and challenges of requirements traceability and asks
	questions such as "How much traceability is enough?" and "What kinds
	of traceability provide cost effective solutions?" Traditional, automated,
	and lean traceability methods are all discussed},
  doi = {10.1109/COMPSAC.2006.57},
  file = {:./literature/Cleland-Huang2006.pdf:PDF},
  issn = {0730-3157},
  keywords = {requirement traceability;software application;software process improvement;formal
	specification;formal verification;safety-critical software;software
	maintenance;software process improvement;},
  owner = {Stephan},
  timestamp = {2010.12.08}
}

@ARTICLE{Cleland-Huang2003,
  author = {Cleland-Huang, J. and Chang, C.K. and Christensen, M.},
  title = {Event-based traceability for managing evolutionary change},
  journal = {IEEE Transactions on Software Engineering},
  year = {2003},
  volume = {29},
  pages = { 796-810},
  number = {9},
  month = {Sept.},
  abstract = {Although the benefits of requirements traceability are widely recognized,
	the actual practice of maintaining a traceability scheme is not always
	entirely successful. The traceability infrastructure underlying a
	software system tends to erode over its lifetime, as time-pressured
	practitioners fail to consistently maintain links and update impacted
	artifacts each time a change occurs, even with the support of automated
	systems. This paper proposes a new method of traceability based upon
	event-notification and is applicable even in a heterogeneous and
	globally distributed development environment. Traceable artifacts
	are no longer tightly coupled but are linked through an event service,
	which creates an environment in which change is handled more efficiently,
	and artifacts and their related links are maintained in a restorable
	state. The method also supports enhanced project management for the
	process of updating and maintaining the system artifacts.},
  doi = {10.1109/TSE.2003.1232285},
  file = {:./literature/01232285.pdf:PDF},
  issn = {0098-5589},
  keywords = { bibliographies, software maintenance, systems analysis event-notification,
	evolutionary change, heterogeneous globally distributed development
	environment, impacted artifacts, requirements traceability, software
	maintenance, traceability infrastructure, traceability scheme},
  owner = {Stephan},
  review = {discusses how to deal with changes concerning traceability links
	
	
	changes and their impact are analysed and propagated with the help
	of an event-based model
	
	
	no discussion of how initial traceability links are established
	
	
	discussion limited to changing requirements},
  timestamp = {2008.12.08}
}

@INPROCEEDINGS{Cleland-Huang2011,
  author = {Cleland-Huang, Jane and Czauderna, A. and Dekhtyar, A. and Gotel,
	O. and Huffman Hayes, J. and Keenan, E. and Leach, G. and Maletic,
	J. I. and Poshyvanyk, D. and Shin, Y. and Zisman, A. and Antoniol,
	G. and Berenbach, B. and Egyed, A. and Maeder, P.},
  title = {Grand Challenges, Benchmarks, and TraceLab: Developing Infrastructure
	for the Software Traceability Research Community},
  booktitle = {Proceedings of the 6th International Workshop on Traceability in
	Emerging Forms of Software Engineering},
  year = {2011},
  file = {:./literature/Paper_243.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.06.11}
}

@INPROCEEDINGS{Cleland-Huang2012,
  author = {Cleland-Huang, Jane and Mader, Patrick and Mirakhorli, Mehdi and
	Amornborvornwong, Sorawit},
  title = {Breaking the big-bang practice of traceability: Pushing timely trace
	recommendations to project stakeholders},
  booktitle = {Requirements Engineering Conference (RE), 2012 20th IEEE International},
  year = {2012},
  pages = {231 -240},
  month = {sept.},
  abstract = {In many software intensive systems traceability is used to support
	a variety of software engineering activities such as impact analysis,
	compliance verification, and requirements validation. However, in
	practice, traceability links are often created towards the end of
	the project specifically for approval or certification purposes.
	This practice can result in inaccurate and incomplete traces, and
	also means that traceability links are not available to support early
	development efforts. We address these problems by presenting a trace
	recommender system which pushes recommendations to project stakeholders
	as they create or modify traceable artifacts. We also introduce the
	novel concept of a trace obligation, which is used to track satisfaction
	relations between a target artifact and a set of source artifacts.
	We model traceability events and subsequent actions, including user
	recommendations, using the Business Process Modeling Notation (BPMN).
	We demonstrate and evaluate the efficacy of our approach through
	an illustrative example and a simulation conducted using the software
	engineering artifacts of a robotic system for supporting arm rehabilitation.
	Our results show that tracking trace obligations and generating trace
	recommendations throughout the active phases of a project can lead
	to early construction of traceability knowledge.},
  doi = {10.1109/RE.2012.6345809},
  file = {Cleland-Huang2012.pdf:literature/Cleland-Huang2012.pdf:PDF},
  issn = {1090-750X},
  owner = {patrickr},
  timestamp = {2012.12.03}
}

@INPROCEEDINGS{Cleland-Huang2005,
  author = {Cleland-Huang, J. and Settimi, R. and BenKhadra, O. and Berezhanskaya,
	E. and Christina, S.},
  title = {Goal-Centric Traceability for Managing Non-Functional Requirements},
  booktitle = {Proceedings. 27th International Conference on Software Engineering,
	2005 (ICSE '05)},
  year = {2005},
  pages = { 362-371},
  month = {May},
  publisher = {IEEE},
  abstract = {This paper describes a goal centric approach for effectively maintaining
	critical system qualities such as security, performance, and usability
	throughout the lifetime of a software system. In goal centric traceability
	(GCT) non-functional requirements and their interdependencies are
	modeled as softgoals in a softgoal interdependency graph (SIG). A
	probabilistic network model is then used to dynamically retrieve
	links between classes affected by a functional change and elements
	within the SIG. These links enable developers to identify potentially
	impacted goals; to analyze the level of impact on those goals; to
	make informed decisions concerning the implementation of the proposed
	change; and finally to develop appropriate risk mitigating strategies.
	This paper also reports experimental results for the link retrieval
	and illustrates the GCT process through an example of a change applied
	to a road management system.},
  doi = {10.1109/ICSE.2005.1553579},
  file = {:./literature/01553579.pdf:PDF},
  keywords = {risk management, software maintenance, systems analysis goal-centric
	traceability, impact analysis, link retrieval, nonfunctional requirements
	management, probabilistic network model, softgoal interdependency
	graph, system quality},
  owner = {Stephan},
  review = {goal centric approach for managing traceability and non-functional
	requirements
	
	
	goal centric traceability model
	
	------------------------------------
	
	4 phases:
	
	
	goal modeling
	
	- initially modeling of softgoal interdependency graph
	
	- maintaining SIG
	
	
	impact detection
	
	- traceability links established between functional model and SIG
	elements
	
	- dynamic approach for link retrieval
	
	- using a probabilistic network model
	
	-> information retrieval: maximize metrics recall and precision simultaneously
	
	- retrieval algorithm returns set of potentially impacted SIG elements
	-> user has to filter to remove non-relevant ones
	
	
	goal analysis
	
	- propagation of impact of change
	
	- re-evalutation in SIG (using symbols "strengthens" and " weakens"
	for the change impact on a contribution)
	
	
	decision making
	
	- examination of impact report and decision about implementing changes
	or not
	
	- when decision made which changes are implemented, contributions
	are updated and SIG is maintained},
  timestamp = {2008.05.28}
}

@ARTICLE{Cleland-Huang2007,
  author = {Cleland-Huang, J. and Settimi, R. and Romanova, E. and Berenbach,
	B. and Clark, S.},
  title = {Best practices for automated traceability},
  journal = {Computer},
  year = {2007},
  volume = {40},
  pages = {27--35},
  number = {6},
  file = {Cleland-Huang2007.pdf:literature/Cleland-Huang2007.pdf:PDF},
  owner = {patrickr},
  publisher = {IEEE},
  timestamp = {2012.11.15}
}

@BOOK{Clements2003,
  title = {Documenting Software Architectures. Views and Beyond},
  publisher = {Addison-Wesley Longman, Amsterdam},
  year = {2003},
  author = {Clements, P. and Bachman, F. and Bass, L. and Garlan, D. and Ivers,
	J. and Little, R. and Nord, R. and Stafford, J.},
  series = {SEI Series in Software Engineering},
  abstract = {This book provides practical guidance for documenting software architectures
	and acts as a readable reference for software practitioners creating
	and using software architecture documents. The approach described
	takes advantage of the concept of architectural views, but goes beyond
	that to incorporate other essential information that applies beyond
	any single view. A comprehensive sample documentation package is
	included.},
  keywords = {software architecture, software documentation, architectural views},
  owner = {Stephan},
  timestamp = {2008.10.13},
  url = {http://books.google.de/books?id=ASc9HYPkr4sC}
}

@BOOK{Clements2002,
  title = {Evaluating software architectures: methods and case studies},
  publisher = {Addison-Wesley},
  year = {2002},
  author = {Clements, P. and Kazman, R. and Klein, M.},
  owner = {patrickr},
  timestamp = {2012.04.02}
}

@BOOK{Clements2001,
  title = {Software product lines: practices and patterns},
  publisher = {Addison-Wesley Longman Publishing Co., Inc.},
  year = {2001},
  author = {Paul Clements and Linda Northrop and Linda M. Northrop},
  pages = {576},
  series = {The SEI Series in Software Engineering},
  address = {Boston, MA, USA},
  abstract = {Long a standard practice in traditional manufacturing, the concept
	of product lines is relatively new to the software industry. A software
	product line is a family of systems that share a common set of core
	technical assets, with preplanned extensions and variations to address
	the needs of specific customers or market segments. Software organizations
	of all types and sizes are discovering that when skillfully implemented,
	a product line strategy can yield enormous gains in productivity,
	quality, and time-to-market.
	
	
	Software Product Lines is the culmination of an intensive investigation,
	undertaken by the Software Engineering Institute (SEI) at Carnegie
	Mellon, into how leading-edge software development organizations
	have "retooled" for product lines. With explanations of fundamental
	concepts further illuminated by real-world experience, this book
	spells out the technical issues involved in adopting a product line
	strategy, as well as the organizational and management issues that
	are so critical for success. In providing a comprehensive set of
	practices and patterns, this book defines and explores the key activities
	for software product line development and explains specific practice
	areas in engineering, technical management, and organizational management.
	
	
	Highlights include:
	
	
	 * The benefits of a software product line approach, including actual
	improvement data from industrial success stories
	
	 * Methods to develop a reusable base of core assets and to develop
	products that utilize that core
	
	 * Common problems paired with concrete solutions in the form of reusable
	software product line patterns
	
	 * Twenty-nine practice areas for successful implementation, including
	architecture definition,component development, configuration management,
	market analysis, and training
	
	 * The product line technical probe for identifying technical and
	organizational weaknesses that could impede success
	
	
	Three detailed case studies from the industry lead you step by step
	through the process of developing and managing software product lines,
	illustrating potential pitfalls, creative solutions, and the ultimate
	rewards. Discussion questions, sidebars, and real-world anecdotes
	from the trenches reveal the collective wisdom of those on the front
	line of software product line ventures.},
  file = {:./literature/sw-product-lines_05_03.pdf:PDF},
  isbn = {0-201-70332-7},
  keywords = {software product lines},
  owner = {Robert},
  timestamp = {2008.07.15},
  url = {http://www.amazon.com/Software-Product-Lines-Practices-Engineering/dp/0201703327}
}

@INPROCEEDINGS{Clements1996,
  author = {Paul C. Clements},
  title = {A Survey of Architecture Description Languages},
  booktitle = {Proceedings of the 8th International Workshop on Software Specification
	and Design},
  year = {1996},
  pages = {16-25},
  address = {Germany},
  month = {March},
  abstract = {Architecture description languages (ADLs) are emerging as viable tools
	for formally representing the architectures of systems. While growing
	in number, they vary widely in terms of the abstractions they support
	and analysis capabilities they provide. Further, many languages not
	originally designed as ADLs serve reasonably well at representing
	and analyzing software architectures. This paper summarizes a taxonomic
	survey of ADLs that is in progress. The survey characterizes ADLs
	in terms of: the classes of systems they support; the inherent properties
	of the languages themselves; and the process and technology support
	they provide to represent, refine, analyze, and build systems from
	an architecture. Preliminary results allow us to draw conclusions
	about what constitutes an ADL, and how contemporary ADLs differ from
	each other.},
  doi = {10.1109/IWSSD.1996.501143},
  file = {:./literature/clements96.pdf:PDF},
  keywords = {computer architecture, formal specification, hardware description
	languages, logic CADADL, abstractions, architecture description languages,
	computer architecture, formal specification, software architectures,
	survey},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://selab.cataegu.ac.kr/link/architecture/clements96.pdf}
}

@BOOK{Coad1991,
  title = {Object-Oriented Analysis},
  publisher = {Prentice-Hall, Inc.},
  year = {1991},
  editor = {Barbare Marttine},
  author = {Coad, Peter and Yourdon, Edward},
  edition = {2nd},
  owner = {Steffen},
  timestamp = {2013.10.10}
}

@BOOK{Cockburn2000,
  title = {Writing Effective Use Cases},
  publisher = {Addison-Wesley},
  year = {2000},
  author = {Alistair Cockburn},
  address = {Boston, MA, USA},
  file = {:./literature/BookDraft1.pdf:PDF;:./literature/weuc_extract.pdf:PDF},
  isbn = {0201702258},
  keywords = {use case, requirements engineering, use case templates, system design,
	system analysis},
  owner = {Stephan},
  timestamp = {2008.08.04},
  url = {http://www.amazon.com/exec/obidos/ASIN/0201702258/acmorg-20}
}

@ARTICLE{Coleman1994,
  author = {Don Coleman and Dan Ash and Bruce Lowther and Paul Oman},
  title = {Using Metrics to Evaluate Software System Maintainability},
  journal = {Computer},
  year = {1994},
  volume = {27},
  pages = {44-49},
  number = {8},
  month = {August},
  abstract = {Software metrics have been much criticized in the last few years,
	sometimes justly but more often unjustly, because critics misunderstand
	the intent behind the technology. Software complexity metrics, for
	example, rarely measure the "inherent complexity" embedded in software
	systems, but they do a very good job of comparing the relative complexity
	of one portion of a system with another. In essence, they are good
	modeling tools. Whether they are also good measuring tools depends
	on how consistently and appropriately they are applied.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/2.303623},
  file = {:./literature/r8044.pdf:PDF},
  issn = {0018-9162},
  keywords = {maintainability, evaluation, metrics},
  owner = {Matthias},
  publisher = {IEEE Computer Society Press},
  timestamp = {2008.07.15},
  url = {http://www.idi.ntnu.no/emner/mnfit365/artikler/r8044.pdf}
}

@ARTICLE{Colombo2002,
  author = {Colombo, E. and Francalanci, C. and Pernici, B.},
  title = {Modeling coordination and control in cross-organizational workflows},
  journal = {On the Move to Meaningful Internet Systems 2002: CoopIS, DOA, and
	ODBASE},
  year = {2002},
  pages = {91--106},
  file = {Colombo2002.pdf:literature/Colombo2002.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.10.10}
}

@TECHREPORT{Comella-Dorda2000,
  author = {Comella-Dorda, Santiago and Wallnau, Kurt and Seacord, Robert C.
	and Robert, John},
  title = {A Survey of Legacy System Modernization Approaches},
  institution = {Carnegie Mellon University/Software Engineering Institute},
  year = {2000},
  number = {CMU/SEI-2000-TN-003},
  month = {April},
  abstract = {Information systems are critical assets for modern enterprises and
	incorporate key knowledge acquired over the life of an organization.
	Although these systems must be updated continuously to reflect evolving
	business practices, repeated modification has a cumulative effect
	on system complexity, and the rapid evolution of technology quickly
	renders existing technologies obsolete. Eventually, the existing
	information systems become too fragile to modify and too important
	to discard. However, organizations must consider modernizing these
	legacy systems to remain viable. The commercial market provides a
	variety of solutions to this increasingly common problem of legacy
	system modernization. However, understanding the strengths and weaknesses
	of each modernization technique is paramount to select the correct
	solution and the overall success of a modernization effort. This
	paper provides a survey of modernization techniques including screen
	scraping, database gateway, XML integration, database replication,
	CGI integration, object-oriented wrapping, and "componentization"
	of legacy systems. This general overview enables engineers performing
	legacy system modernization to preselect a subset of applicable modernization
	techniques for further evaluation.},
  file = {:./literature/00tn003.pdf:PDF},
  keywords = {data bases, computer gateways, object oriented programming, software
	engineering, integrated systems, hypertext, graphical user interface,
	client server systems},
  owner = {Stephan},
  review = {system evolution activities divided into 3 categories: maintenance,
	modernization, and replacement
	
	
	here focus on description and evalutation of legacy system modernization
	techniques, especially black-box modernization
	
	
	maintenance:
	
	- incremental and iterative process
	
	- small changes like bug corrections, or small functional enhancements
	
	- never major structural changes involved
	
	
	replacement (also: big bang approach, cold turkey)
	
	- appropriate for legacy systems for which modernization is not possible
	or cost effective
	
	- used undocumented, outdated, or not extensible systems
	
	
	modernization:
	
	- more extensive changes than maintenance
	
	- often system restructuring, important functional enhancements, new
	software attributes
	
	
	white-box modernization
	
	- initial reverse engineering process required to gain an understanding
	of the internal system
	
	-> modeling the domain, extracting information, creating abstractions
	
	afterwards: system or code restructuring as a transformation from
	one representation form to an other on the same abstraction level
	
	
	black-box modernization
	
	- examine inputs and outputs of legacy system within operating context
	
	-> gain understanding
	
	- often based on wrapping
	
	- legacy system internals ignored
	
	
	modernization techniques
	
	------------------------------
	
	1) user interface modernization
	
	
	screen scraping:
	
	- wrapping old text-based interfaces with a new graphical interface
	
	- introduce modern and usable graphical interface for user -> better
	usability
	
	but: system remains inflexible and difficult to maintain
	
	
	2) data modernization
	
	
	database gateway:
	
	- transformation of vendor specific access protocol to a standardized
	one
	
	e.g. to ODBC, JDBC, or even an ODBC-JDBC-Bridge
	
	
	xml integration:
	
	- used for B2B integrations -> exchange of information between systems
	from different organizations
	
	- XML server as keystone: contact point between corporate infrastructure
	and the rest of the world
	
	
	database replication:
	
	- copying and maintaining database objects in multiple databases ->
	distributed system
	
	- similar effect like using a remote database gateway but sometimes
	more desirable (better performance)
	
	
	3) functional (logic) modernization
	
	
	CGI integration:
	
	- like screenscraping but instead of wrapping old interface direct
	communication between new GUI and business logic or data of legacy
	system
	
	- HTML pages created
	
	
	object oriented wrapping:
	
	- wrapping a legacy system into object oriented world
	
	- individual applications, common services, and business data represented
	as objects
	
	- definition of appropriate object-level interfaces
	
	- Distributed Object Technology (DOT) used (maybe CORBA as object
	middleware)
	
	
	component wrapping:
	
	- similar to oo wrapping but with conformance to a component model
	(EJB, CORBA)
	
	first step in wrapping with EJB: separation of the interface of the
	legacy system into modules consisting of logical units
	
	second step: build a single point of contact -> can be implemented
	as a bean (a service broker)
	
	final step: implement a wrapper bean for each module in the legacy
	system
	
	- a connector coordinates the service management of both the legacy
	system and the EJB server
	
	-> manage transactions, security, resource pooling between server
	and legacy resource},
  timestamp = {2008.05.15},
  url = {ftp://ftp.sei.cmu.edu/pub/documents/00.reports/pdf/00tn003.pdf}
}

@ARTICLE{Constantopoulos1995,
  author = {Constantopoulos, Panos and Jarke, Matthias and Mylopoulos, John and
	Vassiliou, Yannis},
  title = {The software information base: a server for reuse},
  journal = {The International Journal on Very Large Data Bases},
  year = {1995},
  volume = {4},
  pages = {1-43},
  number = {1},
  __markedentry = {[Steffen:]},
  file = {:./literature/Paper_225.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.30}
}

@INPROCEEDINGS{Cook2001,
  author = {Stephen Cook and He Ji and Rachel Harrison},
  title = {Dynamic and Static Views of Software Evolution},
  booktitle = {17th IEEE International Conference on Software Maintenance (ICSM'01)},
  year = {2001},
  pages = {592-601},
  address = {Los Alamitos, CA, USA},
  month = {Nov.},
  publisher = {IEEE Computer Society},
  abstract = {In addition to managing day-to-day maintenance, information system
	managers need to be able to predict and plan the longer-term evolution
	of software systems on an objective, quantified basis. Currently
	this is a difficult task, since the dynamics of software evolution,
	and the characteristics of evolvable software are not clearly understood.In
	this paper we present an approach to understanding software evolution.
	The approach looks at software evolution from two different points
	of view. The dynamic viewpoint investigates how to model software
	evolution trends and the static viewpoint studies the characteristics
	of software artefacts to see what makes software systems more evolvable.
	The former will help engineers to foresee the actions to be taken
	in the evolution process, while the latter provides an objective,
	quantified basis to evaluate the software with respect to its ability
	to evolve and will help to produce more evolvable software systems.},
  doi = {http://doi.ieeecomputersociety.org/10.1109/ICSM.2001.972776},
  file = {:./literature/00972776.pdf:PDF},
  issn = {1063-6773},
  keywords = {software evolution, viewpoints, queuing models, Lehman's Laws, evolvability
	quality model},
  owner = {Stephan},
  review = {2 different points of view on software evolution
	
	- dynamic viewpoint -> how to model software evolution trends
	
	- static viewpoint -> characteristics of software artefacts
	
	
	- evolution as more general term than maintenance
	
	
	- software evolution should be examined in different levels of software
	systems
	
	-> requirements level, architectural level, detailed design and source
	code level
	
	- here only the latter one
	
	
	investigation of evolution dynamics using queuing models
	
	
	static aspects -> subcharacteristics of ISO 9126 for maintainability
	
	- minor modification for analysability -> not restricted to corrective
	modification},
  timestamp = {2008.07.08}
}

@INPROCEEDINGS{Crnkovic2003,
  author = {Crnkovic, I.},
  title = {Component-based software engineering - new challenges in software
	development},
  booktitle = {Proceedings of the 25th International Conference on Information Technology
	Interfaces, 2003. ITI 2003.},
  year = {2003},
  pages = {9-18},
  month = {June},
  publisher = {IEEE Computer Society},
  abstract = {The primary role of component-based software engineering is to address
	the development of systems as an assembly of parts (components),
	the development of parts as reusable entities, and the maintenance
	and upgrading of systems by customising and replacing such parts.
	This requires established methodologies and tool support covering
	the entire component and system lifecycle including technological,
	organisational, marketing, legal, and other aspects. The traditional
	disciplines from software engineering need new methodologies to support
	component-based development.},
  file = {:./literature/0328.pdf:PDF},
  issn = {1330-1012 },
  keywords = { object-oriented programming, software architecture, software development
	management, software maintenance, software quality, software reliability,
	software reusability, software tools COTS, component-based software
	engineering, software architecture, software component, software
	development, software reusability, system lifecycle},
  owner = {Stephan},
  review = {introduces component-based development (CBD)
	
	
	key aspect: reusability
	
	
	disadvantages of CBD:
	
	- about 5 times higher effort
	
	- unknown requirements (functional/ non-funcitonal)
	
	- the better the reusability is the more complex is the component
	
	
	major goals of CBSE:
	
	- systems are assemblies of components
	
	- components are reusable entities
	
	- systems are maintained and upgraded by customising and replacing
	components
	
	
	component specification:
	
	- separation of interface and implementation
	
	- need for complete specifications (including funct., non-funct. req.,
	use cases, tests, ets.)
	
	- component models (standards - COM, .Net, EJB) relate component interfaces
	to class interfaces
	
	- several forms of components throug life-cycle -> Cheesman&Daniels
	
	
	
	CBD needs adapted process
	
	- focus on identification of reusable entities and relations
	
	
	first step: specification of system architecture as logical view(functional
	components and their interaction)
	
	second step: specification of system archite as physical view
	
	
	steps in development process:
	
	1 find components
	
	2 select components - trade-off-analysis - maybe adjust architecture
	and reformulate requirements
	
	3 alternatively: create components
	
	4 adapt selected components (modify through parametrization, wrapping
	code or some directly integrated)
	
	5 compose and deploy components
	
	6 replace earlier with later versions - maintenance respectivly evolution
	
	
	software architecture
	
	classical approach - top-down
	
	- functionality-based architectural design
	
	- architecture assessment
	
	-> development or selection of components
	
	
	other approach - mix of bottom-up and top-down
	
	- elicit system requirements and analyse possible candidate components
	
	-> component selection and specification have impact on final architecture
	
	-> software architecture optimizes interaction between given components
	
	
	different aspects while modeling a component-based architecture: conceptual,
	implementation and deployment view
	
	
	challenges:
	
	- trusted components, effects of different degrees of trustworthiness
	through composition
	
	- component certification
	
	- composition predictability: can system attributes be derived from
	component attributes
	
	- RE becomes more complex considering possible candidate components
	that may lack of some features to fulfill all system requirements
	
	- evolution using components: which can/should/must be updated
	
	- version management with component configuration
	
	- ensure quality/ non-functional attributes for the whole system
	
	- tool support for CBD
	
	
	claim: .Net improves specification by including function characteristics
	and design characteristics
	
	no reference but would be interesting to read further
	
	
	interesting reference: [5] (book) Compnonent-based software engineering:
	putting the pieces together},
  timestamp = {2008.04.17},
  url = {http://www.mrtc.mdh.se/publications/0328.pdf}
}

@ARTICLE{Crook2003,
  author = {Crook, R. and Ince, D. and Nuseibeh, B.},
  title = {Modelling access policies using roles in requirements engineering},
  journal = {Information and Software Technology},
  year = {2003},
  volume = {45},
  pages = {979--991},
  number = {14},
  file = {Crook2003.pdf:literature/Crook2003.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.11.30}
}

@PHDTHESIS{Cruz2009,
  author = {David Bettencourt da Cruz},
  title = {POSAAM – Eine Methode zu mehr Systematik und Expertenunabh ̈angigkeit
	in der qualitativen Architekturbewertung},
  school = {TU München},
  year = {2009},
  abstract = {Die Bewertung von Softwarearchitekturen ist eine Form der analytischen
	Qualitätssicherung. Es ist bekannt, dass die Behebung von Fehlentwicklungen
	frühzeitig im Softwareentwicklungsprozess (z.B. in der Entwurfsphase)
	mit weniger Kosten verbunden ist, als die Behebung von Fehlentwicklungen
	zu einem späten Zeitpunkt im Softwareentwicklungsprozess (z.B. nach
	der Auslieferung des Systems). Ziel der Bewertung von Softwarearchitekturen
	ist die Erkennung von Fehlentwicklungen frühzeitig im Entwicklungsprozess,
	um diese Fehlentwicklungen frühzeitig beheben zu können und somit
	Kosten zu sparen.
	
	Es existieren sowohl quantitative als auch qualitative Architekturbewertungsmethoden.
	Bei quantitativen Methoden werden durch die Kombination von initialen
	Schätzungen oder Erfahrungswerten mithilfe von Berechnungsvorschriften
	zu erwartende Ausprägungen von Qualitätsmerkmalen des zu erstellenden
	Systems ermittelt. Bei den qualitativen Methoden wird vorliegendes
	Wissen über die geeignete Gestaltung von Architekturen genutzt, um
	potenzielle Missstände in zu prüfenden Architekturen zu identifizieren.
	
	In der vorliegenden Arbeit wird die qualitative Architketurbewertungsmethode
	POSAAM (Pattern Orieneted Software Architecture Analysis Method)
	entwickelt. Zu diesem Zweck wird in der Methode auf das in Architekturmustern
	gekapselte Expertenwissen zugegriffen. Architekturmuster beinhalten
	Wissen über geeignete Gestaltungen von Architekturen zur Lösung von
	Problemen einer Problemklasse. Die Methode beschreibt, wie das in
	Architekturmustern gekapselte Expertenwissen geeignet hinterlegt
	wird, um die systematische Nutzung des Expertenwissens während der
	Bewertung zu ermöglichen.
	
	Durch die Nutzung von Mustern zum Zwecke der Architekturbewertung
	werden die Objektivität, Systematik, Nachvollziehbar- und Wiederholbarkeit
	im Vergleich zu existierenden Methoden gesteigert.},
  file = {:./literature/Cruz2009.pdf:PDF},
  keywords = {POSAAM, musterbasiert, Evaluation, Muster, Prinzip, Qualitätsmerkmal},
  owner = {Stephan},
  review = {Qualitätsmerkmale, Muster und Prinzpien werden in Wissensmodell (Ontologie)
	in Beziehung gesetzt
	
	
	Architektur wird auf Grundlage der Muster und des Wissensmodells gegen
	Anforderungen geprüft
	
	
	Muster beschrieben mit wiederkehrenden Anteilen und Variationsmöglichkeiten
	
	+ Sensitivity und Trade-off Points bezüglich der Qualitätsmerkmale
	
	
	Wissensmodell enthält nur textuelle Beschreibung
	
	Bsp.: Architekturmuster Caching
	
	Einfluss Qualiätsmerkmal:
	
	positiv: Performanz, Verfügbarkeit
	
	negativ: Speichereffizienz
	
	Die Qualitätsmerkmale Performanz und Speichereffizienz werden maßgeblich
	durch die Variationsmöglichkeit ”Strategie zur Haltung von Daten
	im Cache“ beeinflusst.
	
	
	keine quantitative Einschätzung
	
	nur Verwendung für Evaluation nicht für Entwurf
	
	--> interessante Referenz: Dissertation Malich},
  timestamp = {2010.02.16},
  url = {http://deposit.ddb.de/cgi-bin/dokserv?idn=996917705&dok_var=d1&dok_ext=pdf&filename=996917705.pdf}
}

@INPROCEEDINGS{Cubranic2003,
  author = {Davor Cubranic and Gail C. Murphy},
  title = {Hipikat: Recommending Pertinent Software Development Artifacts},
  booktitle = {25th International Conference on Software Engineering, ICSE},
  year = {2003},
  pages = {408-418},
  address = {Los Alamitos, CA, USA},
  month = {May},
  publisher = {IEEE Computer Society},
  abstract = {A newcomer to a software project must typically come up-to-speed on
	a large, varied amount of information about the project before becoming
	productive. Assimilating this information in the open-source context
	is difficult because a newcomer cannot rely on the mentoring approach
	that is commonly used in traditional software developments. To help
	a newcomer to an open-source project become productive faster, we
	propose Hipikat, a tool that forms an implicit group memory from
	the information stored in a project's archives, and that recommends
	artifacts from the archives that are relevant to a task that a newcomer
	is trying to perform. To investigate this approach, we have instantiated
	the Hipikat tool for the Eclipse open-source project. In this paper
	we describe the Hipikat tool, we report on a qualitative study conducted
	with a Hipikat mock-up on a medium-sized in-house project, and we
	report on a case study in which Hipikat recommendations were evaluated
	for a task on Eclipse.},
  doi = {http://doi.ieeecomputersociety.org/10.1109/ICSE.2003.1201219},
  file = {:./literature/01201219.pdf:PDF},
  issn = {0270-5257},
  keywords = {formal specification, reverse engineering, software tools Eclipse
	open-source project, Hipikat software tool, software project development},
  owner = {Robert},
  timestamp = {2008.07.15}
}

@INPROCEEDINGS{Cui2008,
  author = {Cui, Xiaofeng and Sun, Yanchun and Mei, Hong},
  title = {Towards Automated Solution Synthesis and Rationale Capture in Decision-Centric
	Architecture Design},
  booktitle = {Proceedings of the Seventh Working IEEE/IFIP Conference on Software
	Architecture (WICSA 2008)},
  year = {2008},
  series = {WICSA '08},
  pages = {221--230},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid = {1344115},
  doi = {10.1109/WICSA.2008.14},
  file = {:./literature/cui2008.pdf:PDF},
  isbn = {978-0-7695-3092-5},
  keywords = {Software Architecture Design, Design Decision, Design Rationale},
  numpages = {10},
  owner = {Sebastian},
  timestamp = {2013.07.26},
  url = {http://dx.doi.org/10.1109/WICSA.2008.14}
}

@INPROCEEDINGS{Cui2009,
  author = {Cui, Xiaofeng and Sun, Yanchun and Xiao, Sai and Mei, Hong},
  title = {Architecture Design for the Large-Scale Software-Intensive Systems:
	A Decision-Oriented Approach and the Experience},
  booktitle = {Engineering of Complex Computer Systems, 2009 14th IEEE International
	Conference on},
  year = {2009},
  pages = {30 -39},
  month = {june},
  abstract = {Software architectures are considered the key means to manage the
	complexity of large-scale systems from the high abstraction levels
	and system-wide perspectives. The traditional software design methodologies
	and the emerging architecture design methods still fall short of
	coping with the architectural complexity and difficulty in practice.
	The recent research on the architecture design decisions mostly focuses
	on its representation, providing little support for the architecture
	design task itself. In this paper we propose a decision-oriented
	architecture design approach ABC/DD, based on the decision-abstraction
	and issue-decomposition principles specific to the architecture level
	design of software. The approach models software architecture from
	the perspective of design decisions, and accomplishes the architecture
	design from eliciting architecturally significant design issues to
	exploiting and making decisions on the solutions for these issues.
	We illustrate the application of the approach with two real-life
	large-scale software-intensive projects, showing that the decision-oriented
	approach accommodates the characteristics and demands of the architecture
	level, and facilitates the design of architecture and the capture
	of the essential decisions for large complex systems.},
  added-at = {2013-02-28T11:13:35.000+0100},
  biburl = {http://www.bibsonomy.org/bibtex/253f9fd82ec3c10631c0d5e5f8faeea7b/fritzsolms},
  doi = {10.1109/ICECCS.2009.42},
  file = {:./literature/cui2009.pdf:PDF},
  interhash = {b15f2abed8660972cbd30ba4533c4ffd},
  intrahash = {53f9fd82ec3c10631c0d5e5f8faeea7b},
  keywords = {approach;issue-decomposition architecture architecture;software complexity
	decision-abstraction design design;software management;software methodology;object-oriented
	metrics; principle;decision-oriented principle;large-scale programming;software
	software-intensive system;software},
  owner = {Sebastian},
  review = {{Summary}{(Fritz Solms)} Introduce decision-oriented architecture
	design approaches \cite{cui_architectureDesign_2009} associate candidate
	solutions with architectural issues/challanges, capture the decision
	on whether or not that architectural solution is used in a proposed
	architecture and the rationale for that decision.},
  timestamp = {2013.07.26}
}

@ARTICLE{Curtis2000,
  author = {Curtis, S. and Gesler, W. and Smith, G. and Washburn, S.},
  title = {Approaches to sampling and case selection in qualitative research:
	examples in the geography of health},
  journal = {Social Science \& Medicine},
  year = {2000},
  volume = {50},
  pages = {1001--1014},
  number = {7},
  file = {Curtis2000.pdf:literature/Curtis2000.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.11.06}
}

@ARTICLE{Cysneiros2004,
  author = {Cysneiros, L.M. and do Prado Leite, J.C.S.},
  title = {Nonfunctional Requirements: From Elicitation to Conceptual Models},
  journal = {IEEE Transactions on Software Engineering},
  year = {2004},
  volume = {30},
  pages = {328-350},
  number = {5},
  month = {May},
  abstract = {Nonfunctional requirements (NFRs) have been frequently neglected or
	forgotten in software design. They have been presented as a second
	or even third class type of requirement, frequently hidden inside
	notes. We tackle this problem by treating NFRs as first class requirements.
	We present a process to elicit NFRs, analyze their interdependencies,
	and trace them to functional conceptual models. We focus our attention
	on conceptual models expressed using UML (Unified Modeling Language).
	Extensions to UML are proposed to allow NFRs to be expressed. We
	show how to integrate NFRs into the class, sequence, and collaboration
	diagrams. We also show how use cases and scenarios can be adapted
	to deal with NFRs. This work was used in three case studies and their
	results suggest that by using our proposal we can improve the quality
	of the resulting conceptual models.},
  doi = {10.1109/TSE.2004.10},
  file = {:./literature/tse-nfr.pdf:PDF},
  issn = {0098-5589},
  keywords = {formal specification, object-oriented programming, specification languages
	UML, Unified Modeling Language, functional conceptual models, goal
	graphs, nonfunctional requirements, requirements elicitation, software
	design},
  owner = {Stephan},
  review = {process-oriented approach for integrating NFR into design
	
	- explicit traces between conceptual model and NFR
	
	- integrate NFR into UML
	
	
	2 independent evolutionary perspectives: functional and non-functional
	
	
	basis for approach: Language Extended Lexicon (LEL)
	
	-----------------------------------------------------------------
	
	- natural language representation
	
	- structured as hypertext graph
	
	- denotations and connotations
	
	- providing natural traceability
	
	- principles: minimum vocabulary, maximum circularity
	
	
	NFR presented using NFR framework [Chung et al.]
	
	----------------------------------------------
	
	but: no detailed elicitation process or NFR integration into design
	
	- inspired by and/or trees used in problem solving
	
	- NFR operationalisations in SIG become functional requirements ->
	Bosch
	
	- here extensed to distinguish dynamic and static operationalizations
	
	dynamic: -> call for actions to be performed
	
	static -> express the need for the use of data to store information
	necessary for satisficing NFR
	
	
	procedure for non-functional model
	
	------------------------------------------
	
	- for every LEL symbol search for NFR -> for each NFR create NFR graph
	
	- search for operationalizations using behavioural responses from
	the LEL
	
	-> top-down and/or bottom-up approach for filling gap in graph between
	root softgoal originating from LEL symbol and found operationalizations
	
	- check set of graphs that model non-functional perspective for possible
	conflicts
	
	
	3 heuristics for identifying interdependencies:
	
	- compare all NFR graphs of same type
	
	- compare graphs that are classified in the knowledge base as possibly
	conflicting
	
	- compare pair wise the rest of all graphs that have not been compared
	
	
	integration of nonfunctional and functional perspectives
	
	------------------------------------------------------------------
	
	use cases:
	
	- identify LEL symbol in use case
	
	- search set of NFR graphs for symbol
	
	- check for every NFR graph with symbol if use case realizes dynamic
	operationalizations
	
	- constraints in NFR can be specified using OCL with pre and post
	conditions
	
	
	do the same for scenarios
	
	
	class diagrams
	
	- every class in a class diagram has to be named with a LEL symbol
	
	- pick a class and search all NFR graphs
	
	- for dynamic operationalizations check operations of class
	
	- for static operationalizations check attributes
	
	
	4 heuristics to use UML class diagrams to handle NFR
	
	- classes created to satisfice NFR have traceability link to NFR (creation
	of a new class is always a design decision)
	
	- for each added operation (to satisfice NFR) there is a traceability
	link
	
	- add pre or postconditions to operations of NFR demands them
	
	- for each added attribute there is a traceability link
	
	
	collaboration diagram
	
	- similar like other diagrams
	
	- for added messages between objects establish traceability link
	
	
	disadvantages/ open issues:
	
	---------------------------------
	
	- NFR attributes spread over the functional model
	
	- scalability
	
	- strategy my be effective for NFR demanding actions -> affects software
	design
	
	difficult: NFR like maintainability, portability not easily operationalized
	in a specific point of artifact
	
	-> related to how design is organized
	
	-> not dealt with in integration
	
	- no NFR outfactored (like in AOP)
	
	- automation of process
	
	
	personal remark: what about components? only classes considered},
  timestamp = {2008.04.02}
}

@INBOOK{Cysneiros2003,
  chapter = {6},
  pages = {115-138},
  title = {Non-Functional Requirements Elicitation},
  publisher = {Kluwer},
  year = {2003},
  editor = {Julio Cesar Sampaio do Prado Leite and Jorge Horacio Doorn},
  author = {Cysneiros, L.M. and Yu, Eric},
  volume = {753},
  series = {The Springer International Series in Engineering and Computer Science},
  note = {Perspectives on Software Requirements},
  file = {:./literature/cysneiros2003.pdf:PDF},
  keywords = {non-functional requirements, requirements elicitation, LEL, NFR framework,
	NFR graph},
  owner = {Stephan},
  timestamp = {2008.06.05},
  url = {http://itecweb.math.yorku.ca/~cysneiro/ITEC4040/NFR%20Elicitation.pdf}
}

@ARTICLE{Cysneiros2001,
  author = {Luiz Marcio Cysneiros and Julio Cesar Sampaio do Prado Leite and
	Jaime de Melo Sabat Neto},
  title = {A Framework for Integrating Non-Functional Requirements into Conceptual
	Models},
  journal = {Requirements Engineering},
  year = {2001},
  volume = {6},
  pages = {97-115},
  number = {2},
  month = {Juni},
  abstract = {The development of complex information systems calls for conceptual
	models that describe aspects beyond entities and activities. In particular,
	recent research has pointed out that conceptual models need to model
	goals, in order to capture the intentions which underlie complex
	situations within an organisational context. This paper focuses on
	one class of goals, namely non-functional requirements (NFR), which
	need to be captured and analysed from the very early phases of the
	software development process. The paper presents a framework for
	integrating NFRs into the ER and OO models. This framework has been
	validated by two case studies, one of which is very large. The results
	of the case studies suggest that goal modelling during early phases
	can lead to a more productive and complete modelling activity.},
  file = {:./literature/rej2001.pdf:PDF},
  keywords = {Entity-relationship model; Non-functional requirements; Quality attributes;
	Requirements elicitation; Requirements engineering; UML},
  owner = {Stephan},
  review = {approach adopts goal-oriented method by Chung et al. for the representation
	of NFR as softgoals
	
	-> used in conjunction with object-oriented models representing functional
	requirements as goals
	
	-> deals with conflicts among goals and softgaoals (Chung et al. only
	among softgoals)
	
	
	proposed strategy based on a Language Extended Lexicon (LEL)
	
	-> all application relevant terms included - special vocabulary
	
	important: circularity in descriptions and minimum vocabulary
	
	- LEL could also be used for capturing the vocabulary of a whole domain
	instead for a single system (but not considered here)
	
	
	strategy:
	
	- build lexicon
	
	- build functional model
	
	- build non-functional model using SIG
	
	- integrate both models
	
	
	NFR:
	
	- classification in primary and specific NFRs as well as in dynamic
	and static NFRs (orthogonal)
	
	- sub-goals will be understood as attributes (when integrating the
	models)
	
	-> 2 types of attributes
	
	- general attributes (express time constraints and specific behaviour)
	
	- data attributes (express specific data that must be an attribute
	of a data class)
	
	
	integration of functional and non-functional model:
	
	- extensions made to ER and OO model (UML) to represent NFR
	
	-> iteratively check and include representation of NFR from softgoal
	tree in ER/OO model
	
	-> add necessary attributes to OO model for satisficing NFR},
  timestamp = {2008.05.27},
  url = {http://www-di.inf.puc-rio.br/~julio/Slct-pub/rej2001.pdf}
}

@ARTICLE{Doemges1998,
  author = {D\"omges, Rale and Pohl, Klaus},
  title = {Adapting Traceability Environments to Project-Specific Needs},
  journal = {Communications of the ACM},
  year = {1998},
  volume = {Vol. 41 No. 12},
  abstract = {This article focuses on adapting traceability environments to project-specific
	needs. Requirements traceability is defined as the ability to describe
	and follow the life of a requirement, in both a forward and backward
	direction. While present traceability environments do offer some
	flexibility in the definition of trace data types, they do not lend
	themselves easily to a situated approach to defining trace capture
	and usage strategies. To empower the project-specific definition
	of data types, a traceability environment must provide capabilities
	to define new data types and to adjust predefined types according
	to project-specific needs. Moreover, it should systematically support
	the project manager in considering recorded experiences and the actual
	needs. Establishing project-specific traceability definitions does
	not guarantee that traces are correctly captured and used. To ensure
	definition-conform trace recording and usage, definitions must be
	communicated to stakeholders performing the process and must be applied
	in the corresponding situations throughout the project. INSET: Examples
	of Project-Specific Trace Capture and Usage.},
  file = {:./literature/CREWS-99-04.pdf:PDF},
  institution = {Biblioteca de Ciencias y Tecnología ¨Félix Morales Bueno¨ [http://bibcyt.ucla.edu.ve/cgi-win/be_oai.exe]
	(Venezuela)},
  owner = {Elke},
  publisher = {Association for Computing Machinery},
  timestamp = {2011.06.08},
  url = {http://bibcyt.ucla.edu.ve/cgi-win/be_alex.exe?Acceso=T070300005085/12&Nombrebd=Bciucla}
}

@ARTICLE{Doemges1998a,
  author = {Ralf D\"omges and Klaus Pohl},
  title = {{Adapting traceability environments to project-specific needs}},
  journal = {Communications of The ACM},
  year = {1998},
  volume = {41},
  pages = {54--62},
  doi = {10.1145/290133.290149},
  file = {Doemges1998a.pdf:literature/Doemges1998a.pdf:PDF},
  issue = {12},
  masid = {773215},
  owner = {patrickr},
  timestamp = {2012.12.17}
}

@STANDARD{Doerr,
  title = {Das ReqMan Prozessrahmenwerk},
  organization = {Fraunhofer IESE},
  author = {Jörg D\"orr and
	
	Tom Koenig and
	
	Thomas Olsson and
	
	Sebastian Adam},
  year = {2006},
  url = {http://re-wissen.de/Wissen/},
  file = {:./literature/iese-141_06.pdf:PDF},
  owner = {elkeb},
  timestamp = {2012.03.30}
}

@INPROCEEDINGS{Dai2007,
  author = {Dai, F. and Li, T.},
  title = {Tailoring software evolution process},
  booktitle = {Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed
	Computing, 2007. SNPD 2007. Eighth ACIS International Conference
	on},
  year = {2007},
  volume = {2},
  pages = {782--787},
  organization = {IEEE},
  file = {Dai2007.pdf:literature/Dai2007.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.23}
}

@TECHREPORT{Daly1995b,
  author = {J Daly and A Brooks and J Miller and M Roper},
  title = {Structured Interviews on the Object-Oriented Paradigm},
  year = {1995},
  file = {:./literature/10.1.1.84.4603.pdf:PDF},
  owner = {elkeb},
  timestamp = {2011.11.22}
}

@MISC{Daly1995,
  author = {J. Daly and J. Miller and A. Brooks and M. Roper and M. Wood},
  title = {Issues on the Object-Oriented Paradigm: A Questionnaire Survey},
  year = {1995},
  file = {:./literature/10.1.1.51.9494.pdf:PDF},
  owner = {elkeb},
  timestamp = {2011.11.22}
}

@INPROCEEDINGS{Daly1995a,
  author = {Daly, J. and Miller, J. and Brooks, A. and Roper, M. and Wood, M.},
  title = {A survey of experiences amongst object-oriented practitioners},
  booktitle = {Software Engineering Conference, 1995. Proceedings., 1995 Asia Pacific},
  year = {1995},
  pages = {137 -146},
  month = {dec},
  doi = {10.1109/APSEC.1995.496962},
  file = {:./literature/00496962.pdf:PDF},
  keywords = {C++ language;analysis;degradation;design;electronic newsgroups;electronic
	questionnaire;experienced object-oriented developers;inappropriate
	design;inheritance;maintenance;missing design documentation;object-oriented
	mailing list;object-oriented paradigm;object-oriented practitioners;object-oriented
	software;poor design;postal questionnaire;practitioner group;programmer
	productivity;questionnaire survey;software reuse;structured interviews;human
	resource management;inheritance;object-oriented languages;object-oriented
	methods;object-oriented programming;professional aspects;software
	maintenance;software reusability;system documentation;},
  owner = {elkeb},
  review = {Zusammenfassung von Daly1995},
  timestamp = {2011.11.22}
}

@ARTICLE{Damian2006,
  author = {Damian, D. and Chisan, J.},
  title = {An empirical study of the complex relationships between requirements
	engineering processes and other processes that lead to payoffs in
	productivity, quality, and risk management},
  journal = {Software Engineering, IEEE Transactions on},
  year = {2006},
  volume = {32},
  pages = {433--453},
  number = {7},
  file = {Damian2006.pdf:literature/Damian2006.pdf:PDF},
  owner = {patrickr},
  publisher = {IEEE},
  timestamp = {2012.11.15}
}

@ARTICLE{Dangle2005,
  author = {Dangle, K.C. and Larsen, P. and Shaw, M. and Zelkowitz, M.V.},
  title = {Software process improvement in small organizations: a case study},
  journal = {Software, IEEE},
  year = {2005},
  volume = {22},
  pages = {68--75},
  number = {6},
  file = {Dangle2005.pdf:literature/Dangle2005.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@INPROCEEDINGS{Dantas2007,
  author = {Dantas, Cristine and Murta, Leonardo and Werner, Cl\'{a}udia},
  title = {Mining Change Traces from Versioned {UML} Repositories},
  booktitle = {Proceedings of the Brazilian Symposium on Software Engineering (SBES'07)},
  year = {2007},
  pages = {236-252},
  file = {:./literature/Paper_59.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- as software evolves, analysis and design models should evolve as
	well
	
	
	Research Questions:
	
	- which elements in design/analysis models should change due to given
	change
	
	- which elements changed together and are likely to do so again
	
	
	Contribution:
	
	- detection of change traces through data mining on UML repository
	
	
	Solution:
	
	- use historical information to discover traceability-links (since
	rule-based/IR methods do not take this information into account)
	
	- basic assumption: if two elements change together, they are related
	(association rules)
	
	- each trace can be enhanced with following information:
	
	* who changed it
	
	* when did it change
	
	* where did it change
	
	* why did it change
	
	* what was changed
	
	* how was changed performed
	
	- apply association rules on UML elements to form change traces (based
	on support and confidence metrics)
	
	- use minimum tresholds to filter proposed impacts
	
	-> granularity of entities: entire UML
	
	-> granularity of changes: only "modification"
	
	-> granularity of results: entire UML
	
	
	Open Issues:
	
	- no linkage/tracing to implementation (source code)
	
	- only UML classes used for evaluation},
  timestamp = {2011.02.10}
}

@ARTICLE{Dardenne1993,
  author = {Dardenne, A. and Van Lamsweerde, A. and Fickas, S.},
  title = {Goal-directed requirements acquisition},
  journal = {Science of computer programming},
  year = {1993},
  volume = {20},
  pages = {3--50},
  number = {1},
  file = {Dardenne1993.pdf:literature/Dardenne1993.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.12.18}
}

@INPROCEEDINGS{Dauenhauer2009,
  author = {Dauenhauer, G. and Aschauer, T. and Pree, W.},
  title = {Variability in Automation System Models},
  booktitle = {Proceedings of the 11th International Conference on Software Reuse:
	Formal Foundations of Reuse and Domain Engineering (ICSR '09)},
  year = {2009},
  pages = {116--125},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  abstract = {Model driven engineering as well as software product line engineering
	are two approaches that increase the productivity of creating software.
	Despite the rather mature support of the individual approaches, tools
	and techniques for their combination, promising product specific
	customization of models, are still inadequate. We identify core problems
	of current approaches when applied to automation system models and
	propose a solution based on an explicit notion of variability embedded
	in the core of the modeling language itself.},
  doi = {10.1007/978-3-642-04211-9_12},
  file = {:./literature/Variability_in_Automation_System_Models.pdf:PDF},
  isbn = {978-3-642-04210-2},
  keywords = {variability; automation systems; clabjects},
  location = {Falls Church, Virginia},
  numpages = {10},
  owner = {gerlach},
  timestamp = {2013.05.14},
  url = {http://link.springer.com/chapter/10.1007%2F978-3-642-04211-9_12}
}

@INPROCEEDINGS{Davis2002,
  author = {L. Davis and Rose F. Gamble},
  title = {Identifying Evolvability for Integration},
  booktitle = {Proceedings of the First International Conference on COTS-Based Software
	Systems (ICCBSS '02)},
  year = {2002},
  series = {LNCS},
  pages = {65-75},
  address = {London, UK},
  month = {Januar},
  publisher = {Springer-Verlag},
  abstract = {The seamless integration of commercial-off-the-shelf (COTS) components
	offers many benefits associated with reuse. Even with successful
	composite applications, unexpected interoperability conflicts can
	arise when COTS products are upgraded, new components are needed,
	and the application requirements change. Recent approaches to integration
	follow pattern-based design principles to construct integration architecture
	for the composite application. This integration architecture provides
	a design perspective for addressing the problematic interactions
	among components within the application environment. However, little
	attention has been paid to the evolvability of these architectures
	and their embedded functionality. In this paper, we discuss the need
	for design traceability based on the history of interoperability
	conflicts and resolution decisions that comprise the integration
	architecture. Additionally, we advocate that certain functional aspects
	of a pattern can be pinpointed to resolve a conflict. Combining these
	two aspects of integration architecture design, we illustrate that
	often evolution is possible with minimal changes to the integration
	solution.},
  doi = {10.1007/3-540-45588-4_7},
  file = {:./literature/identifyingEvolvability.pdf:PDF},
  isbn = {3-540-43100-4},
  keywords = {evolvability, COTS integration},
  owner = {Robert},
  timestamp = {2008.07.15}
}

@ARTICLE{DeFillippi1998,
  author = {DeFillippi, R.J. and Arthur, M.B.},
  title = {Paradox in Project-Based Enterprise},
  journal = {CALIFORNIA MANAGEMENT REVIEW},
  year = {1998},
  volume = {10},
  pages = {125},
  number = {2},
  file = {DeFillippi1998.pdf:literature/DeFillippi1998.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.10.22}
}

@INPROCEEDINGS{Deissenboeck2007,
  author = {Florian Deissenboeck and Stefan Wagner and Markus Pizka and Stefan
	Teuchert and Jean-Francois Girard},
  title = {An Activity-Based Quality Model for Maintainability},
  booktitle = {Proceedings of the 23rd International Conference on Software Maintenance
	(ICSM 2007)},
  year = {2007},
  pages = {184-193},
  publisher = {IEEE},
  abstract = {Maintainability is a key quality attribute of successful software
	systems. However, its management in practice is still problematic.
	Currently, there is no comprehensive basis for assessing and improving
	the maintainability of software systems. Quality models have been
	proposed to solve this problem. Nevertheless, existing approaches
	do not explicitly take into account the maintenance activities, that
	largely determine the software maintenance effort. This paper proposes
	a 2-dimensional model of maintainability that explicitly associates
	system properties with the activities carried out during maintenance.
	The separation of activities and properties facilitates the identification
	of sound quality criteria and allows to reason about their interdependencies.
	This transforms the quality model into a structured and comprehensive
	quality knowledge base that is usable in industrial project environments.
	For example, review guidelines can be generated from it. The model
	is based on an explicit quality metamodel that supports its systematic
	construction and fosters preciseness as well as completeness. An
	industrial case study demonstrates the applicability of the model
	for the evaluation of the maintainability of Matlab Simulink models
	that are frequently used in modelbased development of embedded systems.},
  file = {:./literature/activity_based_quality_model.pdf:PDF},
  keywords = {maintainability, activity-based quality model, software maintenance},
  owner = {Stephan},
  timestamp = {2009.04.28},
  url = {http://www4.informatik.tu-muenchen.de/~deissenb/publications/2007_deissenboeckf_maintainability.pdf}
}

@INPROCEEDINGS{Dekhtyar2007,
  author = {Dekhtyar, Alex and Hayes, Jane Huffman and Antoniol, Guiliano},
  title = {Benchmarks for Traceability?},
  booktitle = {Proceedings of Traceability in Emerging Forms of Software Engineering},
  year = {2007},
  file = {:./literature/Paper_244.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.06.11}
}

@INPROCEEDINGS{Delamare2008,
  author = {Delamare, Romain and Baudry, Beno\^{\i}t and Le Traon, Yves},
  title = {Regression test selection when evolving software with aspects},
  booktitle = {Proceedings of the 2008 AOSD workshop on Linking aspect technology
	and evolution},
  year = {2008},
  series = {LATE '08},
  pages = {7:1--7:5},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[qurat:]},
  acmid = {1404960},
  articleno = {7},
  doi = {http://doi.acm.org/10.1145/1404953.1404960},
  file = {:/literature/RegressionTesting/Regression test selection when evolving software with aspects.pdf:PDF},
  isbn = {978-1-60558-147-7},
  keywords = {code based, aspectual},
  location = {Brussels, Belgium},
  numpages = {5},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://doi.acm.org/10.1145/1404953.1404960}
}

@INPROCEEDINGS{DeLucia2008,
  author = {De Lucia, A. and Fasano, F. and Oliveto, R.},
  title = {Traceability management for impact analysis},
  booktitle = {Proceedings of Frontiers of Software Maintenance (FoSM 2008)},
  year = {2008},
  pages = {21-30},
  address = {Beijing, China},
  month = {October},
  file = {:./literature/Paper_114.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- changes have impact on other software artifacts as tests, requirements,
	architecture and documentation
	
	- traceability management has been proposed to solve this issue
	
	
	Research Questions:
	
	- review of traceability management, its research directions and challanges
	
	
	Contribution:
	
	- review of traceability management in context of change impact analysis
	
	
	-> no new information
	
	-> paper states that SIS can be identified through traceability
	
	-> paper gives overview how traceability can be obtained
	
	-> paper gives no overview of IA techniques that use traceability
	
	-> paper uses inappropriate classification into horizontal and vertical
	traceability (use inter and intra model instead)},
  timestamp = {2011.03.14}
}

@BOOK{DeMarco2004,
  title = {Was man nicht messen kann, kann man nicht kontrollieren},
  publisher = {mitp-Verlag},
  year = {2004},
  author = {Tom DeMarco},
  pages = {564},
  address = {Bonn},
  edition = {2},
  month = {Juni},
  note = {ISBN 3-8266-1488-7},
  abstract = {»Was man nicht messen kann, kann man nicht kontrollieren.« Dieser
	viel zitierte Satz steht im Zentrum dieses Buches. Tom DeMarco vertritt
	die Meinung, dass erheblich weniger Softwareprojekte aus dem Ruder
	liefen, wenn zu Beginn eines Projekts eine ehrliche Aufwandschätzung
	vorgenommen würde. In diesem Buch erfahren Sie, wie Sie Ihre Softwareprojekte
	so organisieren können, dass sie messbar und somit besser kontrollierbar
	sind.},
  keywords = {software metrics},
  owner = {Robert},
  timestamp = {2006.09.18},
  url = {http://www.amazon.de/nicht-messen-kann-kann-kontrollieren/dp/3826614887}
}

@BOOK{Demeyer2008,
  title = {Object-Oriented Reengineering Patterns},
  publisher = {Square Bracket Associates},
  year = {2008},
  author = {Serge Demeyer and St{\'e}phane Ducasse and Oscar Nierstrasz},
  address = {Kehrsatz, Switzerland},
  abstract = {The rapid growth of object-oriented development over the past twenty
	years has given rise to many object-oriented systems that are large,
	complex and hard to maintain. Object-Oriented Reengineering Patterns
	addresses the problem of understanding and reengineering such object-oriented
	legacy systems. This book collects and distills successful techniques
	in planning a reengineering project, reverse-engineering, problem
	detection, migration strategies and software redesign. The material
	in this book is presented as a set of "reengineering patterns" ---
	recurring solutions that experts apply while reengineering and maintaining
	object-oriented systems. The principles and techniques described
	in this book have been observed and validated in a number of industrial
	projects, and reflect best practice in object-oriented reengineering.},
  annote = {book},
  file = {:./literature/OORP.pdf:PDF},
  isbn = {978-3-9523341-2-6},
  keywords = {reengineering; object-oriented patterns, reverse engineering},
  owner = {Stephan},
  timestamp = {2009.04.22},
  url = {http://www.iam.unibe.ch/~scg/OORP}
}

@INPROCEEDINGS{Demirors1998,
  author = {Demir{\"o}rs, E. and Demir{\"o}rs, O. and Dikenelli, O. and Keskin,
	B.},
  title = {Process improvement towards ISO 9001 certification in a small software
	organization},
  booktitle = {Proceedings of the 20th international conference on Software engineering},
  year = {1998},
  pages = {435--438},
  file = {Demirors1998.pdf:literature/Demirors1998.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@INPROCEEDINGS{Demirors2000,
  author = {Demirors, O. and Demirors, E. and Tarhan, A. and Yildiz, A.},
  title = {Tailoring ISO/IEC 12207 for instructional software development},
  booktitle = {Euromicro Conference, 2000. Proceedings of the 26th},
  year = {2000},
  volume = {2},
  pages = {300--307},
  organization = {IEEE},
  file = {Demirors2000.pdf:literature/Demirors2000.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.23}
}

@INPROCEEDINGS{Demuth2011,
  author = {Demuth, Andreas and Lopez-Herrejon, Roberto E. and Egyed, Alexander},
  title = {Cross-Layer Modeler - A Tool for Flexible Multilevel Modeling with
	Consistency Checking},
  booktitle = {Proceedings of ESEC/FSE 2011},
  year = {2011},
  pages = {452-455},
  address = {Szeged, Hungary},
  month = {September},
  file = {:/literature/Paper_207.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.03.19}
}

@INPROCEEDINGS{Deng2004a,
  author = {D. Deng and {P.C.-Y.} Sheu and T. Wang},
  title = {Model-based testing and maintenance},
  booktitle = {Multimedia Software Engineering, 2004. Proceedings. {IEEE} Sixth
	International Symposium on},
  year = {2004},
  pages = {278--285},
  abstract = {This paper presents a semantic software development model {(SSDM)}
	for object-oriented software. It organizes all the information generated
	during the software development lifecycle including requirements,
	design, implementation, testing, and maintenance. Based on {SSDM,}
	software testing and maintenance can be carried out in a more systematic,
	efficient and complete manner, and can be enhanced by a set of proactive
	rules defined.},
  doi = {10.1109/MMSE.2004.51},
  file = {:E\:/PhD/Research Papers/literature/RegressionTesting/model based testing and maintinence.pdf:PDF},
  keywords = {model-based maintenance, model-based testing, object-oriented methods,
	object-oriented software, program testing, semantic software development
	model, software maintenance, software quality, software testing},
  owner = {Annie},
  review = {relationsbetween several system artifacts are captured specifically.
	
	
	rulebased approach
	
	modification is not further defined 
	
	no specific test structure
	
	
	no case study and evaluation
	
	scope: system testing
	
	artefacts: usecase, class, sequence, activity},
  timestamp = {2011.01.04}
}

@MISC{DoD1985,
  author = {{Department of Defense}},
  title = {{Trusted Computer System Evaluation Criteria (TCSEC)}},
  howpublished = {Department of Defense Standard, DoD 5200.28-STD},
  month = {Dec.},
  year = {1985},
  citeseerurl = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.9.5479},
  file = {:./literature/dod85.pdf:PDF},
  key = {DoD 5200.28-Std},
  keywords = {security, evaluation criteria, orange book},
  owner = {Stephan},
  timestamp = {2008.10.13},
  url = {http://csrc.nist.gov/publications/history/dod85.pdf}
}

@INPROCEEDINGS{Deprez2007,
  author = {Deprez, J.-C. and Monfils, F.F. and Ciolkowski, M. and Soto, M.},
  title = {Defining Software Evolvability from a Free/Open-Source Software Perspective},
  booktitle = {Proceedings of the Third International IEEE Workshop on Software
	Evolvability},
  year = {2007},
  pages = {29-35},
  month = {Oct.},
  publisher = {IEEE Computer Society},
  abstract = {This paper studies various sources of information to identify factors
	that influence the evolvability of Free and Open-Source Software
	(FIOSS) endeavors. The sources reviewed to extract criteria are (1)
	interviews with FIOSS integrators, (2) the scientific literature,
	and (3) existing standard, norms as well as (4) three quality assessment
	methodologies specific to FIOSS , namely, QSOS, OpenBRR and Open
	Source Maturity Model. This effort fits in the larger scope of QUALOSS,
	a research project funded by the European Commission, whose goal
	is to develop a methodology to assess the evolvability and robustness
	of FIOSS endeavors.},
  doi = {10.1109/SE.2007.15},
  file = {:./literature/04383094.pdf:PDF},
  keywords = {public domain software, software qualityEuropean Commission, free
	software, open source maturity model, open-source software, quality
	assessment methodologies, software evolvability},
  owner = {Stephan},
  review = {examination of evolvability on sub characteristics from an open source
	software perspective
	
	
	-> evolution examined concerning community, development process, and
	tools
	
	
	evolvability sub characteristics determined from interview with practitioners
	of FlOSS domain
	
	- project maturity
	
	- community quality -> continuity
	
	- standard adherence
	
	- readability, maintainability, testability -> no distinction between
	these from practitioners point of view
	
	
	characteristics determined from ISO 9126
	
	- maintainability
	
	- analyzability
	
	- changeability
	
	- flexibility (stability)
	
	- testability
	
	- compliance to maintainability standards
	
	also from portability
	
	- portability
	
	- adaptability
	
	- installability
	
	- coexistence
	
	- compliance to portability standards
	
	further
	
	- interoperability
	
	- usability (understandability, learnability, operability, attractiveness)
	
	
	in literature 3 dimensions of software evolution:
	
	- in domain
	
	- in experience
	
	- in process
	
	
	moreover determined quality criteria from evolution definitions e.g.:
	
	- stability of users' needs, of norms and standards, in laws
	
	- stability/maturity of the design, technologies, development process
	
	- willingness of the community
	
	from FlOSS assessment methodologies e.g.:
	
	- fork probability
	
	- project popularity
	
	- modularity of architecture
	
	- plug-ability
	
	- deploy-ability},
  timestamp = {2008.07.30}
}

@ARTICLE{DerAalst2003,
  author = {van Der Aalst, W.M.P. and Ter Hofstede, A.H.M. and Kiepuszewski,
	B. and Barros, A.P.},
  title = {Workflow patterns},
  journal = {Distributed and parallel databases},
  year = {2003},
  volume = {14},
  pages = {5--51},
  number = {1},
  file = {DerAalst2003.pdf:literature/DerAalst2003.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.11.26}
}

@INPROCEEDINGS{Dingsoyr2004,
  author = {Dingsoyr, T. and Moe, N.B.},
  title = {The process workshop: a tool to define electronic process guides
	in small software companies},
  booktitle = {Software Engineering Conference, 2004. Proceedings. 2004 Australian},
  year = {2004},
  pages = {350--357},
  file = {Dingsoyr2004.pdf:literature/Dingsoyr2004.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.26}
}

@INPROCEEDINGS{DiPenta2002,
  author = {Di Penta, Massimiliano and Gradara, S. and Antoniol, Guiliano},
  title = {Traceability Recovery in RAD Software Systems},
  booktitle = {Proceedings of the 10th International Workshop on Program Comprehension},
  year = {2002},
  pages = {207-216},
  file = {:./literature/Paper_271.pdf:PDF},
  owner = {Steffen},
  timestamp = {2013.10.22}
}

@ARTICLE{DiRomualdo1998,
  author = {DiRomualdo, A. and Gurbaxani, V.},
  title = {STRATEGIC INTENT FOR IT OUTSOURCING.},
  journal = {Sloan Management Review},
  year = {1998},
  volume = {39},
  pages = {67--80},
  number = {4},
  file = {DiRomualdo1998.pdf:literature/DiRomualdo1998.pdf:PDF},
  owner = {patrickr},
  publisher = {Sloan Management Review},
  timestamp = {2012.10.15}
}

@INPROCEEDINGS{Djebbi2007,
  author = {Djebbi, O. and Salinesi, C. and Fanmuy, G.},
  title = {Industry survey of product lines management tools: Requirements,
	qualities and open issues},
  booktitle = {Requirements Engineering Conference, 2007. RE'07. 15th IEEE International},
  year = {2007},
  pages = {301--306},
  organization = {IEEE},
  file = {Djebbi2007.PDF:literature/Djebbi2007.PDF:PDF},
  owner = {patrickr},
  timestamp = {2012.08.13}
}

@ARTICLE{Dobrica2002,
  author = {Dobrica, L. and Niemel\"a, E.},
  title = {A survey on software architecture analysis methods},
  journal = {IEEE Transactions on Software Engineering},
  year = {2002},
  volume = {28},
  pages = {638-653},
  number = {7},
  month = {July},
  abstract = {The purpose of the architecture evaluation of a software system is
	to analyze the architecture to identify potential risks and to verify
	that the quality requirements have been addressed in the design.
	This survey shows the state of the research at this moment, in this
	domain, by presenting and discussing eight of the most representative
	architecture analysis methods. The selection of the studied methods
	tries to cover as many particular views of objective reflections
	as possible to be derived from the general goal. The role of the
	discussion is to offer guidelines related to the use of the most
	suitable method for an architecture assessment process. We will concentrate
	on discovering similarities and differences between these eight available
	methods by making classifications, comparisons and appropriateness
	studies.},
  doi = {10.1109/TSE.2002.1019479},
  file = {:./literature/01019479.pdf:PDF},
  issn = {0098-5589},
  keywords = {reviews, software architecture, software qualityappropriateness studies,
	classifications, objective reflections, potential risk identification,
	scenarios, software architecture analysis methods, software architecture
	assessment process, software quality attributes, software quality
	requirements, survey},
  owner = {Stephan},
  review = {description and comparion of eight architecture evaluation techniques:
	
	SAAM, SAAMCS, ESAAMI, SAAMER, ATAM, SBAR, ALPSM, SAEM
	
	
	SAAMER: SAAM for Evolution and Reusability
	
	SBAR: Scenario-based Architecture Reengineering
	
	
	ATAM is considered as the most applicable method, SAAM as the most
	mature one},
  timestamp = {2008.04.02}
}

@BOOK{Drira2013,
  title = {Software Architecture: 7th European Conference, Ecsa 2013, Montpellier,
	France, July 1-5, 2013, Proceedings},
  publisher = {Springer-Verlag New York Incorporated},
  year = {2013},
  author = {Drira, K.},
  series = {Lecture Notes in Computer Science / Programming and Software Engineering},
  file = {:./literature/Software_Architecture_ECSA2013.pdf:PDF},
  isbn = {9783642390302},
  owner = {Sebastian},
  timestamp = {2013.07.24},
  url = {http://books.google.de/books?id=gbFxnAEACAAJ}
}

@ARTICLE{Drivalos2009,
  author = {Drivalos, N. and Kolovos, D. and Paige, R. and Fernandes, K.},
  title = {Engineering a DSL for software traceability},
  journal = {Software Language Engineering},
  year = {2009},
  pages = {151--167},
  file = {Drivalos2009.pdf:literature/Drivalos2009.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.31}
}

@INPROCEEDINGS{Drivalos2008,
  author = {Nikolaos Drivalos and Dimitrios S. Kolovos and Richard F. Paige and
	Kiran J. Fernandes},
  title = {Engineering a {DSL} for Software Traceability},
  booktitle = {First International Conference on Software Language Engineering (SLE
	2008)},
  year = {2008},
  volume = {5452},
  series = {LNCS},
  pages = {151-167},
  publisher = {Springer},
  abstract = {The software artefacts at different levels of abstraction and at different
	stages of the development process are closely inter-related. For
	developers to stay in control of the development process, traceability
	information must be maintained. In this paper, we present the engineering
	of the Traceability Metamodelling Language (TML), a metamodelling
	language dedicated to defining traceability metamodels. We present
	the abstract syntax of the language and its semantics, which are
	defined using a translational approach. Finally, we provide a case
	study that demonstrates the construction of a traceability metamodel
	that captures traceability information between two metamodels using
	TML.},
  doi = {10.1007/978-3-642-00434-6_10},
  file = {:./literature/Drivalos2008.pdf:PDF},
  keywords = {software traceability, DSL, TML, traceability metamodeling language},
  owner = {Stephan},
  review = {a metamodeling language is defined for traceability meta models
	
	
	intended to ease integration of tools with different traceability
	models},
  timestamp = {2010.07.30}
}

@INPROCEEDINGS{Drivalos2008a,
  author = {Nicholas Drivalos and Richard F. Paige and Kiran J. Fernandes and
	Dimitrios S. Kolovos},
  title = {Towards Rigorously Defined Model-to-Model Traceability},
  booktitle = {Proceedings ECMDA Traceability Workshop (ECMDA-TW) 2008},
  year = {2008},
  pages = {17-26},
  month = {Jun},
  file = {:./literature/Drivalos2008a.pdf:PDF},
  keywords = {model traceability},
  owner = {Stephan},
  timestamp = {2010.12.08}
}

@INPROCEEDINGS{Duboc2007,
  author = {Leticia Duboc and David Rosenblum and Tony Wicks},
  title = {A framework for characterization and analysis of software system
	scalability},
  booktitle = {Proceedings of the 6th Joint Meeting of the European Software Engineering
	Conference and the ACM SIGSOFT Symposium on The Foundations of Software
	Engineering (ESEC-FSE '07)},
  year = {2007},
  pages = {375-384},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The term scalability appears frequently in computing literature, but
	it is a term that is poorly deﬁned and poorly understood. The lack
	of a clear, consistent and systematic treatment of scalability makes
	it diﬃcult to evaluate claims of scalability and to compare claims
	from diﬀerent sources. This paper presents a framework for precisely
	characterizing and analyzing the scalability of a software system.
	The framework treats scalability as a multi-criteria optimization
	problem and captures the dependency relationships that underlie typical
	notions of scalability. The paper presents the results of a case
	study in which the framework and analysis method were applied to
	a real-world system, demonstrating that it is possible to develop
	a precise, systematic characterization of scalability and to use
	the characterization to compare the scalability of alternative system
	designs.},
  doi = {http://doi.acm.org/10.1145/1287624.1287679},
  file = {:./literature/SoftwareSystemScalability-p375-duboc.pdf:PDF},
  isbn = {978-1-59593-811-4},
  keywords = {scalability characteristics, quality attribute},
  location = {Dubrovnik, Croatia},
  owner = {Stephan},
  timestamp = {2008.10.09}
}

@INPROCEEDINGS{Duboc2006,
  author = {Leticia Duboc and David S. Rosenblum and Tony Wicks},
  title = {A framework for modelling and analysis of software systems scalability},
  booktitle = {Proceedings of the 28th international conference on Software engineering
	(ICSE '06)},
  year = {2006},
  pages = {949-952},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Scalability is a widely-used term in scientific papers, technical
	magazines and software descriptions. Its use in the most varied contexts
	contribute to a general confusion about what the term really means.
	This lack of consensus is a potential source of problems, as assumptions
	are made in the face of a scalability claim. A clearer and widely-accepted
	understanding of scalability is required to restore the usefulness
	of the term. This research investigates commonly found definitions
	of scalability and attempts to capture its essence in a systematic
	framework. Its expected contribution is in assisting software developers
	to reason, characterize, communicate and adjust the scalability of
	software systems.},
  doi = {http://doi.acm.org/10.1145/1134285.1134460},
  file = {:./literature/ModellingAnalysisScalabiltiy-p949-duboc.pdf:PDF},
  isbn = {1-59593-375-1},
  keywords = {quality attribute, scalability},
  location = {Shanghai, China},
  owner = {Stephan},
  timestamp = {2008.10.09}
}

@INPROCEEDINGS{Ducasse2004,
  author = {Ducasse, St\'{e}phane and G\^{i}rba, Tudor and Favre, Jean-Marie},
  title = {Modeling Software Evolution by Treating History as a First Class
	Entity},
  booktitle = {Proceedings of the Workshop on Software Evolution through Transformations:
	Model-based vs. Implementation-level Solutions (SETra '04)},
  year = {2004},
  pages = {71-82},
  file = {:./literature/Paper_98.pdf:PDF},
  owner = {Steffen},
  review = {same as Girba2004, Girba2005, Girba2006},
  timestamp = {2011.02.24}
}

@INPROCEEDINGS{Duenas2005,
  author = {Juan C. Dueñas and Rafael Capilla},
  title = {The Decision View of Software Architecture},
  booktitle = {Proceedings of the 2nd European Workshop on Software Architecture
	(EWSA 2005)},
  year = {2005},
  volume = {3527},
  series = {LNCS},
  pages = {222-230},
  month = {Jun},
  publisher = {Springer},
  abstract = {Documenting software architectures is a key aspect to achieve success
	when communicating the architecture to different stakeholders. Several
	architectural views have been used with different purposes during
	the design process. The traditional view on software architecture
	defines this in terms of components and connectors. Also, the “4+1”
	view model proposes several views from the same design to satisfy
	the interests of the different stakeholders involved in the modelling
	process. In this position paper we try to go a step beyond previous
	proposals, to detail the idea of considering the architecture as
	a composition of architectural design decisions. We will propose
	a set of elements, information and graphical notation to record the
	design decisions during the modelling process.},
  doi = {10.1007/11494713_15},
  file = {:./literature/ewsa-2005.pdf:PDF},
  keywords = {software architecture, design decisions, decision view, architectural
	views, design rationale},
  owner = {Stephan},
  review = {documentation of design decisions is important due to several reasons
	(understandability for different stakeholders, maintainability)
	
	
	introduction of decision view as intermediary view to Rational's 4+1
	views (Kruchten et al.)
	
	
	--> new UML element with several attributes representing a design
	decision},
  timestamp = {2008.10.01},
  url = {http://triana.escet.urjc.es/ADDSS/articulos/ewsa-2005.pdf}
}

@INPROCEEDINGS{Eaddy2007a,
  author = {Marc Eaddy and Alfred Aho},
  title = {Towards Assessing the Impact of Crosscutting Concerns on Modularity},
  booktitle = {AOSD Workshop on Assessment of Aspect Techniques (ASAT 2007)},
  year = {2007},
  pages = {3},
  address = {Vancouver, BC, Canada},
  month = {March 12},
  abstract = {The goal of aspect­oriented programming is to modularize crosscutting
	concerns. To fully appreciate this goal, we must first understand
	how crosscutting concerns affect modularity and software quality,
	and to what extent. This is hard to quantify, partly because terms
	such as “crosscutting”, “concern”, and “modularity” are ill­defined
	[11] [1], and partly because the scope of the crosscutting concern
	problem is unknown. We propose a research agenda whose first step
	is to formalize the crosscutting concern problem. We present a set
	theoretic concern model (§2) that formalizes terminology and provides
	a foundation for a suite of concern metrics (§3) for quantifying
	the distribution and separation of concerns. Second, we must determine
	the extent of the problem. We advocate a concern assignment methodology
	(§4) whereby all the concerns of a program (and their associated
	code fragments) are rigorously identified. The third step is to argue
	convincingly that crosscutting concerns negatively impact modularity
	and software quality. For this, we propose to correlate our concern
	metrics with traditional modularity metrics and external quality
	indicators such as fault proneness [10] (§5).},
  file = {:./literature/Towards_Assessing_the_Impact_of_Crosscutting_Concerns_on_Modularity.pdf:PDF},
  keywords = {crosscutting concerns, modularity, scattering},
  owner = {Robert},
  timestamp = {2008.07.22},
  url = {http://www.cs.columbia.edu/~eaddy/publications/Towards%20Assessing%20the%20Impact%20of%20Crosscutting%20Concerns%20on%20Modularity.pdf}
}

@INPROCEEDINGS{Eaddy2007,
  author = {Marc Eaddy and Alfred Aho and Gail C. Murphy},
  title = {Identifying, Assigning, and Quantifying Crosscutting Concerns},
  booktitle = {ACoM '07: Proceedings of the First International Workshop on Assessment
	of Contemporary Modularization Techniques},
  year = {2007},
  pages = {2},
  address = {Washington, DC, USA},
  month = {May},
  publisher = {IEEE Computer Society},
  abstract = {Crosscutting concerns degrade software quality. Before we can modularize
	the crosscutting concerns in our programs to increase software quality,
	we must first be able to find them. Unfortunately, accurately locating
	the code related to a concern is difficult, and without proper metrics,
	determining how much the concern is crosscutting is impossible. We
	propose a systematic methodology for identifying which code is related
	to which concern, and a suite of metrics for quantifying the amount
	of crosscutting code. Our concern identification and assignment guidelines
	resolve some of the ambiguity issues encountered by other researchers.
	We applied this approach to systematically identify all the requirement
	concerns in a 13,531 line program. We found that 95% of the concerns
	were crosscutting - indicating a significant potential for improving
	modularity - and that our metrics were better able to determine which
	concerns would benefit the most from reengineering.},
  doi = {http://dx.doi.org/10.1109/ACOM.2007.4},
  file = {:./literature/Eaddy2007Identifying.pdf:PDF},
  isbn = {0-7695-2967-4},
  keywords = {formal specification, program diagnostics, software metrics, software
	qualitycrosscutting concern identification, crosscutting concern
	quantification, formal specification, software metrics, software
	quality},
  owner = {Robert},
  timestamp = {2008.07.22},
  url = {http://www.cs.columbia.edu/~eaddy/publications/Identifying,%20Assigning,%20and%20Quantifying%20Crosscutting%20Concerns.pdf}
}

@ARTICLE{earl2001,
  author = {Earl, Michael},
  title = {Knowledge management strategies: toward a taxonomy},
  journal = {J. of Management Information Systems},
  year = {2001},
  volume = {18},
  pages = {215--242},
  number = {1},
  file = {:./literature/Earl2001.pdf:PDF},
  owner = {matthias},
  publisher = {ME Sharpe},
  timestamp = {2013.08.28}
}

@INCOLLECTION{Easterbrook2008,
  author = {Easterbrook, Steve and Singer, Janice and Storey, Margaret-Anne and
	Damian, Daniela},
  title = {Selecting Empirical Methods for Software Engineering Research},
  booktitle = {Guide to Advanced Empirical Software Engineering},
  publisher = {Springer London},
  year = {2008},
  editor = {Shull, Forrest and Singer, Janice and SjÃ¸berg, Dag I. K.},
  pages = {285-311},
  note = {10.1007/978-1-84800-044-5_11},
  abstract = {Selecting a research method for empirical software engineering research
	is problematic because the benefits and challenges to using each
	method are not yet well catalogued. Therefore, this chapter describes
	a number of empirical methods available. It examines the goals of
	each and analyzes the types of questions each best addresses. Theoretical
	stances behind the methods, practical considerations in the application
	of the methods and data collection are also briefly reviewed. Taken
	together, this information provides a suitable basis for both understanding
	and selecting from the variety of methods applicable to empirical
	software engineering.},
  affiliation = {University of Toronto Department of Computer Science M5S 2E4 Toronto
	Ontario Canada},
  file = {:./literature/SelectingEmpiricalMethods.pdf:PDF},
  isbn = {978-1-84800-044-5},
  keyword = {Computer Science},
  owner = {elkeb},
  timestamp = {2011.06.23},
  url = {http://dx.doi.org/10.1007/978-1-84800-044-5_11}
}

@ARTICLE{Eden2006,
  author = {A.H. Eden and T. Mens},
  title = {Measuring software flexibility},
  journal = {IEE Proceedings - Software},
  year = {2006},
  volume = {153},
  pages = {113-125},
  number = {3},
  month = {June },
  abstract = {Flexibility has been recognised as a desirable quality of software
	since the earliest days of software engineering. Classic and contemporary
	software design literature suggests that particular implementations
	are more ﬂexible than others, but stops short of suggesting objective
	criteria for quantifying such claims. To measure software ﬂexibility
	in precise terms, we introduce the notion of evolution complexity
	and demonstrate how it can be used to measure and compare the ﬂexibility
	of (1) programming paradigms (Object-Oriented against Procedural
	programs), (2) architectural styles (Shared Data, Pipes and Filters,
	and Abstract Data Type) and (3) design patterns (Visitor and the
	Abstract Factory). We also demonstrate how evolution complexity can
	be used to choose the most ﬂexible design policy. We conclude with
	experimental results corroborating our claims.},
  doi = {10.1049/ip-sen:20050045},
  file = {:./literature/Eden2006.pdf:PDF},
  issn = {1462-5970},
  keywords = {software flexibility, evolution complexity, quality attribute, metrics},
  owner = {Stephan},
  timestamp = {2008.10.09},
  url = {http://www.eden-study.org/articles/2006/measuring-sw-flexibility_ieesw.pdf}
}

@INPROCEEDINGS{Egyed2002,
  author = {Alexander Egyed},
  title = {Reasoning about Trace Dependencies in a Multi-Dimensional Space},
  booktitle = {Proceedings of the 1st International Workshop on Traceability, co-located
	with ASE 2002},
  year = {2002},
  address = {Edinburgh, Scotland, UK},
  month = {September},
  citeseerurl = {http://citeseer.ist.psu.edu/635983.html},
  file = {:./literature/Reasoning_about_Trace_Dependencies_in_a_Multi-Dimensional_Space.pdf:PDF},
  keywords = {traceability},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.15},
  url = {http://www.alexander-egyed.com/publications/Reasoning_about_Trace_Dependencies_in_a_Multi-Dimensional_Space.pdf}
}

@INPROCEEDINGS{Egyed2001,
  author = {Alexander Egyed},
  title = {A Scenario-Driven Approach to Traceability},
  booktitle = {Proceedings 23rd International Conference on Software Engineering,
	(ICSE'01)},
  year = {2001},
  pages = {123-132},
  month = {May},
  publisher = {IEEE},
  abstract = {Abstract: Design traceability has been widely recognized as being
	an integral aspect of software development. In the past years this
	fact has been amplified due to the increased use of legacy systems
	and COTS (commercial-off-the-shelf) components mixed with the growing
	use of elaborate "upstream" software modeling techniques such as
	the Unified Modeling Language (UML). The more intensive emphasis
	on upstream (non-programming) software development issues has, however,
	widened the gap between software components (e.g., subsystems, modules)
	and software models (e.g., class diagrams, data flow diagrams), creating
	the need for a better understanding of the intricacies and interrelationships
	between the two. This paper demonstrates how observable run-time
	information of software systems can be used to detect traceability
	information between software systems and their models. We do this
	by employing a technique that evaluates the "footprints" that usage
	scenarios (e.g., test cases) make during the execution of software
	systems. Those footprints can be compared, resulting in additional
	traceability information among modeling elements associated with
	those scenarios. Our approach is tool supported.},
  citeseerurl = {http://citeseer.ist.psu.edu/egyed01scenariodriven.html},
  doi = {http://doi.ieeecomputersociety.org/10.1109/ICSE.2001.919087},
  file = {:./literature/A_Scenario-Driven_Approach_to_Traceability.pdf:PDF},
  keywords = {traceability, test scenarios, models, UML, legacy systems},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.15},
  url = {http://www.alexander-egyed.com/publications/A_Scenario-Driven_Approach_to_Traceability.pdf}
}

@INCOLLECTION{Egyed2005,
  author = {Egyed, A. and Biffl, S. and Heindl, M. and Gr{\"u}nbacher, P.},
  title = {A value-based approach for understanding cost-benefit trade-offs
	during automated software traceability},
  booktitle = {Proceedings of the 3rd international workshop on Traceability in
	emerging forms of software engineering},
  year = {2005},
  pages = {2--7},
  file = {Egyed2005 - A value-based approach for understanding cost-benefit trade-offs.pdf:literature/Egyed2005 - A value-based approach for understanding cost-benefit trade-offs.pdf:PDF},
  organization = {ACM},
  owner = {tobiask},
  timestamp = {2012.03.06}
}

@INPROCEEDINGS{Egyed2007,
  author = {Egyed, Alexander and Binder, Gernot and Grünbacher, Paul},
  title = {STRADA: A Tool for Scenario-based Feature-to-Code Trace Detection
	and Analysis},
  booktitle = {Proceedings of the 29th International Conference on Software Engineering
	(ICSE' 07)},
  year = {2007},
  pages = {41-42},
  address = {Minneapolis, USA},
  month = {May},
  file = {:./literature/Paper_267.pdf:PDF},
  owner = {Steffen},
  timestamp = {2013.10.22}
}

@ARTICLE{Egyed2004,
  author = {Egyed, A. and Grünbacher, P.},
  title = {Identifying requirements conflicts and cooperation: how quality attributes
	and automated traceability can help},
  journal = {IEEE Software},
  year = {2004},
  volume = {21},
  pages = {50-58},
  number = {6},
  month = {Nov.-Dec.},
  abstract = {Requirements about software attributes have numerous complex and nontrivial
	interdependencies. Requirements conflict with each other when they
	make contradicting statements about common software attributes, and
	they cooperate when they mutually enforce such attributes. Because
	software developers rarely apply formal requirements specification
	techniques in practice, and because reliable techniques for natural
	language understanding aren't available, it's generally infeasible
	to automatically identify conflicts and cooperation among requirements.
	In software development and maintenance, identifying conflicts and
	cooperation among requirements is challenging. Fortunately, quality
	attributes can help. In addition, automated traceability techniques
	can eliminate falsely identified conflicts and cooperation efficiently.},
  doi = {10.1109/MS.2004.40},
  file = {:./literature/01353223.pdf:PDF},
  issn = {0740-7459},
  keywords = {formal specification, formal verification, program debugging, software
	maintenance, software quality automated program traceability, formal
	requirements specification, software attributes, software development,
	software maintenance, trace dependencies},
  owner = {Stephan},
  timestamp = {2008.06.05}
}

@INPROCEEDINGS{Eisenbarth2001,
  author = {Thomas Eisenbarth and Rainer Koschke and Daniel Simon},
  title = {Aiding Program Comprehension by Static and Dynamic Feature Analysis},
  booktitle = {Proceedings of the IEEE International Conference on Software Maintenance
	(ICSM'01)},
  year = {2001},
  pages = {602-611},
  address = {Washington, DC, USA},
  abstract = {Understanding a system's implementation without prior knowledge is
	a hard task for reengineers in general. However, some degree of automatic
	aid is possible. The authors present a technique for building a mapping
	between the system's externally visible behavior and the relevant
	parts of the source code. The technique combines dynamic and static
	analyses to rapidly focus on the system's parts urgently required
	for a goal-directed process of program understanding.},
  doi = {10.1109/ICSM.2001.972777},
  file = {:./literature/icsm2001.pdf:PDF},
  isbn = {0-7695-1189-9},
  keywords = {program diagnostics, reverse engineering, software maintenance, systems
	re-engineeringautomatic aid, dynamic analyses, externally visible
	behavior, goal-directed process, prior knowledge, program comprehension,
	program understanding, reengineers, source code, static analyses,
	static/dynamic feature analysis, system implementation understanding},
  owner = {Robert},
  timestamp = {2008.07.15},
  url = {http://www.bauhaus-stuttgart.de/bauhaus/papers/icsm2001.pdf}
}

@STANDARD{IEEE29148-2011,
  title = {Systems and software engineering -- Life cycle processes -- Requirements
	engineering},
  organization = {IEEE},
  author = {Institute of Electrical and Electronics Engineers},
  year = {2011},
  abstract = {ISO/IEC/IEEE 29148:2011 contains provisions for the processes and
	products related to the engineering of requirements for systems and
	software products and services throughout the life cycle. It defines
	the construct of a good requirement, provides attributes and characteristics
	of requirements, and discusses the iterative and recursive application
	of requirements processes throughout the life cycle. ISO/IEC/IEEE
	29148:2011 provides additional guidance in the application of requirements
	engineering and management processes for requirements-related activities
	in ISO/IEC 12207:2008 and ISO/IEC 15288:2008. Information items applicable
	to the engineering of requirements and their content are defined.
	The content of ISO/IEC/IEEE 29148:2011 can be added to the existing
	set of requirements-related life cycle processes defined by ISO/IEC
	12207:2008 or ISO/IEC 15288:2008, or can be used independently.},
  file = {:./literature/IEEE29148-2011.pdf:PDF},
  owner = {matthias},
  timestamp = {2014.02.25}
}

@INPROCEEDINGS{ElGhazi2008,
  author = {El Ghazi, Hamid and Assar, Said},
  title = {A Multi View based Traceability Management Method},
  booktitle = {Proceedings of the 2nd International Conference on Research Challenges
	in Information Science (RCIS '08)},
  year = {2008},
  pages = {393-400},
  file = {:./literature/Paper_265.pdf:PDF},
  owner = {Steffen},
  timestamp = {2013.05.13}
}

@ARTICLE{Elo2008,
  author = {Elo, S. and Kyng{\"a}s, H.},
  title = {The qualitative content analysis process},
  journal = {Journal of advanced nursing},
  year = {2008},
  volume = {62},
  pages = {107--115},
  number = {1},
  file = {Elo2008.pdf:literature/Elo2008.pdf:PDF},
  owner = {patrickr},
  publisher = {Wiley Online Library},
  timestamp = {2012.10.05}
}

@BOOK{Embley2011,
  title = {Handbook of Conceptual Modeling: Theory, Practice, and Research Challenges},
  publisher = {Springer},
  year = {2011},
  author = {Embley, D.W. and Thalheim, B.},
  isbn = {9783642158643},
  lccn = {2011922130},
  owner = {matthias},
  timestamp = {2012.12.20},
  url = {http://books.google.de/books?id=tSqvcQAACAAJ}
}

@INBOOK{Embley2013,
  chapter = {Conceptual-Model Programming: A Manifesto},
  pages = {3-16},
  title = {Handbook of Conceptual Modeling
	
	Theory, Practice, and Research Challenges},
  publisher = {Springer},
  year = {2011},
  editor = {David W. Embley and Bernhard Thalheim},
  author = {David W. Embley and Stephen W. Liddle and Oscar Pastor},
  file = {:./literature/Embley2011.pdf:PDF},
  owner = {matthias},
  timestamp = {2013.05.28}
}

@INPROCEEDINGS{Engels2000,
  author = {Gregor Engels and Luuk Groenewegen},
  title = {Object-oriented modeling: a roadmap},
  booktitle = {Proceedings of the Conference on The Future of Software Engineering,
	ICSE'00},
  year = {2000},
  pages = {103-116},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Object-oriented modeling has become the de-facto standard in the early
	phases of a software development process during the last decade.
	The current state-of-the-art is dominated by the existence of the
	Unified Modeling Language (UML), the development of which has been
	initiated and pushed by industry. 
	
	This paper presents a list of requirements for an ideal object-oriented
	modeling language and compares it with the achievements of UML and
	other object-oriented modeling approaches. This forms the base for
	the discussion of a roadmap for object-oriented modeling, which is
	structured according to a classification scheme of six different
	themes, which are language-, model- or process-related, respectively.},
  doi = {http://doi.acm.org/10.1145/336512.336541},
  file = {:./literature/EG00objectorientedModelling.pdf:PDF},
  isbn = {1-58113-253-0},
  keywords = {Object-oriented modeling, UML, profile, views, patterns, frameworks,
	development process},
  location = {Limerick, Ireland},
  owner = {Stephan},
  review = {describes requirements for an ideal object-oriented modeling approach
	
	- user-friendliness
	
	- understandability
	
	- precision, correctness, richness
	
	- separation of concerns, modularization, object-orientation
	
	- homogeinity of and consistency between model parts, views and aspects
	
	
	perspectives on object-oriented modeling
	
	- language structure
	
	- model constituents
	
	- model composition
	
	- model review
	
	- modeling process
	
	
	open issues in:
	
	- language structure: semantics, completeness
	
	- model constituents: views, aspects, patterns, frameworks
	
	- model composition: scalability, horizontal/vertical composition
	techniques
	
	- modeling process: consistency, coordination and communication
	
	- model review: animation/simulation and analytical techniques
	
	
	interesting reference:
	
	- [24] Ghezzi, Jazayeri: Fundamentals of software engineering (Buch)
	-> well-known software engineering principles and qualities},
  timestamp = {2008.04.17},
  url = {http://wwwcs.uni-paderborn.de/cs/ag-engels/Papers/2000/EG00objectorientedModelling.pdf}
}

@TECHREPORT{Engels2012,
  author = {Engels, Gregor et al.},
  title = {Quasar 3.0 - A Situational Approach to Software Engineering},
  institution = {Capgemini},
  year = {2012},
  file = {:./literature/Quasar3_external_V1.1paper.pdf:PDF},
  owner = {Sebastian},
  timestamp = {2013.07.24}
}

@ARTICLE{Engstroem2010,
  author = {Emelie Engstroem and Per Runeson and Mats Skoglund},
  title = {A systematic review on regression test selection techniques},
  journal = {Information and Software Technology},
  year = {2010},
  volume = {52},
  pages = {14--30},
  number = {1},
  month = jan,
  abstract = {Regression testing is verifying that previously functioning software
	remains after a change. With the goal of finding a basis for further
	research in a joint industry-academia research project, we conducted
	a systematic review of empirical evaluations of regression test selection
	techniques. We identified 27 papers reporting 36 empirical studies,
	21 experiments and 15 case studies. In total 28 techniques for regression
	test selection are evaluated. We present a qualitative analysis of
	the findings, an overview of techniques for regression test selection
	and related empirical evidence. No technique was found clearly superior
	since the results depend on many varying factors. We identified a
	need for empirical studies where concepts are evaluated rather than
	small variations in technical implementations.},
  doi = {10.1016/j.infsof.2009.07.001},
  issn = {0950-5849},
  keywords = {Empirical studies, regression testing, Systematic review, Test selection},
  owner = {Annie},
  timestamp = {2011.01.04},
  url = {http://www.sciencedirect.com/science/article/B6V0B-4WSY49Y-2/2/16d6e068c7f2019b1fb8971d92974ed5}
}

@INPROCEEDINGS{Engstrom2008,
  author = {Engstrom, E.om, Emelie and Skoglund, Mats and Runeson, Per},
  title = {Empirical evaluations of regression test selection techniques: a
	systematic review},
  booktitle = {Proceedings of the Second ACM-IEEE international symposium on Empirical
	software engineering and measurement},
  year = {2008},
  series = {ESEM '08},
  pages = {22--31},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[qurat:]},
  acmid = {1414011},
  doi = {http://doi.acm.org/10.1145/1414004.1414011},
  file = {:/literature/RegressionTesting/Systematic Review.pdf:PDF},
  isbn = {978-1-59593-971-5},
  keywords = {regression testing, systematic review, test selection},
  location = {Kaiserslautern, Germany},
  numpages = {10},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://doi.acm.org/10.1145/1414004.1414011}
}

@ARTICLE{Engwall2004,
  author = {Engwall, M. and Westling, G.},
  title = {Peripety in an R\&D drama: capturing a turnaround in project dynamics},
  journal = {Organization Studies},
  year = {2004},
  volume = {25},
  pages = {1557--1578},
  number = {9},
  file = {Engwall2004.pdf:literature/Engwall2004.pdf:PDF},
  owner = {patrickr},
  publisher = {Sage Publications},
  timestamp = {2012.10.19}
}

@INPROCEEDINGS{Eramo2008,
  author = {Eramo, R. and Pierantonio, A. and Romero, J. R. and Vallecillo, A.},
  title = {Change Management in Multi-Viewpoint System Using ASP},
  booktitle = {Proc. of the 5th Int. Workshop on ODP for Enterprise Computing (EDOC
	2008)},
  year = {2008},
  pages = {19-28},
  address = {Munich, Germany},
  file = {:./literature/Paper_248.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.07.20}
}

@MASTERSTHESIS{Erdtmann2012,
  author = {Erdtmann, Christina},
  title = {Einsetzbarkeit von Requirements Traceability in kleinen Softwarefirmen
	– eine Praxisstudie},
  school = {TU Ilmenau},
  year = {2012},
  file = {:literature/Bachelorarbeit_42024_Erdtmann.pdf:PDF},
  owner = {elkeb},
  timestamp = {2012.12.17}
}

@BOOK{Erl2008,
  title = {SOA Design Patterns},
  publisher = {Prentice Hall International},
  year = {2008},
  author = {Thomas Erl},
  owner = {Stephan},
  timestamp = {2010.10.29}
}

@BOOK{Erl2007,
  title = {{SOA}: Principles of Service Design},
  publisher = {Prentice Hall Press},
  year = {2007},
  author = {Thomas Erl},
  address = {Upper Saddle River, NJ, USA},
  month = {July},
  isbn = {9780132344821},
  keywords = {service-oriented architecture, SOA, web services, design principles},
  owner = {Stephan},
  timestamp = {2008.10.13},
  url = {http://portal.acm.org/citation.cfm?id=1406153#}
}

@INPROCEEDINGS{Espinoza2006,
  author = {Angelina Espinoza and Pedro P. Alarc{\'o}n and Juan Garbajosa},
  title = {Analyzing and Systematizing Current Traceability Schemas},
  booktitle = {Proceedings of the 30th Annual IEEE/NASA Software Engineering Workshop
	SEW-30 (SEW'06)},
  year = {2006},
  pages = {21-32},
  month = {April},
  publisher = {IEEE},
  __markedentry = {[Steffen:]},
  abstract = {The aim of this work is to produce a traceability model to enhance
	processes and tasks, which make extensive use of traceability information
	such as, V amp;V, change management and impact analysis, under the
	roundtrip engineering approach. This paper analyzes several current
	traceability approaches, in order to obtain their relevant features,
	to identify overlaps and inconsistencies between them, and to select
	the best traceability practices. It was identified that, several
	issues still make difficult the adoption of a wide-scale traceability
	activity, in the software/system engineering practice, such as, there
	is a lack of a commonly accepted traceability definition, a standard
	way of specifying traceability between artifacts, and a traceability
	type classification. Basing on these findings, an approach for a
	"traceability schema specification" and a first implementation on
	a software/system engineering environment are provided. The schema
	attempts to systematize the definition, deployment and maintenance
	of a traceability implementation},
  doi = {10.1109/SEW.2006.12},
  file = {:./literature/Espinoza2006.pdf:PDF},
  keywords = {hange management;impact analysis;roundtrip engineering approach;software/system
	engineering environment;traceability schema specification;traceability
	type classification;verification amp;validation;formal specification;program
	diagnostics;program verification;systems analysis},
  owner = {Stephan},
  review = {a traceability metatype is defined with required or recommended properties
	for traceability link types},
  timestamp = {2010.07.30}
}

@ARTICLE{Espinoza2011,
  author = {Espinoza, Angelina and Garbajosa, Juan},
  title = {A study to support agile methods more effectively through traceability},
  journal = {Innovations in Systems and Software Engineering},
  year = {2011},
  volume = {7},
  pages = {53-69},
  number = {1},
  __markedentry = {[Steffen:]},
  file = {:literature/Paper_210.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.25}
}

@INPROCEEDINGS{Essafi2007,
  author = {Essafi, M. and Labed, L. and Ben Ghezala, H.},
  title = {S2D-ProM: A Strategy Oriented Process Model for Secure Software Development},
  booktitle = {Software Engineering Advances, 2007. ICSEA 2007. International Conference
	on},
  year = {2007},
  pages = {24},
  month = {aug.},
  doi = {10.1109/ICSEA.2007.59},
  file = {Essafi2007.pdf:literature/Essafi2007.pdf:PDF},
  keywords = {S2D-ProM;product view;secure software development;strategy oriented
	process model;security of data;software engineering;},
  owner = {patrickr},
  timestamp = {2012.12.11}
}

@ARTICLE{EStdIT1997,
  author = {{ESt}d{IT}},
  title = {V-{M}odell},
  year = {1997},
  volume = {Entwicklungsstandard für IT-Systeme des Bundes, Bundesrepublik Deutschland},
  language = {german},
  owner = {Robert},
  timestamp = {2008.07.15},
  url = {\href{http://www http://www.v-modell.iabg.de/}, Stand 15.April 2006}
}

@MISC{3SGreenPaper,
  author = {{European Community for Software \& Software Services (ECSS)}},
  title = {{3S Green Paper on Software and Service Architecture, Infrastructures
	and Engineering -- a working document for a future EU Action Paper
	on the area}},
  month = {Okt.},
  year = {2007},
  note = {Version 1.2},
  file = {:./literature/WP1_D1.2_GreenPaper_v_ecss_websitepdf.pdf:PDF},
  keywords = {software architecture, software engineering, challenges},
  owner = {Stephan},
  timestamp = {2009.03.17}
}

@INCOLLECTION{Fahad2008,
  author = {Muhammad Fahad and Aamer Nadeem},
  title = {A Survey of UML Based Regression Testing},
  booktitle = {Intelligent Information Processing IV},
  year = {2008},
  pages = {200--210},
  abstract = {Regression testing is the process of ensuring software quality by
	analyzing whether changed parts behave as intended, and unchanged
	parts are not affected by the modifications. Since it is a costly
	process, a lot of techniques are proposed in the research literature
	that suggest testers how to build regression test suite from existing
	test suite with minimum cost. In this paper, we discuss the advantages
	and drawbacks of using {UML} diagrams for regression testing and
	analyze that {UML} model helps in identifying changes for regression
	test selection effectively. We survey the existing {UML} based regression
	testing techniques and provide an analysis matrix to give a quick
	insight into prominent features of the literature work. We discuss
	the open research issues like managing and reducing the size of regression
	test suite, prioritization of the test cases that would be helpful
	during strict schedule and resources that remain to be addressed
	for {UML} based regression testing.},
  file = {:/literature/RegressionTesting/A Survey of UML Based Regression Testing.pdf:PDF},
  owner = {Annie},
  timestamp = {2011.01.04},
  url = {http://dx.doi.org/10.1007/978-0-387-87685-6_25}
}

@INPROCEEDINGS{Falke2005,
  author = {Falke, Raimar and Klein, Raimund and Koschke, Rainer and Quante,
	Jochen},
  title = {The Dominance Tree in Visualizing Software Dependencies},
  booktitle = {Proceedings of the 3rd IEEE International Workshop on Visualizing
	Software for Understanding and Analysis (VISSOFT 2005)},
  year = {2005},
  pages = {1-6},
  address = {Budapest},
  file = {:./literature/Paper_212.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.25}
}

@INPROCEEDINGS{Farooq2010b,
  author = {Qurat ul-ann Farooq},
  title = {A Model Driven Approach to Test Evolving Business Process based Systems},
  booktitle = {In proceedings of Doctoral Symposium at Models 2010},
  year = {2010},
  file = {:/literature/RegressionTesting/A Model Driven Approach to Test Evolving Business Process based Systems.pdf:PDF},
  owner = {Annie},
  timestamp = {2011.04.13},
  url = {http://models2010.ifi.uio.no/papers/DocSymp2010PrelimProceedings.pdf}
}

@INPROCEEDINGS{Farooq2010,
  author = {Q.-u.-a. Farooq and M. Iqbal and Z.I. Malik and M. Riebisch},
  title = {A Model-Based Regression Testing Approach for Evolving Software Systems
	with Flexible Tool Support},
  booktitle = {Engineering of Computer Based Systems (ECBS), 2010 17th IEEE International
	Conference and Workshops on},
  year = {2010},
  pages = {41--49},
  abstract = {Model-based selective regression testing promises reduction in cost
	and labour by selecting a subset of the test suite corresponding
	to the modifications after system evolution. However, identification
	of modifications in the systems and selection of corresponding test
	cases is challenging due to interdependencies among models. State-based
	testing is an important approach to test the system behaviour. Unfortunately
	the existing state-based regression testing approaches do not care
	for dependencies of the state machines with other system models.
	This paper presents the tool support and evaluation of our state-based
	selective regression testing methodology for evolving state-based
	systems. {START} is an Eclipse-based tool for state-based regression
	testing compliant with {UML} 2.1 semantics. {START} deals with dependencies
	of state machines with class diagrams to cater for the change propagation.
	We applied the {START} on a case study and our results show significant
	reduction in the test cases resulting in reduction in testing time
	and cost.},
  doi = {10.1109/ECBS.2010.12},
  file = {:/literature/RegressionTesting/A Model-based Regression Testing Approach for Evolving Software Systems with Flexible Tool Support.pdf:PDF},
  keywords = {Eclipse based tool, flexible tool support, model based regression
	testing approach, program testing, regression analysis, software
	system, software tools, {START,} state based selective regression
	testing methodology, state machines, testing cost reduction, testing
	time reduction, {UML} 2.1 semantics, Unified Modeling Language},
  owner = {Annie},
  timestamp = {2011.01.04}
}

@INPROCEEDINGS{Farooq2007,
  author = {Farooq, Qurat-ul-ann and Iqbal, Muhammad Zohaib Z. and Malik, Zafar
	I and Nadeem, Aamer},
  title = {An approach for selective state machine based regression testing},
  booktitle = {Proceedings of the 3rd international workshop on Advances in model-based
	testing},
  year = {2007},
  series = {A-MOST '07},
  pages = {44--52},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1291540},
  doi = {http://doi.acm.org/10.1145/1291535.1291540},
  file = {:/literature/RegressionTesting/An approach for selective state machine based regression testing.pdf:PDF},
  isbn = {978-1-59593-850-3},
  keywords = {UML, model based testing, regression testing},
  location = {London, United Kingdom},
  numpages = {9},
  owner = {Annie},
  timestamp = {2011.01.04},
  url = {http://doi.acm.org/10.1145/1291535.1291540}
}

@INPROCEEDINGS{Farooq2014,
  author = {Farooq, Qurat-Ul-Ann and Lehnert, Steffen and Riebisch, Matthias},
  title = {Analyzing Model Dependencies for Rule-based Regression Test Selection},
  booktitle = {Modellierung 2014},
  year = {2014},
  address = {Vienna, Austria},
  month = {March},
  owner = {Steffen},
  timestamp = {2014.02.04}
}

@INBOOK{Farooq2011,
  chapter = {10},
  pages = {254-297},
  title = {Model-Based Regression Testing: Process, Challenges and Approaches},
  publisher = {IGI Global},
  year = {2011},
  editor = {Rech, J\"{o}rg and Bunse, Christian},
  author = {Farooq, Q.-u.-a. and Riebisch, M.},
  booktitle = {Emerging Technologies for the Evolution and Maintenance of Software
	Models},
  owner = {Steffen},
  timestamp = {2011.12.29}
}

@MASTERSTHESIS{Fasching2009,
  author = {Fasching, Christian},
  title = {{A tool for software visualization to support Impact Analysis (in
	German: Ein Visualisierungswerkzeug zur Unterst{\"u}tzung der Auswirkungsanalyse)}},
  school = {Upper Austria University of Applied Sciences, Hagenberg, Austria},
  year = {2009},
  file = {:./literature/Master_2.pdf:PDF},
  owner = {Steffen},
  review = {useful stuff: good overview of change process, good overview of IA
	process
	
	
	- IA involves large amount of data which should be visualized to improve
	usability
	
	- thesis outlines important requirements for IA visualization:
	
	* interaction, navigation, zoom, merge, hiding, reload of data, focus
	
	- thesis discusses various vis. techniques which can be used for IA
	
	
	- scope of analysis: source code
	
	- tool: CIAMSS
	
	- language: -
	
	- scalability: -
	
	- granularity
	
	* changes: -
	
	* artifacts: -
	
	* results: -
	
	- technique: dependency graph
	
	- analysis style: global
	
	- evaluation
	
	* size: 6122 artifacts
	
	* precision: -
	
	* recall: -
	
	* time: several minutes},
  timestamp = {2011.01.07}
}

@INPROCEEDINGS{Favre2004,
  author = {Favre, Jean-Marie},
  title = {Towards a Basic Theory to Model Model Driven Engineering},
  booktitle = {Proceedings of the Workshop on Software Model Engineering},
  year = {2004},
  address = {Lisboa, Portugal},
  month = {October},
  file = {:./literature/Paper_239.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.05.16}
}

@ARTICLE{Favre2005,
  author = {Favre, Jean-Marie and NGuyen, Tam},
  title = {Towards a Megamodel to Model Software Evolution Through Transformations},
  journal = {Electronic Note},
  year = {2005},
  volume = {127},
  pages = {59-74},
  number = {3},
  file = {:./literature/Paper_241.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.05.16}
}

@BOOK{Favre2003,
  title = {UML and the Unified Process},
  publisher = {IRM Press},
  year = {2003},
  author = {Liliana Favre},
  file = {:./literature/1931777446.pdf:PDF},
  keywords = {UML, Unified Process},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://slava.parma.ru/Doc/Unsorted/New/BOOKS/1931777446%20-%20UML%20and%20the%20Unified%20Process%20-%20fly.pdf}
}

@INPROCEEDINGS{Feng2006,
  author = {Feng, Tie and Maletic, Jonathan I.},
  title = {Applying Dynamic Change Impact Analysis in Component-based Architecture
	Design},
  booktitle = {Proceeding of the Seventh International Conference on Software Engineering,
	Artificial Intelligence, Networking and Parallel/Distributed Computing
	(SNPD 2006)},
  year = {2006},
  pages = {43-48},
  address = {Las Vegas, Nevada, USA},
  month = {June},
  file = {:./literature/Paper_11.PDF:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- IA for maintenance of component-based software
	
	- support change of software architectures
	
	
	Research Questions:
	
	- support dynamic IA at architecture level for software evolution
	
	
	Contribution:
	
	- taxonomy of changes in component-based architecture
	
	- set of impact rules to transfer changes among components
	
	- method for slicing of component interaction traces
	
	
	Solution:
	
	- define 2 rules for static composition of models (i.e. component
	models only)
	
	- capture dynamic component interaction with traces (Component Interaction
	Trace - CIT)
	
	(algorithm provided by paper, applied on UML component and sequence
	diagrams)
	
	- change taxonomy for atomic changes (add/remove provided interface,
	add/remove required interface, add/remove method from prov. interface,
	add/remove method from req. interface) 
	
	-> similar to Ryder2001
	
	- change taxonomy for composite changes (i.e. add interface, add n
	methods to interface)
	
	- learn about impact transmission from intra-component connections
	(nothing but a dependency matrix)
	
	- implemented in SOCIAT tool
	
	-> granularity of entities: (arch.) components, methods, interfaces
	
	-> granularity of changes: add/remove interface, method
	
	-> granularity of results: (arch.) components, methods, interfaces
	
	
	Open Issues:},
  timestamp = {2011.01.05}
}

@INPROCEEDINGS{Fidge1993,
  author = {Fidge, C. J. and Lister, A. M.},
  title = {The Challenges of Non-Functional Computing Requirements},
  booktitle = {Seventh Australian Software Engineering Conference (ASWEC'93)},
  year = {1993},
  pages = {77-84},
  address = {Sydney},
  month = {September},
  abstract = {In the past non-functional computing requirements such as timeliness,
	dependability and adaptability have been treated informally, but
	current research is developing formal software engineering methodologies
	that allow for them. This article surveys this research, relates
	it to the overall software development process and identifies areas
	in need of further work.},
  file = {:./literature/fidge93c.pdf:PDF},
  keywords = {non-functional computing, challenges, software development process},
  owner = {Stephan},
  review = {some facts for State of the Art 1993
	
	
	mostly concerned with timeliness, dependabilities, adaptability
	
	
	some methods:
	
	- CEDER: timeliness
	
	- Mars dependability evaluation, testability
	
	- Draper design approch
	
	
	unresolved challanges:
	
	- integrate NFR into SW dev. life-cycle
	
	- existing spec. languages difficult to extend
	
	- lack of notations for intangle req. like adaptability, security
	
	- lack of metrics for ranking NFRs, ways of expressing importance
	
	- no accepted modeling languages
	
	
	- for design:
	
	 only heuristics, only some special but no general guidelines, no
	formal techniques},
  timestamp = {2008.04.11},
  url = {http://sky.fit.qut.edu.au/~fidgec/Publications/fidge93c.pdf}
}

@TECHREPORT{Fiege2007,
  author = {Fiege, René and Stelzer, Dirk},
  title = {Modellierung Serviceorientierter Architeckturen mit Axiomatic Design
	- Analyse des Beitrages zur Verbesserung der Entwurfsqualität},
  institution = {TU-Ilmenau},
  year = {2007},
  month = {Juli},
  abstract = {Axiomatic Design (AD) ist eine Methode, die den Entwurf beliebiger
	Systeme unterstützen kann. AD hilft, Anforderungen klar voneinander
	abzugrenzen und unterstützt die Entwicklung von Systemen, deren Komponenten
	eine überschaubare Komplexität aufweisen und weitgehend unabhängig
	voneinander sind. Diese Ziele des AD korrespondieren mit wesentlichen
	Architekturzielen für Serviceorientierte Architekturen (SOA), nämlich
	„ausgewogene Granularität“, „lose Kopplung“ und „hohe Autonomie“
	von Services. In diesem Arbeitsbericht analysieren wir, welchen Beitrag
	AD zum Entwurf von SOA leisten kann. Anhand eines Fallbeispiels untersuchen
	wir, inwiefern AD helfen kann, Services zu entwerfen, welche eine
	ausgewogene Granularität aufweisen, in sich autonom und untereinander
	lose gekoppelt sind.},
  file = {:./literature/IBzWI_2007-04.pdf:PDF},
  keywords = {Axiomatic Design, Serviceorientierte Architekturen, Entwurf, Architekturziele},
  owner = {Stephan},
  timestamp = {2008.04.10},
  url = {http://www.db-thueringen.de/servlets/DerivateServlet/Derivate-11891/IBzWI_2007-04.pdf}
}

@INPROCEEDINGS{Filho2003,
  author = {Gilberto A. A. Cysneiros Filho and Andrea Zisman and George Spanoudakis},
  title = {Traceability Approach for i* and {UML} Models},
  booktitle = {Proceedings of the 2nd International Workshop on Software Engineering
	for Large-Scale Multi-Agent Systems (SELMAS'03)},
  year = {2003},
  __markedentry = {[Steffen:]},
  abstract = {In this paper we propose an approach that can be used to generate
	traceability relations between organisational models specified in
	i * and software systems models represented in UML (in particular
	use case and class diagrams). Our approach proposes different types
	of traceability relationships between i* and UML models and uses
	traceability rules to generate the different types of traceability
	relations between them. The traceability rules and traceable models
	are represented in XML. This makes possible the use of our approach
	in settings where the models are created and managed autonomously.
	The approach is supported by a prototype tool that interprets the
	rules and generates traceability relations.},
  citeseerurl = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.124.1309},
  file = {:./literature/Cysneiros03.pdf:PDF},
  keywords = {requirements engineering, traceability, organisational models, system
	models, XML},
  owner = {Stephan},
  review = {rule-based approache for traceability
	
	
	relations between i* and UML models are established via defined relation
	types and rules
	
	
	should be applicable for URN to UML as well},
  timestamp = {2010.08.05}
}

@ARTICLE{Filho2010,
  author = {Roberto S. Silva Filho and Christof J. Budnik and William M. Hasling
	and Monica McKenna and Rajesh Subramanyan},
  title = {Supporting Concern-Based Regression Testing and Prioritization in
	a Model-Driven Environment},
  journal = {Computer Software and Applications Conference Workshops},
  year = {2010},
  volume = {0},
  pages = {323-328},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/COMPSACW.2010.63},
  file = {:/literature/RegressionTesting/STA2010-Workshop.pdf:PDF},
  isbn = {978-0-7695-4105-1},
  keywords = {MDRT, MBRT},
  owner = {Steffen},
  publisher = {IEEE Computer Society},
  timestamp = {2012.03.01}
}

@MISC{Filss2005,
  author = {Christop Filß and Reinhard Höhn and Stephan Höppner and Martin Schumacher
	and Herbert Wetzel},
  title = {Rahmen zur Auswahl von Vorgehensmodellen},
  month = {März},
  year = {2005},
  note = {Arbeitsbericht der GI Fachgruppe WI-VM, Arbeitskreis „Vorgehensmodelltypen“},
  abstract = {Der Markt bietet eine Vielzahl von Vorgehensmodellen, Frameworks für
	Vorgehensmodelle, Methodensammlungen,
	
	Tool-Kits und er stellt auch immer wieder neue Vorgehensmodelle vor.
	Bei
	
	jedem neuen Projekt muss immer wieder die Frage gestellt werden, ob
	das im Hause eingesetzte
	
	Vorgehensmodell auch für die neuen Fragestellungen geeignet ist, ob
	neue Fragestellungen Erweiterungen
	
	erfordern, ob weitere Vorgehensmodelle eingeführt werden müssen, eventuell
	sogar komplett
	
	alte Ergebnisse zu einem neuen Vorgehensmodell migriert werden müssen
	oder ob man sich
	
	auf ein Framework einigt und dessen fallweise projektindividuelle
	Ausgestaltung zuläßt. Man denke
	
	hierbei etwa an Themen wie Web-Applikationen, Knowledge-Management
	Projekte, Data Warehouse
	
	Lösungen für die gerade die Modelle mit dem höchsten Verbreitungsgrad
	(RUP, ARIS) nicht
	
	gerüstet sind.
	
	In Berlin, im GI Workshop der Fachgruppe WI-VM, (VM04) am 22.4.2004
	wurde die Idee geboren,
	
	das Entscheidungsproblem des Vorgehensmodelleinsatzes in einem Arbeitskreis
	zu behandeln:
	
	· Vorgehensmodell einsetzen ja/nein
	
	· wenn ja welches VM
	
	· in welchem Umfang sollen VM eingesetzt werden, VM oder VM-Framework,
	etc.
	
	· wie sind VM abzugrenzen, ist XP, sind agile Methoden in die Kategorie
	der VM einzuordnen
	
	Die Arbeitsgruppe hat es sich zum Ziel gesetzt, die „Entscheidungsproblematik
	Vorgehensmodell“
	
	zu beleuchten, mit Hilfe einer Kategorisierung einen Überblick über
	die bestehenden Vorgehensmodelle
	
	zu geben, und Kriterien für die Auswahlentscheidung vorstellen.},
  file = {:./literature/ms_ArbeitsberichtWI-VM05.pdf:PDF},
  keywords = {Vorgehensmodell, IDEF, UML, Zachman, V-Modell, RUP, OTK},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://www.faw.uni-linz.ac.at/PublicationFullText/2005vm/ms_ArbeitsberichtWI-VM05.pdf}
}

@INPROCEEDINGS{Finkelstein2000,
  author = {Anthony Finkelstein and Jeff Kramer},
  title = {Software engineering: a roadmap},
  booktitle = {Proceedings of the Conference on The Future of Software Engineering,
	ICSE '00},
  year = {2000},
  pages = {3-22},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {This paper provides a roadmap for software engineering. It identifies
	the principal research challenges being faced by the discipline and
	brings together the threads derived from the key research specialisations
	within software engineering. The paper draws heavily on the roadmaps
	covering specific areas of software engineering research collected
	in this volume.},
  doi = {http://doi.acm.org/10.1145/336512.336519},
  file = {:./literature/finalfinkelstein.pdf:PDF},
  isbn = {1-58113-253-0},
  keywords = {software engineering, research, discipline, future, strategy},
  location = {Limerick, Ireland},
  owner = {Stephan},
  review = {gives an introduction to todays software engineering discipline and
	its orientation with some nice statements
	
	overview about technical literature
	
	
	states main research challanges:
	
	- compositionality: effect of composing components
	
	- change: how to cope with req. changes, predict change effects
	
	- non-functional properties: how to model NF properties, consider
	early stages, integrate models with other ones in system development
	
	- service-view: shift from product-oriented to service-view
	
	- perspectives: new methods for separating concerns
	
	- non-classical life cycles: adapt classical methods to evolutionary,
	rapid, extreme approaches
	
	- architecture: present, reason about and manage evolution of SWAs
	
	- configurability: use components to configure, customize and evolve
	systems
	
	- domain specificity: exploit properties of particular domains},
  timestamp = {2008.04.17}
}

@MASTERSTHESIS{Fischer2007,
  author = {Anja Fischer},
  title = {Konzeption und prototypische Implementierung eines Web Service Security
	Frameworks},
  school = {Technical University of Ilmenau},
  year = {2007},
  type = {Diploma thesis},
  address = {Ilmenau, Germany},
  month = {Dec.},
  abstract = {Aktuell werden Web Services nicht in Integrationsszenarien eingesetzt,
	in denen ein hohes Maß an IT-Sicherheit benötigt wird. Diese Tatsache
	resultiert aus fehlenden Technologien und Konzepten, die es ermöglichen
	könnten, Web Services in sicherheitskritischen Szenarien zu verwenden.
	Das in dieser Arbeit entwickelte Konzept für die Middleware-Plattform
	(Web Service Security Framework) verbindet Web Services mit aktuellen
	Sicherheitstechnologien. Eine Anforderungs- und Risikoanalyse führte
	zu einem Katalog von Sicherheitsanforderungen. Speziell die Risikoanalyse
	zeigte, dass die Ursachen der Schwachstellen des Web Service Security
	Frameworks sowohl auf die Verteilung und Heterogenität der Systemlandschaft
	als auch auf Fehler innerhalb der Trusted-Computing-Base-Komponenten
	zurückzuführen sind. Im nächsten Schritt erfolgte der Entwurf des
	Web Service Security Frameworks auf Grundlage der zuvor definierten
	Anforderungen. Die abgeleitete Sicherheitspolitik beruht auf den
	Bausteinen Authentisierung und Autorisierung. Sie enthält zusätzlich
	Regeln, die die Kommunikation, den Umgang mit persistenten Daten
	und die Protokollierung von Systemereignissen betreffen. Die technische
	Systemlandschaft basiert auf der Java Plattform SE 5 als Programmiersprache
	und der Java Plattform Enterprise Edition Spezifikation 5.0 als die
	angestrebte Architektur. Mit der anschließenden prototypischen Implementierung
	wurde die Zugriffskontrolle als Auszug aus dem Konzept umgesetzt.
	Bei der Implementierung waren folgende Zielstellungen maßgebend:
	Transparenz der Sicherheitsmechanismen gegenüber den Web Services
	und Implementierung der Zugriffskontrolle als Referenzmonitor. Die
	Zugriffskontrolle wurde als Axis2-Handler basierend auf dem Axis2-Framework
	realisiert. Das zuvor eingeführte Szenario "Elektronische Rechnungsstellung"
	als Beispiel zur kooperativen Auftragsabwicklung in der Logistik
	wird im Prototyp durch einen Web Service unterstützt. Dieser Web
	Service generiert aus Daten, die in einer XML-Struktur vorliegen,
	ein PDF-Dokument und signiert dieses mit einer digitalen Signatur.},
  file = {:./literature/DA_Fischer.pdf:PDF},
  keywords = {Web Service, security policies, security architecture, Axis2},
  owner = {Stephan},
  timestamp = {2008.10.13}
}

@INPROCEEDINGS{Fischer2008,
  author = {Anja Fischer and Winfried E. K\"uhnhauser},
  title = {Integration von {S}icherheitsmodellen in {W}eb {S}ervices},
  booktitle = {Proceedings D-A-CH Security},
  year = {2008},
  abstract = {Web Services haben als technologische Plattform für Unternehmensgrenzen
	überschreitende Kooperationssysteme in den letzten Jahren erheblich
	an Bedeutung gewonnen und bilden bereits heute die Basistechnologie
	für ein breites Spektrum von Anwendungsszenarien. Eingeschränkt wird
	die Breite dieses Spektrums derzeit vor allem durch unzureichende
	Möglichkeiten, IT-Sicherheitseigenschaften in Web Service Plattformen
	zu integrieren; Anwendungsszenarien, in denen Sicherheitseigenschaften
	unabdingbare Voraussetzung sind, sind dieser Technologie daher heute
	noch weitgehend verschlossen.
	
	Diese Arbeit stellt ein Framework vor, welches die Deﬁnition und Integration
	anwendungsspeziﬁscher Sicherheitspolitiken in Web Service basierten
	Kooperationssystemen auf der Grundlage elementarer Referenzmonitorprinzipien
	und einer kleinen präzise deﬁnierten Trusted Computing Base ermöglicht.},
  file = {:./literature/Paper_DA_Fischer.pdf:PDF},
  keywords = {Web Services, SOAP, ERP-Systeme, Trusted Computing Base, Referenzmonitorprinzipien,
	Interzeptoren, Sicherheitspolitiken, Sicherheitsmodelle, HRU-Modelle},
  owner = {Stephan},
  timestamp = {2008.10.13},
  url = {http://www.tu-ilmenau.de/fakia/fileadmin/template/startIA/vsbs/forschung/publications/DACH08.pdf}
}

@ARTICLE{Fitzgerald2003,
  author = {Fitzgerald, B. and Russo, N.L. and O'Kane, T.},
  title = {Software development method tailoring at Motorola},
  journal = {Communications of the ACM},
  year = {2003},
  volume = {46},
  pages = {64--70},
  number = {4},
  file = {Fitzgerald2003.pdf:literature/Fitzgerald2003.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.24}
}

@INPROCEEDINGS{Fitzgerald2000,
  author = {Fitzgerald, B. and Russo, N. and O'Kane, T.},
  title = {An empirical study of system development method tailoring in practice},
  booktitle = {Proceedings of the Eighth European Conference on Information Systems},
  year = {2000},
  pages = {187--194},
  file = {Fitzgerald2000.pdf:literature/Fitzgerald2000.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.24}
}

@BOOK{Florac1999,
  title = {Measuring the software process: Statistical process control for software
	process improvement},
  publisher = {Addison-Wesley Professional},
  year = {1999},
  author = {Florac, W.A. and Carleton, A.D.},
  owner = {patrickr},
  timestamp = {2012.06.12}
}

@INPROCEEDINGS{Fluri2006,
  author = {Fluri, Beat and Gall, Harald C.},
  title = {Classifying Change Types for Qualifying Change Couplings},
  booktitle = {Proceeding of the 14th IEEE International Conference on Program Comprehension
	(ICPC 2006)},
  year = {2006},
  pages = {35-45},
  address = {Athens},
  file = {:./literature/Paper_52.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- current history based IA approaches deal with changes related to
	textual lines and not classes / methods etc.
	
	- current change coupling cannot difference between minor/unimportant
	changes in text and real changes (i.e. formatting of texts is stored
	as change, although it is no real change)
	
	- current version control systems are not able to enrich changes with
	source code structure information
	
	
	Research Questions:
	
	
	Contribution:
	
	- new approach for classifying changes types based on code revisions
	
	- taxonomy of source code changes to support further analyses (+ definition
	of change types)
	
	- definition of significance of change
	
	
	Solution:
	
	- define source code changes as tree edit operations of abstract syntax
	tree (smallest source code entities are statements)
	
	- further classify changes according to a significance level (low,
	medium, high, crucial)
	
	* local changes considered as low significance whereas interface changes
	are considered crucial
	
	- devide OOP-classes into several parts: class body, method body,
	class declaration, method declaration, attribute declaration to increase
	support for changes
	
	- each source code entity has a label (represent kind of entity) and
	a textual description (the actual source code, e.g. method call with
	parameters)
	
	- extract changes from Eclipse CVS plugin
	
	- change coupling groups weighted by number of transactions they occured
	in
	
	-> granularity of entities: class, method, statements
	
	-> granularity of changes: atomic changes + combinations of atomic
	changes
	
	-> granularity of results: class, method, statements
	
	
	Open Issues:
	
	- significance levels (low, medium, high, crucial) might not be sufficient
	enough to distinguish properly between changes, additional float
	values might be better suited
	
	- class renaming not considered
	
	- tree-diff algorithm assumes slight changes between versions},
  timestamp = {2011.02.09}
}

@INPROCEEDINGS{Fluri2005,
  author = {Fluri, Beat and Gall, Harald C. and Pinzger, Martin},
  title = {Fine-Grained Analysis of Change Couplings},
  booktitle = {Proceeding of the Fifth IEEE International Workshop on Source Code
	Analysis and Manipulation 2005},
  year = {2005},
  pages = {66-74},
  month = {November},
  file = {:./literature/Paper_49.pdf:PDF},
  owner = {Steffen},
  review = {- earlier version of Fluri2006 with same scope and problem
	
	- however, focus is on change couplings only and not on change types},
  timestamp = {2011.02.09}
}

@ARTICLE{Foeldenauer2006,
  author = {Jürgen Földenauer},
  title = {Requirements Engineering aus Sicht der CMMI},
  journal = {OBJEKTspektrum-Online-Ausgabe: Requirements Engineering},
  year = {2006},
  volume = {2},
  booktitle = {Requirements Engineering aus Sicht der CMMI},
  file = {:./literature/foldenauer_OS_RE_06.pdf:PDF},
  keywords = {CMMI},
  owner = {Robert},
  publisher = {OBJEKTspektrum},
  timestamp = {2006.09.17},
  url = {http://www.sigs-datacom.de/sd/publications/os/2006/re/index.htm}
}

@PHDTHESIS{Folmer2005a,
  author = {Folmer, Eelke},
  title = {Software Architecture Analysis of Usability},
  school = {University of Groningen},
  year = {2005},
  file = {:./literature/thesis.pdf:PDF},
  keywords = {software architecture, architecture analysis, usability},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://dissertations.ub.rug.nl/FILES/faculties/science/2005/e.folmer/thesis.pdf}
}

@TECHREPORT{Folmer,
  author = {Folmer, Eelke and Bosch, Jan},
  title = {Experiences with Software Architecture Analysis of Usability},
  institution = {University of Groningen},
  abstract = {Studies of software engineering projects show that a significant large
	part of the maintenance costs of software systems is spent on dealing
	with usability issues. Fixing usability problems during the later
	stages of development has proven to be costly since many changes
	cannot be easily accommodated by the software architecture. These
	high costs prevent developers from meeting all the usability requirements,
	resulting in systems with less than optimal usability. Explicit evaluation
	of a software architecture for its support of usability is a tool
	to cost effectively develop usable systems. It allows for more “usability
	tuning” on the detailed design level, hence, preventing part of the
	high costs incurred by adaptive maintenance activities once the system
	has been implemented. Based on our investigations into the relationship
	between usability and software architecture, we developed a Scenario
	based Architecture Level UsabiliTy Analysis technique (SALUTA). The
	contribution of this paper is that it provides experiences and problems
	we encountered when conducting architecture analysis of usability
	at three industrial case studies performed in the domain of web based
	enterprise systems (e.g. e-commerce-, content management- and enterprise
	resource planning systems). We make some general observations and
	some architecture assessment related observations. For each experience,
	a problem description, examples, causes, solutions and research issues
	are identified.},
  file = {:./literature/JoSMEXF.pdf:PDF},
  keywords = {Software Architecture, Usability, architecture analysis},
  owner = {Stephan},
  review = {-> see Folmer2004},
  timestamp = {2008.04.02},
  url = {http://lucio.ls.fi.upm.es/status/results/JoSMEXF.pdf}
}

@INPROCEEDINGS{Folmer2005,
  author = {Folmer, E. and Bosch, J.},
  title = {Case studies on analyzing software architectures for usability},
  booktitle = {31st EUROMICRO Conference on Software Engineering and Advanced Applications,
	2005.},
  year = {2005},
  pages = {206-213},
  publisher = {IEEE Computer Society},
  abstract = {Studies of software engineering projects reveal that a large number
	of usability related change requests are made after its deployment.
	Fixing certain usability problems during the later stages of development
	has proven to be costly, since some of these changes require changes
	to the software architecture i.e. this often requires large parts
	of code to be completely rewritten. Explicit evaluation of usability
	during architectural design may reduce the risk of building a system
	that fails to meet its usability requirements and may prevent high
	costs incurring adaptive maintenance activities once the system has
	been implemented. In this paper, we demonstrate the use of a scenario
	based architecture analysis technique for usability we developed,
	at two case studies.},
  doi = {10.1109/EUROMICRO.2005.17},
  file = {:./literature/01517744.pdf:PDF},
  keywords = {software architecture, software performance evaluation, software reusability
	scenario based architecture analysis, software architecture, software
	engineering, software usability problem},
  owner = {Stephan},
  timestamp = {2008.04.02}
}

@ARTICLE{Folmer2004a,
  author = {Folmer, Eelke and Bosch, Jan},
  title = {Architecting for usability; a survey},
  journal = {Journal of Systems and Software},
  year = {2004},
  volume = {70},
  pages = {61-78},
  number = {1-2},
  month = {Feb},
  abstract = {Over the years the software engineering community has increasingly
	realized the important role software architecture plays in fulfilling
	the quality requirements of a system. The quality attributes of a
	software system are, to a large extent determined by the system’s
	software architecture. In recent years, the software engineering
	community has developed various tools and techniques that allow for
	design for quality attributes, such as performance or maintainability,
	at the software architecture level. We believe this design approach
	can be applied not only to “traditional” quality attributes such
	as performance or maintainability but also to usability. This survey
	explores the feasibility of such a design approach. Current practice
	is surveyed from the perspective of a software architect. Are there
	any design methods that allow for design for usability at the architectural
	level? Are there any evaluation tools that allow assessment of architectures
	for their support of usability? What is usability? A framework is
	presented which visualizes these three research questions. Usability
	should drive design at all stages, but current usability engineering
	practice fails to fully achieve this goal. Our survey shows that
	there are no design techniques or assessment tools that allow for
	design for usability at the architectural level.},
  citeseerurl = {http://citeseer.ist.psu.edu/folmer03architecting.html},
  doi = {10.1016/S0164-1212(02)00159-0},
  file = {:./literature/survey.pdf:PDF},
  keywords = {Software architecture, Usability, Design for quality attributes},
  owner = {Stephan},
  review = {main questions:
	
	-------------------
	
	Are there any design methods that allow for design for usability at
	the architectural level?
	
	Are there any evaluation tools that allow assessment of architectures
	for their support of usability?
	
	What is usability?
	
	
	most challanging task for a software architect: focus on design for
	specific attributes which contribut to the quality of a software
	system
	
	
	traditionally 2 approaches to usability engineering
	
	- concerned with interfaces/ detailed design or system in context/
	requirements analysis
	
	
	most usability issues do not depend on intefaces but on functionality
	(e.g. undo)
	
	
	design for usability:
	
	------------------------
	
	2 approaches: process oriented (user-centered design) and product
	oriented
	
	
	sources: interface guidelines, design heuristics and principles, usability
	patterns
	
	
	principles: consistency, task match, appropriate visual presentation,
	user control, memory-load reduction, error handling, guidance and
	support
	
	patterns -> catalogs
	
	
	shortcomings:
	
	- late detection of usability issues
	
	- requirements change -> design techniques can only partly model future
	uses of a product
	
	
	- iterative process -> prohibits preservation of design knowledge
	(mistakes made over and over again without learning)
	
	
	- requirements need have to be expressed more concretely in terms
	of the solution domain to influence architectural design
	
	
	- quality attributes often constraint by architecture
	
	- effect of single architecture decisions for quality attributes often
	unclear
	
	-> iteratively design for and assess for usability at the architectural
	level improves usability
	
	
	what is usability?
	
	---------------------
	
	- different definitions but overlapping and not important for design
	at architectural level
	
	
	important sources: Shackel, Nielson, ISO 9241-11, ISO 9126
	
	-> overview: 2 categories of attributes
	
	- objective criteria (user performance: learnability, efficiency...)
	
	- subjective criteria (user view: satisfaction or attitude)
	
	
	- only in ISO 9126: recognition of influence between usability and
	other quality attributes
	
	
	usability evaluation:
	
	------------------------
	
	- testing: requires representative users
	
	- inspection: requires usability specialists or software developers,
	users and other professionals
	
	- inquiry: requires usability evaluators -> e.g. questionaires
	
	-> but there are no techniques for architectural design
	
	
	usability framework:
	
	-------------------------
	
	difficult to draw a relation between usability attributes and software
	architecture
	
	-> decompose attributes -> indicators that measure usability
	
	but indicators interaction dependent -> defined for each type of interaction
	
	
	connect problem with solution domain through intermediate layer with
	usability properties
	
	-> properties are higher-level concepts, directly connected to design
	decisions
	
	
	no one-to-one mapping
	
	
	research issues:
	
	-------------------
	
	- design process: when finished? assessment techniques needed to determine
	if architecture meets NFRs
	
	- development or identification of design decisions that improve usability
	
	- usability requiremts need to be more contretely expressed in terms
	of solution domain
	
	
	- design heuristics should specificially suggest which architectural
	styles and patterns to use to improve usability
	
	
	interesting references: usability pattern catalogues
	
	- Perzel, Kane: Usability Patterns for Applications on the world wide
	web
	
	- Tidwell: Interaction Design Patterns
	
	- Welie: The Amsterdam Collection of Patterns in User Interface Design
	http://www.welie.com/patterns/},
  timestamp = {2008.04.02},
  url = {http://www.ls.fi.upm.es/status/results/survey.pdf}
}

@INPROCEEDINGS{Folmer2003,
  author = {E. Folmer and J. Bosch},
  title = {Usability patterns in Software Architecture},
  booktitle = {Proceedings of the 10th International Conference on Human-Computer
	Interaction, HCII2003},
  year = {2003},
  volume = {1},
  pages = {93-97},
  address = {Crete},
  month = {June},
  abstract = {Over the years the software engineering community has increasingly
	realized the important role software architecture plays in fulfilling
	the quality requirements of a system. Practice shows that for current
	software systems, most usability issues are still only detected during
	testing and deployment. To improve the usability of a software system,
	usability patterns can be applied. However, too often software systems
	prove to be inflexible towards such modifications which lead to potentially
	prohibitively high costs for implementing them afterwards. The reason
	for this shortcoming is that the software architecture of a system
	restricts certain usability patterns from being implemented after
	implementation. Several of these usability patterns are “architecture
	sensitive”, such modifications are costly to implement due through
	their structural impact on the system. Our research has identified
	several usability patterns that require architectural support. We
	argue the importance of the relation between usability and software
	architecture. Software engineers and usability engineers should be
	aware of the importance of this relation. The framework which illustrates
	this relation can be used as a source to inform architecture design
	for usability.},
  citeseerurl = {http://citeseer.ist.psu.edu/folmer03usability.html},
  file = {:./literature/patterns.pdf:PDF},
  keywords = {usability, pattern, software architecture},
  owner = {Stephan},
  review = {- usability attributes require explicit attention during system development
	
	- apply patterns when designing the architecture, because it's difficult
	to apply them after implementation of the majority of a system
	
	
	"obvious": usability patterns have positive effect on architecture
	and are architecture sensitive
	
	difficult: direct relationship between usability attributes and software
	architecture
	
	
	-> usability framework
	
	- linkage between usability attributes, properties, and patterns (e.g.
	learnability - guidance - wizard)
	
	- property more concrete form than requirement (attribute) -> decomposition
	
	
	- concentration on patterns, that can be applied during design of
	architecture
	
	- top-down approach starting from definition of usability
	
	- patterns address usability properties, no one-to-one mapping},
  text = {E. Folmer and J. Bosch, Usability patterns in Software Architecture,
	Accepted for HCI International 2003.},
  timestamp = {2008.04.02},
  url = {http://is.ls.fi.upm.es/status/results/patterns.pdf}
}

@INPROCEEDINGS{Folmer2004,
  author = {Eelke Folmer and Jilles van Gurp and Jan Bosch},
  title = {Software Architecture Analysis of Usability},
  booktitle = {Engineering Human Computer Interaction and Interactive Systems, JointWorking
	Conferences EHCI-DSVIS 2004},
  year = {2004},
  editor = {Rémi Bastide and Philippe Palanque and Jörg Roth},
  volume = {3425/2005},
  series = {LNCS},
  pages = {38-58},
  month = {July},
  publisher = {Springer},
  abstract = {Studies of software engineering projects [1,2] show that a large number
	of usability related change requests are made after its deployment.
	Fixing usability problems during the later stages of development
	often proves to be costly, since many of the necessary changes require
	changes to the system that cannot be easily accommodated by its software
	architecture. These high costs prevent developers from meeting all
	the usability requirements, resulting in systems with less than optimal
	usability. The successful development of a usable software system
	therefore must include creating a software architecture that supports
	the right level of usability. Unfortunately, no architecture-level
	usability assessment techniques exist. To support software architects
	in creating a software architecture that supports usability, we present
	a scenario based assessment technique that has been successfully
	applied in several cases. Explicit evaluation of usability during
	architectural design may reduce the risk of building a system that
	fails to meet its usability requirements and may prevent high costs
	incurring adaptive maintenance activities once the system has been
	implemented.},
  doi = {10.1007/b136790},
  file = {:./literature/ehci2004.pdf:PDF},
  keywords = {Software Architecture, Usability},
  owner = {Stephan},
  review = {description of the SALUTA assessment method
	
	-> see Folmer2003a
	
	
	here also further examples},
  timestamp = {2008.04.02},
  url = {http://publications.jillesvangurp.com/ehci2004.pdf}
}

@INPROCEEDINGS{Folmer2003a,
  author = {E. Folmer and J. Gurp and J. Bosch},
  title = {Scenario-Based Assessment of Software Architecture Usability},
  booktitle = {Proceedings of Workshop on Bridging the Gaps Between Software Engineering
	and Human-Computer Interaction, ICSE},
  year = {2003},
  address = {Portland},
  abstract = {Over the years the software engineering community has increasingly
	realized the important role software architecture plays in fulfilling
	the quality requirements of a system. The quality attributes of a
	software system are, to a large extent determined by the system’s
	software architecture .Usability is an essential part of software
	quality. The usability of software has traditionally been evaluated
	on completed systems. Evaluating usability at completion introduces
	a great risk of wasting effort on software products that are not
	usable. A scenario based assessment approach has proven to be successful
	for assessing quality attributes such as modifiability and maintainability
	[12]. It is our conjecture that scenario based assessment can also
	be applied for usability assessment. This paper presents and describes
	a scenario based assessment method to evaluate whether a given software
	architecture (provided usability) meets the usability requirements
	(required usability). The Scenariobased Architecture Level UsabiliTy
	Assessment (SALUTA) method consists of five main steps, goal selection,
	usage profile creation, software architecture description, scenario
	evaluation and interpretation.},
  citeseerurl = {http://citeseer.ist.psu.edu/article/folmer03scenariobased.html},
  file = {:./literature/scenario_assmt_ICSE2003.pdf:PDF},
  keywords = {scenario, assessment, software architecture, usability},
  owner = {Stephan},
  review = {needed: assessment technique for usability that fulfills the requirement:
	
	- provide data to determine if NFRs are met by the architecture, when
	is design process finished
	
	
	3 types of assessment techniques:
	
	- scenario based
	
	- simulation
	
	- mathematical modeling
	
	
	Usability assessment technique SALUTA
	
	-------------------------------------------------
	
	assessment -> comparison between required values of a particular quality
	attribute with its provided values
	
	
	steps:
	
	1. determine the goal of the assessment
	
	2. describe required usability: create usage profile
	
	- scenario definition: variables - users, tasks, context
	
	2.1 identify the users
	
	2.2 identify the tasks
	
	2.3 identify the context of operation
	
	2.4 create attribute preference table for relation of scenario to
	usability
	
	2.5 scenario selection
	
	2.6 scenario prioritization
	
	3. describe provided usability: describe the SA
	
	4. evaluate scenarios
	
	-> 3 complementary techniques
	
	- pattern based
	
	- design decision based
	
	- use case map based
	
	5. interpret results
	
	
	scenario profile: describes the semantics of software quality attributes},
  text = {E. Folmer, J. V. Gurp, and J. Bosch, Scenario-Based Assessment of
	Software Architecture Usability, Proceedings of Workshop on Bridging
	the Gaps Between Software Engineering and Human-Computer Interaction,
	ICSE, Portland, 2003.},
  timestamp = {2008.04.02},
  url = {http://www.ls.fi.upm.es/status/results/scenario_assmt_ICSE2003.pdf}
}

@ELECTRONIC{FowlerDI,
  author = {Fowler, Martin},
  month = {Jan},
  year = {2004},
  title = {Inversion of Control Containers and the Dependency Injection pattern},
  howpublished = {http://martinfowler.com/articles/injection.html},
  abstract = {In the Java community there's been a rush of lightweight containers
	that help to assemble components from different projects into a cohesive
	application. Underlying these containers is a common pattern to how
	they perform the wiring, a concept they refer under the very generic
	name of "Inversion of Control". In this article I dig into how this
	pattern works, under the more specific name of "Dependency Injection",
	and contrast it with the Service Locator alternative. The choice
	between them is less important than the principle of separating configuration
	from use.},
  keywords = {dependency injection, inversion of controls},
  owner = {Stephan},
  timestamp = {2010.03.05}
}

@BOOK{Fowler2002,
  title = {Patterns of Enterprise Application Architecture},
  publisher = {Addison-Wesley Longman},
  year = {2002},
  author = {Martin Fowler},
  owner = {Stephan},
  timestamp = {2010.10.29}
}

@ARTICLE{Fowler2001,
  author = {Martin Fowler},
  title = {Reducing Coupling},
  journal = {IEEE Software},
  year = {2001},
  volume = {18},
  pages = {102-104},
  number = {4},
  month = {Jul/Aug},
  address = {Los Alamitos, CA, USA},
  doi = {http://dx.doi.org/10.1109/MS.2001.936226},
  file = {:./literature/00936226.pdf:PDF},
  issn = {0740-7459},
  keywords = {software coupling, dependencies},
  owner = {Robert},
  publisher = {IEEE Computer Society Press},
  timestamp = {2008.07.15}
}

@BOOK{Fowler1999,
  title = {Refactoring: Improving the design of existing code},
  publisher = {Addison Wesley, Longman, Inc.},
  year = {1999},
  author = {Martin Fowler},
  pages = {464},
  address = {Amsterdam},
  language = {english},
  owner = {Robert},
  review = {Place URL here, since BibTech can't deal with "&" symbols
	
	
	http://books.google.de/books?hl=de&lr=&id=1MsETFPD3I0C&oi=fnd&pg=PP19&ots=pKM4l_RFdd&sig=BDysQzM0oidTBlXPZRr6T8M2Ygk},
  timestamp = {2008.07.15}
}

@INCOLLECTION{Fradet1999,
  author = {Fradet, Pascal and M\'{e}tayer, Daniel and P\'{e}rin, Micha\"{e}l},
  title = {Consistency Checking for Multiple View Software Architectures},
  booktitle = {Software Engineering - ESEC/FSE 1999},
  publisher = {Springer Berlin / Heidelberg},
  year = {1999},
  editor = {Nierstrasz, Oscar and Lemoine, Michel},
  volume = {1687},
  series = {Lecture Notes in Computer Science},
  pages = {410-428},
  affiliation = {IRISA/INRIA Campus de Beaulieu 35042 Rennes Cedex France},
  file = {:./literature/Paper_202.pdf:PDF},
  isbn = {978-3-540-66538-0},
  keyword = {Computer Science},
  owner = {Steffen},
  timestamp = {2012.03.15}
}

@INPROCEEDINGS{Franch1998,
  author = {Franch, X.},
  title = {Systematic formulation of non-functional characteristics of software},
  booktitle = {Requirements Engineering, 1998. Proceedings. 1998 Third International
	Conference on},
  year = {1998},
  pages = {174-181},
  publisher = {IEEE Computer Society},
  abstract = {This paper presents NoFun, a notation aimed at dealing with non-functional
	aspects of software systems at the product level in the component
	programming framework. NoFun can be used to define hierarchies of
	non-functional attributes, which can be bound to individual software
	components, libraries of components or (sets of) software systems.
	Non-functional attributes can be defined in several ways, being possible
	to choose a particular definition in a concrete context. Also, NoFun
	allows to state the values of the attributes in component implementations,
	and to formulate non-functional requirements over component implementations.
	The notation is complemented with an algorithm able to select the
	best implementation of components (with respect to their non-functional
	characteristics) in their context of use },
  doi = {10.1109/ICRE.1998.667823},
  file = {:./literature/00667823.pdf:PDF},
  keywords = {formal specification, software libraries, software qualityNoFun, component
	programming framework, individual software components, libraries,
	nonfunctional software characteristics, systematic formulation},
  owner = {Stephan},
  review = {introduces NoFun, a language for formulating non-functionality
	
	
	describes use for NF-attributes, NF-behaviour and NF-requirements},
  timestamp = {2008.04.14},
  url = {http://ieeexplore.ieee.org/iel4/5429/14673/00667823.pdf?tp=&isnumber=&arnumber=667823}
}

@INCOLLECTION{Frank2013,
  author = {Ulrich Frank},
  title = {Domain-Specific Modeling Languages - Requirements Analysis and Design
	Guidelines},
  booktitle = {Domain Engineering: Product Lines, Conceptual Models, and Languages},
  publisher = {Springer},
  year = {2013},
  editor = {Iris Reinhartz-Berger and Aron Sturm and Tony Clark and Yair Wand
	and Sholom Cohen and Jorn Bettin},
  pages = {133-157},
  abstract = {In recent years, the development of domain-specific modeling languages
	has gained remarkable attention. This is for good reasons. A domain-specific
	modeling language incorporates concepts that represent domain-level
	knowledge. Hence, systems analysts are not forced to reconstruct
	these concepts from scratch. At the same time, domain-specific modeling
	languages contribute to model integrity, because they include already
	constraints that would otherwise have to be added manually. Even
	though there has been a considerable amount of research on developing
	and using domain-specific modeling languages, there is still lack
	of comprehensive methods to guide the design of these languages.
	With respect to the complexity and risk related to developing a domain-specific
	modeling language, this is a serious shortfall. This chapter is aimed
	at a contribution to filling the gap. At first, it presents guidelines
	for selecting a metamodeling language. Its main focus is on supporting
	the process from analyzing requirements to specifying and evaluating
	a domain-specific modeling language.},
  file = {:./literature/Frank2013.pdf:PDF},
  owner = {matthias},
  timestamp = {2013.11.18},
  url = {http://link.springer.com/chapter/10.1007%2F978-3-642-36654-3_6}
}

@TECHREPORT{Frank2010,
  author = {Ulrich Frank},
  title = {Outline of a method for designing domain-specific
	
	modelling languages},
  institution = {ZBW – Leibniz-Informationszentrum Wirtschaft},
  year = {2010},
  type = {ICB-Research Report},
  number = {42},
  abstract = {In recent years, the development of domain-specific modelling languages
	has gained markable attention. This is for good reasons: A domain-specific
	modelling language rates concepts that represent domain-level knowledge.
	Hence, systems analysts are not forced to reconstruct these concepts
	from scratch. At the same time, domain-specific ling languages contribute
	to model integrity, because they include already constraints would
	otherwise have to be added manually. Even though there has been a
	considerable amount of research on developing and using domain-specific
	modelling languages, there still lack of comprehensive methods to
	guide the design of these languages. With respect the complexity
	and risk related to developing a domain-specific modelling language,
	this serious shortfall. This research report is aimed at a contribution
	to filling the gap. It the prolegomena of a method for developing
	domain-specific modelling languages, based on the experience gathered
	in several language specification projects. The method consists of
	two main parts: a meta modelling language and a process model. The
	MEMO metamodelling language (MEMO MML) is specified in a further
	report. Therefore, its description is restricted to a brief overview.
	Instead, the main focus of this report is on the process model, which
	describes essential steps to be accounted for during the development
	of a domain-specific modelling language. It includes heuristics to
	develop requirements and meta modelling guidelines that support frequent
	design decisions. The description of the method is complemented by
	examples which are mainly taken from the design of the MEMO Organisation
	Modelling Language.},
  file = {:./literature/DSLDesign-Frank2010.pdf:PDF},
  owner = {matthias},
  timestamp = {2013.03.08},
  url = {http://hdl.handle.net/10419/58163}
}

@TECHREPORT{Freimut2002,
  author = {Freimut, B. and Punter, T and Biffl, Stefan and Ciolkowski, Marcus},
  title = {Report on the state-of-the-art of Empirical Studies in Software Engineering},
  institution = {E188 - Institut f{\"u}r Softwaretechnik und Interaktive Systeme;
	Technische Universit{\"a}t Wien},
  year = {2002},
  file = {:./literature/10.1.1.95.3520.pdf:PDF},
  owner = {elkeb},
  timestamp = {2011.06.30}
}

@INPROCEEDINGS{Fritz2010,
  author = {Fritz, Thomas and Murphy, Gail C.},
  title = {{Using information fragments to answer the questions developers ask}},
  booktitle = {32nd Intl. Conf. on Software Engineering},
  year = {2010},
  pages = {175-184},
  doi = {10.1145/1806799.1806828},
  file = {:./literature/Fritz2010.pdf:PDF},
  isbn = {9781605587196},
  keywords = {Information needs,[Electronic Manuscript],human-centric software engineering,information
	fragments},
  mendeley-groups = {ECSA2014,ICSE2015},
  mendeley-tags = {Information needs},
  owner = {Sebastian},
  timestamp = {2014.03.07},
  url = {http://portal.acm.org/citation.cfm?doid=1806799.1806828}
}

@TECHREPORT{Frolund1998,
  author = {Svend Frolund and Jari Koistinen},
  title = {QML: A Language for Quality of Service Specification},
  institution = {HP Software Technology Laboratory},
  year = {1998},
  number = {HPL-98-10},
  month = {February},
  abstract = {To be competitive, future software system must provide not only the
	correct functionality, but also an adequate level of quality of service
	(QoS). By QoS, we refer to non-functional properties, such as reliability,
	performance, timing, and security. To provide an adequate level of
	QoS, software systems need to include capabilities such as QoS negotiation,
	monitoring, and adaptation. These capabilities all require the expected
	and the provided QoS levels to be explicitly specified. QoS can be
	specified statically at the time of implementation, design, or dynamically
	at deployment or runtime. To facilitate QoS specification, we present
	a general Quality of service Modeling Language (QML) for defining
	multi-category QoS specifications for components in distributed object
	systems. QML is designed to support QoS in general, encompassing
	QoS categories such as reliability, performance, security, and timing.
	QoS specification in QML facilitate the static decomposition of a
	software system into components with precisely specified QoS boundaries.
	They also facilitate dynamic QoS functions, such as negotiations,
	monitoring, and adaptation. QML is designed for a good fit with object-oriented
	distributed architectures and concepts such as interfaces and inheritance.
	It also allows specification at a fine-grained level for operations,
	operation arguments, and attributes. QML enables user- defined QoS
	categories, and allows specifications within those categories to
	be associated with component interface definitions. In addition,
	checks can be made dynamically to determine whether one QML specification
	satisfies another. This mechanism allows us to dynamically match
	QoS requirements and offers.},
  file = {:./literature/HPL-98-10.pdf:PDF},
  keywords = {specification languages, QoS, distributed object systems},
  owner = {Stephan},
  timestamp = {2008.05.15},
  url = {http://www.hpl.hp.com/techreports/98/HPL-98-10.html}
}

@INPROCEEDINGS{Froelund1998,
  author = {Svend Frølund and Jari Koistinen},
  title = {Quality of services specification in distributed object systems design},
  booktitle = {COOTS'98: Proceedings of the 4th conference on USENIX Conference
	on Object-Oriented Technologies and Systems (COOTS)},
  year = {1998},
  address = {Berkeley, CA, USA},
  month = {September},
  organization = {HP Software Technology Laboratory},
  publisher = {USENIX Association},
  abstract = {Traditional object-oriented design methods deal with the functional
	aspects of systems, but they do not address quality of service (QoS)
	aspects such as reliability, availability, performance, security,
	and timing. However, deciding which QoS properties should be provided
	by individual system components is an important part of the design
	process. Different decisions are likely to result in different component
	implementations and system structures. Thus, decisions about component-level
	QoS should be made at design time, before the implementation is begun.
	Since these decisions are an important part of the design process,
	they should be captured as part of the design. We propose a general
	Quality-of-Service specification language, which we call QML. In
	this paper we show how QML can be used to capture QoS properties
	as part of designs. In addition, we extend UML, the de-facto standard
	object-oriented modeling language, to support the concepts of QML.
	QML is designed to integrate with object-oriented features, such
	as interfaces, classes, and inheritance. In particular, it allows
	specification of QoS properties through refinement of existing QoS
	specifications. Although we exemplify the use of QML to specify QoS
	properties within the categories of reliability and performance,
	QML can be used for specification within any QoS category-QoS categories
	are user-defined types in QML.},
  file = {:./literature/HPL-98-159.pdf:PDF},
  keywords = {quality-of-service, specification, distributed object systems, software
	design, quality-of-service-enabled systems},
  location = {Santa Fe, New Mexico},
  owner = {Stephan},
  timestamp = {2008.05.15},
  url = {http://www.hpl.hp.com/techreports/98/HPL-98-159.pdf}
}

@TECHREPORT{Fuchs2009,
  author = {Fuchs, Jahn},
  title = {Systematic Literature Review},
  institution = {Ilmenau University of Technology, Department of Software Systems
	/ Process Informatics},
  year = {2009},
  month = {July},
  file = {:./literature/Paper_198.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.03.01}
}

@INPROCEEDINGS{Fuggetta2000,
  author = {Alfonso Fuggetta},
  title = {Software process: a roadmap},
  booktitle = {Proceedings of the Conference on The Future of Software Engineering,
	ICSE '00},
  year = {2000},
  pages = {25-34},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Software process research deals with the methods and technologies
	used to assess, support, and improve software development activities.
	The field has grown up during the 80s to address the increasing complexity
	and criticality of software development activities. This paper aims
	to briefly present the history and achievements of software process
	research, some critical evaluation of the results produced so far,
	and possible directions for future work.direct correlation between
	the quality of the process and the quality of the developed software.
	The research area that deals with these issues is referred to using
	the term software process.},
  doi = {http://doi.acm.org/10.1145/336512.336521},
  file = {:./literature/finalfuggetta.pdf:PDF},
  isbn = {1-58113-253-0},
  keywords = {software process},
  location = {Limerick, Ireland},
  owner = {Stephan},
  review = {indroduction to software process research area
	
	- concerned with methods and technologies assessing, supporting and
	improving software development activities
	
	
	assumption: correlation between quality of software process and quality
	of developed software
	
	important standards: ISO 12207 software lifecycle activities and ISO
	15504 software process capability determination
	
	
	stages of sw lifecycle: requirements analysis, specification, design,
	development, verification, validation, deployment, operation, maintenance,
	retirement
	
	
	software process: technology, methods and techniques (guidelines),
	organizational behaviour, marketing and economy
	
	
	process modeling: activities, roles, artifacts, tools --> Process
	Modeling Languages (PML)
	
	PSEE (Process-oriented Software Engineering Environment): supports
	creation and exploitation of software process models
	
	quality models: CMM, ISO 9001
	
	
	further main contributions: definition of metrics, empirical methods,
	empirical results
	
	
	software processes: PSP (Personal Software Process), Unified Software
	Development Process (Unified Process)
	
	
	challanges:
	
	- PMLs must be tolerant, easy to adopt for praticioners
	
	- PSEEs must be non-intrusive (smooth to integrate in traditional
	development), tolerant against inconsistencies and deviations and
	must state the process clearly
	
	- scope of process improvement methods should be widened, learn from
	other domains},
  timestamp = {2008.04.17},
  url = {http://www.cs.ucl.ac.uk/staff/A.Finkelstein/fose/finalfuggetta.pdf}
}

@ARTICLE{Girba2006,
  author = {G\^{i}rba, Tudor and Ducasse, St\'{e}phane},
  title = {Modeling History to Analyze Software Evolution},
  journal = {Journal of Software Maintenance and Evolution: Research and Practice},
  year = {2006},
  volume = {18},
  pages = {207-236},
  file = {:./literature/Paper_86.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- many approaches deal with history information to support software
	evolution
	
	- however there is no metamodel to enable reuse and easy comparison
	
	
	Research Questions:
	
	- what is required for building a metamodel for analyzing software
	history
	
	- how to construct this metamodel in order to support many different
	approaches / activities focused on history / changes
	
	
	Contribution:
	
	- survey of software evolution analyses
	
	- "Hismo" metamodel for software evolution where history is explicitly
	modeled as entity
	
	- times is aded on top of structural information
	
	
	Solution:
	
	- why a metamodel for software evolution:
	
	* no explicit entity to assign evolution properties
	
	* difficult to combine evolution information with version information
	
	* often no semantic units expressed in version management
	
	 - no information what exactly changed (class, method etc.)
	
	- so far, two approaches are common:
	
	* version-centered approaches
	
	 - a "version" is the lowest granularity
	
	 - evolution obtained by comparing two versions against each other
	
	* history-centered approaches
	
	 - provide answers to "where" and "what" happended, therefore versions
	are flattened
	
	 - use several measurements like: age of an entity, number of changes,
	number of authors which changed the entity
	
	- as a result of this investigation, the following requirements should
	be met by the metamodel:
	
	* different levels of abstraction and detail levels (i.e. from "files"
	down to "methods")
	
	* comparison of property evolution (e.g. number of methods in class)
	
	* combination of different property evolutions (e.g. number of methods
	in class + changed by certain author)
	
	* selectability: select any period in history
	
	* navigation through relations between histories
	
	- core of "Hismo" metamodel comprised of three entities:
	
	* history: set of versions
	
	* version: adds "time" to snapshots by relating snapshots to history
	
	* snapshot: placeholder for entity which evolution is studied (i.e.
	files, classes)
	
	- support many different history measurements:
	
	* evolution of a property P
	
	* earliest evolution of P
	
	* latest evolution of P
	
	* age of P
	
	* number of changes to P and so on....
	
	- use this metamodel for various approaches:
	
	* co-change detection
	
	* hierarchy evolution
	
	-> granularity of entities: class, method, variable
	
	-> granularity of changes: changes to files
	
	-> granularity of results: class, method, variable
	
	
	Open Issues:},
  timestamp = {2011.02.23}
}

@INPROCEEDINGS{Girba2007,
  author = {G\^{i}rba, Tudor and Ducasse, St\'{e}phane and Kuhn, Adrian},
  title = {Using Concept Analysis to Detect Co-Change Patterns},
  booktitle = {Proceedings of the Ninth international workshop on Principles of
	software evolution: in conjunction with the 6th ESEC/FSE joint meeting},
  year = {2007},
  pages = {83-89},
  address = {Dubrovnik, Croatia},
  file = {:./literature/Paper_118.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- changes crosscut system's architecture and all layers and components
	
	- changes have to be made in different "places" of a software
	
	
	Research Questions:
	
	- how can changes reveal hidden dependencies within the system (between
	entities)
	
	
	Contribution:
	
	- approach based on concept analysis to discover components which
	change in same way and at same time
	
	- apply approach on different levels of abstraction
	
	- concept analysis detects entities with same properties and requires
	manual inspection due to large size of EIS
	
	- propose heuristic to reduce false-positives in EIS
	
	
	Solution:
	
	- use formal concept analysis to detect common change patterns, affected
	many entities at the same time
	
	- formal concept analysis (FCA) uses matrix to store entities and
	properties whereas each matrix field denotes whether entity has property
	or not
	
	- use historical measure to detect changes between two versions
	
	* identify history in which a certain change condition is met
	
	- use logical expressions to build up entity/property-matrix
	
	* combine properties with tresholds and run on two versions to identify
	changes and changes to several properties
	
	- approach build upon Hismo-metamodel, see [Girba2006]
	
	- use 3 measures to detect changes:
	
	* NOP: number of packages
	
	* NOC: number of classes
	
	* NOM: number of methods
	
	- input for FCA:
	
	* entities: histories
	
	* properties: changed in version x
	
	- build concept lattice from matrix
	
	- heuristic removes entities from concepts which changed more often
	than the concept itself (treshold value)
	
	- remove concepts with less than 2 entities (otherwise no co-change)
	
	- use different co-change patterns for different entities:
	
	* method: 
	
	 - parallel complexity (complexity change in one method invokes complexity
	change in other method): compute number of paths through method (McCabe-number)
	
	 - dispersed logic: no change to method complexity, but to number
	of statements
	
	* class:
	
	 - shotgun surgery: change in one class causes changes in many other
	classes, detect classes which do not change their interface but implementation
	
	 - parallel inheritance: classes which change their number of children
	together
	
	 - parallel semantics: detect classes which add methods in parallel
	
	* package:
	
	 - package parallel semantics: detect classes with parallel semantics
	
	-> granularity of entities: package, class, method
	
	-> granularity of changes: fine-grained, add/remove statement/method,
	change statement/method
	
	-> granularity of results: package, class, method
	
	
	Open Issues:
	
	- not all change patterns evaluated in case studies
	
	- improve filter-algorithm (tweak treshold)},
  timestamp = {2011.04.01}
}

@INPROCEEDINGS{Girba2004a,
  author = {G\^{i}rba, Tudor and Ducasse, St\'{e}phane and Lanza, Michele},
  title = {{Yesterday’s Weather}: Guiding Early Reverse Engineering Efforts
	by Summarizing the Evolution of Changes},
  booktitle = {Proceeding of the 20th IEEE International Conference on Software
	Maintenance (ICSM ’04)},
  year = {2004},
  pages = {40-49},
  publisher = {IEEE Computer Society},
  file = {:./literature/Paper_79.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- reverse/reengineering efforts daunting if only the systems source
	code is available
	
	- changes stored in version control system help to understand evolution
	of system
	
	- however, extract required information from version control system
	requires a lot of work if not done by machine
	
	
	Research Questions:
	
	- how can one (automatically) utilize information stored in version
	control systems to guide developers (assist in reengineering and
	comprehension)
	
	- where to start when reengineering
	
	
	Contribution:
	
	- approach for identifying candidate classes for reengineering etc.
	from source code version control system
	
	- approached called "Yesterdays Wheather" based on assumption, that
	classes changed recently also change in future
	
	
	Solution:
	
	- approach build on top of some main assumptions:
	
	* parts of the system that changed need to be understood first
	
	* not every change is useful
	
	* parts which changed in the most recent past are most likely to change
	again
	
	- identify classes that changed the most in recent past and check
	whether they changed a lot within the past (--> most likely candidates)
	
	- OOP classes are primary element of approach and finest level of
	granularity
	
	- changes to classes are measured by changes of their total amount
	of methods, results in 3 metrics:
	
	* evolution of number of methods (ENOM): difference between version
	i and i+1, number of +/- methods
	
	* latest evolution of number of methods (LENOM): similar computation
	os ENOM, but rank changes due to their time
	
	* earliest evolution of number of methods (EENOM): opposite of LENOM
	
	- detection fo classes based on intersection between EENOM (classes
	that did change) and LENOM (classes likely to change)
	
	- value of yester wheather's forecast computed by counting the hits
	for all versions and divide them by the total number of possible
	hits
	
	-> granularity of entities: class
	
	-> granularity of changes: changes to the number methods
	
	-> granularity of results: class
	
	
	Open Issues:
	
	- only added and removed methods are used to identify changes, changes
	to existing methods not considered, although the provide most part
	of histories},
  timestamp = {2011.02.22}
}

@INPROCEEDINGS{Girba2004b,
  author = {G\^{i}rba, Tudor and Lanza, Michele},
  title = {Visualizing and Characterizing the Evolution of Class Hierarchies},
  booktitle = {Proceeding of the Fifth International Workshop on Object-Oriented
	Reengineering (WOOR 2004)},
  year = {2004},
  file = {:./literature/Paper_82.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- historical analysis can help understand how a software system evolved
	to current state
	
	- it can help to detect parts that are likely to change again
	
	- however, this requires analyses of vast amounts of data 
	
	
	Research Questions:
	
	- how can one describe and understand evolution of class hierarchies
	
	
	Contribution:
	
	- treating the history of source code artifacts as important entities
	
	- measurements for summarizing evolution of source code entities
	
	- visualize effects of time on such entities
	
	- vis. approach called "Class Hierarchy History Complexity View"
	
	
	Solution:
	
	- define 4 characteristics for class evolution:
	
	* age of hierarchy
	
	* stability of inheritance relationships
	
	* stability of class size
	
	* development effort balance
	
	- definition: history = sequence of versions of the same kind of entity
	(class, method)
	
	- use a polymetric view to visualize histories
	
	- following metrics influence graphical representation (polymetrc
	view):
	
	* position metric
	
	* entity width metric
	
	* entity height metric
	
	* entity color metric
	
	* relationship width metric
	
	* relationship color metric
	
	- use any of the 4 characteristics of class evolution as a metric
	
	- "Class Hierarchy History Complexity View" uses a tree layout in
	combination with polymetric view
	
	-> granularity of entities: classes
	
	-> granularity of changes: add/remove class/method
	
	-> granularity of results: classes
	
	
	Open Issues:
	
	- interaction with polymetric views would increase usefulness of approach},
  timestamp = {2011.02.23}
}

@INPROCEEDINGS{Girba2005,
  author = {G\^{i}rba, Tudor and Lanza, Michele and Ducasse, St\'{e}phane},
  title = {Characterizing the Evolution of Class Hierarchies},
  booktitle = {Proceeding of the Ninth European Conference on Software Maintenance
	and Reengineering (CSMR'05)},
  year = {2005},
  pages = {2-11},
  file = {:./literature/Paper_81.pdf:PDF},
  keywords = {./literature\Paper_80.pdf},
  owner = {Steffen},
  review = {--> based on Girba2004; a more detailed description but all the same
	ideas, approaches etc.
	
	
	Problem:
	
	- historical information help to understand how a system evolved to
	current state
	
	- however, historical information require analyses of vast amount
	of data
	
	- interpretation of historical data difficult
	
	
	Research Questions:
	
	- how to detect class evolution from vast amount of historical data:
	
	* how old are classes of a hierarchy?
	
	* were there changes to inheritance relationships?
	
	* are classes from a certain hierarchy more often modified than those
	from others?
	
	* are changes evenly distributed among classes of a hierarchy?
	
	
	Contribution:
	
	- define measurements which summarize evolution of software entities
	
	- use measurements to define rules which detect different evolution
	characteristics
	
	
	Solution:
	
	- use 4 characteristics to classify class evolution:
	
	* age of hierarchy:
	
	 - newborne
	
	 - young
	
	 - old
	
	 - persistent
	
	* stability of inheritance relationships:
	
	 - solid
	
	 - fragile
	
	* stability of class size:
	
	 - stable
	
	 - unstable
	
	* development effort:
	
	 - balance
	
	 - unbalanced
	
	- use 2 class evolution metrics:
	
	* number of methods
	
	* number of statements
	
	- utilize the "Class Hierarchy History Complexity View" (see Girba2004b)
	
	- build on top of "Hismo" metamodel (see Girba2006)
	
	-> granularity of entities: classes
	
	-> granularity of changes: add/remove class/method
	
	-> granularity of results: classes
	
	
	Open Issues:
	
	- interaction with polymetric views},
  timestamp = {2011.02.23}
}

@INPROCEEDINGS{Gall2003,
  author = {Gall, Harald and Jazayeri, Mehdi and Krajewski, Jacek},
  title = {{CVS} Release History Data for Detecting Logical Couplings},
  booktitle = {Proceedings of the Sixth International Workshop on Principles of
	Software Evolution},
  year = {2003},
  month = {September},
  file = {:./literature/Paper_100.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- dependencies and interrelations between classes affect maintainability
	
	- important to capture "weaknesses" of software architecture
	
	- analyses on the level of source code not sufficient enough, also
	investigate moduls and larger entities
	
	
	Research Questions:
	
	- how to reason about evolution based on historical data from CVS
	
	- how to extract software evolution patterns and dependencies from
	CVS data
	
	
	Contribution:
	
	- method for software evolution analysis, consisting of 3 steps:
	
	* quantitative analysis based on version information
	
	* change sequence analysis
	
	* relation analysis
	
	- focus is on "relation analysis" which captures dependencies within
	the evolution of classes from CVS data
	
	-> uncover logical couplings between software artifacts
	
	
	Solution:
	
	- method "QCR" investigates historical development of classes
	
	- operates on structural information of programs, moduls and subsystems,
	combinded with version numbers and change information
	
	-> observe change behaviour
	
	-> operate on Java source code to reason about evolution and quality
	of architecture and design
	
	- use the following hierarchy:
	
	* system
	
	* subsystem
	
	* module
	
	* sub-modul
	
	* class
	
	- whole "QCR" consists of 3 methods:
	
	* quantitative analysis (QA): analyze change and growth rate of modules
	
	* change sequence analysis (CAS): identify common change histories
	of modules
	
	* relation analyis (RA): compare modules and find dependencies -->
	paper focuses on this one
	
	- RA detects couplings which refer to similar change patterns among
	different parts of the software
	
	- find classes that were most frequently changed together
	
	- compare changes of classes, based on author, date and time of change
	(use a time window of 4 minutes)
	
	- assumption: all changes done on the same day by the same author
	point to a logical coupling
	
	- the more correspondences are found, the stronger is the observed
	coupling
	
	- distinguish between internal (relations within same module) and
	external (relations to entities in other modules/componets) coupliings
	
	- average class was changed 5 times, so focus analysis on classes
	which were changed more than 5 times
	
	-> granularity of entities: class
	
	-> granularity of changes: header information of CVS change records
	
	-> granularity of results: class
	
	
	Open Issues:
	
	- missed classes which were changed less than 5 times
	
	- coupling only based on date and developer of change},
  timestamp = {2011.02.24}
}

@ARTICLE{Gallagher1991,
  author = {Gallagher, K. B. and Lyle, J. R.},
  title = {Using Program Slicing in Software Maintenance},
  journal = {IEEE Transactions on Software Engineering},
  year = {1991},
  volume = {17},
  pages = {751-761},
  number = {8},
  month = {August},
  booktitle = {IEEE Transactions on Software Engineering},
  file = {:./literature/Paper_68.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- variables and statements may have influence across the whole software
	system
	
	- current program slicing requires a certain variable and line number
	to work
	
	- therefore not suitable for maintenance and impact analysis
	
	
	Research Questions:
	
	- how can maintenance benefit from program slicing
	
	- what must be done to adjust slicing to maintenance needs
	
	
	Contribution:
	
	- forming slice-based decompositions of programs containing only affected
	parts
	
	- isolation of elements for a required change
	
	- create decompositions slices which are independent of statement
	numbers
	
	
	Solution:
	
	- construction of slices is a two-step process
	
	* build a decomposition slice for a variable (can be the union of
	several slices)
	
	* construct the "complement" (slice) from original program
	
	- use decomposition to break program into manageable pieces and to
	garantuee that there are no ripple effects
	
	- use algorithm for dead code detection to construct decomposition
	slice by locating all instructions that are useful (declared as critical)
	
	* mark all output instructions is critical
	
	* trace instructions that impact the output statements (called use-definition)
	
	- examine relationships between decomposition slices to perform actual
	decomposition
	
	* take the decomp. slice for each variable
	
	* form a lattice of these slices
	
	* order them by set inclusions
	
	- remove output statements from slices as they do not contribute anything
	
	-> granularity of entities: variables
	
	-> granularity of changes: changes to statements
	
	-> granularity of results: variables
	
	
	Open Issues:},
  timestamp = {2011.02.17}
}

@ARTICLE{Galster2010,
  author = {Galster, M. and Eberlein, A. and Moussavi, M.},
  title = {Systematic selection of software architecture styles},
  journal = {IET Software},
  year = {2010},
  volume = {4},
  pages = {349-360},
  number = {5},
  month = {Oct.},
  abstract = {Selecting appropriate styles for software architectures is important
	as styles impact characteristics of software (e.g. reliability).
	Moreover, styles influence how software is built as they determine
	architectural elements (e.g. components, connectors) and rules on
	how these elements are integrated in the architecture. Therefore
	this study presents a method, called SYSAS, for the systematic selection
	of architecture styles. In SYSAS, style selection is based on (a)
	characteristics of basic architectural elements that are relevant
	for the developer, and (b) characteristics of the target system that
	are visible to the end user. The selection procedure requires ratings
	about the importance of characteristics of architectural elements
	and results in a ranking of styles. SYSAS can be applied at system
	level as well as for choosing styles for individual subsystems. A
	case study is presented to illustrate SYSAS and its applicability
	and added benefit. Additional case studies are performed to compare
	results of SYSAS with judgements of experts.},
  doi = {10.1049/iet-sen.2009.0004},
  issn = {1751-8806},
  keywords = {SYSAS method;software architecture styles;systematic architecture
	style selection;software architecture; AHP},
  owner = {Stephan},
  timestamp = {2011.01.11}
}

@INPROCEEDINGS{Galster2006,
  author = {Galster, M. and Eberlein, A. and Moussavi, M.},
  title = {Transition from Requirements to Architecture: A Review and Future
	Perspective},
  booktitle = {Seventh ACIS International Conference on Software Engineering, Artificial
	Intelligence, Networking, and Parallel/Distributed Computing, 2006
	(SNPD 2006)},
  year = {2006},
  pages = {9-16},
  month = {June},
  publisher = {IEEE},
  abstract = {Elicitation, modeling and analysis of requirements are main challenges
	during software development. In parallel, software architectures
	have become a well established area in software engineering research
	and practice. However, there is still a lack of fundamental process
	models and guidelines for the transition between the two important
	phases of requirements engineering and software architectures within
	the software development cycle. Substantial progress has been separately
	made in both areas but very little research achievements can be found
	that address the relation between requirements and architectures.
	When doing a review on existing methods that try to overcome this
	gap we realized an urgent need for fundamental research in this area.
	The paper first presents, compares, classifies and evaluates the
	suitability of current approaches. Then, evaluation criteria and
	requirements for a transition methodology are defined. Finally, directions
	for further research are presented.},
  doi = {10.1109/SNPD-SAWN.2006.73},
  file = {:./literature/01640660.pdf:PDF},
  keywords = {software architecture, systems analysis, requirements analysis, requirements
	engineering, software architecture, software development cycles},
  owner = {Stephan},
  review = {description of the transition problem from requirements to architecture
	
	
	compares different approaches: ADLs, goal-oriented approach, use case
	maps...
	
	
	goal-oriented approach (e.g. NFR Framework) most popular
	
	but: drawbacks in qualitative reasoning
	
	-> should be more formal to allow extended tool support
	
	
	use case maps
	
	- show causal paths between responsibilities in organizational structures
	of components
	
	- combine behaviour and structure in one view
	
	- allocate responsibilities to architectural components
	
	
	research in this area is needed - possible directions shown},
  timestamp = {2009.01.09}
}

@INPROCEEDINGS{Galvao2007,
  author = {Galv{\~a}o, I. and Goknil, A.},
  title = {Survey of Traceability Approaches in Model-Driven Engineering},
  booktitle = {11th IEEE International Enterprise Distributed Object Computing Conference,
	2007 (EDOC 2007)},
  year = {2007},
  pages = {313-313},
  month = {Oct.},
  __markedentry = {[Steffen:]},
  abstract = {Models have been used in various engineering fields to help managing
	complexity and represent information in different abstraction levels,
	according to specific notations and stakeholder's viewpoints. Model-Driven
	Engineering (MDE) gives the basic principles for the use of models
	as primary artefacts throughout the software development phases and
	presents characteristics that simplify the engineering of software
	in various domains, such as Enterprise Computing Systems. Hence,
	for its successful application, MDE processes must consider traceability
	practices. They help the understanding, capturing, tracking and verification
	of software artefacts and their relationships and dependencies with
	other artefacts during the software life-cycle. In this survey, we
	discuss the state-of-the-art in traceability approaches in MDE and
	assess them with respect to five general comparison criteria: representation,
	mapping, scalability, change impact analysis and tool support. As
	a complementary result, we have identified some open issues that
	can be better explored by traceability in MDE.},
  doi = {10.1109/EDOC.2007.42},
  file = {:./literature/Galvao2007.pdf:PDF},
  issn = {1541-7719},
  keywords = {abstraction levels;complexity management;enterprise computing systems;impact
	analysis;model-driven engineering;software development;software engineering;software
	life-cycle;traceability approaches;computational complexity;software
	engineering;},
  owner = {Stephan},
  timestamp = {2010.12.08}
}

@BOOK{Gamma1994,
  title = {Design Patterns: Elements of Reusable {Object-Oriented} Softwaresystemen},
  publisher = {{Addison-Wesley} Professional},
  year = {1994},
  author = {Erich Gamma and Richard Helm and Ralph Johnson and John M. Vlissides},
  isbn = {0201633612},
  keywords = {design pattern, gang of four, pattern catalog},
  owner = {Stephan},
  shorttitle = {Design Patterns},
  timestamp = {2010.03.02}
}

@TECHREPORT{Gane1982,
  author = {Gane, Chris P. and Sarson, Trish},
  title = {Structured System Analysis},
  institution = {McDonnell Douglas},
  year = {1982},
  owner = {Steffen},
  timestamp = {2014.01.18}
}

@ARTICLE{Gann2000,
  author = {Gann, D.M. and Salter, A.J.},
  title = {Innovation in project-based, service-enhanced firms: the construction
	of complex products and systems},
  journal = {Research policy},
  year = {2000},
  volume = {29},
  pages = {955--972},
  number = {7},
  file = {Gann2000.pdf:literature/Gann2000.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.22}
}

@INPROCEEDINGS{Garlan2000,
  author = {David Garlan},
  title = {Software architecture: a roadmap},
  booktitle = {Proceedings of the Conference on The Future of Software Engineering,
	ICSE '00},
  year = {2000},
  pages = {91-101},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Over the past decade software architecture has received increasing
	attention as an important subfield of software engineering. During
	that time there has been considerable progress in developing the
	technological and methodological base for treating architectural
	design as an engineering discipline. However, much remains to be
	done to achieve that goal. Moreover, the changing face of technology
	raises a number of new challenges for software architecture. This
	paper examines some of the important trends of software architecture
	in research and practice, and speculates on the important emerging
	trends, challenges, and aspirations.},
  doi = {http://doi.acm.org/10.1145/336512.336537},
  file = {:./literature/Software_Architecture_a_Roadmap.pdf:PDF},
  isbn = {1-58113-253-0},
  keywords = {Software architecture, software design, software engineering},
  location = {Limerick, Ireland},
  owner = {Stephan},
  review = {illustration of the software architecture discipline yesterday, the
	achievements today and challanges for tomorrow
	
	
	important roles of SWA:
	
	- understanding
	
	- reuse
	
	- construction
	
	- evolution
	
	- analysis
	
	- management
	
	
	challanges:
	
	- product line approaches require different methods for development
	
	- system integration plays important role with composition of components,
	therefor higher-level architectural standards are required
	
	- composability needs guaranteed compatibility through contracts
	
	- upscaling architectures, variability (like Internet), common vocabulary
	needed that's understood by all components
	
	- handle dynamically-evolving colletions of components with architecture
	descriptions
	
	- permit end users to compose their own system
	
	- flexibility as an issue, dynamical reconfiguration, mobility
	
	- pervasive computing - resource usage as critical issue},
  timestamp = {2008.04.17},
  url = {http://www.eng.auburn.edu/csse/classes/comp7700/papers/Software_Architecture_a_Roadmap.pdf}
}

@BOOK{Gasser1988,
  title = {Building a secure computer system},
  publisher = {Van Nostrand Reinhold Co.},
  year = {1988},
  author = {Morrie Gasser},
  address = {New York, NY, USA},
  file = {:./literature/gasserbook.pdf:PDF},
  isbn = {0-442-23022-2},
  keywords = {security engineering},
  owner = {Stephan},
  timestamp = {2008.10.13},
  url = {http://nucia.unomaha.edu/dspace/documents/gasserbook.pdf}
}

@ARTICLE{Gea2011,
  author = {de Gea, C. and Juan, M. and Nicol{\'a}s, J. and Alem{\'a}n, J.L.F.
	and Toval, A. and Ebert, C. and Vizca{\'\i}no, A.},
  title = {Requirements Engineering Tools},
  journal = {Software, IEEE},
  year = {2011},
  volume = {28},
  pages = {86-91},
  number = {4},
  file = {:./literature/Paper_247.pdf:PDF},
  owner = {patrickr},
  publisher = {IEEE},
  timestamp = {2012.03.21}
}

@ARTICLE{German2009,
  author = {German, Daniel M. and Hassan, Ahmed E. and Robles, Gregorio},
  title = {Change impact graphs: Determining the impact of prior code changes},
  journal = {Information and Software Technology},
  year = {2009},
  volume = {51},
  pages = {1394-1408},
  file = {:./literature/Paper_69.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- software is constantly changed
	
	- impact of changes spread across whole system
	
	- this may lead to failures in unchanged parts
	
	
	Research Questions:
	
	- how can one detect bugs / their location from source code history
	
	- how to identify functions that were not changed, although they should
	be changed
	
	
	Contribution:
	
	- approach for finding failures in unchanged parts (those that were
	forgotten to be changed)
	
	- utilize prior code changes to determine what functions have been
	modified
	
	- use a change impact graph (CIG) to propagate this changes throughout
	the entire system
	
	
	Solution:
	
	- rough sketch of proposed approach:
	
	* method determines all changed areas of the system which affect a
	reported location
	
	* the method annotates these areas by marking recent code changes
	and propagating the impact of these recent changes
	
	- generate dependency graphs for each function (i.e. containing all
	functions that the function itself is calling) = standard call graphs
	
	- propagation of prior changes computed as:
	
	* define a window of interest [begining, end] and compute the dependency
	graph
	
	* mark all nodes as unaffected
	
	* each node that has been added/changed during time window, mark node
	as changed
	
	* repeat until the dependency graph stops changing:
	
	 - for any still unchanged node, check wether one successor is changed
	/ affected, if so mark the node as affected
	
	- results in node being classified as either changed, unaffected or
	affected
	
	- due to large graphs, pruning is required:
	
	* remove unaffected nodes
	
	* remove nodes outside of area of interest, through 2 possibilities:
	
	 - prune before impact of changes is computed
	
	 - prune after, however their impact will still be considered
	
	- two metrics to judge changes
	
	* ratio of affected functions: (changed + affected nodes) / total
	nodes
	
	* ratio of changed functions: changed nodes / total nodes
	
	- annotate source code with information from CIGs, i.e. coloring the
	code to mark functions as "recently changed" etc.
	
	- to construct CIGs, gather historical data from version control systems
	(i.e. change records):
	
	* remove white spaces, comments and reformat a change record
	
	* identify functions in the change set
	
	* determine type of operation applied on each function (e.g. unchanged,
	added) by comparing it to its previous version
	
	* compute dependency graph for required function
	
	* prune-before, if required
	
	* propagate changes in dependency graph
	
	* prune-after, if required
	
	-> granularity of entities: methods
	
	-> granularity of changes: renamed, merged, splitt and code-cloned
	functions
	
	-> granularity of results: methods
	
	
	Open Issues:
	
	- only applied on prodecural languages, not OOP
	
	- function pointers and polymorphism ignored
	
	- moved or refactored functions not considered during version control
	analysis
	
	- peroid of time not easy to obtain if unclear when a change / bug
	was introduced
	
	- lenght of the period s crucial for approach, tweaking the values
	is important, but to decide?},
  timestamp = {2011.02.17}
}

@ARTICLE{Gersick1988,
  author = {Gersick, C.J.G.},
  title = {TIME AN TRANSITION IN WORK TEAMS: TOWARD A NEW MODEL OF GROUP DEVELOPMENT.},
  journal = {Academy of Management journal},
  year = {1988},
  volume = {31},
  pages = {9--41},
  number = {1},
  file = {Gersick1988.pdf:literature/Gersick1988.pdf:PDF},
  owner = {patrickr},
  publisher = {Academy of Management},
  timestamp = {2012.10.19}
}

@INPROCEEDINGS{Gerth:2009:LCM:1691319.1691336,
  author = {Gerth, Christian and K\"{u}ster, Jochen M. and Engels, Gregor},
  title = {Language-Independent Change Management of Process Models},
  booktitle = {Proceedings of the 12th International Conference on Model Driven
	Engineering Languages and Systems},
  year = {2009},
  series = {MODELS '09},
  pages = {152--166},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  acmid = {1691336},
  doi = {http://dx.doi.org/10.1007/978-3-642-04425-0_12},
  file = {:/literature/changeIdentification/language independent change management of process models.pdf:PDF},
  isbn = {978-3-642-04424-3},
  keywords = {Process model change management, process model differences},
  location = {Denver, CO},
  numpages = {15},
  owner = {Steffen},
  timestamp = {2012.03.01},
  url = {http://dx.doi.org/10.1007/978-3-642-04425-0_12}
}

@INCOLLECTION{Gerth2010,
  author = {Gerth, Christian and KÃ¼ster, Jochen and Luckey, Markus and Engels,
	Gregor},
  title = {Precise Detection of Conflicting Change Operations Using Process
	Model Terms},
  booktitle = {Model Driven Engineering Languages and Systems},
  publisher = {Springer Berlin / Heidelberg},
  year = {2010},
  editor = {Petriu, Dorina and Rouquette, Nicolas and Haugen, Ã˜ystein},
  volume = {6395},
  series = {Lecture Notes in Computer Science},
  pages = {93-107},
  note = {10.1007/978-3-642-16129-2_8},
  affiliation = {Department of Computer Science, University of Paderborn, Germany},
  isbn = {978-3-642-16128-5},
  keyword = {Computer Science},
  owner = {Steffen},
  timestamp = {2012.03.01},
  url = {http://dx.doi.org/10.1007/978-3-642-16129-2_8}
}

@INPROCEEDINGS{Gethers2012,
  author = {Gethers, Malcom and Dit, Bogdan and Kagdi, Huzefa and Poshyvanyk,
	Denys},
  title = {Integrated Impact Analysis for Managing Software Changes},
  booktitle = {Proceedings of the 34th International Conference on Software Engineering
	(ICSE 2012 )},
  year = {2012},
  pages = {430-440},
  address = {Zurich},
  month = {June},
  file = {:./literature/Paper_272.pdf:PDF},
  owner = {Steffen},
  timestamp = {2013.10.22}
}

@INPROCEEDINGS{Gethers2010,
  author = {Gethers, Malcom and Poshyvanyk, Denys},
  title = {Using Relational Topic Models to Capture Coupling among Classes in
	Object-Oriented Software Systems},
  booktitle = {Proceedings of the 26th IEEE International Conference on Software
	Maintenance (ICSM'10)},
  year = {2010},
  pages = {1-10},
  address = {Timisoara, Romania},
  month = {September},
  file = {:./literature/Paper_162.pdf:PDF},
  owner = {Steffen},
  review = {useful stuff:
	
	paper referenced for case study / research question
	
	
	Problem:
	
	- most existing coupling measures rely on structural information,
	e.g. usage relations between classes
	
	- they are not able to detect conceptual couplings, e.g. encoded in
	identifiers or comments
	
	
	Research Questions:
	
	- improve impact detection with enhanced coupling metrics
	
	
	Contribution:
	
	- new coupling detection technique, Relation Topic based Coupling
	(RTC) to compute coupling between classes
	
	- RTC is new probalistic model and relies on Relational Topic Models
	(RTM)
	
	
	Solution:
	
	- RTM is unsupervised probabilistic topic modeling technique
	
	- RTM associates topics with documents
	
	* predicts links between documents based on topics and relations among
	documents
	
	* RTM extends LDA (latent dirichlet allocation)
	
	 - represent software as collection of documents
	
	 - word is basic element, i.e. identifier
	
	 - document corresponds to a class and is a collection of words (identifiers,
	methods etc.)
	
	-> granularity of entities: class
	
	-> granularity of changes:
	
	-> granularity of results: class
	
	
	Open Issues:
	
	- adapt metric to inheritance relations
	
	- adapt granularity to methods},
  timestamp = {2011.07.25}
}

@TECHREPORT{Ghanam2008,
  author = {Ghanam, Yaser and Carpendale, Sheelagh},
  title = {A Survey Paper on Software Architecture Visualization},
  institution = {University of Calgary},
  year = {2008},
  address = {Canada},
  file = {:./literature/Paper_107.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.03.03}
}

@INPROCEEDINGS{Giese2007,
  author = {Giese, C. and Schnieders, A. and Weiland, J.},
  title = {A Practical Approach for Process Family Engineering of Embedded Control
	Software},
  booktitle = {Engineering of Computer-Based Systems, 2007. ECBS'07. 14th Annual
	IEEE International Conference and Workshops on the},
  year = {2007},
  pages = {229--240},
  organization = {IEEE},
  file = {Giese2007.pdf:literature/Giese2007.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.23}
}

@PHDTHESIS{Giesecke2008a,
  author = {Giesecke, Simon},
  title = {Architectural Styles for Early Goal-driven Middleware Platform Selection},
  school = {University of Oldenburg},
  year = {2008},
  file = {:./literature/phd_simon_giesecke.pdf:PDF},
  owner = {Sebastian},
  timestamp = {2013.07.26}
}

@ARTICLE{Giesecke2007,
  author = {Simon Giesecke and Wilhelm Hasselbring and Matthias Riebisch},
  title = {Classifying architectural constraints as a basis for software quality
	assessment},
  journal = {Advanced Engineering Informatics},
  year = {2007},
  volume = {21},
  pages = {169-179},
  number = {2},
  abstract = {Architectural styles and patterns have been studied since the inception
	of software architecture as a discipline. We generalise architectural
	styles, patterns and similar concepts by introducing the notion of
	architectural constraints. An architectural constraint is a vehicle
	for the reuse of architectural design knowledge and for the improvement
	of software quality. It may be used for improving architectural analyses
	of quality characteristics of the software system to be realised.
	We present the method for surveying the literature on architectural
	constraint concepts, and provide a taxonomy covering various definitions
	of architectural styles and patterns.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.aei.2006.11.002},
  file = {:./literature/ADVEI148.pdf:PDF},
  issn = {1474-0346},
  keywords = {Architectural style, Architectural constraints; Software quality assessment},
  owner = {Matthias},
  publisher = {Elsevier Science Publishers B. V.},
  timestamp = {2008.09.25},
  url = {http://www.theoinf.tu-ilmenau.de/~Matthias/home/publ/ADVEI148.pdf}
}

@INPROCEEDINGS{Giesecke2008,
  author = {Simon Giesecke and Matthias Rohr and Wilhelm Hasselbring},
  title = {Architectural Styles for Early Goal-driven Middleware Selection},
  booktitle = {Postproceedings of the 13th European Conference on Pattern Languages
	of Programs (EuroPLoP 08)},
  year = {2008},
  address = {Irsee, Germany},
  month = {Jul},
  file = {:./literature/Giesecke2008.pdf:PDF},
  owner = {Stephan},
  timestamp = {2011.04.04}
}

@INPROCEEDINGS{Ginige2006,
  author = {Jeewani A. Ginige and Uma Sirinivasan and Athula Ginige},
  title = {A Mechanism for Efficient Management of Changes in BPEL based Business
	Processes: An Algebraic Methodology},
  booktitle = {e-Business Engineering, 2006. ICEBE '06. IEEE International Conference
	on},
  year = {2006},
  pages = {171 -178},
  month = {oct. },
  doi = {10.1109/ICEBE.2006.7},
  file = {:/literature/RegressionTesting/A Mechanism for Efficient Management of Changes in BPEL based.pdf:PDF},
  keywords = {WSRT, Kleene algebra with test;Web service composition language;Web
	service definition language;XML;business process execution language;Web
	services;XML;algebra;business data processing;},
  owner = {Steffen},
  review = {+ relations between WSDL sercive descriptions and BPEL processes are
	considered for change propogation
	
	 +WSDL and BPEL descriptions are mapped to algenric expressions Kleen
	Algebra with Tests(KAT)
	
	 +Direct, Indirect, Secondary and Cautionary impacts between the processes
	and wsdl
	
	 +as a result of external service or process element change
	
	 + the architecture of the tool is discussed (plugin centric to embedd
	in eclipse), however the implementation is not done yet.
	
	
	
	Analysis
	
	
	* it can be complex for large processes, however for identitifying
	the semantic differences, it might be more suseful.},
  timestamp = {2012.03.01}
}

@TECHREPORT{Ginsberg1995,
  author = {Ginsberg, M.P. and Quinn, L.H.},
  title = {Process Tailoring and the the Software Capability Maturity Model
	(CMU/SEI-94-TR-024)},
  institution = {SEI},
  year = {1995},
  file = {Ginsberg1995.pdf:literature/Ginsberg1995.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.24}
}

@BOOK{Glaser2009,
  title = {Experteninterviews und qualitative Inhaltsanalyse},
  publisher = {VS Verlag f{\"u}r Sozialwissenschaften},
  year = {2009},
  author = {Gl{\"a}ser, J. and Laudel, G.},
  volume = {2},
  owner = {patrickr},
  timestamp = {2012.09.03}
}

@BOOK{Glaser1967,
  title = {The discovery of grounded theory: Strategies for qualitative research},
  publisher = {Aldine de Gruyter},
  year = {1967},
  author = {Glaser, B.G. and Strauss, A.L.},
  owner = {patrickr},
  timestamp = {2012.09.03}
}

@ARTICLE{Glass2002,
  author = {Glass, R. L. and Vessey, I. and Ramesh, V.},
  title = {Research in Software Engineering: an Analysis of the Literature},
  journal = {Information and Software Technology},
  year = {2002},
  volume = {44},
  pages = {491-506},
  file = {:./literature/Paper_263.pdf:PDF},
  owner = {Steffen},
  timestamp = {2013.05.01}
}

@INPROCEEDINGS{Goguen1982,
  author = {J.A. Goguen and J. Meseguer},
  title = {Security Policies and Security Models},
  booktitle = {Proceedings IEEE Symposium on Security and Privacy},
  year = {1982},
  pages = {11-20},
  month = {Apr.},
  file = {:./literature/noninter.pdf:PDF},
  keywords = {security policies, security models},
  owner = {Stephan},
  timestamp = {2008.10.13},
  url = {http://www.cs.ucsb.edu/~kemm/courses/cs177/noninter.pdf}
}

@INPROCEEDINGS{Goknil2008,
  author = {Goknil, Arda and Kurtev, Ivan and van den Berg, Klaas},
  title = {Change Impact Analysis based on Formalization of Trace Relations
	for Requirements},
  booktitle = {Proceedings of the EC-MDA Traceability Workshop (ECMDA-TW)},
  year = {2008},
  pages = {59-75},
  __markedentry = {[Steffen:]},
  file = {:./literature/Paper_13.PDF:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- changes in requiremements may effect other requirements
	
	
	Research Questions:
	
	- achieve IA on requirements through traceability among requirements
	
	
	Contribution:
	
	- requirements metamodel with well defined requirements relations
	
	- enable tracing of changes with that metamodell
	
	- provide change impact rules for requirements changes
	
	
	Solution:
	
	- requirements metamodel composed of several requirements concept
	(including GRL and SysML), metamodel build as OWL ontology
	
	- 4 types of requirements relations: refines, requires, conflicts
	and contains
	
	- relations can be refined and specialized
	
	- relations can be constrained through OCL expressions
	
	- similar classification of changes (add/remove requirement, add/remove
	relation, requirement/relation modified)
	
	-> granularity of entities: fine-grained metamodel, composed of GRL
	and SysML
	
	-> granularity of changes: atomic change operations
	
	-> granularity of results: all elements of previously defined metamodel
	
	
	Open Issues:
	
	- impact rules do not consider indirect relationships (only direct)},
  timestamp = {2011.01.05}
}

@ARTICLE{Goknil2011,
  author = {Goknil, Arda and Kurtev, Ivan and van den Berg, Klaas and Veldhuis,
	Jan-Willem},
  title = {Semantics of trace relations in requirements models for consistency
	checking and inferencing},
  journal = {Software and Systems Modeling},
  year = {2011},
  volume = {10},
  pages = {31-54},
  number = {1},
  file = {:./literature/Paper_223.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.30}
}

@ARTICLE{Gold2005,
  author = {N. E. Gold and M. Harman and D. Binkley and R. M. Hierons},
  title = {Unifying program slicing and concept assignment for higher-level
	executable source code extraction},
  journal = {Software: Practice and Experience},
  year = {2005},
  volume = {35},
  pages = {977-1006},
  number = {10},
  month = {April},
  abstract = {Program slicing and concept assignment have both been proposed as
	source code extraction techniques. Unfortunately, each has a weakness
	that prevents wider application. For slicing, the extraction criterion
	is expressed at a very low level; constructing a slicing criterion
	requires detailed code knowledge which is often unavailable. The
	concept assignment extraction criterion is expressed at the domain
	level. However, unlike a slice, the extracted code is not executable
	as a separate subprogram in its own right. This paper introduces
	a unification of slicing and concept assignment which exploits their
	combined advantages, while overcoming these two individual weaknesses.
	Our concept slices are executable programs extracted using high-level
	criteria. The paper introduces four techniques that combine slicing
	and concept assignment and algorithms for each. These algorithms
	were implemented in two separate tools used to illustrate the application
	of the concept slicing algorithms in two very different case studies.
	The first is a commercially-written COBOL module from a large financial
	organization, the second is an open source utility program written
	in C.},
  doi = {10.1002/spe.v35:10},
  file = {:./literature/spe05.pdf:PDF},
  keywords = {program slicing, concept assignment, reverse engineering},
  owner = {Robert},
  timestamp = {2007.03.04},
  url = {http://people.brunel.ac.uk/~csstrmh/papers/spe05.pdf}
}

@MISC{Gomaa2005,
  author = {Hassan Gomaa},
  title = {Architecture-Centric Evolution in Software Product Lines},
  howpublished = {Workshop on Architecture-Centric Evolution},
  month = {July},
  year = {2005},
  note = {Position Paper},
  abstract = {This paper describes how an architecture-centric evolution approach
	can be used to develop and evolve software product line architectures.
	The architecturecentric evolution approach described in this paper
	uses a model driven architecture concept in which UML models of the
	software architecture are developed prior to implementation and later
	evolved after original deployment.},
  file = {:./literature/gomaa2005.pdf:PDF},
  keywords = {evolution, software product line},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://wi.wu-wien.ac.at/home/uzdun/ACE2005/01-gomaa.pdf}
}

@BOOK{Gorden1980,
  title = {Interviewing: Strategy, techniques, and tactics},
  publisher = {Dorsey Press Homewood, IL},
  year = {1980},
  author = {Gorden, R.L.},
  owner = {patrickr},
  timestamp = {2012.09.04}
}

@ARTICLE{Gorschek2004,
  author = {Gorschek, T. and Wohlin, C.},
  title = {Packaging software process improvement issues: a method and a case
	study},
  journal = {Software: Practice and Experience},
  year = {2004},
  volume = {34},
  pages = {1311--1344},
  number = {14},
  file = {Gorschek2004.pdf:literature/Gorschek2004.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.26}
}

@INPROCEEDINGS{Gorthi2008,
  author = {Ravi Prakash Gorthi and Anjaneyulu Pasala and Kailash KP Chanduka
	and Benny Leong},
  title = {Specification-Based Approach to Select Regression Test Suite to Validate
	Changed Software},
  booktitle = {Asia-Pacific Software Engineering Conference},
  year = {2008},
  volume = {0},
  pages = {153--160},
  address = {Los Alamitos, {CA,} {USA}},
  publisher = {{IEEE} Computer Society},
  abstract = {Regression testing is used to achieve adequate confidence in changed
	software. To achieve confidence, currently organizations re-execute
	the entire system test suite on the entire software. Re-executing
	entire system test suite is an expensive and time consuming activity.
	To reduce such costs, execution of smaller regression test suite
	to validate the changed software is suggested. Several techniques,
	both code-based and model-based that recommend smaller regression
	test suites have been proposed in the literature. Largely the model-based
	regression test selection techniques are based on design models.
	In this paper, we propose a regression test suite selection approach
	based on commonly used requirement analysis model - {UML} use case
	activity diagram. As a part of the approach we also propose a concept
	called behavioral slicing to structure activity diagrams. Based on
	the proposed approach, a prototype tool has been designed and developed.
	Using the prototype, we have conducted real-world case studies and
	observed impressive productivity and quality gains.},
  annote = {Complete {PDF} document was either not available or accessible. Please
	make sure you're logged in to the digital library to retrieve the
	complete {PDF} document.},
  doi = {http://doi.ieeecomputersociety.org/10.1109/APSEC.2008.56},
  file = {:/literature/RegressionTesting/Specification based Appraoch to Select Regression Test Suite to Validate Changed Software.pdf:PDF},
  keywords = {model based testing, regression ests generation, regression tests
	selection, software maintenance, software testing, MBRT},
  owner = {Annie},
  review = {Artifacts: Structured Activity Diagram
	
	
	Risk based: Node are marked using priorities
	
	
	Change Types: addition, deletion, move and change
	
	
	Test Suite Classification: Added and affected test cases
	
	
	Scope: System level testing
	
	
	Tool Support: No
	
	Case study: yes (retail system case study, 342 Test cases)},
  timestamp = {2011.01.04}
}

@PHDTHESIS{Gotel1995,
  author = {O.C.Z. Gotel},
  title = {Contribution Structures for Requirements Traceability},
  school = {Imperial Collage of Science, Technology and Medicine, University
	of London},
  year = {1995},
  citeseerurl = {http://citeseer.ist.psu.edu/43020.html},
  file = {:./literature/gotel1995.pdf:PDF},
  keywords = {requirements traceability},
  language = {english},
  owner = {patrickr},
  timestamp = {2012.12.03},
  url = {http://csis.pace.edu/~ogotel/research/GOTEL95%20Contribution%20Structures%20for%20Requirements%20Traceability%20(IFIP).pdf}
}

@CONFERENCE{Gotel1997,
  author = {Gotel, O. and Finkelstein, A.},
  title = {Extended requirements traceability: results of an industrial case
	study},
  booktitle = {Requirements Engineering, Proceedings of the Third IEEE International
	Symposium on},
  year = {1997},
  abstract = {Contribution structures offer a way to model the network of people
	who have participated in the requirements engineering process. They
	further provide the opportunity to extend conventional forms of artifact-based
	requirements traceability with the traceability of contributing personnel.
	We describe a case study that investigated the modelling and use
	of contribution structures in an industrial project. In particular,
	we demonstrate how they made it possible to answer previously unanswerable
	questions about the human source(s) of requirements. In so doing,
	we argue that this information addresses problems currently attributed
	to inadequate requirements traceability},
  file = {:./literature/00566866.pdf:PDF},
  owner = {Elke},
  timestamp = {2011.05.30}
}

@INPROCEEDINGS{Gotel1995a,
  author = {Gotel, O. and Finkelstein, A.},
  title = {Contribution structures [Requirements artifacts]},
  booktitle = {Requirements Engineering, 1995., Proceedings of the Second IEEE International
	Symposium on},
  year = {1995},
  pages = {100--107},
  organization = {IEEE},
  file = {Gotel1995a.pdf:literature/Gotel1995a.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.10.23}
}

@ARTICLE{Gotel2012,
  author = {Gotel, O. and M{\"a}der, P.},
  title = {Acquiring Tool Support for Traceability},
  journal = {Software and Systems Traceability},
  year = {2012},
  pages = {43--68},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.08.09}
}

@INPROCEEDINGS{Gotel1994,
  author = {O. C. Z. Gotel and A. C. W. Finkelstein},
  title = {An Analysis of the Requirements Traceability Problem},
  booktitle = {Proceedings of the First International Conference on Requirements
	Engineering, Colorado Springs, CO, USA},
  year = {1994},
  pages = {94-101},
  month = {Apr},
  publisher = {IEEE Computer Society Press},
  abstract = {Investigates and discusses the underlying nature of the requirements
	traceability problem. Our work is based on empirical studies, involving
	over 100 practitioners, and an evaluation of current support. We
	introduce the distinction between pre-requirements specification
	(pre-RS) traceability and post-requirements specification (post-RS)
	traceability to demonstrate why an all-encompassing solution to the
	problem is unlikely, and to provide a framework through which to
	understand its multifaceted nature. We report how the majority of
	the problems attributed to poor requirements traceability are due
	to inadequate pre-RS traceability and show the fundamental need for
	improvements. We present an analysis of the main barriers confronting
	such improvements in practice, identify relevant areas in which advances
	have been (or can be) made, and make recommendations for research.},
  doi = {10.1109/ICRE.1994.292398},
  file = {:./literature/rtprob.pdf:PDF},
  keywords = {systems analysispost-requirements specification traceability, pre-requirements
	specification traceability, requirements engineering practice, requirements
	traceability problem analysis, requirements traceability tools},
  owner = {Matthias},
  review = {Elke},
  timestamp = {2008.07.15},
  url = {http://www.cs.ucl.ac.uk/staff/A.Finkelstein/papers/rtprob.pdf}
}

@INPROCEEDINGS{Gruninger1995,
  author = {Gr\"{u}ninger, M. and Fox, M.S.},
  title = {Methodology for the design and evaluation of ontologies},
  booktitle = {Proceedings Workshop on Basic Ontological Issues in Knowledge Sharing},
  year = {1995},
  address = {Montreal},
  file = {:./literature/Grueninger1995.pdf:PDF},
  keywords = {Ontology Engineering},
  owner = {Stephan},
  timestamp = {2011.03.15}
}

@ARTICLE{Grabher2004,
  author = {Grabher, G.},
  title = {Temporary architectures of learning: knowledge governance in project
	ecologies},
  journal = {Organization studies},
  year = {2004},
  volume = {25},
  pages = {1491--1514},
  number = {9},
  file = {Grabher2004.pdf:literature/Grabher2004.pdf:PDF},
  owner = {patrickr},
  publisher = {Sage Publications},
  timestamp = {2012.10.22}
}

@ARTICLE{Grabher2006,
  author = {Grabher, G. and Ibert, O.},
  title = {Bad company? The ambiguity of personal knowledge networks},
  journal = {Journal of Economic Geography},
  year = {2006},
  volume = {6},
  pages = {251--271},
  number = {3},
  file = {Grabher2006.pdf:literature/Grabher2006.pdf:PDF},
  owner = {patrickr},
  publisher = {Oxford Univ Press},
  timestamp = {2012.10.22}
}

@INPROCEEDINGS{Graham2007,
  author = {Graham, T.C.N. and Kazman, R. and Walmsley, C.},
  title = {Agility and Experimentation: Practical Techniques for Resolving Architectural
	Tradeoffs},
  booktitle = {29th International Conference on Software Engineering (ICSE 2007)},
  year = {2007},
  pages = {519-528},
  month = {May},
  publisher = {IEEE},
  abstract = {This paper outlines our experiences with making architectural tradeoffs
	between performance, availability, security, and usability, in light
	of stringent cost and time-to-market constraints, in an industrial
	web-conferencing system. We highlight the difficulties in anticipating
	future architectural requirements and tradeoffs and the value of
	using agility and experiments as a tool for mitigating architectural
	risks in situations when up front pen- and-paper analysis is simply
	impossible.},
  doi = {10.1109/ICSE.2007.13},
  file = {:./literature/GrahamTCN-AgilityExperimentation.pdf:PDF},
  issn = {0270-5257},
  keywords = {groupware, software architecture, time to marketWeb-conferencing system,
	architectural requirements, architectural risks, architectural tradeoffs,
	time-to-market constraints},
  owner = {Stephan},
  review = {experience report
	
	
	pure top-down design not possible due to too many considerations
	
	-> concurrently work top-down (designing architectural structures
	that meet quality goals) and bottom-up (determining a host of implementation
	specific and environment-specific settings and constraints)
	
	- top-down: requirements and design
	
	- bottom-up: experimentation and refactoring
	
	
	technological and environmental constraints can outweigh design principles
	
	
	to resolve trade-offs: agile approach used in combination with experiments
	(which were invaluable)
	
	
	3 practical strategies for managing change in designing an architecture
	
	- plan to build one to throw away -> not possible (to costly and time
	consuming)
	
	- focus on responding to change rather than extensive up-front planning
	-> agile concepts
	
	- anticipate decisions likely to be changed -> modularization to reduce
	change impact (not possible in example)
	
	
	incremental development, refactoring, continuous empirical evaluation
	
	
	experimentation
	
	- used for questions difficult to answer analytically - mainly technical
	aspects
	
	- top-down architectural deisgn not always possible
	
	- not all changes in the future can be anticipated -> agility is needed},
  timestamp = {2009.12.18},
  url = {http://equis.cs.queensu.ca/~graham/stl/pubs/GrahamTCN-AgilityExperimentation.pdf}
}

@INPROCEEDINGS{Grau2007,
  author = {Gemma Grau and Xavier Franch},
  title = {A Goal-Oriented Approach for the Generation and Evaluation of Alternative
	Architectures},
  booktitle = {Proceedings of the First European Conference on Software Architecture
	(ECSA'07)},
  year = {2007},
  volume = {4758},
  series = {LNCS},
  pages = {139-155},
  publisher = {Springer},
  abstract = {There is a recognized gap between requirements and architectures.
	There is also evidence that architecture evaluation, when done at
	the early phases of the development lifecycle, is an effective way
	to ensure the quality attributes of the final system. As quality
	attributes may be satisfied at a different extent by different alternative
	architectural solutions, an exploration and evaluation of alternatives
	is often needed. In order to address this issue at the requirements
	level, we propose to model architectures using the i* framework,
	a goal-oriented modelling language that allows to represent the functional
	and non-functional requirements of an architecture using actors and
	dependencies instead of components and connectors. Once the architectures
	are modelled, we propose guidelines for the generation of alternative
	architectures based upon existing architectural patterns, and for
	the definition of structural metrics for the evaluation of the resulting
	alternative models. The applicability of the approach is shown with
	the Home Service Robot case study.},
  doi = {10.1007/978-3-540-75132-8_12},
  file = {:./literature/grau_franch_ECSA_2007.pdf:PDF},
  keywords = {goal model, i*, architectural design, non-functional requirements},
  owner = {Stephan},
  timestamp = {2009.01.26},
  url = {http://www.ideaciona.com/PhD/publications/grau_franch_ECSA_2007.pdf}
}

@ARTICLE{Graves2001,
  author = {Graves, Todd L. and Harrold, Mary Jean and Kim, Jung-Min and Porter,
	Adam and Rothermel, Gregg},
  title = {An empirical study of regression test selection techniques},
  journal = {ACM Trans. Softw. Eng. Methodol.},
  year = {2001},
  volume = {10},
  pages = {184--208},
  month = {April},
  __markedentry = {[qurat:]},
  acmid = {367020},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/367008.367020},
  file = {:./literature/RegressionTesting/AnEmpiricalStudyOfRegressionTestSelectionTechniques.pdf:PDF},
  issn = {1049-331X},
  issue = {2},
  keywords = {empirical study, regression testing, selective retest, COMPARITIVE},
  numpages = {25},
  owner = {Annie},
  publisher = {ACM},
  timestamp = {2011.10.20},
  url = {http://doi.acm.org/10.1145/367008.367020}
}

@ARTICLE{Grefen2000,
  author = {Grefen, P. and Aberer, K. and Hoffner, Y. and Ludwig, H.},
  title = {CrossFlow: Cross-organizational workflow management in dynamic virtual
	enterprises},
  year = {2000},
  file = {Grefen2000.pdf:literature/Grefen2000.pdf:PDF},
  owner = {patrickr},
  publisher = {University of Twente, Centre for Telematics and Information Technology},
  timestamp = {2012.10.10}
}

@INPROCEEDINGS{Groher2010,
  author = {Groher, Iris and Egyed, Alexander},
  title = {Selective and consistent undoing of model changes},
  booktitle = {Proceedings of the 13th international conference on Model driven
	engineering languages and systems: Part II},
  year = {2010},
  series = {MODELS'10},
  pages = {123--137},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  acmid = {1929115},
  file = {:/literature/changeIdentification/3.pdf:PDF},
  isbn = {3-642-16128-6, 978-3-642-16128-5},
  keywords = {Rea},
  location = {Oslo, Norway},
  numpages = {15},
  owner = {Steffen},
  timestamp = {2012.03.01},
  url = {http://dl.acm.org/citation.cfm?id=1929101.1929115}
}

@INPROCEEDINGS{Groher2009,
  author = {Groher, I. and Egyed, A.},
  title = {Selective backtracking of model changes},
  booktitle = {Software Engineering - Companion Volume, 2009. ICSE-Companion 2009.
	31st International Conference on},
  year = {2009},
  pages = {231 -234},
  month = {may},
  doi = {10.1109/ICSE-COMPANION.2009.5070989},
  file = {:/literature/changeIdentification/Selective_Backtracking_of_Model_Changes.pdf:PDF},
  keywords = {Read ,chronological backtracking;multiview modeling;selective backtracking;software
	modeling;backtracking;software engineering;},
  owner = {Steffen},
  timestamp = {2012.03.01}
}

@ARTICLE{Gross2001,
  author = {Daniel Gross and Eric S. K. Yu},
  title = {From Non-Functional Requirements to Design through Patterns},
  journal = {Requirements Engineering},
  year = {2001},
  volume = {6},
  pages = {18-36},
  number = {1},
  month = {Feb},
  abstract = {Design patterns aid in documenting and communicating proven design
	solutions to recurring problems. They describe not only how to solve
	design problems, but also why a solution is chosen over others and
	what trade-offs are made. Non-functional requirements (NFRs) are
	pervasive in descriptions of design patterns. They play a crucial
	role in understanding the problem being addressed, the trade-offs
	discussed, and the design solution proposed. However, since design
	patterns are mostly expressed as informal text, the structure of
	the design reasoning is not systematically organised. This paper
	proposes a systematic treatment of NFRs in descriptions of patterns
	and when applying patterns during design. The approach organises,
	analyses and refines non-functional requirements, and provides guidance
	and reasoning support when applying patterns during the design of
	a software system. Three design patterns taken from the literature
	are used to illustrate this approach.},
  citeseerurl = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.23.4115},
  doi = {10.1007/s007660170013},
  file = {:./literature/FromNFRtoDesignthroughPatterns.pdf:PDF},
  keywords = {Architectural properties; Design patterns; Non-functional requirements;
	Process-oriented; Quality attributes; Quality requirements; Rationale;
	Requirements; Satisfying; Softgoal},
  owner = {Stephan},
  timestamp = {2008.05.27},
  url = {http://www.springerlink.com/content/luclrv4jlc5wye4p/}
}

@TECHREPORT{Gruber1993,
  author = {T. Gruber},
  title = {A translation approach to portable ontologies},
  institution = {Computer Science Department, Stanford University, Knowledge Acquisition
	5(2), pp. 199-220},
  year = {1993},
  number = {KSL 92-71},
  address = {Stanford, California 94305},
  month = {April},
  abstract = {To support the sharing and reuse of formally represented knowledge
	among AI systems, it is useful to define the common vocabulary in
	which shared knowledge is represented. A specification of a representational
	vocabulary for a shared domain of discourse - definitions of classes,
	relations, functions, and other objects - is called an ontology.
	This paper describes a mechanism for defining ontologies that are
	portable over representation systems. Definitions written in a standard
	format for predicate calculus are translated by a system called Ontolingua
	into specialized representations, including frame-based systems as
	well as relational languages. This allows researchers to share and
	reuse ontologies, while retaining the computational benefits of specialized
	implementations. 
	
	 We discuss how the translation approach to portability addresses
	several technical problems. One problem is how to accommodate the
	stylistic and organizational differences among representations while
	preserving declarative content. Another is how to translate from
	a very expressive language into restricted languages, remaining system-independent
	while preserving the computational efficiency of implemented systems.
	We describe how these problems are addressed by basing Ontolingua
	itself on an ontology of domain-independent, representational idioms.},
  file = {:./literature/ontolingua-kaj-1993.pdf:PDF},
  keywords = {ontology specification},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.15},
  url = {http://tomgruber.org/writing/ontolingua-kaj-1993.pdf}
}

@INPROCEEDINGS{Grunbacher1997,
  author = {Grunbacher, P.},
  title = {A software assessment process for small software enterprises},
  booktitle = {EUROMICRO 97.'New Frontiers of Information Technology'., Proceedings
	of the 23rd EUROMICRO Conference},
  year = {1997},
  pages = {123--128},
  file = {Grunbacher1997.pdf:literature/Grunbacher1997.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.26}
}

@MASTERSTHESIS{Grunert2011,
  author = {Matthias Grunert},
  title = {Anforderungsstrukturierung für betriebliche Informationssysteme},
  school = {TU Ilmenau},
  year = {2011},
  file = {:./literature/Grunert_ABIS_Entwurf 111125.pdf:PDF},
  owner = {elkeb},
  timestamp = {2012.01.30}
}

@ARTICLE{Guerrero2004,
  author = {Guerrero, F. and Eterovic, Y.},
  title = {Adopting the SW-CMM in a Small IT Organization},
  journal = {Software, IEEE},
  year = {2004},
  volume = {21},
  pages = {29--35},
  number = {4},
  file = {Guerrero2004.pdf:literature/Guerrero2004.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.26}
}

@INPROCEEDINGS{Guo1999,
  author = {G. Guo and J. Atlee and R. Kazman},
  title = {A Software Architecture Reconstruction Method},
  booktitle = {TC2 First Working IFIP Conference on Software Architecture (WICSA1)},
  year = {1999},
  editor = {Patrick Donohoe},
  volume = {140},
  series = {IFIP Conference Proceedings},
  pages = {15-33},
  month = {Feb},
  publisher = {Kluwer},
  abstract = {Changes to a software system during implementation and maintenance
	can cause the architecture of a system to deviate from its documented
	architecture. If design documents are to be useful, maintenance programmers
	must be able to easily evaluate how closely the documents conform
	to the code they are meant to describe. Software architecture recovery,
	which deals with the extraction and analysis of a system’s architecture,
	has gained more tool support in the past few years. However, there
	is little research on developing effective and efficient architectural
	conformance methods. In particular, given the increasing emphasis
	on patterns and styles in the software engineering community, a method
	needs to explicitly aid a user in identifying architectural patterns.
	This paper presents a semi-automatic method, called ARM (Architecture
	Reconstruction Method), that guides a user in the reconstruction
	of software architectures based on the recognition of patterns. Once
	the system’s actual architecture has been reconstructed, we can analyze
	conformance of the software to the documented design patterns.},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  citeseerurl = {http://citeseer.ist.psu.edu/guo99software.html},
  file = {:./literature/goa.pdf:PDF},
  isbn = {0-7923-8453-9},
  keywords = {Design recovery, Reverse engineering, Software Architecture Analysis,
	Design Patterns, Pattern Recognition},
  location = {San Antonio, Texas, USA},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://users.ece.utexas.edu/~perry/prof/wicsa1/final/goa.pdf}
}

@ARTICLE{Gupta2010,
  author = {Gupta, Chetna and Singh, Yogesh and Chauhan, Durg Singh},
  title = {A Dynamic Approach to Estimate Change Impact using Type of Change
	Propagation},
  journal = {Journal of Information Processing Systems},
  year = {2010},
  volume = {6},
  pages = {597-608},
  number = {4},
  month = {December},
  file = {:./literature/Paper_128.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- evolution is ongoing process with frequent changes
	
	- one has to estimate impact of changes when modifying a system
	
	
	Research Questions:
	
	- how can type of change be used to judge effect of change
	
	- how can type of change be used to propagate change
	
	
	Contribution:
	
	- new IA approach by classifying changes based on change-type and
	extent of change-type for source code
	
	- algorithm to classify type of change
	
	
	Solution:
	
	- use 4 categories for classifying changes:
	
	* functional change: add/remove/modify statements which affect functions
	
	* logical change: changes to control-flow
	
	* structural change: add/remove of code in program
	
	* behavioral change: changes to the execution order, entry and exit
	criteria of program
	
	- algorithm for classifying comparison information works as follows:
	
	* calc. functional impacts:
	
	 - create flow graph of program
	
	 - analyze connectivity of changed statements
	
	 - add all changed statements and their direct impacts to other parts
	
	* calc. logic impacts:
	
	 - create control flow graph of program
	
	 - analyse all with change in logic/control flow statements (if, while
	etc.)
	
	 - add all changed statements and all which depend on them (per definition
	or usage)
	
	- source code and modified version are uploaded to user interface
	where "diff" is performed
	
	- results of "diff" and CFG of both versions are stored in database
	
	- then run the classifying algorithm (see above) on data from database
	
	-> granularity of entities: statements, methods
	
	-> granularity of changes:
	
	-> granularity of results: methods
	
	
	Open Issues:
	
	- category "structural change" is senseless, as everything would be
	a structural change as well
	
	- computation of structural change and behavioral change seems not
	to be done in reality},
  timestamp = {2011.04.01}
}

@ARTICLE{Gupta2009,
  author = {Gupta, Chetna and Singh, Yogesh and Chauhan, Durg Singh},
  title = {An Efficient Dynamic Impact Analysis using Definition and Usage Information},
  journal = {International Journal of Digital Content Technology and its Applications},
  year = {2009},
  volume = {3},
  pages = {112-115},
  number = {4},
  file = {:./literature/Paper_143.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- software changes often to add features or fix problems
	
	- recent investigation of dynamic IA techniques
	
	
	Research Questions:
	
	
	Contribution:
	
	- new dynamic IA technique for code which collects only required information
	during regression testing
	
	
	Solution:
	
	- CallImpact algorithm is proposed
	
	- distinguish between direct and indirect impact:
	
	* direct: collect usage traces of execution of changed node
	
	* indirect: analyze previous collected direct sets and further trace
	them
	
	-> granularity of entities: variables
	
	-> granularity of changes: changes to variables
	
	-> granularity of results: variables
	
	
	Open Issues:},
  timestamp = {2011.04.04}
}

@MASTERSTHESIS{Gupta2013,
  author = {Gupta, Nikhilumar},
  title = {Rule-based Dependency Detection Between Source Code and UML Models},
  school = {Ilmenau University of Technology},
  year = {2013},
  month = {February},
  file = {:./literature/Master_9.pdf:PDF},
  owner = {Steffen},
  timestamp = {2013.02.18}
}

@INPROCEEDINGS{Gupta1992,
  author = {Gupta, R. and Harrold, M.J. and Soffa, M.L.},
  title = {An approach to regression testing using slicing},
  booktitle = {Software Maintenance, 1992. Proceerdings., Conference on},
  year = {1992},
  pages = {299 -308},
  month = {nov},
  __markedentry = {[qurat:]},
  doi = {10.1109/ICSM.1992.242531},
  file = {:/literature/RegressionTesting/An Approach to Regression Testing using Slicing.pdf:PDF},
  keywords = {code based, definition-use pairs; partial data flow; recomputation;
	regression testing; slicing; program testing; software maintenance;},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@INPROCEEDINGS{Gwizdala2003,
  author = {Gwizdala, Steve and Jiang, Yong and Rajlich, V\'{a}clav},
  title = {JTracker - A Tool for Change Propagation in Java},
  booktitle = {Proceedings of the Seventh European Conference on Software Maintenance
	and Reengineering},
  year = {2003},
  pages = {223-229},
  month = {March},
  file = {:./literature/Paper_180.PDF:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- programmers add new functions and perform other changes
	
	- this is a complex task in large systems
	
	
	Research Questions:
	
	- how can programmer be guided during changing sofware by tool support
	
	
	Contribution:
	
	- new tool JTracker which assists programmers when changing Java software
	
	- case study to demonstrate tool in practice
	
	
	Solution:
	
	- build a dependency database of the program which is updated after
	each operation
	
	- rest of paper is case study
	
	-> granularity of entities: variable, method, class
	
	-> granularity of changes: 
	
	-> granularity of results: class
	
	
	Open Issues:},
  timestamp = {2011.08.12}
}

@INPROCEEDINGS{Haase1998,
  author = {Haase, V.H.},
  title = {Software process improvement planning with neural networks},
  booktitle = {Euromicro Conference, 1998. Proceedings. 24th},
  year = {1998},
  volume = {2},
  pages = {808--815},
  file = {Haase1998.pdf:literature/Haase1998.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.26}
}

@INPROCEEDINGS{haber2013,
  author = {Haber, Arne and Kolassa, Carsten and Manhart, Peter and Nazari, Pedram
	Mir Seyed and Rumpe, Bernhard and Schaefer, Ina},
  title = {First-class variability modeling in Matlab/Simulink},
  booktitle = {Proceedings of the Seventh International Workshop on Variability
	Modelling of Software-intensive Systems},
  year = {2013},
  series = {VaMoS '13},
  pages = {4:1--4:8},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Modern cars exist in an vast number of variants. Thus, variability
	has to be dealt with in all phases of the development process, in
	particular during model-based development of software-intensive functionality
	using Matlab/Simulink. Currently, variability is often encoded within
	a functional model leading to so called 150%-models which easily
	become very complex and do not scale for larger product lines. To
	counter these problems, we propose a modular variability modeling
	approach for Matlab/Simulink based on the concept of delta modeling
	[8, 9, 24]. A functional variant is described by a delta encapsulating
	a set of modifications. A sequence of deltas can be applied to a
	core product to derive the desired variant. We present a prototypical
	implementation, which is integrated into Matlab/Simulink and offers
	graphical editing of delta models.},
  articleno = {4},
  doi = {10.1145/2430502.2430508},
  file = {:./literature/VariabilitySimulink-haber2013.pdf:PDF},
  isbn = {978-1-4503-1541-8},
  keywords = {Matlab/Simulink, delta modeling, variability},
  location = {Pisa, Italy},
  numpages = {8},
  owner = {matthias},
  timestamp = {2013.03.08},
  url = {http://doi.acm.org/10.1145/2430502.2430508}
}

@INPROCEEDINGS{Haft2005,
  author = {Martin Haft and Bernhard Humm and Johannes Siedersleben},
  title = {{The Architect's Dilemma -- Will Reference Architectures Help?}},
  booktitle = {Proceedings Quality of Software Architectures and Software Quality,
	QoSA-SOQUA},
  year = {2005},
  series = {LNCS},
  pages = {106-122},
  publisher = {Springer},
  abstract = {Effective standard architectures promise to improve the efficiency
	of software projects and the quality of resulting systems. However,
	hardly any standard architecture has become established in practise
	to date. They are either too general or too specific to be effective
	– the architect’s dilemma. Reference architectures have a less binding
	character than standard architectures and still are of high value.
	This paper presents exemplary parts of the Quasar reference architecture
	for business information systems, the result of more than seven years
	of architectural research at sd&m.},
  doi = {10.1007/11558569},
  file = {:./literature/sdm_2005_Will_Reference_Architectures_help.pdf:PDF},
  keywords = {software architecture, reference architecture, standard architecture},
  owner = {Stephan},
  timestamp = {2008.08.01},
  url = {http://www.sdm.de/web4archiv/objects/download/fachartikel/1/sdm_pub_sieders.pdf}
}

@TECHREPORT{Haft2004,
  author = {Haft, Martin and Humm, Bernhard and Siedersleben, Johannes},
  title = {Quasar Reference Interfaces for Business Information Systems},
  institution = {sd\&m Research},
  year = {2004},
  file = {:./literature/QuasarInterfaces.pdf:PDF},
  keywords = {reference interfaces, software architecture},
  owner = {Stephan},
  timestamp = {2008.08.01}
}

@ARTICLE{Haft2007,
  author = {Haft, Martin and Olleck, Bernd},
  title = {Component-based client-architecture ({in German: Komponentenbasierte
	Client-Architektur})},
  journal = {Informatik-Spektrum},
  year = {2007},
  volume = {30},
  pages = {143-158},
  number = {3},
  abstract = {Die Komplexität von Clients wird meist unterschätzt. Ein Client besteht
	eben nicht nur aus ein paar Masken. Es steckt noch eine Menge Funktionalität
	unter der ,,Oberfläche“. Eine geeignete Strukturierung hilft die
	Komplexität beherrschbar zu machen.},
  doi = {10.1007/s00287-007-0153-9},
  file = {:./literature/sdm_pub_is07_3_haft.pdf:PDF},
  keywords = {component-based architecture, client architecture, user interface,
	dialog components},
  owner = {Stephan},
  timestamp = {2008.08.01}
}

@INCOLLECTION{Haitzer2013,
  author = {Haitzer, Thomas and Zdun, Uwe},
  title = {Controlled Experiment on the Supportive Effect of Architectural Component
	Diagrams for Design Understanding of Novice Architects},
  booktitle = {Software Architecture},
  publisher = {Springer Berlin Heidelberg},
  year = {2013},
  editor = {Drira, Khalil},
  volume = {7957},
  series = {Lecture Notes in Computer Science},
  pages = {54-71},
  doi = {10.1007/978-3-642-39031-9\_6},
  file = {:./literature/Haizer2013.pdf:PDF},
  isbn = {978-3-642-39030-2},
  keywords = {Software Architecture; Architectural Component Diagrams; Design and
	Architecture Understanding; Empirical Study; Controlled Experiment},
  owner = {Til},
  timestamp = {2014.03.14},
  url = {http://dx.doi.org/10.1007/978-3-642-39031-9_6}
}

@INPROCEEDINGS{Hall2005,
  author = {Hall, T. and Wernick, P.},
  title = {Program slicing metrics and evolvability: an initial study},
  booktitle = {IEEE International Workshop on Software Evolvability},
  year = {2005},
  pages = { 35-40},
  month = {Sept.},
  publisher = {IEEE Computer Society},
  abstract = {Previous research has identified a number of metrics derived from
	program slicing. In this paper we discuss how these metrics relate
	to the effort required to evolve an existing software-based system.
	Whilst our interest in this work stems from our development of simulation
	models of long-term software evolution processes, it will also be
	directly relevant to the managers of software evolution activities.},
  doi = {10.1109/IWSE.2005.11},
  file = {:./literature/01544760.pdf:PDF},
  keywords = {program slicing, software metrics, software prototyping program slicing,
	software evolution process, software metrics},
  owner = {Stephan},
  review = {no generally accepted measures for evolvability of systems
	
	
	2 dimensions evolvability:
	
	- change in size of system
	
	- change to structure and code of system
	
	
	introducing slice-based measures for evolvability
	
	- program slicing as technique for debugging programs
	
	-> different slicing-based metrics
	
	- examination and quantification of the internal linkage of a system
	
	
	- coverage
	
	- overlap
	
	- clustering
	
	- parallelism
	
	- tightness
	
	- maxCoverage
	
	- minCoverage
	
	
	concept of inertia proposese - as a means to characterise the maintainability
	of a system
	
	-> directly related to evolvability: high inertia -> less evolvability
	
	
	relation between metrics and inertia examined
	
	-> slice-based metrics should be helpful to measure evolvability
	
	
	- low coverage, means higher inertia -> less evolvabilty
	
	- high overlap, high inertia -> low evolvability
	
	- low clustering, higher inertia -> low evolvability
	
	- high parallelism, (possibliy) low inertia -> high evolvability
	
	- high tightness, (low inertia?) -> higher evolvability
	
	- high values for maxCoverage and minCoverage, high inertia -> low
	evolvability},
  timestamp = {2008.08.13}
}

@BOOK{Halvey2005,
  title = {Information technology outsourcing transactions: process, strategies,
	and contracts},
  publisher = {Wiley},
  year = {2005},
  author = {Halvey, J.K. and Melby, B.M.},
  owner = {patrickr},
  timestamp = {2012.10.30}
}

@INPROCEEDINGS{Hammad2009,
  author = {Hammad, Maen and Collard, Michael L. and Maletic, Jonathan I.},
  title = {Automatically Identifying Changes that Impact Code-to-Design Traceability},
  booktitle = {Proceedings of the IEEE 17th International Conference on Program
	Comprehension (ICPC '09)},
  year = {2009},
  pages = {20-29},
  address = {Vancouver, BC},
  month = {May},
  file = {:./literature/Paper_60.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- source code and architecure are not changed/modified together, they
	get out of sync
	
	- updating design documents is time & cost expensive (manpower)
	
	
	Research Questions:
	
	- does a code change impact design
	
	- how updating design documents with code changes
	
	- how updating old design documents to current code using change history
	
	
	Contribution:
	
	- approach that autom. determines if a code change affects the design
	
	- maintain code-to-desgin traceability
	
	
	Solution:
	
	- differentiate between code changes that affect design (add a method)
	and such that not effect design (loops, conditions)
	
	- ignore changes that do not affect design, achieved by applying tool
	"srcTracer":
	
	* transfer source into XML by using srcML
	
	* gather changes by applying srcDiff on the xml
	
	* use XPath queries to identify changes that do impact the design:
	
	 * added/removed classes
	
	 * added/removed methods
	
	 *added/removed relationships
	
	-> granularity of entities: C++ classes and methods
	
	-> granularity of changes: add/remove of class/method/relationship
	
	-> granularity of results: UML classes
	
	
	Open Issues:
	
	- only UML classes are involved in the update procedure, but no other
	models (e.g. components might also change)},
  timestamp = {2011.02.10}
}

@TECHREPORT{Han1996,
  author = {Han, Jun},
  title = {Supporting Impact Analysis and Change Propagation in Software Engineering
	Environments},
  institution = {Monash University, Peninsula School of Computing \& Information Technology},
  year = {1996},
  number = {96-09},
  address = {McMahons Road, Frankston, Victoria 3199, Australia},
  month = {October},
  file = {:./literature/Paper_4.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- IA is tradintially addressed in the field of maintenance
	
	- however IA also useful for forward development / actual development
	of software
	
	-> changes occur during initial development (i.e. bug-fixes, optimizations,
	new requirements etc.)
	
	- most IA approaches extract information from source code (e.g. dependencies)
	to measure impacts
	
	-> they miss a lot of information
	
	
	Research Questions:
	
	
	Contribution:
	
	- approach for IA / change propagation which can be used for forward
	and reengineering
	
	- integrate into software engineering environments to guide developer
	
	-> framework for software change management
	
	- use complete source code for analysis, not just extracted data
	
	
	Solution:
	
	- proposed approach has following characteristics:
	
	* original representation of software system is used for change support
	
	* use change patterns to increase flexibility of IA
	
	* assist automated implementation of change
	
	* IA and change prediction combine automated techniques with guided
	user intervention
	
	- augment kernel of software engineering environment (IDE) with change
	management features
	
	- use dependency graphs to determine EIS from SIS
	
	-> granularity of artifacts: level of statements up to level of modules
	
	-> granularity of changes: update, add, remove
	
	-> granularity of results: no details
	
	- use propagation rules + guided user work to actually implement changes
	
	
	Open Issues:},
  timestamp = {2011.01.01}
}

@BOOK{Hansen2001,
  title = {Wirtschaftsinformatik 1},
  publisher = {Lucius \& Lucius},
  year = {2001},
  author = {Hansen, H. R. and Neumann, G.},
  address = {Stuttgart},
  edition = {8},
  month = {October},
  keywords = {business informatics, information management},
  owner = {Robert},
  timestamp = {2008.07.15},
  url = {http://www.amazon.de/Wirtschaftsinformatik-1-Hans-Robert-Hansen/dp/3825226697}
}

@ARTICLE{Hanssen2005,
  author = {Hanssen, G. and Westerheim, H. and Bj{\o}rnson, F.},
  title = {Tailoring RUP to a defined project type: A case study},
  journal = {Product Focused Software Process Improvement},
  year = {2005},
  pages = {209--228},
  file = {Hanssen2005.pdf:literature/Hanssen2005.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.07.20}
}

@ARTICLE{Harjumaa2005,
  author = {Harjumaa, L.},
  title = {Improving the software inspection process with patterns},
  journal = {ACTA-UNIVERSITATIS OULUENSIS SERIES A SCIENTIAE RERUM NATURALIUM},
  year = {2005},
  volume = {447},
  file = {Harjumaa2005.pdf:literature/Harjumaa2005.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@PHDTHESIS{Harjumaa2005a,
  author = {Harjumaa, L},
  title = {Improving the software inspection process with patterns},
  school = {FIN-90014 University of Oulu, Finland},
  year = {2005},
  file = {Harjumaa2005a.pdf:literature/Harjumaa2005a.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@INPROCEEDINGS{Harrison2007a,
  author = {Harrison, N. and Avgeriou, P.},
  title = {Pattern-Driven Architectural Partitioning: Balancing Functional and
	Non-functional Requirements},
  booktitle = {Second International Conference on Digital Telecommunications, 2007
	(ICDT '07)},
  year = {2007},
  pages = {21-26},
  month = {July},
  publisher = {IEEE},
  abstract = {One of the vexing challenges of software architecture is the problem
	of satisfying the functional specifications of the system to be created
	while at the same time meeting its non-functional needs. In this
	work we focus on the early stages of the software architecture process,
	when initial high-level system partitioning is being performed. Specifically,
	we study the problem of system partitioning with respect to both
	functional requirements and quality attributes. Architecture patterns
	are particularly well-suited to simultaneously addressing functional
	requirements and quality attributes. They support architects in considering
	both, understanding the impact of decisions on other attributes,
	and making tradeoffs among them. Existing architectural design methods
	accommodate pattern use, but do not exploit it in detail. We propose
	a pattern-based approach that leverages the benefits of patterns,
	and fits well with existing methods.},
  doi = {10.1109/ICDT.2007.65},
  file = {:./literature/2007ICDTHarrison.pdf:PDF},
  keywords = {formal specification, software architecture, software qualityfunctional
	specification, pattern-based approach, pattern-driven architectural
	partitioning, software architecture, system partitioning problem},
  owner = {Stephan},
  review = {description of methodical steps how to partition the architecture
	considering functional and non-funtional requirements in balance
	using design patterns},
  timestamp = {2009.11.27}
}

@INPROCEEDINGS{Harrison2007,
  author = {Neil B. Harrison and Paris Avgeriou},
  title = {Leveraging Architecture Patterns to Satisfy Quality Attributes},
  booktitle = {Proceedings First European Conference on Software Architecture, ECSA
	2007},
  year = {2007},
  volume = {4758/2007},
  pages = {263-270},
  publisher = {Springer},
  abstract = {Architectural design has been characterized as making a series of
	decisions that have system-wide impact. These decisions have side
	effects which can have significant impact on the system. However,
	the impact may be first understood much later; when the system architecture
	is difficult to change. Architecture patterns can help architects
	understand the impact of the architectural decisions at the time
	these decisions are made, because patterns contain information about
	consequences and context of the pattern usage. However, this information
	has been of limited use because it is not presented consistently
	or systematically. We discuss the current limitations of patterns
	on evaluating their impact on quality attributes, and propose integrating
	the information of patterns’ impact on quality attributes in order
	to increase the usefulness of architecture patterns.},
  doi = {10.1007/978-3-540-75132-8_21},
  file = {:./literature/Harrison2007.pdf:PDF},
  keywords = {design patterns, quality attributes, architectural design},
  owner = {Stephan},
  review = {evaluation of patterns concerning impact on quality attributes},
  timestamp = {2009.11.27},
  url = {http://www.springerlink.com/content/d775223718v5u08g}
}

@ARTICLE{Harrold2001,
  author = {Harrold, M.J. and Rosenblum, D. and Rothermel, G. and Weyuker, E.},
  title = {Empirical studies of a prediction model for regression test selection},
  journal = {Software Engineering, IEEE Transactions on},
  year = {2001},
  volume = {27},
  pages = {248 -263},
  number = {3},
  month = {mar},
  __markedentry = {[qurat:]},
  doi = {10.1109/32.910860},
  file = {:/literature/RegressionTesting/Empirical studies of a Prediction Model for Regression Test Selection.pdf:PDF},
  issn = {0098-5589},
  keywords = {Comparative, Deja vu;KornShell;TestTube;coverage-based predictors;prediction
	model;regression test selection;regression testing;software maintenance;test
	suite;program testing;software maintenance;statistical analysis;},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@ARTICLE{Harrold1998,
  author = {Mary Jean Harrold},
  title = {Architecture-Based Regression Testing of Evolving Systems},
  journal = {PROCEEDINGS OF THE INTERNATIONAL WORKSHOP ON THE ROLE OF SOFTWARE
	ARCHITECTURE IN TESTING AND ANALYSIS (ROSATEA 1998},
  year = {1998},
  pages = {73---77},
  file = {:/literature/RegressionTesting/Architecture-Based Regression Testing of Evolving Systems.pdf:PDF},
  keywords = {potential research directions},
  owner = {Annie},
  timestamp = {2011.01.04},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.123.7470}
}

@ARTICLE{Harrold1993,
  author = {Harrold, M. Jean and Gupta, Rajiv and Soffa, Mary Lou},
  title = {A methodology for controlling the size of a test suite},
  journal = {ACM Trans. Softw. Eng. Methodol.},
  year = {1993},
  volume = {2},
  pages = {270--285},
  month = {July},
  __markedentry = {[qurat:]},
  acmid = {152391},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/152388.152391},
  file = {:/literature/RegressionTesting/A methodology for Controlling the Size of a Test Suite.pdf:PDF},
  issn = {1049-331X},
  issue = {3},
  keywords = {Read, Relevant, code based},
  numpages = {16},
  owner = {Annie},
  publisher = {ACM},
  timestamp = {2011.10.20},
  url = {http://doi.acm.org/10.1145/152388.152391}
}

@ARTICLE{Hart1968,
  author = {Hart, P. E. and Nilsson, N. J. and Raphael, B.},
  title = {A Formal Basis for the Heuristic Determination of Minimum Cost Paths},
  journal = {IEEE Transactions on Systems Science and Cybernetics},
  year = {1968},
  volume = {4},
  pages = {100-107},
  number = {2},
  keywords = {A*},
  owner = {Steffen},
  timestamp = {2012.07.19}
}

@INPROCEEDINGS{Hartmann1989,
  author = {Hartmann, J. and Robson, D.J.},
  title = {Revalidation during the software maintenance phase},
  booktitle = {Software Maintenance, 1989., Proceedings., Conference on},
  year = {1989},
  pages = {70 -80},
  month = {oct},
  __markedentry = {[qurat:]},
  doi = {10.1109/ICSM.1989.65195},
  file = {:/literature/RegressionTesting/revalidation during software maintinance phase.pdf:PDF},
  keywords = {Read, Relevant, code based, adverse side effects;computational resources;large-scale
	revalidation procedures;maintenance personnel;practical retesting
	tool;selective retesting strategies;software maintenance phase;user
	requirements;program verification;software engineering;},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@INPROCEEDINGS{Hartmann1988,
  author = {Hartmann, J. and Robson, D.J.},
  title = {Approaches to regression testing},
  booktitle = {Software Maintenance, 1988., Proceedings of the Conference on},
  year = {1988},
  pages = {368 -372},
  month = {oct},
  __markedentry = {[qurat:]},
  doi = {10.1109/ICSM.1988.10189},
  file = {:/literature/RegressionTesting/Approaches to Regression Testing.PDF:PDF},
  keywords = {comparative analysis, ;software maintenance;program testing;software
	engineering;software tools;},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@ARTICLE{Hartmann1990,
  author = {Hartmann, Jean and Robson, David J.},
  title = {Techniques for Selective Revalidation},
  journal = {IEEE Softw.},
  year = {1990},
  volume = {7},
  pages = {31--36},
  month = {January},
  acmid = {624905},
  address = {Los Alamitos, CA, USA},
  doi = {http://dx.doi.org/10.1109/52.43047},
  file = {:/literature/RegressionTesting/techniques for selective revalidation.pdf:PDF},
  issn = {0740-7459},
  issue = {1},
  keywords = {Read, CodeBased, Relevant},
  numpages = {6},
  owner = {Annie},
  publisher = {IEEE Computer Society Press},
  timestamp = {2011.10.20},
  url = {http://dx.doi.org/10.1109/52.43047}
}

@INPROCEEDINGS{Hassaine2011,
  author = {Hassaine, Salima and Boughanmi, Ferdaous and Gu\'{e}h\'{e}neuc, Yann-Ga\"{e}l
	and Hamel, Sylvie and Antoniol, Giuliano},
  title = {A Seismology-inspired Approach to Study Change Propagation},
  booktitle = {Proceedings of the 27th International Conference on Software Maintenance
	(ICSM 2011)},
  year = {2011},
  pages = {53-62},
  address = {Williamsburg, VI},
  month = {September},
  file = {:./literature/Paper_194.PDF:PDF},
  owner = {Steffen},
  timestamp = {2011.12.29}
}

@MISC{Hassan,
  author = {Ahmed E. Hassan and Richard C. Holt},
  title = {C-REX: An Evolutionary Code Extractor for C},
  __markedentry = {[qurat:]},
  file = {:/literature/RegressionTesting/c-rex-an-evolutionary code extractor for C.pdf:PDF},
  keywords = {change identification in program code},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@INPROCEEDINGS{Hassan2004,
  author = {Hassan, Ahmed E. and Holt, Richard C.},
  title = {Predicting Change Propagation in Software Systems},
  booktitle = {Proceedings of the 20th IEEE International Conference on Software
	Maintenance (ICSM 2004)},
  year = {2004},
  pages = {284-293},
  address = {Washington, DC, USA},
  month = {September},
  publisher = {IEEE Computer Society},
  file = {:./literature/Paper_36.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- changes occur to implement updates / fix bugs, related entities
	must be updated as well to ensure consistency
	
	
	Research Questions:
	
	- how do changes to an entity propagate to other entities (on the
	level of source code)
	
	
	Contribution:
	
	- several heuristics to predict change propagation on the level of
	source code
	
	- framework to measure performance of heuristics
	
	
	Solution:
	
	- use source code version systems to perform IA on historical information
	
	- transform change information (granularity: files) into more appropriate
	level: source code entities
	
	- several heuristics defined to capture impacts:
	
	* historical co-change records
	
	* code structure relations (i.e. Calls, Uses, Defines)
	
	* code layout (i.e. location of entities relative to classes and components)
	
	* developer data (entities changed frequently by same developer)
	
	* similar names
	
	- several pruning techniques used by heuristics:
	
	* most frequent (i.e. remove the least frequent ones)
	
	* recency technique (i.e. return those that where related in the past)
	
	* combination of "most frequent" and "recency technique" together
	with decay function or counter
	
	- classification of changes into two groups:
	
	* records containing added entities
	
	* records containing no added entities
	
	-> granularity of entities: variables, methods, classes
	
	-> granularity of changes: atomic changes to code entities
	
	-> granularity of results: variables, methods, classes
	
	
	Open Issues:
	
	- heuristics only tested with changes that did not introduce new elements
	
	- same issue as with all other historical approaches: 
	
	* they assume, that checked in changes are all related (which does
	not hold in RL)
	
	- lack of precision (35%-40%)},
  timestamp = {2011.02.04}
}

@INPROCEEDINGS{Hassan2010,
  author = {Hassan, Mohamed Oussama and Deruelle, Laurent and Basson, Henri},
  title = {A knowledge-based system for change impact analysis on software architecture},
  booktitle = {Proceedings of the Fourth International Conference on Research Challenges
	in Information Science (RCIS)},
  year = {2010},
  pages = {545-556},
  address = {Nice, France},
  month = {May},
  file = {:./literature/Paper_182.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- some approaches conduct IA on architecture, however they do not
	study the impact between the architecture and related code
	
	
	Research Questions:
	
	- how to bridge between architecture and code for impact propagation
	
	- how to overcome limitations of current ADLs
	
	
	Contribution:
	
	- propose architectural software components model (ASCM) as base for
	proposed change process, which is able to express architecture stored
	in different ADLs
	
	- propose software component structural model (SCSM) to couple source
	code with ASCM models
	
	- model describes common architectural elements without requiring
	ALD
	
	
	Solution:
	
	- propose change propagation approach based on expert system which
	provides rule management to cope with evolution
	
	- expert system consists of three components:
	
	* fact base: contains the architecture as ASCM graph
	
	* rule base: contains propagation rules
	
	* inference engine: applies rules on the fact base
	
	- propagation of changes based on propagation ruls, which utilize:
	change types, components and relationships between components
	
	- rules can add or remove entities
	
	- they provide a set of change operations (+/-) for components, ports,
	interfaces and connectors
	
	- rules consist of preconditions and invariants
	
	* if precondition is met and at least one invariant violated, then
	there is an impact and this component is marked
	
	* the impact is then propagated to its neighbours according to the
	incoming and outgoing relations between them
	
	- establish connection between architecture and code by linking ASCM
	entities via projection relationship to corresponding SCSM entity
	
	* impacted architecture node may propagate change to source code node
	if such a relationship exists
	
	- approach is implemented in Eclipse plugin, consisting of 4 components:
	
	* multi-language analyzer to parse source code into XML
	
	* software modeler contains and creates ASCM and SCSM models based
	on XML
	
	* expert system
	
	* user interface
	
	
	Open Issues:
	
	- enhance analysis to deal with qualitative and behavioral aspects
	of architecture
	
	- profiling model to assess impact and quality of services provided
	by software application},
  timestamp = {2011.09.21}
}

@INPROCEEDINGS{Hassine2005,
  author = {Hassine, J. and Rilling, J. and Hewitt, J. and Dssouli, R.},
  title = {Change Impact Analysis for Requirement Evolution using Use Case Maps},
  booktitle = {Proceedings of the 8th International Workshop on Principles of Software
	Evolution},
  year = {2005},
  pages = {81-90},
  file = {:./literature/Paper_7.PDF:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- evolution of requirements
	
	- apply IA on higher (more abstract) levels of software
	
	
	Research Questions:
	
	- predict and assess impacts of requirements changes
	
	
	Contribution:
	
	- IA on UCM requirements level
	
	- early analysis and localization of changes
	
	
	Solution:
	
	- introduced UCM slicing algorithm for IA at requirements level (combine
	slicing and dependency analysis)
	
	- algorithm tries to isolate a set of scenarios instead of variables
	etc. (traditionanl: on code)
	
	- user decides what he wants to change and assess (i.e. add/remove
	a function, changing a behavior)
	
	- implemented in CIA tool
	
	-> granularity of entities: UCM specification level
	
	-> granularity of changes: no details
	
	-> granularity of results: UCM specification level
	
	
	Open Issues:
	
	- use of dynamic information to reduce size of slices
	
	- predictive IA measurements at the UCM level},
  timestamp = {2011.01.01}
}

@INPROCEEDINGS{Hattori2008b,
  author = {Hattori, Lile and Guerrero, Dalton and Figueiredo, Jorge and Brunet,
	Jo\~{a}o and Damasio, Jemerson},
  title = {On the Precision and Accuracy of Impact Analysis Techniques},
  booktitle = {Proceedings of the Seventh IEEE/ACIS International Conference on
	Computer and Information Science (icis 2008)},
  year = {2008},
  pages = {513-518},
  address = {Portland, OR},
  month = {May},
  file = {:./literature/Paper_156.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- many algorithms proposed in literature
	
	- most not practical due to too many false-positives
	
	- current comparisons do not use sound measures
	
	
	Research Questions:
	
	- which measures are useful to compare IA approaches
	
	- does a depth measure used for pruning propagation improve results
	
	
	Contribution:
	
	- use precision and recall to measure performance of IA approaches
	
	- own IA approach rely on dependencies and a propagation distance
	
	
	Solution:
	
	- use static analysis to extract dependencies from code and build
	a call graph
	
	- use a defined distance to prune propagation of changes
	
	- use precision and recall to assess IA
	
	-> granularity of entities: class, method, variable
	
	-> granularity of changes: add/remove class, field, method; change
	visibility; change signature / return of method; change field type
	or name; add/remove supertypes
	
	-> granularity of results: class
	
	- implemented in Impala tool
	
	
	Open Issues:
	
	- investigate need to balance precision and recall
	
	- improve Impala to conduct IA on level of methods and variables},
  timestamp = {2011.04.05}
}

@INPROCEEDINGS{Hattori2008a,
  author = {Hattori, Lile and Santos Jr., Gilson dos and Cardoso, Fernando and
	Sampaio, Marcus},
  title = {Mining Software Repositories for Software Change Impact Analysis:
	A Case Study},
  booktitle = {Proceedings of the 23rd Brazilian symposium on Databases},
  year = {2008},
  pages = {210-223},
  address = {Campinas, Sao Paulo, Brazil},
  month = {October},
  file = {:./literature/Paper_43.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- existing "traditional" IA techniques too imprecise and expensive
	
	
	Research Questions:
	
	- how can data mining on software repositories help in IA
	
	- combine trad. IA with mining
	
	
	Contribution:
	
	- comparison of two data mining algorithms for IA: Apriori and DAR
	(Disjunctive Association Rules)
	
	
	Solution:
	
	- sort results of trad. IA based on historical changes (IA + MSR)
	
	- use Bayes theorem to combine both (probalistic approach)
	
	- first step is to compute a graph that represents source (use of
	dependency types like "contains", "isAccessedBy" etc.)
	
	- compute possible impacted elements from the graph
	
	- use MSR + probalistic to remove false-positives from the result
	list (based on frequencies of commits, i.e. "A should be changed
	and B is considered impact, how ofter was A committed together with
	B")
	
	- MSR uses a sliding window (200seconds) to distinguish between changes
	
	- use Apriori or DAR algorithm to weight possible impacts
	
	* dependency graph + MSR
	
	-> granularity of entities: class, method, variable
	
	-> granularity of changes: atomic changes (add/remove, change inheritance
	etc.)
	
	-> granularity of results: class, method, variable
	
	
	Open Issues:
	
	- evaluation performed on 2 projects with less than 4000 LOCs (each
	less than 50 classes) -> results don't seem much useful},
  timestamp = {2011.02.08}
}

@INPROCEEDINGS{Hayes2003,
  author = {Jane Huffman Hayes and Alex Dekhtyar and James Osborne},
  title = {Improving Requirements Tracing via Information Retrieval},
  booktitle = {Proceedings of the 11th IEEE International Conference on Requirements
	Engineering (RE '03)},
  year = {2003},
  pages = {138-147},
  address = {Washington, DC, USA},
  publisher = {IEEE},
  abstract = {This paper presents an approach for improving requirements tracing
	based on framing it as an information retrieval (IR) problem. Specifically,
	we focus on improving recall and precision in order to reduce the
	number of missed traceability links as well as to reduce the number
	of irrelevant potential links that an analyst has to examine when
	performing requirements tracing. Several IR algorithms were adapted
	and implemented to address this problem. We evaluated our algorithms
	by comparing their results and performance to those of a senior analyst
	who traced manually as well as with an existing requirements tracing
	tool. Initial results suggest that we can retrieve a significantly
	higher percentage of the links than analysts, even when using existing
	tools, and do so in much less time while achieving comparable signal-to-noise
	levels.},
  doi = {http://doi.ieeecomputersociety.org/10.1109/ICRE.2003.1232745},
  file = {:./literature/HuffmannHayes2003.pdf:PDF},
  isbn = {0-7695-1980-6},
  keywords = {requirements traceability, information retrieval},
  owner = {Stephan},
  timestamp = {2009.10.14}
}

@ARTICLE{Hayes2004,
  author = {Jane Huffman Hayes and Alex Dekhtyar and Senthil Karthikeyan Sundaram
	and Sarah Howard},
  title = {Helping Analysts Trace Requirements: An Objective Look},
  journal = {Requirements Engineering, IEEE International Conference on},
  year = {2004},
  volume = {0},
  pages = {249-259},
  abstract = {This paper addresses the issues related to improving the overall quality
	of the requirements tracing process for Independent Verification
	and Validation analysts. The contribution of the paper is three-fold:
	we define requirements for a tracing tool based on analyst responsibilities
	in the tracing process; we introduce several new measures for validating
	that the requirements have been satisfied; and we present a prototype
	tool that we built, RETRO (REquirements TRacing On-target), to address
	these requirements. We also present the results of a study used to
	assess RETRO?s support of requirements and requirement elements that
	can be measured objectively.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/ICRE.2004.1335682},
  file = {:./literature/RE2004-camera-edit%5Ev4.pdf:PDF},
  issn = {1090-705X},
  owner = {Elke},
  publisher = {IEEE Computer Society},
  timestamp = {2011.06.17}
}

@INCOLLECTION{Hearnden2006,
  author = {Hearnden, David and Lawley, Michael and Raymond, Kerry},
  title = {Incremental Model Transformation for the Evolution of Model-Driven
	Systems},
  booktitle = {Model Driven Engineering Languages and Systems},
  publisher = {Springer Berlin / Heidelberg},
  year = {2006},
  editor = {Nierstrasz, Oscar and Whittle, Jon and Harel, David and Reggio, Gianna},
  volume = {4199},
  series = {Lecture Notes in Computer Science},
  pages = {321-335},
  note = {10.1007/11880240_23},
  affiliation = {School of ITEE, University of Queensland, Australia},
  file = {:/literature/changeIdentification/Incremental Model Transformation for the.pdf:PDF},
  isbn = {978-3-540-45772-5},
  keyword = {Computer Science},
  keywords = {Read},
  owner = {Steffen},
  review = {Changes
	
	
	model is treated as a tree
	
	
	+Fact addition
	
	+Fact Removel},
  timestamp = {2012.03.01},
  url = {http://dx.doi.org/10.1007/11880240_23}
}

@ARTICLE{Heeks2001,
  author = {Heeks, R. and Krishna, S. and Nicholsen, B. and Sahay, S.},
  title = {Synching or sinking: global software outsourcing relationships},
  journal = {Software, IEEE},
  year = {2001},
  volume = {18},
  pages = {54--60},
  number = {2},
  file = {Heeks2001.pdf:literature/Heeks2001.pdf:PDF},
  owner = {patrickr},
  publisher = {IEEE},
  timestamp = {2012.10.15}
}

@ARTICLE{Heesch2012,
  author = {van Heesch, Uwe and Avgeriou, Paris and Hilliard, Rich},
  title = {A documentation framework for architecture decisions.},
  journal = {Journal of Systems and Software},
  year = {2012},
  volume = {85},
  pages = {795-820},
  number = {4},
  added-at = {2012-03-08T00:00:00.000+0100},
  biburl = {http://www.bibsonomy.org/bibtex/213546c4a07312834f4d4a7a6708a281f/dblp},
  ee = {http://dx.doi.org/10.1016/j.jss.2011.10.017},
  file = {:./literature/heesch2012.pdf:PDF},
  interhash = {0b2d5aa44421ec83d4131a0c539687a6},
  intrahash = {13546c4a07312834f4d4a7a6708a281f},
  keywords = {dblp},
  owner = {Sebastian},
  timestamp = {2013.07.26},
  url = {http://dblp.uni-trier.de/db/journals/jss/jss85.html#HeeschAH12}
}

@INPROCEEDINGS{Heesch2012a,
  author = {van Heesch, Uwe and Avgeriou, Paris and Hilliard, Rich},
  title = {Forces on Architecture Decisions - A Viewpoint.},
  booktitle = {WICSA/ECSA},
  year = {2012},
  pages = {101-110},
  publisher = {IEEE},
  added-at = {2012-11-13T00:00:00.000+0100},
  biburl = {http://www.bibsonomy.org/bibtex/28ae0587f5fafba6ef8a26830f7b7b23e/dblp},
  ee = {http://dx.doi.org/10.1109/WICSA-ECSA.212.18},
  file = {:./literature/heesch2012a.pdf:PDF},
  interhash = {fb21c6f21a7f9364734e941fdd1fad0e},
  intrahash = {8ae0587f5fafba6ef8a26830f7b7b23e},
  isbn = {978-1-4673-2809-8},
  keywords = {dblp},
  owner = {Sebastian},
  timestamp = {2013.07.26}
}

@INPROCEEDINGS{hezavehi2011pla,
  AUTHOR = {Sara Mahdavi-Hezavehi and Uwe van Heesch and Paris Avgeriou},
  TITLE = {A Pattern Language for Architecture Patterns and Software Technologies Introducing Technology Pattern Languages},
  BOOKTITLE = {Proceedings of the 16th European Conference on Pattern Languages of Programs (EuroPLoP)},
  YEAR = {2011},
  PUBLISHER = {Conference Proceedings},
  SEARCHDIRECTION = {ArchPatn},
}

@ARTICLE{vanHeesch2012,
  author = {Uwe van Heesch and Paris Avgeriou and Uwe Zdun and Neil Harrison},
  title = {The supportive effect of patterns in architecture decision recovery—
	A controlled experiment },
  journal = {Science of Computer Programming },
  year = {2012},
  volume = {77},
  pages = {551 - 576},
  number = {5},
  doi = {http://dx.doi.org/10.1016/j.scico.2011.11.008},
  file = {:./literature/vanHeesch2012.pdf:PDF},
  issn = {0167-6423},
  keywords = {Software architecture},
  owner = {matthias},
  timestamp = {2013.08.28},
  url = {http://www.sciencedirect.com/science/article/pii/S0167642311002085}
}

@INPROCEEDINGS{Hegedues2010,
  author = {Heged\"{u}s, \'{A}bel and Ujhelyi, Zolt\'{a}n and R\'{a}th, Istv\'{a}n
	and Horv\'{a}th, \'{A}kos},
  title = {Visualization of Traceability Models with Domain-specific Layouting},
  booktitle = {Proceedings of the Fourth International Workshop on Graph-Based Tools},
  year = {2010},
  file = {:./literature/Paper_229.pdf:PDF},
  journal = {Electronic Communications of the EASST},
  owner = {Steffen},
  timestamp = {2012.05.10}
}

@ARTICLE{Heindl2007,
  author = {Heindl, M.},
  title = {Requirements Tracing Strategies for Change Impact Analysis and Re-Testing
	An Initial Tracing Activity Model and Industry Feasibility Study},
  year = {2007},
  file = {Heindl2007 - Requirements Tracing Strategies for Change Impact Analysis and Re-Testing.pdf:literature/detep/Heindl2007 - Requirements Tracing Strategies for Change Impact Analysis and Re-Testing.pdf:PDF},
  owner = {patrickr},
  publisher = {Citeseer},
  timestamp = {2012.03.21}
}

@CONFERENCE{Heindl2005,
  author = {Heindl, Matthias and Biffl, Stefan},
  title = {A case study on value-based requirements tracing},
  booktitle = {Proceedings of the 10th European software engineering conference
	held jointly with 13th ACM SIGSOFT international symposium on Foundations
	of software engineering},
  year = {2005},
  series = {ESEC/FSE-13},
  pages = {60--69},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Project managers aim at keeping track of interdependencies
	
	between various artifacts of the software development lifecycle,
	
	to find out potential requirements conflicts, to better understand
	
	the impact of change requests, and to fulfill process quality
	
	standards, such as CMMI requirements. While there are many
	
	methods and techniques on how to technically store requirements
	
	traces, the economic issues of dealing with requirements
	
	tracing complexity remain open. In practice tracing is typically
	
	not an explicit systematic process, but occurs rather ad hoc with
	
	considerable hidden tracing-related quality costs. This paper
	
	reports a case study on value-based requirements tracing
	
	(VBRT) that systematically supports project managers in tailoring
	
	requirements tracing precision and effort based on the parameters
	
	stakeholder value, requirements risk/volatility, and
	
	tracing costs. Main results of the case study were: (a) VBRT
	
	took around 35% effort of full requirements tracing; (b) more
	
	risky or volatile requirements warranted more detailed tracing
	
	because of their higher change probability.},
  acmid = {1081717},
  doi = {http://doi.acm.org/10.1145/1081706.1081717},
  file = {:./literature/p60-heindl.pdf:PDF},
  isbn = {1-59593-014-0},
  keywords = {case study, empirical evaluation, requirements tracing, value-based
	software engineering},
  location = {Lisbon, Portugal},
  numpages = {10},
  owner = {Elke},
  review = {Artikelt stellet Methode für ein Tailoring vor anhand Case-Studie
	(Verkehrsleitung)},
  timestamp = {2011.06.06},
  url = {http://doi.acm.org/10.1145/1081706.1081717}
}

@MISC{Heller05,
  author = {Heller},
  title = {Hyper/J - Ein Werkzeug zur Multidimensionalen Separation und Integration
	von Concerns für Java},
  howpublished = {Präsentationsfolien Universität Leipzig},
  year = {2005},
  file = {:./literature/semtools05-heller-slides.pdf:PDF},
  keywords = {Hyper/J, multidimensional separation of concerns},
  owner = {Stephan},
  timestamp = {2009.03.17}
}

@UNPUBLISHED{Henkel2012,
  author = {Thomas Henkel},
  title = {Einsatz von Traceability in einem kleinen Softwareunternehmen - eine
	Fallstudie},
  year = {2012},
  file = {:literature/HS-Traceability-Thomas-Henkel.pdf:PDF},
  owner = {elkeb},
  review = {Hauptseminarsarbeit},
  timestamp = {2012.12.07}
}

@ARTICLE{Henninger2001,
  author = {Henninger, S. and Baumgarten, K.},
  title = {A case-based approach to tailoring software processes},
  journal = {Case-Based Reasoning Research and Development},
  year = {2001},
  pages = {249--262},
  file = {Henninger2001.pdf:literature/Henninger2001.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@TECHREPORT{Henttonen2007,
  author = {Henttonen, Katja},
  title = {Stylebase for Eclipse: An open source tool to support the modeling
	of quality-driven software architecture},
  institution = {VTT Electronics, Finland},
  year = {2007},
  type = {VTT Research Notes},
  number = {2387},
  abstract = {Open source software has gained a lot of well-deserved attention during
	the last few years. Eclipse is one of the most successful open source
	communities providing an open development environment and an application
	lifecycle platform. Eclipse is a vendor- neutral platform for integrating
	tools and services. My thesis work is a case study on contributing
	to Eclipse. The contribution is a software architecture tool called
	ìStylebase for Eclipseî which is implemented as an extension a.k.a.
	plug-in to Eclipse.
	
	Quality-driven architecture design is an approach to software architecture
	design which emphasizes the importance of qualities. Qualities are
	non-functional characteristics of a software system such as security
	or maintainability. Stylebase is a knowledge base of software patterns
	and architectural styles. It stores information that helps a software
	architect in selecting patterns that best support the desired quality
	goals. Stylebase for Eclipse is a tool for browsing and maintaining
	the stylebase. The purpose of the tool is to improve the quality
	of design and increase information sharing and re-use of architectural
	models in development teams.
	
	In the case study, the plug-in is first developed and, after that,
	a new open source community is formed around the plug-in project.
	In order to comply with the open source development model, modularity
	is treated as the most important non-functional requirement. In community
	building phase, efforts are concentrated on marketing the new open
	source project and creating a good technical infrastructure for it.
	
	The most interesting experiences gained during the study are related
	to various aspects of open source development. They are ñ among others
	ñ re-using code from other projects, licensing issues, tools to facilitate
	distributed development , and attracting new users and developers.},
  file = {:./literature/StylebaseForEclipse.pdf:PDF},
  keywords = {Eclipse, open source software, modeling, quality-driven software,
	software architecture, basecode, database design, stylebase, open
	source community},
  owner = {Stephan},
  review = {describes the development of the Stylebase plug-in and the goal to
	establish an open source community, not the plug-in itsself},
  timestamp = {2009.12.02}
}

@ARTICLE{Herbsleb2001,
  author = {Herbsleb, J.D. and Moitra, D.},
  title = {Global software development},
  journal = {Software, IEEE},
  year = {2001},
  volume = {18},
  pages = {16--20},
  number = {2},
  file = {Herbsleb2001.pdf:literature/Herbsleb2001.pdf:PDF},
  owner = {patrickr},
  publisher = {IEEE},
  timestamp = {2012.10.15}
}

@INPROCEEDINGS{Herndon2006,
  author = {Herndon, M.A. and Salars, S.},
  title = {6.4 Two Case Studies in Implementing Model Based Process Improvement
	in Small Organizations},
  booktitle = {International Research Workshop for Process Improvement in Small
	Settings},
  year = {2006},
  pages = {245},
  file = {:literature/Blowers2005.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@INCOLLECTION{Herold2008,
  author = {Herold, Sebastian and Klus, Holger and Welsch, Yannick and Deiters,
	Constanze and Rausch, Andreas and Reussner, Ralf and Krogmann, Klaus
	and Koziolek, Heiko and Mirandola, Raffaela and Hummel, Benjamin
	and Meisinger, Michael and Pfaller, Christian},
  title = {CoCoME - The Common Component Modeling Example},
  booktitle = {The Common Component Modeling Example},
  publisher = {Springer Berlin Heidelberg},
  year = {2008},
  editor = {Rausch, Andreas and Reussner, Ralf and Mirandola, Raffaela and Plášil,
	František},
  volume = {5153},
  series = {Lecture Notes in Computer Science},
  pages = {16-53},
  doi = {10.1007/978-3-540-85289-6_3},
  file = {:./literature/cocome.pdf:PDF},
  isbn = {978-3-540-85288-9},
  owner = {Sebastian},
  timestamp = {2014.03.19},
  url = {http://dx.doi.org/10.1007/978-3-540-85289-6_3}
}

@INPROCEEDINGS{Herold2007,
  author = {Sebastian Herold and Andreas Metzger and Heiko Stallbaum and Andreas
	Rausch},
  title = {Towards Bridging the Gap between Goal-Oriented Requirements Engineering
	and Compositional Architecture Development},
  booktitle = {Proceedings of the Second Workshop on Sharing and Reusing architectural
	Knowledge - Architecture, rationale, and Design Intent. 29th International
	Conference on Software Engineering (ICSE 2007)},
  year = {2007},
  address = {Minneapolis, USA},
  month = {May},
  publisher = {IEEE},
  abstract = {Requirements engineering and architectural design are key activities
	for the successful development of software-intensive systems. Although
	both activities are strongly intertwined and interrelated, many steps
	to date are driven solely by the intuition and the architectural
	knowledge of individuals. Thus, systematic approaches are needed
	which could minimize the risks of wrong early requirements and architectural
	decisions and foster the explicit reuse of architectural knowledge
	especially for supporting early design decisions are. In this paper,
	we present our vision of supporting the early requirements and architectural
	decisions by making explicit the interactions between the early steps
	and artifacts in requirements engineering and architectural design
	and thereby reusing architectural knowledge. To this end, we propose
	to couple goal-oriented requirements engineeringand compositional
	architecture development by means of a repository of reusable, generic
	architectural drivers.},
  file = {:./literature/Herold2007.pdf:PDF},
  isbn = {0-7695-2951-8},
  keywords = {goal models, architectural drivers, requirements engineering, architectural
	design},
  owner = {Stephan},
  review = {map goals and softgoals from project-specific goal models to general
	architectural drivers
	
	- first identify concrete architectural drivers
	
	- then look for general ones in repository
	
	
	choose reusable components from repository that satisfy the architectural
	drivers to satisfy the goals
	
	
	chosen combination of components can influence goal modeling},
  timestamp = {2009.12.17},
  url = {http://ftp.tu-clausthal.de/ftp/institute/informatik/sse/web/Publikationen/Dokumente/2007-SSE-HMSR07-Towards Bridging the Gap between Goal-Oriented Requirements Engineering and Compositional Architecture Development.pdf}
}

@MASTERSTHESIS{Herpel2007,
  author = {Kristian Herpel},
  title = {{Refactoring und Identifikation von Komponenten}},
  school = {Technical University of Ilmenau},
  year = {2007},
  type = {Diploma Thesis},
  address = {Ilmenau, Germany},
  abstract = {Die Wartung und die Erweiterung bestehender Softwaresysteme sind aufwendige
	Prozesse. Dabei auftretende Risiken können wegen der vorhandenen
	Abhängigkeiten innerhalb des Systems und zu anderen Systemen kaum
	abgeschätzt werden. Die Aufteilung eines Softwaresystems in eigenständige
	Komponenten ist ein geeigneter Ansatz, um die Aufwände in der Wartungsphase
	zu reduzieren und die Pflege zu erleichtern. 
	
	Die Arbeit „Refactoring und Identifikation von Komponenten“ entwirft
	und evaluiert eine Methode, mit der eine systematische Identifikation
	und Extraktion von Komponenten aus einem bestehenden Softwaresystem
	möglich ist. Die Komponenten werden anschließend in das Softwaresystem
	integriert, um eine parallele Pflege zu vermeiden. 
	
	Für die Analyse des bestehenden Softwaresystems und zur Identifikation
	der Komponenten werden die Darstellungsmittel der UML genutzt. Bei
	der Extraktion der Komponenten kommen Refactoring-Schritte und Design-Patterns
	zum Einsatz.},
  file = {:./literature/refactoring_und_identifikation_von_komponenten.pdf:PDF},
  keywords = {refactoring, component identification, Quasar},
  owner = {Stephan},
  timestamp = {2008.08.01},
  url = {http://www.amazon.de/Refactoring-Identifikation-von-Komponenten-Softwaresystem/dp/3639033159/ref=sr_1_12?ie=UTF8&s=books&qid=1217584602&sr=1-12}
}

@INPROCEEDINGS{Herrmann2012,
  author = {Andrea Herrmann and Sebastian Schier},
  title = {Vergleich der manuellen und automatisierten Impact Analyse in einer
	Fallstudie},
  booktitle = {MetriKon 2012},
  year = {2012},
  pages = {129-136},
  address = {Stuttgart, Germany},
  month = {November},
  file = {:./literature/Paper_254.pdf:PDF},
  owner = {Steffen},
  timestamp = {2013.01.03}
}

@TECHREPORT{Hesse2004,
  author = {Wolfgang Hesse and Barbara Krzensk},
  title = {Ontologien in der {S}oftwaretechnik},
  institution = {Fachbereich Mathematik und Informatik, Univ. Marburg, Germany},
  year = {2004},
  abstract = {Zusammenfassung: 
	
	In einigen Fachgebieten der Informatik wie der Künstlichen Intelligenz,
	bei Datenbank- und Web-basierten Systemen spielt der Ontologiebegriff
	eine zunehmend wichtige Rolle - er steht dort (anders als in der
	Philosophie) für die explizite formale, projektübergreifende Konzeptualisierung
	eines Anwendungsbereichs. Für die Softwaretechnik sind Ontologien
	hauptsächlich in den frühen Phasen von Software-Projekten interessant,
	um Modelle und Anwendungs-Komponenten besser standardisieren und
	wieder verwenden zu können.
	
	In diesem Beitrag werden konzeptuelle Modelle in Software-Projekten
	und Ontologien sowie die jeweiligen Vorgehensweisen bei deren Entwicklung
	einander gegenübergestellt sowie die Grundzüge eines Ontologie-basierten
	Software-Engineering (OBSE) skizziert.
	
	
	Abstract: 
	
	The term ontology is becoming increasingly important in several fields
	of Informatics like Artificial Intelligence, Database or Web Technology.
	Unlike its originnal meaning in Philosophy ontology stands for a
	formal explicit specification of a shared conceptualization. In the
	Software Engineering field ontologies play a major role in the early
	phases of software projects since they might facilitate the reuse
	of models and standardized application components. 
	
	In this contribution, conceptual models of software projects are contrasted
	with ontologies and the corresponding life cycle models for their
	development are compared. Finally, principles of an Ontology-based
	Software Engineering (OBSE) approach are sketched.},
  file = {:./literature/H_K_04.pdf:PDF},
  keywords = {Ontologie, ontology, Softwaretechnik, software engineering},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.14},
  url = {http://www.mathematik.uni-marburg.de/~hesse/papers/H_K_04.pdf}
}

@INPROCEEDINGS{Hesse1999,
  author = {Hesse, W. and Noack, J.},
  title = {A multi-variant approach to software process modelling},
  booktitle = {Advanced Information Systems Engineering},
  year = {1999},
  pages = {210--224},
  organization = {Springer},
  file = {Hesse1999.PDF:literature/Hesse1999.PDF:PDF},
  owner = {patrickr},
  timestamp = {2012.07.20}
}

@TECHREPORT{Heumesser2004,
  author = {{Heumesser, N. (Ed.)}},
  title = {Framework for Requirements},
  institution = {EMPRESS Project at ITEA},
  year = {2004},
  month = {April},
  abstract = {In this deliverable a framework for requirements is defined by studying
	given requirements for evolving embedded systems, classifying requirements,
	and allocating these requirements to the various abstraction layers,
	which could, for example, be a system hierarchy. Furthermore, we
	define processes for dealing with these classification schemes, e.g.,
	processes for eliciting and analyzing requirements.},
  file = {:./literature/Empress_D3.1_v1.0_Public_Version.pdf:PDF},
  keywords = {Requirements, Non-Functional Requirements, Requirements Engineering,
	Framework, Classification Scheme, Abstraction Layers, Models, Elicitation,
	Analysis, Product Lines, Product Families},
  owner = {Stephan},
  timestamp = {2009.07.27},
  url = {http://www.empress-itea.org/deliverables/D3.1_v1.0_Public_Version.pdf}
}

@INPROCEEDINGS{Hewitt2005,
  author = {Hewitt, Jacqueline and Rilling, Juergen},
  title = {A Light-Weight Proactive Software Change Impact Analysis Using Use
	Case Maps},
  booktitle = {Proceedings of the IEEE International Workshop on Software Evolvability
	(Software-Evolvability'05)},
  year = {2005},
  pages = {41-48},
  address = {Budapest, Hungary},
  month = {September},
  file = {:./literature/Paper_154.pdf:PDF},
  owner = {Steffen},
  review = {[similar to Hassine2005; same researchers]
	
	
	Problem:
	
	- changing customer needs and technology are driving factors of evolution
	
	- IA research has to focus on higher levels of abstraction like requirements
	
	
	Research Questions:
	
	
	Contribution:
	
	- new IA approach for requirements
	
	- analyse use case maps to assess impact of requirements change to
	a system
	
	
	Solution:
	
	- UCM scenarios provides information how system components interact
	to fulfill requirements
	
	- scenarios contain components
	
	- use dependency analysis among UCM scenarios and components
	
	* related scenarios by common functionality
	
	* define functional groups of scenarios that carry out the same goal
	
	* determine forward and backward dependencies of components
	
	* compute transitive closure of dependencies
	
	-> granularity of entities: UCM scenarios, UCM components
	
	-> granularity of changes: no details given
	
	-> granularity of results: UCM components
	
	- implemented in tool
	
	
	Open Issues:
	
	- more detailed case study},
  timestamp = {2011.04.05}
}

@INBOOK{Higgins2002,
  chapter = {Generic A* Pathfinding},
  pages = {114-121},
  title = {AI Game Programming Wisdom},
  publisher = {Charles River Media},
  year = {2002},
  editor = {Steve Rabin},
  author = {Dan Higgins},
  volume = {1},
  owner = {Steffen},
  timestamp = {2013.10.17}
}

@ARTICLE{Hikichi2006,
  author = {Hikichi, K. and Fushida, K. and Iida, H. and Matsumoto, K.},
  title = {A software process tailoring system focusing to quantitative management
	plans},
  journal = {Product-Focused Software Process Improvement},
  year = {2006},
  pages = {441--446},
  file = {Hikichi2006.pdf:literature/Hikichi2006.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@ARTICLE{Hill1990,
  author = {Mark D. Hill},
  title = {What is scalability?},
  journal = {SIGARCH Computer Architecture News},
  year = {1990},
  volume = {18},
  pages = {18-21},
  number = {4},
  abstract = {Scalability is a frequently-claimed attribute of multiprocessor systems.
	While the basic notion is intuitive, scalability has no generally-accepted
	definition. For this reason, current use of the term adds more to
	marketing potential than technical insight.In this paper, I first
	examine formal definitions of scalability, but I fail to lind a useful,
	rigorous definition of it. I then question whether scalability is
	useful and conclude by challenging the technical community to either
	(1) rigorously define scalability or (2) stop using it to describe
	systems.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/121973.121975},
  file = {:./literature/can90_scalability.pdf:PDF},
  issn = {0163-5964},
  keywords = {quality attribute, scalability},
  owner = {Stephan},
  publisher = {ACM},
  timestamp = {2008.10.09}
}

@ARTICLE{Hobday2000,
  author = {Hobday, M.},
  title = {The project-based organisation: an ideal form for managing complex
	products and systems?},
  journal = {Research policy},
  year = {2000},
  volume = {29},
  pages = {871--893},
  number = {7},
  file = {Hobday2000.pdf:literature/Hobday2000.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.22}
}

@INPROCEEDINGS{Hoffman2003,
  author = {Hoffman, Michael A.},
  title = {Automated impact analysis of object-oriented software systems},
  booktitle = {Proceedings of Conference on Object Oriented Programming Systems
	Languages and Applications (OOPSLA '03)},
  year = {2003},
  pages = {72-73},
  address = {Anaheim, CA},
  month = {October},
  file = {:./literature/Paper_181.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- complex nature of relationships in OO software, caused by information
	hidding, encapsulation, polymorphism etc.
	
	- being able to trace such relations assists maintainers in testing
	and understanding OO software
	
	
	Research Questions:
	
	
	Contribution:
	
	
	Solution:
	
	- IA based on comparative software maintenance (CSM) methodology
	
	- CSM is a multistaged process which enables following activities:
	
	* determine components of a system and their relationships
	
	* model components as extended low level software architecture (ELLSA)
	
	* this creates virtual software system which is used for predictive
	impact analysis (PIA)
	
	* compare ELLSA model structure for PIA and comparative impact analysis
	(CIA) to determine affected components
	
	* instrument source code for test execution coverage and to track
	dynamic execution data
	
	- CSM performs change analysis which is base for impact analysis
	
	- implemented in JFlex tool
	
	* tool scans source files and compiles data into ELLSA model
	
	* this ELLSA model (copy of original) can be used to ask "what if"
	questions which is PIA
	
	* enables comparison of two different versions of ELLSA model
	
	-> granularity of entities: class, method
	
	-> granularity of changes:
	
	-> granularity of results: class, method
	
	
	Open Issues:},
  timestamp = {2011.08.23}
}

@PHDTHESIS{Hoffman2000b,
  author = {Hoffman, Michael A.},
  title = {A Methodology to Support the Maintenance of Object-Oriented Software
	Systems Using Impact Analysis},
  school = {Louisiana State University},
  year = {2000},
  owner = {Steffen},
  timestamp = {2011.09.21}
}

@INPROCEEDINGS{Hoffman2000a,
  author = {Hoffman, Michael A. and Carver, Doris},
  title = {Predictive Impact Analysis},
  booktitle = {Proceedings of the Conference on Software Engineering and Knowledge
	Engineering},
  year = {2000},
  pages = {111-116},
  owner = {Steffen},
  review = {Problem:
	
	
	Research Questions:
	
	
	Contribution:
	
	
	Solution:
	
	
	Open Issues:},
  timestamp = {2011.09.21}
}

@ARTICLE{Hofmeister2007,
  author = {Christine Hofmeister and Philippe Kruchten and Robert L. Nord and
	Henk Obbink and Alexander Ran and Pierre America},
  title = {A general model of software architecture design derived from five
	industrial approaches},
  journal = {Journal of Systems and Software},
  year = {2007},
  volume = {80},
  pages = {106-126},
  number = {1},
  month = {Jan},
  abstract = {We compare five industrial software architecture design methods and
	we extract from their commonalities a general software architecture
	design approach. Using this general approach, we compare across the
	five methods the artifacts and activities they use or recommend,
	and we pinpoint similarities and differences. Once we get beyond
	the great variance in terminology and description, we find that the
	five approaches have a lot in common and match more or less the #ideal#
	pattern we introduced. From the ideal pattern we derive an evaluation
	grid that can be used for further method comparisons.},
  doi = {10.1016/j.jss.2006.05.024},
  file = {:./literature/Hofmeister2007.pdf:PDF},
  issn = {0164-1212},
  keywords = {Software architecture, global analysis, Siemens Four Views, ADD, RUP,
	architectural analysis, architectural synthesis, architectural design,
	BAPO/CAFCR, ARES, ASC},
  owner = {Stephan},
  review = {comparison of 5 architectural design methods, ADD, S4V, RUP, BAPO/CAFCR,
	ASC
	
	
	derivation of general model with activities: architectural analysis,
	architectural synthesis, architectural evalutation
	
	
	activities are performed iteratively not sequentially
	
	-> concept of backlog},
  timestamp = {2010.02.10},
  url = {http://www.sciencedirect.com/science/article/B6V0N-4KBDWBF-1/2/5e9a2d6ee319512208734e7e1f648b52}
}

@ARTICLE{Hofmeister2005,
  author = {Hofmeister, C. and Nord, R.L. and Soni, D.},
  title = {Global Analysis: moving from software requirements specification
	to structural views of the software architecture},
  journal = {IEE Proceedings - Software},
  year = {2005},
  volume = {152},
  pages = {187-197},
  number = {4},
  month = {Aug.},
  abstract = {Software architecture design approaches typically treat architecture
	as an abstraction of the implemented system. However, doing so means
	that the concepts, languages, notations, and tools for architecture
	are much more closely related to those of detailed design and implementation
	than to those of software requirements. Thus the gap between requirements
	and architecture represents a paradigm shift, while that between
	architecture and detailed design does not. Global Analysis, which
	is part of the Siemens Four Views architecture design approach, is
	a set of activities that serves to reduce the magnitude of this gap
	by guiding the architecture design process, capturing design rationale,
	and supporting traceability between requirements and architecture.
	In this paper Global Analysis is re-examined in light of five years
	of teaching it, reflecting on it, comparing it to other approaches,
	and examining how it was applied in four new systems. This experience
	confirms the value of the Global Analysis activities and the importance
	of capturing its results. In some cases the benefit went beyond that
	envisioned, and in other cases Global Analysis was not applied as
	expected. Because the templates that are provided for Global Analysis
	results have such a strong influence on how the activities were performed,
	this will be the focus of future changes.},
  doi = {10.1049/ip-sen:20045052},
  file = {:./literature/HofmeisterIEE05.pdf:PDF},
  keywords = {formal specification, software architecture, Global Analysis, Siemens
	Four Views, architecture design approach, software architecture design,
	software requirements specification, architectural synthesis},
  owner = {Stephan},
  review = {report on 5 years of experience with global analysis
	
	
	need for traceability mentioned, also said to be supported but not
	really discribed how
	
	
	tool support needed
	
	
	strategies support transition from problem to solution space, but
	nothing on how to describe views or find design elements},
  timestamp = {2010.02.10}
}

@BOOK{Hofmeister2000,
  title = {Applied Software Architecture},
  publisher = {Addison-Wesley Longman Publishing Co., Inc.},
  year = {2000},
  author = {Christine Hofmeister and Robert Nord and Dilip Soni},
  pages = {397},
  address = {Boston, MA, USA},
  comment = {http://books.google.de/books?hl=de&lr=&id=3klAPCIB3hQC&oi=fnd&pg=PR14&ots=NlFizZ9FNM&sig=Qmgb_QP5Ch8UMdbJ8GS3SBQO2xs},
  isbn = {0-201-32571-3},
  keywords = {software architectre, software analysis, global analysis},
  owner = {Stephan},
  timestamp = {2008.07.03}
}

@INPROCEEDINGS{Hollenbach1996,
  author = {Hollenbach, C. and Frakes, W.},
  title = {Software process reuse in an industrial setting},
  booktitle = {Software Reuse, 1996., Proceedings Fourth International Conference
	on},
  year = {1996},
  pages = {22--30},
  file = {Hollenbach1996.pdf:literature/Hollenbach1996.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@INPROCEEDINGS{Hong2010,
  author = {Hong, Youngki and Kim, Minho and Lee, Sang-Woong},
  title = {Requirements Management Tool with Evolving Traceability for Heterogeneous
	Artifacts in the Entire Life Cycle},
  booktitle = {Proceedings of the 8th ACIS International Conference on Software
	Engineering Research, Management and Applications},
  year = {2010},
  file = {:./literature/Paper_221.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.30}
}

@ARTICLE{Hopf1982,
  author = {Hopf, C.},
  title = {Norm und Interpretation. Einige methodische und theoretische Probleme
	der Erhebung und Analyse subjektiver Interpretationen in qualitativen
	Untersuchungen},
  journal = {Zeitschrift f{\"u}r Soziologie},
  year = {1982},
  volume = {11},
  pages = {307--329},
  number = {3},
  file = {Hopf1982.pdf:literature/Hopf1982.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.09.03}
}

@ARTICLE{Hopf1978,
  author = {Hopf, C.},
  title = {Die Pseudo-Exploration-{\"U}berlegungen zur Technik qualitativer
	Interviews in der Sozialforschung},
  journal = {Zeitschrift f{\"u}r Soziologie},
  year = {1978},
  volume = {7},
  pages = {97--115},
  number = {2},
  file = {Hopf1978.pdf:literature/Hopf1978.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.09.04}
}

@TECHREPORT{Hordijk2004,
  author = {W. T. B. Hordijk and D. Krukkert and R. J. Wieringa},
  title = {The impact of architectural decisions on quality attributes of enterprise
	information systems: a survey of the design space},
  year = {2004},
  type = {Technical Report},
  month = {November},
  eprint_note = {Imported from CTIT},
  eprintid = {5758},
  file = {:./literature/0000011d.pdf:PDF},
  howpublished = {http://eprints.eemcs.utwente.nl/5758/},
  issn = {1381-3625},
  keywords = {architectural decisions, quality attributes},
  official_url = {http://www.ub.utwente.nl/webdocs/ctit/1/0000011d.pdf},
  owner = {Stephan},
  publisher = {Centre for Telematics and Information Technology, University of Twente},
  refereed = {No},
  research_groups = {EWI-IS: Information Systems},
  timestamp = {2008.04.02},
  url = {http://doc.utwente.nl/49914/1/0000011d.pdf}
}

@MASTERSTHESIS{Horkoff2006,
  author = {Jennifer Horkoff},
  title = {Using i* Models for Evaluation},
  school = {University of Toronto},
  year = {2006},
  keywords = {i*, non-functional requirement, goal-oriented requirements engineering},
  owner = {Stephan},
  timestamp = {2010.11.09},
  url = {http://www.cs.utoronto.ca/~jenhork/MScThesis/Thesis.pdf}
}

@INPROCEEDINGS{Houdek2004,
  author = {F. Houdek and M. Weber},
  title = {Future Trends in Automotive Requirements Engineering},
  booktitle = {14th Annual International Symposium 4th European Systems Engineering
	Conference},
  year = {2004},
  organization = {DaimlerChrysler AG},
  publisher = {INCOSE},
  abstract = {In the last few years, requirements engineering for software-based
	systems has attracted a great deal of attention in the automotive
	industry. Requirements specification documents have been recognized
	as a crucial clement in the software and system quality chain. Consequently,
	several industrial initiatives have been launched to improve requirements
	specification quality, the creation process and tool support. For
	instance, many automotive OEMs have introduced requirements engineering
	expert groups and piloting of requirements management tools.
	
	Despite the fact that the situation is still substantially heterogeneous,
	we observe a common level that the more mature projects have adapted
	as the current state of practice. However, due to methodological
	and tool restrictions, this level still falls very short of the full
	potential of tool-supported systematic requirements management in
	the automotive domain.
	
	In this paper, we summarize the current state of the practice in requirements
	engineering for software-based automotive systems (such as electronic
	control units) and identify future research directions and tool enhancement
	requirements. Additionally, we try to identify some popular myths,
	i.e. ideas that are often mentioned in the context of automotive
	requirements engineering hut which seem to be unrealistic and/or
	undesirable from our point of view.},
  keywords = {automotive, requirements engineering},
  owner = {Robert},
  timestamp = {2006.08.14},
  url = {http://www.software-kompetenz.de/?25007}
}

@INPROCEEDINGS{tenHove2009,
  author = {ten Hove, David and Goknil, Arda and Kurtev, Ivan and Berg van den,
	Klaas and Goede de, Koos},
  title = {Change Impact Analysis for SysML Requirements Models based on Semantics
	of Trace Relations},
  booktitle = {Proceedings of the ECMDA Traceability Workshop (ECMDA-TW)},
  year = {2009},
  pages = {17-28},
  address = {Enschede, the Netherlands},
  month = {June},
  file = {:./literature/Paper_140.PDF:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- not much work spent of usage of traceability link semantics for
	IA
	
	- no precise definition of traceability relation
	
	
	Research Questions:
	
	- how to keep models synchronized with what stakeholders want to have
	modeled and implemented
	
	- how to improve IA by exploiting additional semantic information
	of traceability links
	
	
	Contribution:
	
	- formal definition of requirements relations in SysML for IA
	
	- propagate inconsistences of models via relations between them to
	propose model changes
	
	- plug-in for BluePrint modeler
	
	
	Solution:
	
	- IA process is comprised of following tasks:
	
	* external consistency checking: take requirements and changes as
	input to find external inconsistencies
	
	 - identification of domain change which should be done by requirements
	engineer
	
	 - splitt changes into primitive/atomic domain changes
	
	 - use propagation rules to propagate these changes
	
	* model changing:
	
	 - map external inconsistencies to model
	
	 - perform model change
	
	* iterating: requirements engineer might want to repeat entire process
	
	==> use of propagation rules
	
	-> granularity of entities: SysML requirements
	
	-> granularity of changes: add/remove requirement, add/remove part
	of requirement
	
	-> granularity of results: SysML requirements
	
	
	Open Issues:},
  timestamp = {2011.04.04}
}

@ARTICLE{Hsia1997,
  author = {Hsia, Pei and Li, Xiaolin and Kung, David Chenho and Hsu, Chih-Tung
	and Li, Liang and Toyoshima, Yasufumi and Chen, Cris},
  title = {A technique for the selective revalidation of OO software},
  journal = {Journal of Software Maintenance},
  year = {1997},
  volume = {9},
  pages = {217--233},
  month = {July},
  acmid = {271597},
  address = {New York, NY, USA},
  doi = {10.1002/(SICI)1096-908X(199707/08)9:4<217::AID-SMR152>3.3.CO;2-U},
  file = {:/literature/RegressionTesting/A Technique for the Selective Revalidation of ObjectOriented Software.pdf:PDF},
  issn = {1040-550X},
  issue = {4},
  keywords = {acceptance testing, class firewall, object-orientated software testing,
	regression testing, software maintenance, software validation, code
	based, discusses important dependencies of classesf},
  numpages = {17},
  owner = {Annie},
  publisher = {John Wiley \&amp; Sons, Inc.},
  timestamp = {2011.01.04},
  url = {http://portal.acm.org/citation.cfm?id=271587.271597}
}

@ARTICLE{Huang2006a,
  author = {Huang, L. and Hu, H. and Ge, J. and Boehm, B. and L{\"u}, J.},
  title = {Tailor the value-based software quality achievement process to project
	business cases},
  journal = {Software Process Change},
  year = {2006},
  pages = {56--63},
  file = {Huang2006a.pdf:literature/Huang2006a.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.07.20}
}

@INPROCEEDINGS{Huang2008,
  author = {Huang, Lulu and Song, Yeong-Tae},
  title = {A Dynamic Impact Analysis Approach for Object-Oriented Programs},
  booktitle = {Proceedings of the Conference on Advanced Software Engineering and
	Its Applications (ASEA '08)},
  year = {2008},
  pages = {217-220},
  address = {Hainan Island},
  month = {December},
  file = {:./literature/Paper_136.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- approach proposed in [Huang2007] not yet implemented
	
	
	Research Questions:
	
	- how to detect runtime inheritance relations
	
	- what is the improvement compared to other tools / approaches?
	
	
	Contribution:
	
	- improvements of [Huang2007]
	
	- implemented in JDIA tool
	
	
	Solution:
	
	- dynamic source code IA
	
	- identification of runtime inheritance as follows:
	
	* identify how inheritance hierarchy is reflected in an execution
	trace
	
	 - i.e. monitoring constructor calls
	
	* investigate differences of event sequences from certain java-instantiation
	rules to identify inheritance relationships
	
	- JDIA tool consists of:
	
	* event collection module
	
	* event processing module
	
	* impact analysis module
	
	* I/O processing module
	
	-> granularity of artifacts: variables, methods
	
	-> granularity of changes: atomic changes (i.e. add method, remove
	method, add variable etc.)
	
	-> granularity of results: impacted variables, impacted methods
	
	
	Open Issues:},
  timestamp = {2011.04.04}
}

@INPROCEEDINGS{Huang2007,
  author = {Huang, Lulu and Song, Yeong-Tae},
  title = {Precise Dynamic Impact Analysis with Dependency Analysis for Object-oriented
	Programs},
  booktitle = {Proceedings of the 5th ACIS International Conference on Software
	Engineering Research, Management \& Applications (SERA 2007)},
  year = {2007},
  pages = {374-384},
  address = {Busan},
  month = {August},
  file = {:./literature/Paper_152.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- dynamic IA shown to be more precise than static IA
	
	- however they neglect dependency information and therefore lose precision
	
	
	Research Questions:
	
	
	Contribution:
	
	- new approach combining dynamic IA with dependencies
	
	- take into account the characteristics of OO software
	
	- use dependencies to cut away false-positives to increase precision
	
	
	Solution:
	
	- proposed dynamic IA calculates impact according to runtime binary
	dependency information of program elements
	
	- collect execution traces, consider several different entry/exit
	types (e.g. method entry without arguments etc.)
	
	- imact of method implementation change is calculated as follows:
	
	* calculate execution-after set for the method
	
	 - contains all methods which cause event (entry/exit) after changed
	method
	
	* calculate dependency graph for changed method
	
	 - dependencies between methods are "pass parameters" and "return
	values" as they affect state / behavior of object [same applies for
	variables]
	
	* add all methods in the depedency graph to change set
	
	- impact of method interface change is calculated as follows:
	
	* forward execution trace to find method entry of changed method
	
	* backward trace to find caller
	
	* add changed method and its callers to the impact set
	
	- impact of atomic changes to variables calculated as follows:
	
	* calculate methods which depend on this variable, add those to the
	impact set
	
	* add methods which depend on methods from step 1 to impact set
	
	-> granularity of artifacts: variables, methods
	
	-> granularity of changes: atomic changes (i.e. add method, remove
	method, add variable etc.)
	
	-> granularity of results: impacted variables, impacted methods
	
	
	Open Issues:
	
	- implement approach in tool
	
	- perform dynamic IA on statement-level to increase precision},
  timestamp = {2011.03.14}
}

@INPROCEEDINGS{Huang2006,
  author = {Huang, Lulu and Song, Yeong-Tae},
  title = {Dynamic Impact Analysis Using Execution Profile Tracing},
  booktitle = {Proceedings of the Fourth International Conference on Software Engineering
	Research, Management and Applications (SERA'06)},
  year = {2006},
  pages = {237-244},
  address = {Seattle, Washington},
  month = {August},
  file = {:./literature/Paper_137.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- trad. static IA too imprecise and hardly useful
	
	- existing dynamic techniques introduce too much overhead (space &
	time)
	
	
	Research Questions:
	
	- how to improve dynamic IA
	
	
	Contribution:
	
	- new dynamic IA technique which is safe and has better performance
	
	
	Solution:
	
	- online IA at method level which does not require source code
	
	- replace "method return events" with "method return into events"
	
	- reduce redundancy in execution traces:
	
	* skip executions which do not traverse changed methods
	
	* remove methods whose events are listed before any event of a changed
	method
	
	-> granularity of entities: methods
	
	-> granularity of changes: changes to methods
	
	-> granularity of results: methods
	
	
	Open Issues:
	
	- implement approach in tool
	
	- conduct case study
	
	- incorporate static IA to improve detection},
  timestamp = {2011.04.04}
}

@ARTICLE{HuffmanHayes2007,
  author = {Huffman Hayes, Jane and Dekhtyar, Alex and Sundaram, Senthil and
	Holbrook, Ashlee and Vadlamudi, Sravanthi and April, Alain},
  title = {REquirements Tracing On target (RETRO): Improving Software Maintenance
	through Traceability Recovery},
  journal = {Innovations in Systems and Software Engineering},
  year = {2007},
  volume = {3},
  pages = {193-202},
  number = {3},
  month = {September},
  file = {:./literature/Paper_270.pdf:PDF},
  owner = {Steffen},
  timestamp = {2013.10.22}
}

@ARTICLE{Hug2009,
  author = {Hug, C. and Rieu, D. and Henderson-Sellers, B. and others},
  title = {A method to build information systems engineering process metamodels},
  journal = {Journal of Systems and Software},
  year = {2009},
  volume = {82},
  pages = {1730--1742},
  number = {10},
  file = {Hug2009.PDF:literature/Hug2009.PDF:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.08.06}
}

@ARTICLE{Humm2008,
  author = {Humm, Bernhard},
  title = {Was ist eigentlich ein Service?},
  journal = {Softwaretechnik-Trends},
  year = {2008},
  volume = {28},
  pages = {8-11},
  number = {4},
  month = {Nov.},
  abstract = {In der Literatur zur Service-Orientierten Architektur (SOA) wird der
	Begriff des Service häufig synonym zu den in der Softwaretechnik
	etablierten Begriffen Komponente, Schnittstelle und Operation verwendet.
	In dem Artikel wird eine alternative Definition vorgestellt, welche
	den Service in den Kontext der Geschäftsarchitektur eines Unternehmens
	stellt. Zusammenhänge zu den in der Softwaretechnik etablierten Begriffen
	werden aufgezeigt.},
  file = {:./literature/Was_ist_eigentlich_ein_Service.pdf:PDF},
  keywords = {SOA, Service, Geschäftsservice, Anwendungsservice},
  owner = {Stephan},
  timestamp = {2009.02.10},
  url = {http://www.fbi.h-da.de/fileadmin/personal/b.humm/Publikationen/Humm_-_Was_ist_eigentlich_ein_Service__GI-WKS_Software-Architektur_2008_.pdf}
}

@ARTICLE{Hunt1998,
  author = {Hunt, James J. and Vo, Kiem-Phong and Tichy, Walter F.},
  title = {Delta algorithms: an empirical analysis},
  journal = {ACM Trans. Softw. Eng. Methodol.},
  year = {1998},
  volume = {7},
  pages = {192--214},
  month = {April},
  acmid = {279321},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/279310.279321},
  file = {:/literature/changeIdentification/Delta Algorithams.pdf:PDF},
  issn = {1049-331X},
  issue = {2},
  keywords = {Read, benchmark, delta encoding, differencing},
  numpages = {23},
  owner = {Steffen},
  publisher = {ACM},
  timestamp = {2012.03.01},
  url = {http://doi.acm.org/10.1145/279310.279321}
}

@INPROCEEDINGS{Hutchins1998,
  author = {Hutchins, Matthew and Gallagher, Keith},
  title = {Improving Visual Impact Analysis},
  booktitle = {Proceedings of the 14th IEEE International Conference on Software
	Maintenance (ICSM'98)},
  year = {1998},
  pages = {294-303},
  address = {Bethesda, Maryland, USA},
  month = {March},
  file = {:./literature/Paper_97.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- visualizing impacts is important for developers to highlight entities
	that are affected by a change
	
	- current visualization though acyclic graphs misses some important
	information and is therefore less useful
	
	
	Research Questions:
	
	- how to improve visualization of impacts and dependencies between
	software entities
	
	
	Contribution:
	
	- analysis of graph representation and why it is not sufficient enough
	
	- new visualization technique based on "interference" based on program
	variables
	
	- design of technique is presented and examples of possible application
	are given
	
	
	Solution:
	
	- current graph visualization for slice uses 2 types of graphs:
	
	* "strong dependency graph" to visualize slices which are directly
	dependent:
	
	 - transitive egdes are not shown
	
	 - edges to node itself are not shown
	
	 - reduces complexity of visualization
	
	* "weak dependency graph" to visualize slices which are mutually dependent
	on another variable
	
	- based on both concepts, define "interference" between variables
	A and B:
	
	* A is not strongly dependent on B and vice versa
	
	* decomposition slices on A and B have common statements which are
	not explained by strong dependencies towards B
	
	- use the following metrics to further reduce visible entities:
	
	* hide any variable
	
	* hide variables with empty slices (size of slice < 3)
	
	* group equivalent variables of the same procedure into one entity
	
	* group all slices of all variables of a procedure into one entity
	
	* hide variables without relationships to current selection
	
	- arrange variables in a grid-structure
	
	- arrange variables in a way to allow fast assessment of effort (by
	evaluating their strong dependencies):
	
	* all infering variables will be displayed to the right
	
	* all variables affected by a change are displayed above
	
	- implemented in command-line tool which outputs postscript files
	
	-> granularity of entities: variables
	
	-> granularity of changes: changes that affect variables
	
	-> granularity of results: variables
	
	
	Open Issues:
	
	- new layout is confusing for larger systems
	
	- approach not tested in software maintenance},
  timestamp = {2011.02.24}
}

@INPROCEEDINGS{Hutchinson2003,
  author = {Hutchinson, J. and Kotonya, G. and Bloin, B. and Sawyer, P.},
  title = {Understanding the Impact of Change in {COTS}-Based Systems},
  booktitle = {Proceedings of the International Conference on Software Engineering
	Research and Practice (SERP '03)},
  year = {2003},
  address = {Las Vegas, USA},
  month = {June},
  file = {:./literature/Paper_144.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- black-box nature of COTS components adds new challenges to IA
	
	- withtout proper AI, COTS components are hard to maintain and adapt
	
	
	Research Questions:
	
	- how to cope with the back-box nature of COTS components?
	
	
	Contribution:
	
	- combined approach to assess impact of change on COTS software and
	document system architecture
	
	
	Solution:
	
	- defined process for COTS-based software development
	
	* use CADL to describe architectures
	
	* use requirements to identify suitable components
	
	* use links between requirements and components
	
	- two models available for IA process, conduct IA on both:
	
	* CADL architecture
	
	 - extend impact model of [Chaumun1999] and adapt to CADL
	
	* process model after which the system was developed
	
	- use traceability based IA
	
	-> granularity of entities: requirements, components
	
	-> granularity of changes: no details
	
	-> granularity of results: requirements, components
	
	
	Open Issues:
	
	- tool support},
  timestamp = {2011.04.04}
}

@INPROCEEDINGS{Ibarguengoitia2003,
  author = {Ibarguengoitia, G. and Salazar, JA and Sanchez, MG and Ramirez, AY},
  title = {A procedure for customizing a software process},
  booktitle = {Computer Science, 2003. ENC 2003. Proceedings of the Fourth Mexican
	International Conference on},
  year = {2003},
  pages = {68--72},
  organization = {IEEE},
  file = {Ibarguengoitia2003.pdf:literature/Ibarguengoitia2003.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.23}
}

@ARTICLE{Ibert2004,
  author = {Ibert, O.},
  title = {Projects and firms as discordant complements: organisational learning
	in the Munich software ecology},
  journal = {Research Policy},
  year = {2004},
  volume = {33},
  pages = {1529--1546},
  number = {10},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.19}
}

@INPROCEEDINGS{Ibrahim2006,
  author = {Ibrahim, Suhaimi and Idris, Norbik Bashah and Munro, Malcolm and
	Deraman, Aziz},
  title = {A Software Traceability Validation For Change Impact Analysis of
	Object Oriented Software},
  booktitle = {Proceedings of the International Conference on Software Engineering
	Research and Practice \& Conference on Programming Languages and
	Compilers, SERP 2006},
  year = {2006},
  volume = {1},
  pages = {453-459},
  address = {Las Vegas, Nevada, USA},
  month = {June},
  file = {:./literature/Paper_74.pdf:PDF},
  journal = {Software Engineering Research and Practice 2006},
  owner = {Steffen},
  review = {Problem:
	
	- IA help to relate consequences of ripple-effects of a proposed change
	
	- IA in combination with traceability helps to do so across many different
	levels of a software system
	
	
	Research Questions:
	
	- include artifacts of different development stages with different
	granularity into impact analysis
	
	
	Contribution:
	
	- software traceability approach integrating different levels of a
	software systems
	
	- support for top-down and bottom-up traceability
	
	- prototype tool CATIA
	
	
	Solution:
	
	- use traceability-links to cover requirements, design, code and tests
	
	- use of standard vertical/horizontal traceability
	
	- use 3 techniques for traceability detection:
	
	* explicit links: low-level dependencies discovered by code analyzer
	
	* cognitive links: dependencies between requirements and code, established
	by designers
	
	* concept location: dependencies between requirements and code, established
	through automated tests
	
	- perform static analysis on code to gather dependencies of classes
	and methods
	
	- perform dynamic analysis to gather dependencies of requirements
	by executing tests
	
	- case study conducted with 20 students, analyzing an automotive control
	system 4KLOC
	
	-> granularity of entities: classes, methods, requirements, test cases
	
	-> granularity of changes: methods
	
	-> granularity of results: classes, methods, requirements, test cases
	
	
	Open Issues:
	
	- approach less accurate at finer granularity
	
	- top-down impacts (from requirements to code) were less useful},
  timestamp = {2011.02.18}
}

@ARTICLE{Ibrahim2005a,
  author = {Ibrahim, Suhaimi and Idris, Norbik Bashah and Munro, Malcolm and
	Deraman, Aziz},
  title = {Integrating Software Traceability for Change Impact Analysis},
  journal = {The International Arab Journal of Information Technology},
  year = {2005},
  volume = {2},
  pages = {301-308},
  number = {4},
  month = {October},
  file = {:./literature/Paper_72.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- ripple effects propagate throughout entire system
	
	- maintenance makes up most part of software "development" costs
	
	
	Research Questions:
	
	- capturing impacts from a given change through traceability
	
	
	Contribution:
	
	- traceability approach assisting in IA on OOP software
	
	- integration of high-level and low-level models for requirements,
	test cases, design and code
	
	
	Solution:
	
	- trace and capture relationship among the entire system at all levels
	of granularity (= hypothesizing traces)
	
	- gather traces / dependencies as follows:
	
	* identify test cases for each requirements
	
	* validate against documentation if available
	
	* run a test scenario for each test case to gather ripple effects
	
	* perform static code analysis to capture call graphs
	
	- use a set of matrices to capture traceability relations in the system
	
	- use 2 methods to capture traceability relations:
	
	* explicit traceability, e.g. UML inter-class relations
	
	* domain knowlegde, i.e. knowledge how items are related
	
	-> granularity of entities: classes, methods, requirements, test cases
	
	-> granularity of changes: methods
	
	-> granularity of results: classes, methods, requirements, test cases
	
	
	Open Issues:
	
	- no graphical representation of detected traceability-links},
  timestamp = {2011.02.17}
}

@ARTICLE{Ibrahim2005b,
  author = {Ibrahim, Suhaimi and Idris, Norbik Bashah and Munro, Malcolm and
	Deraman, Aziz},
  title = {A Requirements Traceability to support Change Impact Analysis},
  journal = {Asean Journal of Information Technology},
  year = {2005},
  volume = {4},
  pages = {345-355},
  number = {4},
  booktitle = {Asean Journal of Information Technology},
  file = {:./literature/Paper_78.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- ripple-effects and changes propaget across all levels of software,
	not just code
	
	- most IA techniques focus on one level of analysis and neglect others
	
	
	Research Questions:
	
	
	Contribution:
	
	- traceability approach for IA linking high-level and low-level software
	entities
	
	- solution for ripple-effects across different levels of software
	
	
	Solution:
	
	- use direct and indirect traceability
	
	* capture direct traceability with static/dynamic analysis
	
	* capture indirect traceability with transitive closure
	
	- distinguish between horizontal (inter) and vertical (intra) traceability
	for requirements, design, code and test
	
	- first step of approach involves finding existing traceability-links
	
	* gather links between requirements and tests through the softwares
	documentation
	
	* run test scenarios to gather dependencies between method calls and
	tests (dynamic analysis)
	
	* perform static analysis to gather dependencies between classes and
	methods (class-class, class-method, method-method)
	
	- second step (IA) uses ripple-effects of call graphs and dependency
	graphs
	
	- use tool CodeParser to gather all this information and store dependencies
	in matrices
	
	- use 2 methods to capture traceability relations (either bottom-up
	or top-down):
	
	* explicit traceability, e.g. UML inter-class relations
	
	* domain knowlegde, i.e. knowledge how items are related
	
	-> granularity of entities: classes, methods, requirements, test cases
	
	-> granularity of changes: methods
	
	-> granularity of results: classes, methods, requirements, test cases
	
	
	Open Issues:
	
	- high-level design models not considered (only low-level: class diagram)
	
	- developer has to establish some of the traceability-links by hand},
  timestamp = {2011.02.21}
}

@MASTERSTHESIS{Igel2010,
  author = {Andreas Igel},
  title = {Traceability in Agile Software Development Projects},
  school = {TU Ilmenau},
  year = {2010},
  file = {:./literature/Diplomarbeit-Andreas.Igel.pdf:PDF},
  owner = {elkeb},
  review = {- Umfrage, welches Potential hätte Trecebility im agilen Umfeld},
  timestamp = {2011.07.01}
}

@INPROCEEDINGS{Imtiaz2008,
  author = {Imtiaz, Salma and Ikram, Naveed and Imtiaz, Saima},
  title = {Impact Analysis from Multiple Perspectives: Evaluation of Traceability
	Techniques},
  booktitle = {Proceedings of the 3rd International Conference on Software Engineering
	Advances},
  year = {2008},
  pages = {457-464},
  month = {October},
  file = {:./literature/Paper_220.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.30}
}

@MISC{IEEE1471-2000,
  author = {{Institute of Electrical and Electronics Engineers}},
  title = {IEEE Recommended Practice for Architectural Description of Software-Intensive
	Systems},
  howpublished = {IEEE Std 1471-2000},
  month = {Sept},
  year = {2000},
  note = {also ISO/IEC 42010 (2007)},
  abstract = {This recommended practice addresses the activities of the creation,
	analysis, and sustainment of architectures of software-intensive
	systems, and the recording of such architectures in terms of architectural
	descriptions. A conceptual framework for architectural description
	is established. The content of an architectural description is defined.
	Annexes provide the rationale for key concepts and terminology, the
	relationships to other standards, and examples of usage.},
  file = {:./literature/IEEEStd1471-2000.pdf:PDF;:./literature/ISOIEC42010(IEEE1471-2000).pdf:PDF},
  keywords = {standard, architectural description, architecture, software-intensive
	system, stakeholder concerns, system stakeholder, view, viewpoint},
  owner = {Stephan},
  timestamp = {2009.02.10}
}

@MISC{IEEE1219-1998,
  author = {{Institute of Electrical and Electronics Engineers}},
  title = {{IEEE Standard for Software Maintenance}},
  howpublished = {IEEE Std 1219-1998},
  month = {Oct},
  year = {1998},
  file = {:./literature/00720567.pdf:PDF},
  key = {IEEE Std 1219-1998},
  keywords = {software maintenance IEEE Std 1219-1998, IEEE standard, software life-cycle,
	software maintenance activities management, software maintenance
	activity execution},
  owner = {Stephan},
  timestamp = {2008.06.16}
}

@STANDARD{IEEE830-1998,
  title = {{IEEE Recommended Practice for Software Requirements Specifications}},
  organization = {IEEE},
  author = {{Institute of Electrical and Electronics Engineers}},
  number = {IEEE Std 830-1998},
  year = {1998},
  abstract = {The content and qualities of a good software requirements specification
	(SRS) are de- scribed and several sample SRS outlines are presented.
	This recommended practice is aimed at specifying requirements of
	software to be developed but also can be applied to assist in the
	selec- tion of in-house and commercial software products. Guidelines
	for compliance with IEEE/EIA 12207.1-1997 are also provided.},
  doi = {10.1109/IEEESTD.1998.88286},
  file = {:./literature/IEEEStd830-1998.pdf:PDF},
  key = {IEEE Std 830-1998},
  keywords = {contract, customer, prototyping, software requirements specification,
	supplier, system requirements specifications},
  owner = {matthias},
  timestamp = {2014.02.25}
}

@MISC{IEEE1990,
  author = {{Institute of Electrical and Electronics Engineers}},
  title = {{IEEE Standard Glossary of Software Engineering Terminology}},
  year = {1990},
  abstract = {Describes the IEEE Std 610.12-1990, IEEE standard glossary of software
	engineering terminology, which identifies terms currently in use
	in the field of software engineering. Standard definitions for those
	terms are established.},
  citeulike-article-id = {1341545},
  file = {:./literature/00159342.pdf:PDF},
  key = {IEEE Std 610.12-1990},
  keywords = {development software},
  number = {IEEE Std 610.12-1990},
  organization = {IEEE},
  owner = {Stephan},
  priority = {2},
  timestamp = {2010.10.28},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=159342}
}

@MISC{IEEE1984,
  author = {{Institute of Electrical and Electronics Engineers}},
  title = {{IEEE Guide to Software Requirements Specification}},
  year = {1984},
  abstract = {Discusses the background information for writing a good software requirements
	specification (SRS). The characteristics of a good SRS are that it
	is unambiguous (hence use of formal requirements specifications languages
	because of pitfalls in natural language), complete, verifiable, consistent,
	modifiable, traceable, and useable during the operation and maintenance
	phase. The preparation evolution and tools for developing an SRS
	are described. The methods used to express software requirements
	i.e. input/output specifications and mathematical, functional timing,
	and other models are discussed, also annotation of requirement and
	common pitfalls in their expression. Finally there is an SRS prototype
	outline which includes general description and specification requirements.},
  doi = {10.1109/IEEESTD.1984.119205},
  file = {:./literature/IEEEStd830-1984.pdf:PDF},
  key = {IEEE Std 830-1984},
  keywords = {SRS;SRS prototype outline;formal requirements specifications languages;input/output
	specifications;software requirements specification;software engineering;systems
	analysis},
  number = {IEEE Std 830-1984},
  organization = {IEEE},
  owner = {Stephan},
  timestamp = {2010.12.08}
}

@MISC{ISO/IEC25010,
  author = {{International Standardization Organisation}},
  title = {{ISO/IEC 25010:2011 Software Engineering -- Software product Quality
	Requirements and Evaluation (SQuaRE) Quality model}},
  year = {to appear 2011},
  key = {ISO/IEC 25010},
  keywords = {product quality, non-functional properties, quality attribute},
  owner = {Stephan},
  timestamp = {2009.05.11}
}

@MISC{ISO42010,
  author = {{International Standardization Organisation}},
  title = {ISO/IEC/IEEE 42010 - Systems and software engineering - Architecture
	description},
  year = {2011},
  file = {:./literature/iso42010.pdf:PDF},
  owner = {Sebastian},
  timestamp = {2013.11.28}
}

@MISC{ISO/IEC14764-2006,
  author = {{International Standardization Organisation}},
  title = {{Software Engineering---Software Life Cycle Processes---Maintenance}},
  howpublished = {ISO/IEC 14764:2006, IEEE Std 14764-2006},
  year = {2006},
  file = {:./literature/ISO14764.pdf:PDF},
  key = {ISO/IEC 14764:2006},
  keywords = {life cycle, software process, maintainability, maintenance, software
	maintenance, standards},
  owner = {Stephan},
  timestamp = {2009.02.12}
}

@MISC{ISO/IEC27001:2005,
  author = {{International Standardization Organisation}},
  title = {{ISO/IEC 27001:2005 Information technology -- Security techniques
	-- Information security management systems -- Requirements}},
  month = {June},
  year = {2005},
  file = {:./literature/ISO27001.pdf:PDF},
  key = {ISO/IEC 9126-1},
  keywords = {information security, security techniques, information security management
	systems, security requirements},
  owner = {Stephan},
  timestamp = {2008.10.13}
}

@MISC{ISO/IEC9126-1:2001,
  author = {{International Standardization Organisation}},
  title = {{ISO/IEC 9126-1 International Standard. Software Engineering -- Product
	quality -- Part 1: Quality models}},
  month = {June},
  year = {2001},
  file = {:./literature/ISO_IEC_9126_Software_Quality.PDF:PDF},
  key = {ISO/IEC 9126-1},
  keywords = {product quality, non-functional properties, quality attribute},
  owner = {Stephan},
  timestamp = {2008.06.17}
}

@INPROCEEDINGS{Inzinger2013,
  author = {Inzinger, Christian and Hummer, Waldemar and Lytra, Ioanna and Leitner,
	Philipp and Tran, Huy and Zdun, Uwe and Dustdar, Schahram},
  title = {Decisions, Models, and Monitoring A Lifecycle Model for the Evolution
	of Service-Based Systems},
  booktitle = {17th IEEE International EDOC Conference},
  year = {2013},
  abstract = {The process of engineering and provisioning service-based systems
	(SBS), which is becoming the predominant model for enterprise computing,
	follows a complex and dynamic lifecycle with different phases and
	levels of abstraction. We tackle the problem of making this lifecycle
	explicit, providing development time and runtime support for evolutionary
	changes in such systems. SBSs are modeled as integrated ecosystems
	consisting of four conceptual layers (or phases): design, implementation,
	deployment, and runtime. Our work is driven by the notion that identifying
	the right changes (monitoring) and effecting of these changes (adaptation)
	usually takes place individually on each layer. While considering
	changes on a single layer (e.g., runtime adaptation) is often sufficient,
	some cases require systematic escalation to adjacent layers. We present
	a generic lifecycle model that provides an abstracted view of the
	problem domain and can be mapped to concrete artifacts on each individual
	layer. We introduce a real-life scenario taken from the telecommunications
	domain, which serves as the basis for discussion of the challenges
	and our solution. Based on the scenario and our experience from a
	research project on Virtual Service Platforms, we evaluate three
	concrete use cases which illustrate the diversity of evolutionary
	changes supported by the approach.},
  file = {:./literature/Inzinger-edoc2013.pdf:PDF},
  owner = {matthias},
  timestamp = {2013.09.19},
  url = {http://www.infosys.tuwien.ac.at/staff/hummer/docs/2013-edoc-lifecycle.pdf}
}

@BOOK{ISOIEC25010,
  title = {ISO/IEC 25010:2011 Systems and software engineering -- Systems and
	software Quality Requirements and Evaluation (SQuaRE) -- System and
	software quality models},
  publisher = {ISO/IEC},
  year = {2011},
  author = {ISO/IEC},
  file = {ISOIEC25010.pdf:literature/ISOIEC25010.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.12.21}
}

@BOOK{ISOIEC9126,
  title = {ISO/IEC 9126. Software engineering -- Product quality},
  publisher = {ISO/IEC},
  year = {2001},
  author = {ISO/IEC},
  file = {:literature/ISO_IEC_9126_Software_Quality.PDF:PDF;:literature/ISOIEC9126_1.pdf:PDF;ISOIEC9126.pdf:literature/ISOIEC9126.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.12.21}
}

@MISC{ITU-T2008,
  author = {{ITU-T}},
  title = {{Recommendation ITU-T Z.151 User requirements notation (URN) -- Language
	definition}},
  month = {November},
  year = {2008},
  abstract = {Recommendation ITU-T Z.151 defines the User Requirements Notation
	(URN) intended for the elicitation, analysis, specification, and
	validation of requirements. URN combines modelling concepts and notations
	for goals (mainly for non-functional requirements and quality attributes)
	and scenarios (mainly for operational requirements, functional requirements,
	and performance and architectural reasoning). The goal sub-notation
	is called goal-oriented requirements language (GRL) and the scenario
	sub-notation is called use case map (UCM).},
  file = {:./literature/T-REC-Z.151-200811.pdf:PDF},
  keywords = {URN, user requirements notation, GRL, goal-oriented requirements language,
	UCM, use case maps, standard},
  organization = {ITU-T},
  owner = {Stephan},
  timestamp = {2010.11.23}
}

@ARTICLE{Ivkovic2006,
  author = {Ivkovic, Igor and Kontogiannis, Kostas},
  title = {Towards automated establishment of model dependencies using formal
	concept analysis},
  journal = {International Journal of Software Engineering and Knowledge Engineering},
  year = {2006},
  volume = {16},
  pages = {499-522},
  number = {4},
  month = {Aug},
  abstract = {Software evolution is an iterative and incremental process that encompasses
	the modification and alteration of software models at different levels
	of abstraction. These modifications are usually performed independently,
	but the objects to which they are applied to, are in most cases mutually
	dependent. Inconsistencies and drift among related artifacts may
	be created if the effects of an alteration are not properly identified,
	recorded, and propagated in other dependent models. For large systems,
	it is possible that there is a considerable number of such model
	dependencies, for which manual extraction is not feasible. In this
	paper, we introduce an approach for automating the identification
	and encoding of dependence relations among software models and their
	elements. The proposed dependency extraction technique first uses
	association rules to map types between models at different levels
	of abstraction. Formal concept analysis is then used to identify
	clusters of model elements that pertain to similar or associated
	concepts. Model elements that cluster together are considered related
	by a dependency relation. The technique is used to synchronize business
	process specifications with the underlying J2EE source code models.},
  file = {:./literature/Ivkovic2006.pdf:PDF},
  keywords = {traceability, model dependencies, n-gram matching, software evolution,
	model synchronization, formal concept analysis},
  owner = {Stephan},
  timestamp = {2010.12.10}
}

@INPROCEEDINGS{Jasz2008,
  author = {J\'{a}sz, Judit and Besz\'{e}des, \'{A}rp\'{a}d and Gyim\'{o}thy,
	Tibor and Rajlich, V\'{a}clav},
  title = {Static Execute After/Before as a replacement of traditional software
	dependencies},
  booktitle = {Proceedings of the IEEE International Conference on Software Maintenance
	(ICSM '08)},
  year = {2008},
  pages = {137-146},
  address = {Beijing},
  month = {October},
  file = {:./literature/Paper_166.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- trad. program dependency based techniques suffer from poor scalability
	and are time consuming
	
	- not all dependencies captured by current / trad. techniques
	
	
	Research Questions:
	
	- how do SEB/SEA perform in contrast to trad. prog. dep.
	
	
	Contribution:
	
	- introduction of "Static Execute Before" (SEB) and "Static Execute
	After" (SEA) dependencies
	
	- comparison of SEA/SEB with trad. program dependencies
	
	
	Solution:
	
	- create SEA and SEB based on control flow, data flow and other dependencies
	
	- use component control flow graph (CCFG)
	
	* only consider call site nodes and flow edges
	
	[more details on SEA: Beszedes2007a]
	
	* SEB is inverse SEA
	
	-> granularity of entities: method
	
	-> granularity of changes:
	
	-> granularity of results: method
	
	
	Open Issues:
	
	- optimization of SEB/SEA generation (firefox case study could not
	be completed due to exhaustion)
	
	- investigate hidden dependencies which might missed by SEA/SEB},
  timestamp = {2011.07.26}
}

@PHDTHESIS{Joensson2005,
  author = {J\"{o}nsson, Per},
  title = {Impact Analysis Organisational Views and Support Techniques},
  school = {Department of Systems and Software Engineering
	
	School of Engineering
	
	Blekinge Institute of Technology
	
	Sweden},
  year = {2005},
  file = {:./literature/PhD_1.PDF:PDF},
  owner = {Steffen},
  review = {useful stuff: taxonomy for software engineering validation by Zelkowitz
	and Wallace
	
	useful stuff: investigation of thresholds for IA methods and why not
	sufficient (p. 134)
	
	
	- thesis explores impact analysis in scope of requirements and presents
	organisational views on impact analysis
	
	- results of thesis:
	
	* most studies focus on technical views of impact analysis
	
	* however, organisational views, like creating understanding how IA
	is used in practice, neglected by most studies
	
	- thesis discusses 20 different uses for impact analysis in software
	development, e.g. analyzing system impact or time-cost-tradeoffs
	
	- use latent semantic indexing as core for requirements IA of a term-by-document
	matrix, which associates terms with documents
	
	* identify keywords
	
	* identify dependencies using LSI
	
	* examine results to predict impact
	
	
	- scope of analysis: requirements
	
	- tool: SVDLIBC
	
	- language: -
	
	- scalability: -
	
	- granularity
	
	* changes:
	
	* artifacts: requirements
	
	* results: requirements
	
	- technique: IR
	
	- analysis style:
	
	- evaluation
	
	* size: 400 requirements
	
	* precision: 0.171
	
	* recall: 0.177
	
	* time:},
  timestamp = {2011.01.01}
}

@ARTICLE{Jaber2013,
  author = {Jaber, K. and Sharif, B. and Chang Liu},
  title = {A Study on the Effect of Traceability Links in Software Maintenance},
  journal = {Access, IEEE},
  year = {2013},
  volume = {1},
  pages = {726-741},
  doi = {10.1109/ACCESS.2013.2286822},
  file = {:./literature/Jaber2013.pdf:PDF},
  issn = {2169-3536},
  keywords = {software maintenance;TraceLink;industrial firm;maintenance phase;maintenance
	tasks;prototype link tracing tool;software artifacts;software development;software
	maintenance;traceability link model;traceability system links;Business;Maintenance
	engineering;Software systems;Teamwork;Unified modeling language;Software
	engineering;empirical study;software maintenance;traceability links},
  owner = {Til},
  timestamp = {2014.03.14}
}

@BOOK{Jablonski1996,
  title = {Workflow management: modeling concepts, architecture and implementation},
  publisher = {International Thomson Computer Press},
  year = {1996},
  author = {Jablonski, S. and Bussler, C.},
  owner = {patrickr},
  timestamp = {2012.11.26}
}

@ARTICLE{Jaccheri1993,
  author = {Jaccheri, M.L. and Conradi, R.},
  title = {Techniques for process model evolution in EPOS},
  journal = {Software Engineering, IEEE Transactions on},
  year = {1993},
  volume = {19},
  pages = {1145--1156},
  number = {12},
  file = {Jaccheri1993.pdf:literature/Jaccheri1993.pdf:PDF},
  owner = {patrickr},
  publisher = {IEEE},
  timestamp = {2012.07.23}
}

@INPROCEEDINGS{Jackson2000,
  author = {Daniel Jackson and Martin Rinard},
  title = {Software analysis: a roadmap},
  booktitle = {Proceedings of the Conference on The Future of Software Engineering,
	ICSE '00},
  year = {2000},
  pages = {133-145},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We describe the challenges of software analysis by presenting a series
	ofdichotomies.Each gives a spectrum on which any particular analysis
	can be placed;together,they give some structure to the space ofpossible
	analyses.Our intent is not,however,to provide a survey of existing
	analyses within this space,but to argue that some regions are more
	likely to be important in the future than others.Recognizing that
	our opinions do not represent the consensus ofthe community,we have
	tried,for each dichotomy,to make a case for both extremes (or at
	least identifying the contexts in which one makes more sense) while
	arguing primarily for one over the other. 
	
	We argue that in the future analyses will be model-driven, namely
	centered on abstract models of behaviour; modular and incremental,
	to enable analysis of components, and of systems before completion;and
	focused and partial,rather than uniform, paying closer attention
	to properties that matter most and to the parts of the software that
	affect those properties. In support of such analyses,we expect modelling
	languages to be global,with a focus on structural relationships across
	the system,and declarative, and we expect the analyses themselves
	to make more use of induction than has been fashionable recently.Finally,although
	we believe that unsound analyses have a bright future,we expect the
	increasing importance of infrastructural software to bring a renewed
	credibility to sound, precise and resource-intensive analyses.},
  doi = {http://doi.acm.org/10.1145/336512.336545},
  file = {:./literature/icse00.pdf:PDF},
  isbn = {1-58113-253-0},
  keywords = {software engineering, software analysis},
  location = {Limerick, Ireland},
  owner = {Stephan},
  review = {discussion about analysis techniques - overall not helpful
	
	
	analysis: extraction of behavioural information from the software
	represented as an abstract model or code
	
	
	global vs. local models:
	
	- two kinds: object models, state transition diagrams
	
	- static (syntactic strukture) vs. dynamic (runtime states)
	
	- data intensive vs. control intensive
	
	- global relationships vs. states of an individual object
	
	
	mapping of models to code:
	
	- nodes in an object model might map to classes in an oo language,
	actions in an event model might map to specific method invocations
	
	-> challange: need for more sophisticated mappings to account for
	implementation decisions},
  timestamp = {2008.04.17},
  url = {http://cag.csail.mit.edu/~rinard/paper/icse00.pdf}
}

@BOOK{Jacobson1993,
  title = {Object-Oriented Software Engineering: A Use Case Driven Approach},
  publisher = {Addison-Wesley},
  year = {1993},
  author = {Ivar Jacobson},
  pages = {528},
  keywords = {object-oriented programming, software engineering},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.15}
}

@BOOK{Jacobson1997,
  title = {Software reuse: architecture, process and organization for business
	success},
  publisher = {ACM Press/Addison-Wesley Publishing Co.},
  year = {1997},
  author = {Ivar Jacobson and Martin Griss and Patrik Jonsson},
  pages = {528},
  isbn = {0-201-92476-5},
  keywords = {software reuse, software architecture, software process},
  owner = {Robert},
  timestamp = {2008.07.15},
  url = {http://www.amazon.com/Software-Reuse-Architecture-Organization-Business/dp/0201924765}
}

@INPROCEEDINGS{JAÂ©ron1999,
  author = {Thierry Jaeron and Jean-Marc Jaezaequel and Yves Le Traon and Pierre
	Morel},
  title = {Efficient Strategies for Integration and Regression Testing of OO
	Systems},
  booktitle = {Proceedings of the 10th International Symposium on Software Reliability
	Engineering},
  year = {1999},
  pages = {260},
  publisher = {{IEEE} Computer Society},
  abstract = {In this paper, we present a model, a strategy and a methodology for
	planning integration and regression testing from an {OO} model. We
	show how to produce a model of structural system test dependencies
	which evolves with the refinement process of the {OO} design. The
	model, that is the test dependency graph, serves as a basis for ordering
	classes and methods to be tested for regression and integration purposes
	(minimization of test stubs. The mapping from {UML} to the defined
	model is detailed as well as the test methodology. While the complexity
	of optimal stub minimization is exponential with the size of the
	model, an algorithm which computes a strategy for integration testing
	with a quadratic complexity is detailed This algorithm provides an
	efficient testing order for minimizing the number of stubs. A comparison
	is given of various integration strategies with the proposed optimized
	algorithm (a real-world case study illustrates this comparison).
	The results of the experiments seem to give nearly optimal stubs
	with a low cost despite the exponential complexity of getting optimal
	stubs.},
  file = {:/literature/RegressionTesting/Efficient Strategies for Integration and Regression Testing of OO Systems.pdf:PDF},
  isbn = {0-7695-0443-4},
  keywords = {design-for-testability, oo systems, test dependency graph, testing
	strategies, uml},
  owner = {Annie},
  review = {not enough details for regression testing},
  timestamp = {2011.01.04},
  url = {http://portal.acm.org/citation.cfm?id=851020.856188&coll=GUIDE&dl=GUIDE&CFID=54491404&CFTOKEN=93053143}
}

@PHDTHESIS{Jansen2008a,
  author = {Jansen, Anton},
  title = {Architectural design decisions},
  school = {University of Groningen},
  year = {2008},
  file = {:./literature/thesis_anton_jansen.pdf:PDF},
  owner = {Sebastian},
  timestamp = {2013.07.26}
}

@ARTICLE{BabarASR2013, 
author={Lianping Chen and Ali Babar, M. and Nuseibeh, B.}, 
journal={Software, IEEE}, 
title={Characterizing Architecturally Significant Requirements}, 
year={2013}, 
month={March}, 
volume={30}, 
number={2}, 
pages={38-45}, 
keywords={software architecture;ASR;architecturally significant requirements;architecture interactions;empirical study;grounded theory;software development experiences;Computer architecture;Contracts;Software architecture;Software devlopment;ASR;architecturally significant requirements;empirical study;grounded theory;nonfunctional requirements;quality attributes;requirements;software architectures;software engineering;specifications}, 
doi={10.1109/MS.2012.174}, 
ISSN={0740-7459},}

@INPROCEEDINGS{Jansen2005,
  author = {Jansen, Anton and Bosch, Jan},
  title = {Software Architecture as a Set of Architectural Design Decisions},
  booktitle = {5th Working Conf. on Software Architecture},
  year = {2005},
  pages = {109-120},
  abstract = {Software architectures have high costs for change, are complex, and
	erode during evolution. We believe these problems are partially due
	to knowledge vaporization. Currently, almost all the knowledge and
	information about the design decisions the architecture is based
	on are implicitly embedded in the architecture, but lack a first-class
	representation. Consequently, knowledge about these design decisions
	disappears into the architecture, which leads to the aforementioned
	problems. In this paper, a new perspective on software architecture
	is presented, which views software architecture as a composition
	of a set of explicit design decisions. This perspective makes architectural
	design decisions an explicit part of a software architecture. Consequently,
	knowledge vaporization is reduced, thereby alleviating some of the
	fundamental problems of software architecture.},
  doi = {http://dx.doi.org/10.1109/WICSA.2005.61},
  file = {:./literature/JansenBosch_ArchitectureDesignDecisions.pdf:PDF},
  isbn = {0-7695-2548-2},
  keywords = {software architecture, design decisions},
  owner = {Stephan},
  review = {a software architecture is seen as a set of architectural design decisions
	
	
	a definition of design decision is provided
	
	
	Archium design approach:
	
	an architectural model and a decision model are combined in an composition
	model},
  timestamp = {2009.08.05}
}

@ARTICLE{Jansen2008,
  author = {Jansen, Anton and Bosch, Jan and Avgeriou, Paris},
  title = {Documenting after the fact: Recovering architectural design decisions},
  journal = {The Journal of Systems and Software},
  year = {2008},
  volume = {81},
  pages = {536--557},
  number = {4},
  address = {New York, NY, USA},
  citeulike-article-id = {6112564},
  file = {:./literature/jansen2008.pdf:PDF},
  owner = {Sebastian},
  posted-at = {2009-11-15 07:47:54},
  priority = {0},
  publisher = {Elsevier Science Inc.},
  timestamp = {2013.07.23}
}

@ARTICLE{Jarke1998,
  author = {Jarke, Matthias},
  title = {Requirements tracing},
  journal = {Commun. ACM},
  year = {1998},
  volume = {41},
  pages = {32--36},
  number = {12},
  month = {December},
  acmid = {290145},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/290133.290145},
  file = {:./literature/Paper_245.pdf:PDF},
  issn = {0001-0782},
  issue = {12},
  numpages = {5},
  owner = {Steffen},
  publisher = {ACM},
  timestamp = {2012.06.11},
  url = {http://doi.acm.org/10.1145/290133.290145}
}

@BOOK{Jarke1993a,
  title = {Database application engineering with DAIDA},
  publisher = {Springer-Verlag New York, Inc.},
  year = {1993},
  author = {Jarke, M.},
  owner = {patrickr},
  timestamp = {2012.08.15}
}

@INPROCEEDINGS{Jarke2004,
  author = {Jarke, M. and Miatidis, M. and Schluter, M. and Brandt, S.},
  title = {Media-assisted product and process traceability in supply chain engineering},
  booktitle = {System Sciences, 2004. Proceedings of the 37th Annual Hawaii International
	Conference on},
  year = {2004},
  pages = {10--pp},
  organization = {IEEE},
  file = {Jarke2004.pdf:literature/Jarke2004.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.08.01}
}

@INPROCEEDINGS{Jashki2008,
  author = {Jashki, Mohammad-Amin and Zafarani, Reza and Bagheri, Ebrahim},
  title = {Towards a More Efficient Static Software Change Impact Analysis Method},
  booktitle = {Proceedings of the 8th ACM SIGPLAN-SIGSOFT workshop on Program analysis
	for software tools and engineering (PASTE '08)},
  year = {2008},
  file = {:./literature/Paper_28.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- current approaches for IA only focus on source files, not on media,
	configuration, documentation files
	
	- web-based platforms use declarative XML-languages rather than procedural
	languages, so most static/dynamic IA fail
	
	
	Research Questions:
	
	- how to mine software repositories to find closely related files
	which provide
	
	
	Contribution:
	
	- static IA method that creates clusters of closely associated program
	files based on their modification history from repositories
	
	- new metric for measuring conceptual distance of 2 files
	
	
	Solution:
	
	- basic assumption: files frequently seen together in commits have
	impact on each other
	
	- create a matrix storing mutual file manipulations (gained from change
	logs), informs about degree of closeness between 2 files
	
	- estimate a lower dimensional representation of the matrix through
	Principle Component Analysis (PCA) and then reduce matrix
	
	- create clusters of closely related files from this matrix
	
	-> granularity of entities: files
	
	-> granularity of changes: CVS change records
	
	-> granularity of results: files
	
	
	Open Issues:
	
	- files committed in a single working session are considered as interdependent
	/ similar which is not always true (same issue as Sherriff2007)
	
	- doesn't work for projects in early stage, since very few change
	logs are available (same as Sherriff2007)
	
	- precision depends on clustering algorithm and is max. 69%},
  timestamp = {2011.02.02}
}

@INPROCEEDINGS{Jastram2011,
  author = {Jastram, M. and Graf, A.},
  title = {Requirements, Traceability and DSLs in Eclipse with the Requirements
	Interchange Format (RIF/ReqIF)},
  booktitle = {Proceedings Workshop Modellbasierte Entwicklung eingebetteter Systeme
	(MBEES2011)},
  year = {2011},
  month = {February},
  organization = {Dagstuhl},
  file = {:./literature/Requirements_Traceability_and_DSLs_in_Eclipse_with_the_Requirements_Interchange_Format.pdf:PDF},
  owner = {gerlach},
  quality = {1},
  timestamp = {2013.05.02}
}

@ARTICLE{Jaufman2005,
  author = {Jaufman, O. and M{\"u}nch, J.},
  title = {Acquisition of a project-specific process},
  journal = {Product Focused Software Process Improvement},
  year = {2005},
  pages = {13--32},
  file = {Jaufman2005.pdf:literature/Jaufman2005.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.07.20}
}

@BOOK{Jeckle2003,
  title = {UML 2 glasklar},
  publisher = {Hanser Fachbuchverlag},
  year = {2003},
  author = {Jeckle, Mario and Rupp, Chris and Hahn, J{\"u}rgen and Zengler, Barbara
	and Queins, Stefan},
  abstract = {Wirklich neu ist UML inzwischen nicht mehr, dennoch gibt es noch viele
	Ber{\"u}hrungs{\"a}ngste, was vor allem an einem mangelnden {\~A}?berblick
	{\"u}ber die M{\"o}glichkeiten und der fehlenden Einsicht in den
	Praxisbezug zu liegen scheint. Mit UML 2 glasklar vom Autorenteam
	Mario Jeckle, Chris Rupp, J{\"u}rgen Hahn, Barbara Zengler und Stefan
	Queins ist diese Begr{\"u}ndung zumindest im deutschen Sprachraum
	keine Entschuldigung mehr: Das Buch sorgt einerseits f{\"u}r einen
	umfassenden {\~A}?berblick {\"u}ber alle ...},
  keywords = {UML 2},
  owner = {Robert},
  timestamp = {2008.07.15},
  url = {http://www.jeckle.de/{UML}-glasklar/}
}

@INPROCEEDINGS{Jeske2000,
  author = {Jeske, D.R. and Akber Qureshi, M.},
  title = {Estimating the failure rate of evolving software systems},
  booktitle = {Software Reliability Engineering, 2000. ISSRE 2000. Proceedings.
	11th International Symposium on},
  year = {2000},
  pages = {52 -61},
  __markedentry = {[qurat:]},
  doi = {10.1109/ISSRE.2000.885860},
  file = {:/literature/RegressionTesting/00885860.pdf:PDF},
  keywords = {failiure estimation, customer usage patterns;customer-perceived failure
	rate;evolving software systems;operational profile;posterior distribution;simulated
	load scenarios;software failure rate estimation;software products;software
	testing;program testing;software reliability;},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@INPROCEEDINGS{Jeuring2006,
  author = {Johan Jeuring and Rinus Plasmeijer},
  title = {Generic Programming for Software Evolution},
  booktitle = {Proceedings of the International ERCIM Workshop on Software Evolution
	2006},
  year = {2006},
  editor = {Laurence Duchien, Maja D'Hondt and Tom Mens},
  pages = {97-104},
  address = {France},
  month = {April},
  organization = {LIFL - INRIA, Université des Sciences et Technologies de Lille},
  comment = {ftp://ftp.umh.ac.be/pub/ftp_infofs/2006/ERCIMproceedings.pdf},
  file = {:./literature/2006-024.pdf:PDF;:./literature/ERCIMproceedings2006.pdf:PDF},
  keywords = {generic programming, software evolution},
  owner = {Stephan},
  timestamp = {2008.07.11},
  url = {http://webdoc.sub.gwdg.de/ebook/serien/ah/UU-CS/2006-024.pdf}
}

@INPROCEEDINGS{Jiang2007,
  author = {{Hsin-yi} Jiang and Nguyen, T.N. and Chang, C.K. and Fei Dong},
  title = {Traceability Link Evolution Management with Incremental Latent Semantic
	Indexing},
  booktitle = {31st Annual International Computer Software and Applications Conference
	(COMPSAC 2007)},
  year = {2007},
  volume = {1},
  pages = {309-316},
  month = {July},
  publisher = {IEEE},
  abstract = {As dynamic as software development, software artifacts are also constantly
	in evolution. As a result, traceability links among them are also
	changing over time. Even though traceability link recovery (TLR)
	tools have been successful in generating traceability relations among
	documentation and source code, they work on a snapshot of the artifacts
	at a particular time. Traceability link evolution has not been well-addressed.
	This hinders developers from having good understanding of the evolution
	of software. In this paper, we describe our incremental approach
	to traceability link recovery and management with the latent semantic
	indexing method. To complement with that approach, we suggest the
	use of the versioned hypermedia technology (VH). Traceability links
	can be consistently stored, versioned, and managed across different
	types of software artifacts.},
  doi = {10.1109/COMPSAC.2007.225},
  file = {:./literature/04291019.pdf:PDF},
  keywords = {hypermedia, software management, software prototypingincremental latent
	semantic indexing, software artifacts, software development, software
	evolution, traceability link evolution management, traceability link
	management, traceability link recovery, versioned hypermedia technology},
  owner = {Stephan},
  timestamp = {2009.01.26}
}

@ARTICLE{SPE:SPE1092,
  author = {Jiang, Bo and Tse, T. H. and Grieskamp, Wolfgang and Kicillof, Nicolas
	and Cao, Yiming and Li, Xiang and Chan, W. K.},
  title = {Assuring the model evolution of protocol software specifications
	by regression testing process improvement},
  journal = {Software: Practice and Experience},
  year = {2011},
  volume = {41},
  pages = {1073--1103},
  number = {10},
  doi = {10.1002/spe.1092},
  file = {:/literature/RegressionTesting/Assuring the model evolution of protocol software.pdf:PDF},
  issn = {1097-024X},
  keywords = {model-based testing, regression testing, protocol document testing},
  owner = {Steffen},
  publisher = {John Wiley \& Sons, Ltd},
  timestamp = {2012.03.01},
  url = {http://dx.doi.org/10.1002/spe.1092}
}

@ARTICLE{Jirapanthong2009,
  author = {Jirapanthong, Waraporn and Zisman, Andrea},
  title = {XTraQue: traceability for product line systems},
  journal = {Software and Systems Modeling},
  year = {2009},
  volume = {8},
  pages = {117-144},
  number = {1},
  __markedentry = {[Steffen:]},
  abstract = {Product line engineering has been increasingly used to support the
	development and deployment of software systems that share a common
	set of features and are developed based on the reuse of core assets.
	The large number and heterogeneity of documents generated during
	the development of product line systems may cause difficulties to
	identify common and variable aspects among applications, and to reuse
	core assets that are available under the product line. In this paper,
	we present a traceability approach for product line systems. Traceability
	has been recognised as an important task in software system development.
	Traceability relations can improve the quality of the product being
	developed and reduce development time and cost. We present a rule-based
	approach to support automatic generation of traceability relations
	between feature-based object-oriented documents. We define a traceability
	reference model with nine different types of traceability relations
	for eight types of documents. The traceability rules used in our
	work are classified into two groups namely (a) direct rules, which
	support the creation of traceability relations that do not depend
	on the existence of other relations, and (b) indirect rules, which
	require the existence of previously generated relations. The documents
	are represented in XML and the rules are represented in an extension
	of XQuery. A prototype tool called XTraQue has been implemented.
	This tool, together with a mobile phone product line case study,
	has been used to demonstrate and evaluate our work in various experiments.
	The results of these experiments are encouraging and comparable with
	other approaches that support automatic generation of traceability
	relations.},
  affiliation = {Dhurakij Pundit University Faculty of Information Technology 110/1-4
	Prachachuen Road Laksi Bangkok 10210 Thailand},
  doi = {10.1007/s10270-007-0066-8},
  file = {:./literature/Jirapanthong2009.pdf:PDF},
  issn = {1619-1366},
  issue = {1},
  keyword = {Computer Science},
  keywords = {rule-based traceability},
  owner = {Stephan},
  publisher = {Springer Berlin / Heidelberg},
  timestamp = {2010.12.11},
  url = {http://dx.doi.org/10.1007/s10270-007-0066-8}
}

@TECHREPORT{Johansen2005,
  author = {Trond Johansen and Tom Gilb},
  title = {From Waterfall to Evolutionary Development (Evo): How we rapidly
	created faster, more user-friendly, and more productive software
	products for a competitive multi-national market},
  institution = {FIRM A/S},
  year = {2005},
  abstract = {Evolutionary development (Evo) focuses on early delivery of high value
	to stakeholders, and on obtaining and utilizing feedback from stakeholders.
	This paper describes from a project manager’s viewpoint, the positive
	experiences that one organization rapidly achieved on switching from
	using the Waterfall method to Evo. Major benefit came from paying
	greater attention to the quality requirements as opposed to the previous
	practice of concentrating solely on the required functionality.},
  file = {:./literature/FIRM-FromWaterfall2Evo.pdf:PDF},
  keywords = {Evolutionary Development, Usability, Method},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://www.compaid.com/caiInternet/ezine/FIRM-FromWaterfall2Evo.pdf}
}

@ARTICLE{Johansson2005,
  author = {Johansson, E. and Nedstam, J. and Wartenberg, F. and H{\"o}st, M.},
  title = {A qualitative methodology for tailoring SPE activities in embedded
	platform development},
  journal = {Product Focused Software Process Improvement},
  year = {2005},
  pages = {267--289},
  file = {Johansson2005.pdf:literature/Johansson2005.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.07.20}
}

@BOOK{Jones1998,
  title = {Estimating software costs},
  publisher = {McGraw-Hill},
  year = {1998},
  author = {Jones, C. and Jones, T.C.},
  volume = {3},
  owner = {patrickr},
  timestamp = {2013.01.02}
}

@ARTICLE{Jones2008,
  author = {Jones, C. and Lichtenstein, B.B.},
  title = {Temporary inter-organizational projects: How temporal and social
	embeddedness enhance coordination and manage uncertainty},
  journal = {The Oxford handbook of inter-organizational relations},
  year = {2008},
  pages = {231--255},
  file = {Jones2008.pdf:literature/Jones2008.pdf:PDF},
  owner = {patrickr},
  publisher = {Oxford: Oxford},
  timestamp = {2012.10.19}
}

@TECHREPORT{Jones2005,
  author = {Steve Jones and Mike Morris},
  title = {A Methodology for Service Architectures},
  institution = {Capgemini},
  year = {2005},
  month = {October},
  abstract = {Service Oriented Architecture is a powerful term that is regularly
	abused to refer to development technologies rather than an architectural
	approach, in the same was as Object Oriented Design was abused to
	refer to programming languages rather than a fundamentally different
	approach to design. This paper lays down a methodology for Service
	Oriented Architecture which deals only with Service as it applies
	to Architecture, and with Architecture where it is about exposing
	the Services framework. Its purpose is to explain how a Service Architecture
	is created, how this in turn drives Service Orientation in broader
	Enterprise and Solution architectures, and how this impacts all aspects
	of IT delivery from Business Process to standard code development.
	The Service Architecture methodology described here is fundamentally
	a process of top-down discovery of what a business or business problem
	is about, rather than the “how” of implementation. Architecture is
	about context, frameworks, blueprints and standards, not about the
	individual aspects of delivery. Other methodologies already describe
	how to deliver software projects, this methodology helps provide
	the architecture to ensure that the delivery is Service Oriented.},
  file = {:./literature/jones2005.pdf:PDF},
  keywords = {methodology, service architectures},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://www.oasis-open.org/apps/group_public/download.php/15071/A%20methodology%20for%20Service%20Architectures%201%202%204%20-%20OASIS%20Contribution.pdf}
}

@INPROCEEDINGS{Juergens2011,
  author = {Juergens, E. and Hummel, B. and Deissenboeck, F. and Feilkas, M.
	and Schlo? andgel, C. and Wu? andbbeke, A.},
  title = {Regression Test Selection of Manual System Tests in Practice},
  booktitle = {Software Maintenance and Reengineering (CSMR), 2011 15th European
	Conference on},
  year = {2011},
  pages = {309 -312},
  month = {march},
  __markedentry = {[qurat:]},
  doi = {10.1109/CSMR.2011.44},
  file = {:/literature/RegressionTesting/Regression Test Selection of Manual System Tests in Practice.pdf:PDF},
  issn = {1534-5351},
  keywords = {analysis comparative, code modifications;impact analysis;manual system
	tests;regression test selection;software maintenance;program testing;software
	maintenancec},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@ARTICLE{Jugdev2005,
  author = {Jugdev, K. and Muller, R.},
  title = {A retrospective look at our evolving understanding of project success},
  journal = {Project Management Journal},
  year = {2005},
  volume = {36},
  pages = {19},
  number = {4},
  file = {Jugdev2005.pdf:literature/Jugdev2005.pdf:PDF},
  owner = {patrickr},
  publisher = {Project Management Institute},
  timestamp = {2012.10.18}
}

@MASTERSTHESIS{Jung2008,
  author = {Reiner Jung},
  title = {Ontology-based Metadata for MidArch-Styles},
  school = {Universität Oldenburg},
  year = {2008},
  type = {Diploma Thesis},
  abstract = {The MidArch-Method is a process developed by Simon Giesecke for migration
	and integration of middleware-based enterprise applications. His
	process uses middleware-oriented architectural styles for the development
	of the resulting system architecture. A middleware-based style is
	an architectural style where the primary elements of composition
	are based on different middleware technologies and frameworks. For
	example the style inversion of control introduces container and embedded
	components as composition elements. The framework Spring for instances
	developed around inversion of control. A specialized style for Spring
	includes additional restrictions and specialized composition elements.
	This approach results in a vast set of architectural styles. The
	selection of a appropriate style for a given migration or integration
	effort is therefore a complex task. 
	
	
	In practice, the decision for an architectural style is often made
	ad-hoc and not in a systematic way. In my thesis, I developed an
	approach based on metadata of architectural styles. The approach
	is based on extracting properties of middleware-oriented architectural
	styles from the technical documentation. The metadata is represented
	using a OWL/SWRL ontology. In addition, I developed an approach for
	using this metadata to support the selection of an architectural
	style. A case study for a Web-based information system evaluates
	the proposed approach.},
  comment = {Ontology for download http://www.oiloftrop.de/images/publications/style-meta-data.owl},
  file = {:./literature/Jung2008.pdf:PDF},
  owner = {matthias},
  timestamp = {2013.01.28},
  url = {http://www.oiloftrop.de/images/publications/thesis.pdf}
}

@BOOK{Jungnickel1999,
  title = {Graphs, networks and algorithms},
  publisher = {Springer-Verlag},
  year = {1999},
  author = {Dieter Jungnickel},
  volume = {5},
  series = {Algorithms and Computation in Mathematics},
  adress = {Berlin ; Heidelberg [u.a.]},
  category = {network},
  doi = {10.1007/b138283},
  owner = {Robert},
  status = {skimmed},
  timestamp = {2008.07.15},
  url = {http://books.google.de/books?hl=de&lr=&id=aW19U_HQDucC&oi=fnd&pg=PR7&ots=gdoXNQJzgQ&sig=TK4RZmlLd2k95dJmXyHly7a4Kw4}
}

@ARTICLE{Jurison1999,
  author = {Jurison, J.},
  title = {Software project management: the manager's view},
  journal = {Communications of the AIS},
  year = {1999},
  volume = {2},
  pages = {2},
  number = {3es},
  file = {Jurison1999.pdf:literature/Jurison1999.pdf:PDF},
  owner = {patrickr},
  publisher = {Association for Information Systems},
  timestamp = {2012.10.18}
}

@INPROCEEDINGS{Kuester2012a,
  author = {Martin K{\"u}ster and Benjamin Klatt},
  title = {{Leveraging Design Decisions in Evolving Systems}},
  booktitle = {14th Workshop Software-Reengineering (WSR 2012)},
  year = {2012},
  address = {Bad-Honnef, Germany},
  month = {May 02-04},
  bdsk-url-1 = {http://fg-sre.gi.de/konferenzen/wsr/wsr-2012.html},
  file = {:./literature/kuester2012a.pdf:PDF},
  owner = {matthias},
  pdf = {http://sdqweb.ipd.uka.de/publications/pdfs/kuester2012a.pdf},
  timestamp = {2013.01.28},
  url = {http://fg-sre.gi.de/konferenzen/wsr/wsr-2012.html}
}

@INPROCEEDINGS{Konemann:2010:CIM:1929101.1929114,
  author = {K\"{o}nemann, Patrick},
  title = {Capturing the intention of model changes},
  booktitle = {Proceedings of the 13th international conference on Model driven
	engineering languages and systems: Part II},
  year = {2010},
  series = {MODELS'10},
  pages = {108--122},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  acmid = {1929114},
  file = {:/literature/changeIdentification/IndepDiff_MODELS10.pdf:PDF},
  isbn = {3-642-16128-6, 978-3-642-16128-5},
  keywords = {model differencing, model patching, model refactoring},
  location = {Oslo, Norway},
  numpages = {15},
  owner = {Steffen},
  timestamp = {2012.03.01},
  url = {http://dl.acm.org/citation.cfm?id=1929101.1929114}
}

@INPROCEEDINGS{Konemann2010,
  author = {K\"{o}nemann, Patrick},
  title = {Capturing the intention of model changes},
  booktitle = {Proceedings of the 13th international conference on Model driven
	engineering languages and systems: Part II},
  year = {2010},
  series = {MODELS'10},
  pages = {108-122},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  acmid = {1929114},
  file = {:/literature/changeIdentification/Capturing the Intention of Model Changes.pdf:PDF},
  isbn = {3-642-16128-6, 978-3-642-16128-5},
  keywords = {Read, model differencing, model patching, model refactoring},
  location = {Oslo, Norway},
  numpages = {15},
  owner = {Steffen},
  review = {CHANGES
	
	+ Atomic Changes
	
	+Semantic Changes
	
	+model independent changes},
  timestamp = {2012.03.01},
  url = {http://dl.acm.org/citation.cfm?id=1929101.1929114}
}

@TECHREPORT{Konemann2009,
  author = {K\"{o}nemann, Patrick},
  title = {Integrating decision management with UML modeling concepts and tools},
  institution = {Technical University of Denmark},
  year = {2009},
  number = {IMM-Technical Report-2009-07},
  month = {April},
  file = {:/literature/changeIdentification/tr09_07-decisions_tr_v4.pdf:PDF},
  journal = {2009 Joint Working IEEEIFIP Conference on Software Architecture European
	Conference on Software Architecture},
  keywords = {Read},
  owner = {Steffen},
  pages = {297--300},
  publisher = {Ieee},
  timestamp = {2012.03.01},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5290824}
}

@INPROCEEDINGS{Konemann2009a,
  author = {K\"{o}nemann, Patrick},
  title = {Model-independent differences},
  booktitle = {Proceedings of the 2009 ICSE Workshop on Comparison and Versioning
	of Software Models},
  year = {2009},
  series = {CVSM '09},
  pages = {37-42},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid = {1564647},
  doi = {http://dx.doi.org/10.1109/CVSM.2009.5071720},
  file = {:/literature/changeIdentification/tr08_20.pdf:PDF},
  isbn = {978-1-4244-3714-6},
  keywords = {read},
  numpages = {6},
  owner = {Steffen},
  timestamp = {2012.03.01},
  url = {http://dx.doi.org/10.1109/CVSM.2009.5071720}
}

@INPROCEEDINGS{Koenemann2009,
  author = {K\"{o}nemann, Patrick and Kindler, Ekkart and Unland, Ludger},
  title = {Difference-based Model Synchronization in an Industrial MDD Process},
  booktitle = {Proceedings of the Second European Workshop on Model Driven Tool
	and Process Integration},
  year = {2009},
  volume = {Second European Workshop on Model Driven Tool and Process Integration9},
  pages = {1-12},
  organization = {Enschede, Netherlands},
  abstract = {Models play a central role in model-driven software engineering. There
	are different kinds of models during the development process, which
	are related to each other and change over time. Therefore, it is
	difficult to keep the different models consistent with each other.
	Consistency of different models is maintained manually in many cases
	today. This paper presents an approach for automated model differencing,
	so that the differences between two model versions can be extracted
	and stored. It can then be re-used independently of the models it
	was created from to interactively merge different model versions,
	and for synchronizing other types of models. The main concern is
	to apply our concepts to an industrial process, in particular keeping
	usability and performance in mind.},
  file = {:/literature/changeIdentification/tr08_07-net.pdf:PDF},
  keywords = {Read},
  owner = {Annie},
  review = {Changes
	
	
	+Atomic Change
	
	 +ChangedValue
	
	 +change type
	
	 +add , change, move, rename
	
	
	+Composite Change
	
	
	 +Composition of atomic and other composite changes},
  timestamp = {2011.10.20}
}

@INCOLLECTION{Koenemann2010,
  author = {K\"{o}nemann, Patrick and Zimmermann, Olaf},
  title = {Linking Design Decisions to Design Models in Model-Based Software
	Development},
  booktitle = {Software Architecture},
  publisher = {Springer Berlin Heidelberg},
  year = {2010},
  editor = {Babar, MuhammadAli and Gorton, Ian},
  volume = {6285},
  series = {Lecture Notes in Computer Science},
  pages = {246-262},
  doi = {10.1007/978-3-642-15114-9_19},
  file = {:./literature/Koenemann2010.pdf:PDF},
  isbn = {978-3-642-15113-2},
  owner = {Sebastian},
  timestamp = {2014.03.18},
  url = {http://dx.doi.org/10.1007/978-3-642-15114-9_19}
}

@INPROCEEDINGS{Kuster2013,
  author = {K\"{u}ster, Martin},
  title = {{Architecture-Centric modeling of design decisions for validation
	and traceability}},
  booktitle = {7th European Conference on Software Architecture (ECSA 2013)},
  year = {2013},
  pages = {184--191},
  annote = {- work of K\"{o}nemann and Zimmermann are very similar in respect
	to the validation / consistency - nutzt das Meta-Modell von Capilla
	et al.- Fokus: semantische Verkn\"{u}pfung f\"{u}r die automatische
	Validierung von getroffenen Entscheidungen - Dokumentation (Recording)
	der Entscheidungen mittels kompakter DSL - Validierung der Entscheidung
	auf G\"{u}ltigkeit anhand von OCL-Contraints},
  doi = {10.1007/978-3-642-39031-9\_16},
  file = {:./literature/Kuester2013.pdf:PDF},
  keywords = {Constraints,Design Decisions,architectural model,traceability},
  mendeley-tags = {Constraints,Design Decisions,architectural model,traceability},
  owner = {Sebastian},
  timestamp = {2014.03.18},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-39031-9\_16}
}

@INPROCEEDINGS{Kuster2012,
  author = {K\"uster, Martin and Trifu, Mircea},
  title = {A case study on co-evolution of software artifacts using integrated
	views},
  booktitle = {Proceedings of the WICSA/ECSA 2012 Companion Volume on - WICSA/ECSA
	'12},
  year = {2012},
  pages = {124},
  address = {New York, New York, USA},
  publisher = {ACM Press},
  doi = {10.1145/2361999.2362025},
  file = {:./literature/kuester2012.pdf:PDF},
  isbn = {9781450315685},
  owner = {Sebastian},
  timestamp = {2014.01.14},
  url = {http://dl.acm.org/citation.cfm?doid=2361999.2362025}
}

@INPROCEEDINGS{Kaartinen2007,
  author = {Kaartinen, J. and Palviainen, J. and Koskimies, K.},
  title = {A Pattern-Driven Process Model for Quality-Centered Software Architecture
	Design--A Case Study on Usability-Centered Design},
  booktitle = {18th Australian Software Engineering Conference, 2007. ASWEC 2007},
  year = {2007},
  pages = {17-26},
  month = {April},
  abstract = {Quality requirements of software systems typically affect large portions
	of the system, and should be taken into account early in the design
	process. Patterns have become a mainstream technique to associate
	frequent quality-related design problems with proven solutions. We
	present a generic pattern-driven design process model, and apply
	this to usability, obtaining a usability-centered design process
	model. As a case study, we have applied the model to the usability-centered
	software architecture design of a stone crusher control system.},
  doi = {10.1109/ASWEC.2007.8},
  file = {:./literature/04159655.pdf:PDF},
  issn = {1530-0803},
  keywords = {object-oriented programming, software architecture, software quality,
	user centred designpattern-driven design process model, quality-centered
	software architecture design, software system quality requirements,
	stone crusher control system, usability-centered design process model,
	usability-centered software architecture design},
  owner = {Stephan},
  timestamp = {2008.04.02}
}

@INPROCEEDINGS{Kabaili2001,
  author = {Kabaili, Hind and Keller, Rudolf K. and Lustman, Fran\c{c}ois},
  title = {A Change Impact Model Encompassing Ripple Effect and Regression Testing},
  booktitle = {Proceedings of the Fifth International Workshop on Quantitative Approaches
	in Object-Oriented Software Engineering},
  year = {2001},
  pages = {25-33},
  address = {Budapest, Hungary},
  file = {:./literature/Paper_102.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- maintenance major problem in SWE
	
	- success of maintenance depends on changeability of software
	
	
	Research Questions:
	
	- how can one evaluate (estimate) changeability of OO software based
	on a formal model for impacts and ripple-effects
	
	
	Contribution:
	
	- change impact model for OO software to evaluate changeability:
	
	* discover classes impacted by ripple-effects
	
	* discover classes that should be re-tested
	
	- model contains ripple-effect model and regression-testing model
	
	
	Solution:
	
	- classes, methods and variables are basic entity of proposed IA model
	
	- changes to classes, methods and variables are considered (i.e. add/remove,
	change super class etc.)
	
	- impact depends on type of change and type of relationship between
	entities
	
	- model for ripple-effects comprised of two steps:
	
	* identify directly affected classes
	
	* apply standard IA model on previous discoverd classes 
	
	 - reason about the type of link/dependency between classes, e.g.
	"Inheritance"
	
	- model for regression testing:
	
	* based on class-dependencies
	
	* reason about dependency graph to find classes which should be re-tested
	
	-> granularity of artifacts: classes, methods, variables
	
	-> granularity of changes: atomic changes to classes, methods and
	variables
	
	-> granularity of results: affected classes
	
	
	Open Issues:
	
	- dependency graph approach likely to report too much as affected
	
	- both proposed models not been tested},
  timestamp = {2011.03.02}
}

@INPROCEEDINGS{Kabaili01changeimpact,
  author = {Hind Kabaili and Rudolf K. Keller and FranÃ§ois Lustman and D\'{e}partement
	Iro and Universit\'{e} De Montr\'{e}al},
  title = {Change Impact Model Encompassing Ripple Effect and Regression Testing},
  booktitle = {In Proceedings of the Fifth International Workshop on Quantitative
	Approaches in Object-Oriented Software Engineering},
  year = {2001},
  pages = {25--33},
  file = {:/literature/RegressionTesting/a change impact model encompassing.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.03.01}
}

@ARTICLE{Kafeza2001,
  author = {Kafeza, E. and Chiu, D. and Kafeza, I.},
  title = {View-based contracts in an e-service cross-organizational workflow
	environment},
  journal = {Technologies for E-Services},
  year = {2001},
  pages = {74--88},
  file = {Kafeza2001.pdf:literature/Kafeza2001.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.10.10}
}

@PHDTHESIS{Kagdi2008,
  author = {Kagdi, Huzefa},
  title = {Mining Software Repositories to support software evolution},
  school = {Kent State University},
  year = {2008},
  month = {August},
  file = {:./literature/PhD_3.pdf:PDF},
  owner = {Steffen},
  review = {- thesis is build upon comprehensive survey of MSR in {Kagdi2007b}
	
	- thesis develops approach to mine evolutionary couplings from version
	histories, which then can be used for impact analysis
	
	- mining approach is combined with dependency analysis of single version
	to improve coupling detection
	
	- goal is to build a holistic software change recommendation approach
	
	- apply dependency analysis on single version and validate the results
	with MSR
	
	- approach mines a certain potion of version history (called training
	set) to infer change couplings, then mine later versions to check
	whether changes can be predicted properly with training set
	
	- thesis applies MSR for various problems next to impact analysis,
	i.e mining for traceability links from repositories
	
	
	- scope of analysis: code
	
	- tool: codeDiff, sqminer
	
	- language:
	
	- scalability: -
	
	- granularity
	
	* changes: change record
	
	* artifacts: file, class, method, variable
	
	* results: file, class, method, variable
	
	- technique: HM, DG
	
	- analysis style: global
	
	- evaluation
	
	* size: 600 KLOC
	
	* precision: -
	
	* recall: -
	
	* time: -},
  timestamp = {2011.02.08}
}

@INPROCEEDINGS{Kagdi2007c,
  author = {Kagdi, Huzefa},
  title = {Improving Change Prediction with Fine-Grained Source Code Mining},
  booktitle = {Proceedings of the twenty-second IEEE/ACM international conference
	on Automated software engineering},
  year = {2007},
  pages = {559-562},
  address = {New York, NY, USA},
  file = {:./literature/Paper_53.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- current IA approaches based on MSR usually consider files and entities
	on very high level of abstraction
	
	
	Research Questions:
	
	- apply MSR on fine-grained software/source code entities (not just
	on level of files)
	
	
	Contribution:
	
	- change preditcion approach based on fine-grained couplings between
	source code entities mined from CVS repository
	
	- combination with trad. IA techniques as static analysis to improve
	prediction
	
	
	Solution:
	
	- extend MSR to lower code levels such as control statements, preprocessor
	directives and comments/annotations
	
	- basic approach consists of 3 steps:
	
	* extract change-sets from CVS
	
	* process changes at various levels of abstraction
	
	 * obtain this information at the granularity of source code lines
	by applying line-diff algorithms/tools and transfer it into srcML
	(code as XML)
	
	 * use standard XML tools to get changes (add/delete/insert) between
	two XML documents
	
	* apply data mining techniques to infer couplings by change prediction
	rules
	
	 * use 3 heuristics to group related change sets:
	
	 - TimeInterval: all changes within certain amount of time are considered
	related
	
	 - Committer: all changes by a certain developer considered related
	
	 - TimeIntervall + Committer: combination of both heuristics
	
	- use MSR and IA to cross-validate and evaluate each other to supply
	better results
	
	-> granularity of entities: class, method, statement
	
	-> granularity of changes: adaptable
	
	-> granularity of results: class, method, statement
	
	
	Open Issues:
	
	- additional gain of combination with trad. (dependency.based) IA
	techniques
	
	- proposed heuristics don't seem to be much useful, should be replaced
	by other ones},
  timestamp = {2011.02.09}
}

@ARTICLE{Kagdi2007b,
  author = {Kagdi, Huzefa and Collard, Michael L. and Maletic, Jonathan I.},
  title = {A survey and taxonomy of approaches for mining software repositories
	in the context of software evolution},
  journal = {Journal of Software Maintenance and Evolution: Research and Practice},
  year = {2007},
  volume = {19},
  pages = {77-131},
  booktitle = {Journal of Software Maintenance and Evolution: Research and Practice},
  file = {:./literature/Paper_46.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	
	Research Questions:
	
	
	Contribution:
	
	
	Solution:
	
	
	Open Issues:},
  timestamp = {2011.02.08}
}

@INPROCEEDINGS{Kagdi2005,
  author = {Kagdi, Huzefa. and Collard, Michael L. and Maletic, Jonathan I.},
  title = {Towards a taxonomy of approaches for mining of source code repositories},
  booktitle = {Proceedings of the 2nd International Workshop on Mining Software
	Repositories (MSR '05)},
  year = {2005},
  pages = {90-94},
  address = {New York},
  file = {:./literature/Paper_47.pdf:PDF},
  owner = {Steffen},
  review = {- first attempt of a survey for MSR approaches, likely the early version
	of Kagdi2007b
	
	
	Problem:
	
	- version repositories provide detailed information on changes, but
	not in a source code-aware manner concerning syntax and semantics
	
	
	Research Questions:
	
	- methods to gain more usable change information from source code
	repositories
	
	- what methods are available for Mining Software Repositories (MSR)
	
	
	Contribution:
	
	- discussion of several MSR techniques
	
	- taxonimic description of MSR approaches},
  timestamp = {2011.02.08}
}

@INPROCEEDINGS{Kagdi2010,
  author = {Kagdi, Huzefa and Gethers, Malcom and Poshyvanyk, Denys and Collard,
	Michael L.},
  title = {Blending Conceptual and Evolutionary Couplings to Support Change
	Impact Analysis in Source Code},
  booktitle = {Proceedings of the 17th IEEE Working Conference on Reverse Engineering
	(WCRE'10)},
  year = {2010},
  pages = {119-128},
  address = {Beverly, Massachusetts, USA},
  month = {October},
  file = {:./literature/Paper_163.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- much work spent on IA techniques
	
	- however, most approaches still lack accuracy
	
	
	Research Questions:
	
	- improve accuracy of existing IA approaches
	
	
	Contribution:
	
	- new IA technique that combines evolutionary and conceptual techniques
	
	- technique is developer-centric, i.e. focused on identifiers, comments
	etc.
	
	
	Solution:
	
	- conceptual information obtained with IR techniques
	
	- evolutionary information (co-change patterns) mined from historical
	sources
	
	- approach consists of 4 steps:
	
	* select first entity
	
	* compute conceptual couplings with IR using the version of the selected
	entity
	
	 - compute similarities between entities
	
	* mine commits from repository to compute evolutionary couplings,
	consider only versions before step 2
	
	 - use "itemset"-mining as order of entities is not important
	
	 - retrieve change sets from repository
	
	 - process fine-grained change sets
	
	 - mine evolutionary couplings
	
	* combine both couplings to predict the impact
	
	 - question whether to use the intersection or union of both
	
	-> granularity of entities: statement
	
	-> granularity of changes:
	
	-> granularity of results: statement
	
	
	Open Issues:
	
	- combine and evaluate other conceptual and evolutionary couplings
	
	- addition of static and dynamic analysis information},
  timestamp = {2011.07.25}
}

@INPROCEEDINGS{Kagdi2007a,
  author = {Kagdi, Huzefa and Maletic, Jonathan I.},
  title = {Combining Single-Version and Evolutionary Dependencies for Software-Change
	Prediction},
  booktitle = {Proceedings of 4th International Workshop on Mining Software Repositories
	(MSR'07)},
  year = {2007},
  pages = {107-110},
  address = {Minneapolis, MN},
  month = {May},
  file = {:./literature/Paper_41.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- mining version histories / repositories has become important during
	last years
	
	- version histories provide useful information to perform IA
	
	- IA via dependencies focuses on a single version / snapshot only,
	which might not be complete or contains enough information
	
	
	Research Questions:
	
	- couple "traditional IA" with investigation of version histories
	gained from repositories
	
	
	Contribution:
	
	- approach for coupled IA through history mining and dependency detection
	(aka trad. IA techniques)
	
	
	Solution:
	
	- convert source code from histories into XML using srcML
	
	- use frequent pattern mining tool to uncover co-changes from code
	repository
	
	-> granularity of entities: adaptable
	
	-> granularity of changes: adaptable analysis of change records
	
	-> granularity of results: adaptable
	
	
	Open Issues:
	
	- if dependency prediction and history prediction produce different
	results, which one to trust?},
  timestamp = {2011.02.04}
}

@INPROCEEDINGS{Kagdi2007d,
  author = {Kagdi, Huzefa and Maletic, Jonathan I.},
  title = {Software Repositories: A Source for Traceability Links},
  booktitle = {Proceedings of the 4th ACM International Workshop on Traceability
	in Emerging Forms of Software Engineering (GCT/TEFSE’07)},
  year = {2007},
  pages = {32-39},
  address = {Lexington, KY, USA},
  month = {March},
  file = {:./literature/Paper_104.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.03.03}
}

@INPROCEEDINGS{Kagdi2006,
  author = {Kagdi, Huzefa and Maletic, Jonathan I.},
  title = {Software-Change Prediction: Estimated+Actual},
  booktitle = {Proceedings of the Second International IEEE Workshop on Software
	Evolvability (SE '06)},
  year = {2006},
  pages = {38-43},
  address = {Philadelphia, PA},
  month = {September},
  file = {:./literature/Paper_44.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- trad. IA only applied on single version and it is non-adaptive
	
	- new mining-software-repositories-approach (MSR) relies only on historical
	data and therefore might infer wrong impacts
	
	
	Research Questions:
	
	- combining estimated change sets of IA and mining-software-repositories
	(MSR) to improve impact prediction
	
	
	Contribution:
	
	- overview of IA and mining-software-repositories (MSR)
	
	- framework to combine IA with MSR
	
	
	Solution:
	
	- use traditional techniques to perform IA on single revisions of
	source code
	
	- use MSR to gather hidden dependencies between multiple revisions
	of source code
	
	-> granularity of entities: adaptable
	
	-> granularity of changes: change records
	
	-> granularity of results: adaptable
	
	
	Open Issues:
	
	- selection of changes / revisions that are used for analysis (e.g.
	rev. 50-200., rev.1-400, all rev.?)},
  timestamp = {2011.02.08}
}

@INPROCEEDINGS{Kagdi2007e,
  author = {Kagdi, Huzefa and Maletic, Jonathan I. and Sharif, Bonita},
  title = {Mining Software Repositories for Traceability Links},
  booktitle = {Proceedings of the 15th IEEE International Conference on Program
	Comprehension (ICPC '07)},
  year = {2007},
  pages = {145-154},
  file = {:./literature/Paper_103.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.03.03}
}

@INPROCEEDINGS{Kampffmeyer2007,
  author = {Holger Kampffmeyer and Steffen Zschaler},
  title = {Finding the Pattern You Need: The Design Pattern Intent Ontology},
  booktitle = {Model Driven Engineering Languages and Systems,Proceedings 10th International
	Conference, MODELS 2007},
  year = {2007},
  editor = {Gregor Engels and Bill Opdyke and Douglas C. Schmidt and Frank Weil},
  volume = {4735/2007},
  series = {LNCS},
  pages = {211-225},
  address = {Nashville, USA},
  publisher = {Springer},
  abstract = {Since the seminal book by the Gang of Four, design patterns have proven
	an important tool in software development. Over time, more and more
	patterns have been discovered and developed. The sheer amount of
	patterns available makes it hard to find patterns useful for solving
	a specific design problem. Hence, tools supporting searching and
	finding design patterns appropriate to a certain problem are required.
	To develop such tooling, design patterns must be described formally
	such that they can be queryed by the problem to be solved. Current
	approaches to formalising design patterns focus on the solution structure
	of the pattern rather than on the problems solved. In this paper,
	we present a formalisation of the intent of the 23 patterns from
	the Gang-of-Four book. Based on this formalisation we have developed
	a Design Pattern Wizard that proposes applicable design patterns
	based on a description of a design problem.},
  doi = {10.1007/978-3-540-75209-7},
  file = {:./literature/models07_dpio.pdf:PDF},
  keywords = {design pattern, ontology},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://www.steffen-zschaler.de/publications/models07_dpio.pdf}
}

@TECHREPORT{Kang1990,
  author = {K. Kang and S. Cohen and J. Hess and W. Novak and A. Peterson},
  title = {Feature-Oriented Domain Analysis ({FODA}) Feasibility Study},
  institution = {SEI Institute, Carnegie Mellon University},
  year = {1990},
  number = {CMU/SEI-90-TR-021},
  address = {USA},
  abstract = {Successful Software reuse requires the systematic discovery and exploitation
	of commonality across related software systems. By examining related
	software systems and the underlying theory of the class of systems
	they represent, domain analysis can provide a generic description
	of the requirements of that class of systems and a set of approaches
	for their implementation. This report will establish methods for
	performing a domain analysis and describe the products of the domain
	analysis process. To illustrate the application of domain analysis
	to a representative class of software systems, this report will provide
	a domain analysis of window management system software.},
  file = {:./literature/2_FODA.pdf:PDF},
  keywords = {software engineering, requirements, management planning and control,
	feasibility studies},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.15},
  url = {http://selab.postech.ac.kr/classes/eece700A/materials/papers/2_FODA.pdf}
}

@ARTICLE{Kannenberg2009,
  author = {Andrew Kannenberg and Dr. Hossein Saiedian},
  title = {Why Software Requirements Traceability Remains a Challenge},
  journal = {CrossTalk The Journal of Defense Software Engineering},
  year = {2009},
  file = {:./literature/200907-Kannenberg.pdf:PDF},
  owner = {elkeb},
  timestamp = {2011.12.21}
}

@INPROCEEDINGS{Kautz2000,
  author = {Kautz, K. and Hansen, H.W. and Thaysen, K.},
  title = {Applying and adjusting a software process improvement model in practice:
	the use of the IDEAL model in a small software enterprise},
  booktitle = {Proceedings of the 22nd international conference on Software engineering},
  year = {2000},
  pages = {626--633},
  file = {Kautz2000.pdf:literature/Kautz2000.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@ARTICLE{Kazman1996,
  author = {Kazman, R. and Abowd, G. and Bass, L. and Clements, P.},
  title = {Scenario-based analysis of software architecture},
  journal = {IEEE Software},
  year = {1996},
  volume = {13},
  pages = {47-55},
  number = {6},
  month = {Nov},
  abstract = {Despite advances in clarifying high level design needs, analyzing
	a system's ability to meet desired quality criteria is still difficult.
	The authors propose using scenarios to make analysis more straightforward.
	In their case study report, they analyze lessons learned with this
	approach. They developed the Software Architecture Analysis Method,
	an approach that uses scenarios to gain information about a system's
	ability to meet desired quality attributes. Scenarios are brief narratives
	of expected or anticipated system uses from both user and developer
	views and they provide a look at how the system satisfies quality
	attributes in various use contexts},
  doi = {10.1109/52.542294},
  file = {:./literature/Kazman1996.pdf:PDF},
  issn = {0740-7459},
  keywords = {Software Architecture Analysis Method;anticipated system uses;case
	study report;developer views;high level design needs;quality attributes;quality
	criteria;scenario based analysis;software architecture;use contexts;software
	development management;software quality;software reliability;systems
	analysis;},
  owner = {Stephan},
  timestamp = {2010.11.15}
}

@ARTICLE{Kazman1999,
  author = {Rick Kazman and S. Jeromy Carri\`{e}re},
  title = {Playing Detective: Reconstructing Software Architecture from Available
	Evidence},
  journal = {Automated Software Engineering},
  year = {1999},
  volume = {6},
  pages = {107-138},
  number = {2},
  abstract = {Because a system's software architecture strongly influences its quality
	attributes such as modifiability, performance, and security, it is
	important to analyze and reason about that architecture. However,
	architectural documentation frequently does not exist, and when it
	does, it is often “out of sync” with the implemented system. In addition,
	it is rare that software development begins with a clean slate; systems
	are almost always constrained by existing legacy code. As a consequence,
	we need to be able to extract information from existing system implementations
	and utilize this information for architectural reasoning. This paper
	presents Dali, an open, lightweight workbench that aids an analyst
	in extracting, manipulating, and interpreting architectural information.
	By assisting in the reconstruction of architectures from extracted
	information, Dali helps an analyst redocument architectures, discover
	the relationship between “as-implemented” and “as-designed”architectures,
	analyze architectural quality attributes and plan for architectural
	change.},
  address = {Hingham, MA, USA},
  doi = {http://dx.doi.org/10.1023/A:1008781513258},
  file = {:./literature/kazmancarriere.pdf:PDF},
  issn = {0928-8910},
  keywords = {architectural views, software architecture, source model extraction},
  owner = {Stephan},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2008.04.29},
  url = {http://www.ics.uci.edu/~andre/ics223w2006/kazmancarriere.pdf}
}

@TECHREPORT{Kazman2000,
  author = {Rick Kazman and Mark Klein and Paul Clements},
  title = {{ATAM: Method for Architecture Evaluation}},
  institution = {CMU/SEI},
  year = {2000},
  number = {CMU/SEI-2000-TR-004},
  month = {August},
  abstract = {If a software architecture is a key business asset for an organization,
	then architectural analysis must also be a key practice for that
	organization. Why? Because architectures are complex and involve
	many design tradeoffs. Without undertaking a formal analysis process,
	the organization cannot ensure that the architectural decisions made---particularly
	those which affect the achievement of quality attribute such as performance,
	availability, security, and modifiability---are advisable ones that
	appropriately mitigate risks. In this report, we will discuss some
	of the technical and organizational foundations for performing architectural
	analysis, and will present the Architecture Tradeoff Analysis Method\textsuperscript{SM}
	(ATAM)---a technique for analyzing software architectures that we
	have developed and refined in practice over the past three years.},
  file = {:./literature/Kazman2000.pdf:PDF},
  keywords = {ATAM, scenario-based architectural assessment, architecture evaluation},
  owner = {Stephan},
  timestamp = {2010.11.15},
  url = {http://www.sei.cmu.edu/reports/00tr004.pdf}
}

@ARTICLE{KBSt2004,
  author = {KBSt},
  title = {V-{M}odell {XT}},
  year = {2004},
  volume = {Koordinierungs- und Beratungsstelle der Bundesregierung für Informationstechnik
	in der Bundesverwaltung, Bundesrepublik Deutschland, Version 1.2},
  language = {german},
  owner = {Robert},
  timestamp = {2008.07.15},
  url = {http://www.v-modell-xt.de}
}

@ARTICLE{Keegan2001,
  author = {Keegan, A. and Turner, J.R.},
  title = {Quantity versus quality in project-based learning practices},
  journal = {Management Learning},
  year = {2001},
  volume = {32},
  pages = {77--98},
  number = {1},
  file = {Keegan2001.pdf:literature/Keegan2001.pdf:PDF},
  owner = {patrickr},
  publisher = {Sage Publications},
  timestamp = {2012.10.22}
}

@INPROCEEDINGS{Keenan2004,
  author = {Keenan, F.},
  title = {Agile process tailoring and problem analysis (APTLY)},
  booktitle = {Software Engineering, 2004. ICSE 2004. Proceedings. 26th International
	Conference on},
  year = {2004},
  pages = {45--47},
  file = {Keenan2004.pdf:literature/Keenan2004.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@INBOOK{Keller2011,
  chapter = {2},
  pages = {32-56},
  title = {Change Impact Analysis for UML Model Maintenance},
  publisher = {IGI Global},
  year = {2011},
  editor = {Rech, J\"{o}rg and Bunse, Christian},
  author = {Keller, Anne and Demeyer, Serge},
  file = {:./literature/Paper_195.PDF:PDF},
  owner = {Steffen},
  timestamp = {2011.12.29}
}

@INPROCEEDINGS{Keller2009,
  author = {Keller, Anne and Schippers, Hans and Demeyer, Serge},
  title = {Supporting Inconsistency Resolution through Predictive Change Impact
	Analysis},
  booktitle = {Proceedings of the 6th International Workshop on Model-Driven Engineering,
	Verification and Validation},
  year = {2009},
  address = {Denver, Colorado, USA},
  month = {October},
  file = {:/literature/Paper_208.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.03.22}
}

@ARTICLE{Kelly1999,
  author = {Kelly, D.P. and Culleton, B.},
  title = {Process improvement for small organizations},
  journal = {Computer},
  year = {1999},
  volume = {32},
  pages = {41--47},
  number = {10},
  file = {Kelly1999.pdf:literature/Kelly1999.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@ARTICLE{Kern2000,
  author = {Kern, T. and Willcocks, L.},
  title = {Exploring information technology outsourcing relationships: theory
	and practice},
  journal = {The Journal of Strategic Information Systems},
  year = {2000},
  volume = {9},
  pages = {321--350},
  number = {4},
  file = {Kern2000.pdf:literature/Kern2000.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.11}
}

@ARTICLE{Kernaghan1990,
  author = {Kernaghan, J.A. and Cooke, R.A.},
  title = {Teamwork in planning innovative projects: Improving group performance
	by rational and interpersonal interventions in group process},
  journal = {Engineering Management, IEEE Transactions on},
  year = {1990},
  volume = {37},
  pages = {109--116},
  number = {2},
  file = {Kernaghan1990.pdf:literature/Kernaghan1990.pdf:PDF},
  owner = {patrickr},
  publisher = {IEEE},
  timestamp = {2012.10.22}
}

@INPROCEEDINGS{Khan2008,
  author = {Khan, Safoora Shakil and Greenwood, Phil and Garcia, Alessandro and
	Rashid, Awais},
  title = {On the Interplay of Requirements Dependencies and Architecture Evolution:
	An Exploratory Study},
  booktitle = {Proceedings of the 20th International Conference Advanced Information
	Systems Engineering (CAiSE '08)},
  year = {2008},
  pages = {243-257},
  address = {Montpellier, France},
  month = {June},
  file = {:./literature/Paper_266.pdf:PDF},
  journal = {Lecture Notes in Computer Science},
  owner = {Steffen},
  timestamp = {2013.05.13}
}

@INPROCEEDINGS{Khan2009,
  author = {Khan, Safoora Shakil and Lock, Simon},
  title = {Concern tracing and change impact analysis: An exploratory study},
  booktitle = {Proceedings of the 2009 ICSE Workshop on Aspect-Oriented Requirements
	Engineering and Architecture Design},
  year = {2009},
  pages = {44-48},
  address = {Vancouver, BC, Canada},
  month = {May},
  file = {:./literature/Paper_130.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- hard to ensure that architecture meets requirements
	
	- change impact difficult to predict without traceability
	
	- current traceability techniques capture too much data to be of use
	(really??)
	
	
	Research Questions:
	
	- do concern-based dependencies help to identify unstable components
	and anticipate change
	
	
	Contribution:
	
	- concern oriented dependency taxonomy to capture dependencies between
	requirements and architecture
	
	
	Solution:
	
	- use concern-oriented approach
	
	- approach includes 3 different analysis aspects:
	
	* early separation of wide-scoped requirements
	
	* reason about compositional requirements
	
	* ensure that each requirement is implemented by the architecture
	
	- defined a dependency taxonomy:
	
	* goal dependency
	
	* task dependency
	
	* service dependency
	
	* conditional dependency
	
	* infrastructural dependency
	
	* usability dependency
	
	- dependencies can either be "overlap", "intertwine" or "conform"
	
	- apply concentration metrics to measure the number of concerns
	
	-> granularity of entities: use cases, architectural components
	
	-> granularity of changes: no details given
	
	-> granularity of results: architectural components
	
	
	Open Issues:
	
	- refine and extend taxonomy},
  timestamp = {2011.04.04}
}

@INCOLLECTION{Khan2011,
  author = {Khan, Tamim and Heckel, Reiko},
  title = {On Model-Based Regression Testing of Web-Services Using Dependency
	Analysis of Visual Contracts},
  booktitle = {Fundamental Approaches to Software Engineering},
  publisher = {Springer Berlin / Heidelberg},
  year = {2011},
  editor = {Giannakopoulou, Dimitra and Orejas, Fernando},
  volume = {6603},
  series = {Lecture Notes in Computer Science},
  pages = {341-355},
  note = {10.1007/978-3-642-19811-3_24},
  affiliation = {Department of Computer Sciences, Leicester University, UK},
  file = {:/literature/RegressionTesting/On Model-Based Regression Testing ofWeb-Services.pdf:PDF},
  keywords = {NEW},
  owner = {Annie},
  timestamp = {2011.04.18},
  url = {http://dx.doi.org/10.1007/978-3-642-19811-3_24}
}

@INPROCEEDINGS{Khomh2009,
  author = {Khomh, Foutse and Di Penta, Massimiliano and Gu\'{e}h\'{e}neuc, Yann-Ga\"{e}l},
  title = {An Exploratory Study of the Impact of Code Smells on Software Change-proneness},
  booktitle = {Proceedings of the 16th Working Conference on Reverse Engineering
	(WCRE '09)},
  year = {2009},
  pages = {75-84},
  month = {October},
  file = {:./literature/Paper_15.PDF:PDF},
  journal = {Proceedings of the 16th Working Conference on Reverse Engineering
	(WCRE)},
  owner = {Steffen},
  review = {Problem:
	
	
	Research Questions:
	
	
	Contribution:
	
	
	Solution:
	
	
	Open Issues:},
  timestamp = {2011.01.05}
}

@INPROCEEDINGS{Khomh2008,
  author = {Khomh, F. and Gueheneuc, Y.-G.},
  title = {Do Design Patterns Impact Software Quality Positively?},
  booktitle = {12th European Conference on Software Maintenance and Reengineering,
	(CSMR 2008).},
  year = {2008},
  pages = {274 -278},
  month = {April},
  abstract = {We study the impact of design patterns on quality attributes in the
	context of software maintenance and evolution. We show that, contrary
	to popular beliefs, design patterns in practice impact negatively
	several quality attributes, thus providing concrete evidence against
	common lore. We then study design patterns and object-oriented best
	practices by formulating a second hypothesis on the impact of these
	principles on quality. We show that results for some design patterns
	cannot be explained and conclude on the need for further studies.
	Thus, we bring further evidence that design patterns should be used
	with caution during development because they may actually impede
	maintenance and evolution.},
  doi = {10.1109/CSMR.2008.4493325},
  file = {:./literature/Khomh2008.pdf:PDF},
  issn = {1534-5351},
  keywords = {design patterns;software evolution;software maintenance;software quality;object-oriented
	programming;software maintenance;software quality;},
  owner = {Stephan},
  review = {quantiative evaluation if design patterns have impact on software
	quality based on questionaire},
  timestamp = {2010.04.15}
}

@INPROCEEDINGS{Kiczales2001,
  author = {Kiczales, Gregor and Hilsdale, Erik and Hugunin, Jim and Kersten,
	Mik and Palm, Jeffrey and Griswold, William G.},
  title = {An Overview of AspectJ},
  booktitle = {Proceedings of the 15th European Conference on Object-Oriented Programming
	(ECOOP '01)},
  year = {2001},
  volume = {2072},
  series = {LNCS},
  pages = {327-353},
  address = {London, UK},
  publisher = {Springer-Verlag},
  abstract = {AspectJ™ is a simple and practical aspect-oriented extension to Java..
	With just a few new constructs, AspectJ provides support for modular
	implementation of a range of crosscutting concerns. In AspectJ’s
	dynamic join point model, join points are well-defined points in
	the execution of the program; pointcuts are collections of join points;
	advice are special method-like constructs that can be attached to
	pointcuts; and aspects are modular units of crosscutting implementation,
	comprising pointcuts, advice, and ordinary Java member declarations.
	AspectJ code is compiled into standard Java bytecode. Simple extensions
	to existing Java development environments make it possible to browse
	the crosscutting structure of aspects in the same kind of way as
	one browses the inheritance structure of classes. Several examples
	show that AspectJ is powerful, and that programs written using it
	are easy to understand.},
  doi = {10.1007/3-540-45337-7_18},
  file = {:./literature/ECOOP2001-Overview.pdf:PDF},
  isbn = {3-540-42206-4},
  keywords = {aspect-oriented development, AspectJ},
  owner = {Stephan},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Kiczales1997,
  author = {Gregor Kiczales and John Lamping and Anurag Menhdhekar and Chris
	Maeda and Cristina Lopes and Jean-Marc Loingtier and John Irwin},
  title = {Aspect-Oriented Programming},
  booktitle = {Proceedings European Conference on Object-Oriented Programming (ECOOP)},
  year = {1997},
  editor = {Mehmet Ak\c{s}it and Satoshi Matsuoka},
  volume = {1241},
  pages = {220-242},
  address = {Berlin, Heidelberg, and New York},
  publisher = {Springer-Verlag},
  abstract = {We have found many programming problems for which neither procedural
	nor object-oriented programming techniques are sufficient to clearly
	capture some of the important design decisions the program must implement.
	This causes the implementation of those design decisions to be scattered
	throughout the code, resulting in “tangled” code that is excessively
	difficult to develop and maintain. We present an analysis of why
	it is that such design decisions have been so difficult to clearly
	capture in actual code. We call the issues these decisions address
	ASPECTS, and say that the reason they have been hard to capture is
	that they CROSS-CUT the system’s basic functionality. We present
	the basis for a new programming technique, called aspect-oriented
	programming, that makes it possible to clearly express programs involving
	such aspects, including appropriate isolation, composition and reuse
	of the aspecsion is rooted in systems we have built using aspect-oriented
	programming.},
  citeseerurl = {http://citeseer.ist.psu.edu/article/kiczales97aspectoriented.html},
  file = {:./literature/tr-aop.pdf:PDF},
  keywords = {aspect oriented programming},
  owner = {Stephan},
  timestamp = {2008.04.29},
  url = {http://agni.csa.iisc.ernet.in/ProgrammingLanguages/aspect/tr-aop.pdf}
}

@PHDTHESIS{Kilpinen2008,
  author = {Kilpinen, M.S.},
  title = {The Emergence of Change at the Systems Engineering and Software Design
	Interface - An Investigation of Impact Analysis},
  school = {Cambridge University, Engineering Department},
  year = {2008},
  file = {:./literature/PhD_2.PDF:PDF},
  owner = {Steffen},
  review = {- thesis is concerned with problem that most IA studies only mention
	the application in practice and do not describe how it should be
	performed
	
	- studies conducted within scope of thesis show a sharp decrease in
	design work when marginally improving IA
	
	
	- scope of analysis:
	
	- tool:
	
	- language:
	
	- scalability:
	
	- granularity
	
	* changes:
	
	* artifacts:
	
	* results:
	
	- technique:
	
	- analysis style:
	
	- evaluation
	
	* size:
	
	* precision:
	
	* recall:
	
	* time:},
  timestamp = {2011.01.01}
}

@INPROCEEDINGS{Kim2005,
  author = {Kim, S.Y. and Choi, H.J.},
  title = {An evaluation of process performance for a small-team project-a case
	study},
  booktitle = {Computer and Information Science, 2005. Fourth Annual ACIS International
	Conference on},
  year = {2005},
  pages = {308--313},
  file = {Kim2005.pdf:literature/Kim2005.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@INPROCEEDINGS{Kim2008,
  author = {Kim, S. and Dae-Kyoo Kim and Lunjin Lu and Soo-Yong Park},
  title = {A Tactic-Based Approach to Embodying Non-functional Requirements
	into Software Architectures},
  booktitle = {Proc. 12th International IEEE Enterprise Distributed Object Computing
	Conference, 2008. EDOC '08.},
  year = {2008},
  pages = {139-148},
  month = {Sept.},
  publisher = {IEEE},
  abstract = {This paper presents an approach for embodying nonfunctional requirements
	(NFRs) into software architecture using architectural tactics. Architectural
	tactics are reusable architectural building blocks, providing general
	architectural solutions for commonly occurring issues related to
	quality attributes. In this approach, architectural tactics are represented
	as feature models, and their semantics is defined using the role-based
	metamodeling language (RBML) which is a UML-based pattern specification
	notation. Given a set of NFRs, architectural tactics are elected
	and composed. The composed tactic is then used to instantiate an
	initial architecture for the application where the NFRs are embodied.
	A stock trading system is used to demonstrate the approach.},
  doi = {10.1109/EDOC.2008.18},
  file = {:./literature/Kim2008_EmbodyingNFRintoSWA.pdf:PDF},
  issn = {1541-7719},
  keywords = {Unified Modeling Language, metacomputing, software architecture, stock
	marketsRBML, UML-based pattern specification, architectural tactics,
	nonfunctional requirements, quality attributes, role-based metamodeling
	language, software architectures, stock trading system, tactic-based
	approach},
  owner = {Stephan},
  timestamp = {2009.06.17}
}

@CONFERENCE{Kim2010,
  author = {Kim, Tae-hyung and Kim, Kimun and Kim, Woomok},
  title = {An Interactive Change Impact Analysis based on an Architectural Reflexion
	Model Approach},
  booktitle = {Proceedings of the IEEE 34th Annual Computer Software and Applications
	Conference (COMPSAC '10)},
  year = {2010},
  pages = {297-302},
  address = {Seoul},
  month = {July},
  file = {:./literature/Paper_21.pdf:PDF},
  journal = {IEEE 34th Annual Computer Software and Applications Conference},
  owner = {Steffen},
  review = {Problem:
	
	- rapidly changing and evolving software systems
	
	- want to explore impacts of changes on a higher level / abstract
	models
	
	- product-line development in huge companies require merge of code/models
	once basic components etc. change (concurrent development)
	
	
	Research Questions:
	
	- generate static architecture from code analysis / reconstruct architecture
	
	
	Contribution:
	
	- recovery of architecure from code
	
	- IA on recovered architecture to support evolution
	
	
	Solution:
	
	- revised version of reflexion model proposed in [Murphy1995]
	
	- practical architecture reconstruction model
	
	- implemented in iCIA (visualization tool for IA)
	
	- architectural reflexion model computed as follows: 1. define high-level
	model 2. extract source model 3. define mapping 4. compute reflexion
	model 5. investigate differences / similarities (like Murphy1995)
	
	- 3 kinds of software entities: file, class, function
	
	- iCIA capable of detecting ripple effects
	
	- provides static code based IA, based on dependencies
	
	-> granularity of entities: file, class, function, variable
	
	-> granularity of changes:
	
	-> granularity of results: file, class, function, variable
	
	
	Open Issues:},
  timestamp = {2011.01.07}
}

@ARTICLE{Kirova2008,
  author = {Kirova, Vassilka and Kirby, Neil and Kothari, Darshak and Childres,
	Glenda},
  title = {Effective requirements traceability: Models, tools, and practices},
  journal = {Bell Labs Technical Journal},
  year = {2008},
  volume = {12 (4)},
  pages = {143-157},
  abstract = {The complexity of telecom systems and their production, coupled with
	today's globalization of markets, customers, and development teams,
	have made it critical to define and institutionalize an effective
	strategy for requirements traceability. Being able to trace the life
	of requirements from their origin, through their allocation to components,
	to the finished product provides a basis for collaboration and control
	of functionality, quality, and changes. With the benefits of current
	software engineering techniques and tools, organizations can cost-effectively
	implement traceability aligned with the organization's business goals,
	software engineering maturity, project attributes, and team culture.
	Within Alcatel-Lucent, several business units have engaged in implementing
	traceability and our team has developed an automated traceability
	environment. Based on these experiences we present a framework of
	guidelines for designing effective traceability strategies and tools.},
  file = {:./literature/31163304.pdf:PDF},
  owner = {Elke},
  review = {(EBn)
	
	Autoren haben ein integrierendes Framework für einen konkreten Einsatz
	entwickelt - dabei bestehende Tools integriert
	
	Artikel beschreibt 
	
	- die Herausforderungen 
	
	- die Einflüsse auf das zu entwickelnde Framework (Art der Organisation,
	Projekt, Produkt ...)
	
	- Vorteile des Einsatzes},
  timestamp = {2011.05.19},
  url = {http://web.ebscohost.com/ehost/pdfviewer/pdfviewer?sid=463a19b4-64ec-4764-af9f-04172c70e0f8%40sessionmgr111&vid=4&hid=127}
}

@TECHREPORT{Kitchenham2004,
  author = {Kitchenham, Barbara},
  title = {Procedures for Performing Systematic Reviews},
  institution = {Department of Computer Science, Keele University, UK},
  year = {2004},
  number = {TR/SE-0401},
  month = {July},
  file = {:./literature/Paper_199.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.03.01}
}

@ARTICLE{Kitchenham2001-2003,
  author = {Kitchenham, Barbara A. and Pfleeger, Shari Lawrence},
  title = {Principles of survey research - series of 6 articles},
  journal = {SIGSOFT Softw. Eng. Notes},
  year = {2001-2003},
  volume = {26, 27, 28},
  month = {November},
  acmid = {505535},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/505532.505535},
  file = {::PDF},
  issn = {0163-5948},
  issue = {6},
  numpages = {3},
  owner = {elkeb},
  publisher = {ACM},
  review = {Serie der Artikel für Zitate zusammengefaßt},
  timestamp = {2011.06.29},
  url = {http://doi.acm.org/10.1145/505532.505535}
}

@INCOLLECTION{Kitchenham2008,
  author = {Kitchenham, Barbara A. and Pfleeger, Shari L.},
  title = {Personal Opinion Surveys},
  booktitle = {Guide to Advanced Empirical Software Engineering},
  publisher = {Springer London},
  year = {2008},
  pages = {63-92},
  note = {10.1007/978-1-84800-044-5_3},
  abstract = {Although surveys are an extremely common research method, surveybased
	research is not an easy option. In this chapter, we use examples
	of three software engineering surveys to illustrate the advantages
	and pitfalls of using surveys. We discuss the six most important
	stages in survey-based research: setting the surveyâ€™s objectives;
	selecting the most appropriate survey design; constructing the survey
	instrument (concentrating on self-administered questionnaires); assessing
	the reliability and validity of the survey instrument; administering
	the instrument; and, finally, analysing the collected data. This
	chapter provides only an introduction to survey-based research; readers
	should consult the referenced literature for more detailed advice.},
  affiliation = {Keele University School of Computing and Mathematics Staffordshire
	Keele UK},
  file = {:./literature/AdvancedEmpiricalSoftwareEngineering.pdf:PDF},
  isbn = {978-1-84800-044-5},
  keyword = {Computer Science},
  owner = {elkeb},
  timestamp = {2011.06.29},
  url = {http://dx.doi.org/10.1007/978-1-84800-044-5_3}
}

@ARTICLE{Kitchenham2002a,
  author = {Kitchenham, Barbara A. and Pfleeger, Shari Lawrence},
  title = {Principles of survey research part 2: designing a survey},
  journal = {SIGSOFT Softw. Eng. Notes},
  year = {2002},
  volume = {27},
  pages = {18--20},
  month = {January},
  acmid = {566495},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/566493.566495},
  file = {:./literature/kitchenham2002a.pdf:PDF},
  issn = {0163-5948},
  issue = {1},
  issue_date = {January 2002},
  numpages = {3},
  owner = {elkeb},
  publisher = {ACM},
  timestamp = {2011.06.27},
  url = {http://doi.acm.org/10.1145/566493.566495}
}

@ARTICLE{Kitchenham2002b,
  author = {Kitchenham, Barbara A. and Pfleeger, Shari Lawrence},
  title = {Principles of survey research part 3: constructing a survey instrument},
  journal = {SIGSOFT Softw. Eng. Notes},
  year = {2002},
  volume = {27},
  pages = {20--24},
  month = {March},
  acmid = {511155},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/511152.511155},
  file = {:./literature/kitchenham2002b.pdf:PDF},
  issn = {0163-5948},
  issue = {2},
  keywords = {question construction, question selection, question types, questionnaire
	format, survey construction},
  numpages = {5},
  owner = {elkeb},
  publisher = {ACM},
  timestamp = {2011.06.27},
  url = {http://doi.acm.org/10.1145/511152.511155}
}

@INPROCEEDINGS{Kitchenham2004a,
  author = {Kitchenham, Barbara and Dyb\r{a}, Tore and J\orgensen, Magne},
  title = {Evidence-based Software Engineering},
  booktitle = {Proceedings of the 26th International Conference on Software Engineering
	(ICSE' 04)},
  year = {2004},
  pages = {273-281},
  month = {May},
  file = {:./literature/Paper_200.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.03.01}
}

@ARTICLE{Kitchenham2002,
  author = {Kitchenham, B.A. and Pfleeger, S.L. and Pickard, L.M. and Jones,
	P.W. and Hoaglin, D.C. and El Emam, K. and Rosenberg, J.},
  title = {Preliminary guidelines for empirical research in software engineering},
  journal = {Software Engineering, IEEE Transactions on},
  year = {2002},
  volume = {28},
  pages = { 721 - 734},
  number = {8},
  month = {aug},
  abstract = { Empirical software engineering research needs research guidelines
	to improve the research and reporting processes. We propose a preliminary
	set of research guidelines aimed at stimulating discussion among
	software researchers. They are based on a review of research guidelines
	developed for medical researchers and on our own experience in doing
	and reviewing software engineering research. The guidelines are intended
	to assist researchers, reviewers, and meta-analysts in designing,
	conducting, and evaluating empirical studies. Editorial boards of
	software engineering journals may wish to use our recommendations
	as a basis for developing guidelines for reviewers and for framing
	policies for dealing with the design, data collection, and analysis
	and reporting of empirical studies.},
  doi = {10.1109/TSE.2002.1027796},
  file = {:./literature/01027796.pdf:PDF},
  issn = {0098-5589},
  keywords = { software engineering; software researchers; software engineering;},
  owner = {elkeb},
  timestamp = {2011.06.23}
}

@ARTICLE{Kitchenham2003,
  author = {Kitchenham, Barbara and Pfleeger, Shari Lawrence},
  title = {Principles of survey research part 6: data analysis},
  journal = {SIGSOFT Softw. Eng. Notes},
  year = {2003},
  volume = {28},
  pages = {24--27},
  month = {March},
  acmid = {638758},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/638750.638758},
  file = {:./literature/kitchenham2003.pdf:PDF},
  issn = {0163-5948},
  issue = {2},
  keywords = {statistical analysis, survey methods},
  numpages = {4},
  owner = {elkeb},
  publisher = {ACM},
  timestamp = {2011.06.27},
  url = {http://doi.acm.org/10.1145/638750.638758}
}

@ARTICLE{Kitchenham2002c,
  author = {Kitchenham, Barbara and Pfleeger, Shari Lawrence},
  title = {Principles of survey research part 4: questionnaire evaluation},
  journal = {SIGSOFT Softw. Eng. Notes},
  year = {2002},
  volume = {27},
  pages = {20--23},
  month = {May},
  acmid = {638580},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/638574.638580},
  file = {:./literature/survey-4.pdf:PDF},
  issn = {0163-5948},
  issue = {3},
  keywords = {researcher bias, respondent motivation, survey reliability, survey
	validity},
  numpages = {4},
  owner = {elkeb},
  publisher = {ACM},
  timestamp = {2011.06.27},
  url = {http://doi.acm.org/10.1145/638574.638580}
}

@ARTICLE{Kitchenham2002d,
  author = {Kitchenham, Barbara and Pfleeger, Shari Lawrence},
  title = {Principles of survey research part 5: populations and samples},
  journal = {SIGSOFT Softw. Eng. Notes},
  year = {2002},
  volume = {27},
  pages = {17--20},
  month = {September},
  acmid = {571686},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/571681.571686},
  file = {:./literature/kitchenham2002d.pdf:PDF},
  issn = {0163-5948},
  issue = {5},
  keywords = {populations, sampling, survey methods},
  numpages = {4},
  owner = {elkeb},
  publisher = {ACM},
  timestamp = {2011.06.27},
  url = {http://doi.acm.org/10.1145/571681.571686}
}

@INPROCEEDINGS{klatt2012c,
  author = {Klatt, Benjamin and K\"{u}ster, Martin},
  title = {Respecting component architecture to migrate product copies to a
	software product line},
  booktitle = {Proceedings of the 17th international doctoral symposium on Components
	and Architecture},
  year = {2012},
  series = {WCOP '12},
  pages = {7--12},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Software product lines (SPL) are a well-known concept to efficiently
	develop product variants. However, migrating existing, customised
	product copies to a product line is still an open issue due to the
	required comprehension of differences among products and SPL design
	decisions. Most existing SPL approaches are focused on forward engineering.
	Only few aim to handle SPL evolution, but even those lack support
	of variability reverse engineering, which is necessary for migrating
	product copies to a product line. In this paper, we present how component
	architecture information can be used to enhance a variabilty reverse
	engineering process to target this challenge and show the relevance
	of component architecture in the individual requirements on the resulting
	SPL. We further provide an illustrating example to show how the concept
	is applied.},
  acmid = {2304679},
  doi = {10.1145/2304676.2304679},
  file = {:./literature/klatt2012c.pdf:PDF},
  isbn = {978-1-4503-1348-3},
  keywords = {component architecture, reverse engineering, software product line},
  location = {Bertinoro, Italy},
  numpages = {6},
  owner = {matthias},
  timestamp = {2013.01.28},
  url = {http://doi.acm.org/10.1145/2304676.2304679}
}

@INPROCEEDINGS{Klatt2011,
  author = {Klatt, Benjamin and Rathfelder, Christoph and Kounev, Samuel},
  title = {Integration of event-based communication in the palladio software
	quality prediction framework},
  booktitle = {Proceedings of the joint ACM SIGSOFT conference -- QoSA and ACM SIGSOFT
	symposium -- ISARCS on Quality of software architectures -- QoSA
	and architecting critical systems -- ISARCS},
  year = {2011},
  series = {QoSA-ISARCS '11},
  pages = {43-52},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {2000268},
  doi = {10.1145/2000259.2000268},
  file = {:./literature/p43-klatt.pdf:PDF},
  isbn = {978-1-4503-0724-6},
  keywords = {component-based architectures, event-based communication, performance
	prediction},
  location = {Boulder, Colorado, USA},
  numpages = {10},
  owner = {matthias},
  timestamp = {2013.01.29},
  url = {http://doi.acm.org/10.1145/2000259.2000268}
}

@BOOK{Klepper1998,
  title = {Outsourcing information technology, systems, and services},
  publisher = {Prentice Hall PTR},
  year = {1998},
  author = {Klepper, R. and Jones, W.O.},
  owner = {patrickr},
  timestamp = {2012.10.30}
}

@INPROCEEDINGS{Klimpke2009,
  author = {Klimpke, L. and Hildenbrand, T.},
  title = {Towards End-to-End Traceability: Insights and Implications from Five
	Case Studies},
  booktitle = {Software Engineering Advances, 2009. ICSEA '09. Fourth International
	Conference on},
  year = {2009},
  pages = {465 -470},
  month = {sept.},
  abstract = {Traceability is nowadays an important aspect of software development.
	Despite that fact, many software development enterprises do not maintain
	traceability in an appropriate way. Therefore, we conducted five
	case studies with enterprises differing in size, industry sector,
	type of developed software and number of locations to determine how
	traceability is realized in practice and what has to be considered
	when creating an adoption process for introducing and/or improving
	traceability.},
  doi = {10.1109/ICSEA.2009.74},
  file = {:./literature/05298813.pdf:PDF},
  keywords = {end-to-end traceability;industry sector;requirements management;software
	development enterprises;DP industry;formal specification;project
	management;software development management;},
  owner = {elkeb},
  timestamp = {2011.06.22}
}

@INPROCEEDINGS{Klingemann1999a,
  author = {Klingemann, J. and W{\"a}sch, J. and Aberer, K.},
  title = {Adaptive outsourcing in cross-organizational workflows},
  booktitle = {Advanced Information Systems Engineering},
  year = {1999},
  pages = {417--421},
  organization = {Springer},
  file = {Klingemann1999a.pdf:literature/Klingemann1999a.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.10.10}
}

@INPROCEEDINGS{Klingemann1999,
  author = {Klingemann, J. and Wasch, J. and Aberer, K.},
  title = {Deriving service models in cross-organizational workflows},
  booktitle = {Research Issues on Data Engineering: Information Technology for Virtual
	Enterprises, 1999. RIDE-VE'99. Proceedings., Ninth International
	Workshop on},
  year = {1999},
  pages = {100--107},
  organization = {IEEE},
  file = {Klingemann1999.pdf:literature/Klingemann1999.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.10.10}
}

@INCOLLECTION{Knapp2008,
  author = {Knapp, Alexander and Janisch, Stephan and Hennicker, Rolf and Clark,
	Allan and Gilmore, Stephen and Hacklinger, Florian and Baumeister,
	Hubert and Wirsing, Martin},
  title = {Modelling the CoCoME with the Java/A Component Model},
  booktitle = {The Common Component Modeling Example},
  publisher = {Springer Berlin Heidelberg},
  year = {2008},
  editor = {Rausch, Andreas and Reussner, Ralf and Mirandola, Raffaela and Plášil,
	František},
  volume = {5153},
  series = {Lecture Notes in Computer Science},
  pages = {207-237},
  doi = {10.1007/978-3-540-85289-6_9},
  file = {:./literature/cocome2008.pdf:PDF},
  isbn = {978-3-540-85288-9},
  owner = {Sebastian},
  timestamp = {2014.03.19},
  url = {http://dx.doi.org/10.1007/978-3-540-85289-6_9}
}

@INPROCEEDINGS{Knethen2002,
  author = {Antje von Knethen},
  title = {A Trace Model for System Requirements Changes on Embedded Systems},
  booktitle = {Proc. of 4th International Workshop on Principles of Software Evolution},
  year = {2002},
  pages = {17-26},
  address = {Vienna, Austria},
  abstract = {Technical systems play an important role in our daily lives. Most
	systems have to be changed during their lifetime, but cost estimates
	of changes are often inaccurate and implementation of changes is
	time consuming and cost intensive. Planning and performing changes
	can be supported by precise impact analysis. Traditionally, impact
	analysis has been something that software professionals do intuitively,
	after some cursory examination of code and documentation. But, empirical
	investigation shows that even experienced software professionals
	predict incomplete sets of change impacts. This paper introduces
	an approach that focuses on impact analysis of system requirements
	changes and that is suited for embedded control systems. The approach
	is based on a fine-grained trace model. Empirical studies show that
	the approach allows a more effective impact analysis of changes on
	embedded systems.},
  doi = {http://doi.acm.org/10.1145/602461.602465},
  file = {:./literature/knethen2002.pdf:PDF},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.15}
}

@INPROCEEDINGS{vonKnethen2003,
  author = {von Knethen, A. and Grund, M.},
  title = {{QuaTrace}: a tool environment for (semi-) automatic impact analysis
	based on traces},
  booktitle = {Proceedings of the International Conference on Software Maintenance
	(ICSM 2003)},
  year = {2003},
  pages = {246-255},
  month = {September},
  file = {:./literature/Paper_138.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- cost estimation of changes often inaccurate
	
	- implementation of changes time & cost intensive and error prone
	
	- missing or insufficient documentation one reason for this
	
	
	Research Questions:
	
	- what traces should be established
	
	- who has to establish traces
	
	- who has to analyze traces
	
	
	Contribution:
	
	- constructive approach to support later changes
	
	- approach relies on traceability embedded into a tool environment
	
	- tool environment integrates existing tools (RequisitePro, Rhapsody)
	
	
	Solution:
	
	- take different roles of "developers" into account, distinguish the
	following:
	
	* project planner
	
	* requirements engineer
	
	* maintainer / developer
	
	- underlying traceability model contains following information:
	
	* type of relation (i.e. refinement or dependency), attributes of
	relation
	
	* type of entities
	
	* attributes of entities
	
	* granularity of entities (documents, paragraphs, lines)
	
	- component "Relation-Finder" identifies traces in RequisitePro-projects
	and sets them as explicit traces
	
	* analyses implicit and explicit traces in the project and store them
	in an XML file
	
	 -> implicit links exist between entities with the same name
	
	* analyis only performed on names of entities
	
	- component "Relation-Viewer" performs IA while ordering traces according
	to their change type
	
	* display all traces in a tree
	
	-> scope of approach: requirements, architecture
	
	-> granularity of entities: entire UML
	
	-> granularity of changes: functional changes
	
	-> granularity of results: entire UML
	
	
	Open Issues:
	
	- empirical evaluation of tool environment
	
	- traceing only build upon names of entities},
  timestamp = {2011.03.14}
}

@TECHREPORT{Knethen2002a,
  author = {Antje von Knethen and Barbara Paech},
  title = {A survey on tracing approaches in Practice and Research},
  institution = {Fraunhofer Institut Experimentelle Software Engineering},
  year = {2002},
  type = {IESE-Report},
  number = {095.01/E},
  address = {Kaiserslautern, Germany},
  __markedentry = {[Steffen:]},
  abstract = {Requirements traceability is an important feature of software systems.
	It is used to keep track of the relationships between individual
	requirements, of the change history and of the relationships to other
	software process artefacts, such as test cases or design components.
	
	In the literature, various tracing approaches are mentioned that deal
	with different kinds of documentation entities and relationships
	to be traced. But, so far, there is no encompassing and systematic
	view on tracing approaches in practice and research.
	
	This report provides a traceability taxonomy of the main concepts
	that affect traceability. Existing tracing approaches in practice
	and research are integrated into this taxonomy. In addition, the
	report identifies weaknesses of existing approaches and points out
	further research directions in the area of traceability.},
  file = {:./literature/urn_nbn_de_0011-n-91973.pdf:PDF},
  keywords = {traceability, tracing approach, requirements traceability},
  language = {english},
  owner = {Robert},
  review = {Elke},
  timestamp = {2008.07.15},
  url = {http://publica.fhg.de/documents/N-9197.html}
}

@INPROCEEDINGS{Ko2007,
  author = {Ko, Andrew J. and DeLine, Robert and Venolia, Gina},
  title = {{Information Needs in Collocated Software Development Teams}},
  booktitle = {29th Intl. Conf. on Software Engineering},
  year = {2007},
  pages = {344-353},
  doi = {10.1109/ICSE.2007.45},
  file = {:./literature/Ko2007_Information_Needs.pdf:PDF},
  isbn = {0-7695-2828-7},
  issn = {0270-5257},
  keywords = {Information needs},
  mendeley-groups = {ICSE2015,ECSA2014},
  mendeley-tags = {Information needs},
  owner = {Sebastian},
  timestamp = {2014.03.07},
  url = {http://dl.acm.org/citation.cfm?id=1248867 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4222596}
}

@ARTICLE{Ko2006,
  author = {Andrew J. Ko and Brad A. Myers and Michael J. Coblenz and Htet Htet
	Aung},
  title = {An Exploratory Study of How Developers Seek, Relate, and Collect
	Relevant Information during Software Maintenance Tasks},
  journal = {IEEE Transactions on Software Engineering},
  year = {2006},
  volume = {32},
  pages = {971-987},
  number = {12},
  month = {Dec},
  abstract = {Much of software developers' time is spent understanding unfamiliar
	code. To better understand how developers gain this understanding
	and how software development environments might be involved, a study
	was performed in which developers were given an unfamiliar program
	and asked to work on two debugging tasks and three enhancement tasks
	for 70 minutes. The study found that developers interleaved three
	activities. They began by searching for relevant code both manually
	and using search tools; however, they based their searches on limited
	and misrepresentative cues in the code, environment, and executing
	program, often leading to failed searches. When developers found
	relevant code, they followed its incoming and outgoing dependencies,
	often returning to it and navigating its other dependencies; while
	doing so, however, Eclipse's navigational tools caused significant
	overhead. Developers collected code and other information that they
	believed would be necessary to edit, duplicate, or otherwise refer
	to later by encoding it in the interactive state of Eclipse's package
	explorer, file tabs, and scroll bars. However, developers lost track
	of relevant code as these interfaces were used for other tasks, and
	developers were forced to find it again. These issues caused developers
	to spend, on average, 35 percent of their time performing the mechanics
	of navigation within and between source files. These observations
	suggest a new model of program understanding grounded in theories
	of information foraging and suggest ideas for tools that help developers
	seek, relate, and collect information in a more effective and explicit
	manner.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/TSE.2006.116},
  file = {:./literature/04016573.pdf:PDF},
  issn = {0098-5589},
  keywords = {program debugging, software maintenanceEclipse package explorer, debugging
	task, file tabs, information foraging, program understanding, scroll
	bars, search tool, software development environment, software maintenance
	tasks, source files},
  owner = {Robert},
  publisher = {IEEE Computer Society},
  timestamp = {2008.07.15}
}

@INPROCEEDINGS{Kobayashi2011,
  author = {Kobayashi, K. and Matsuo, A. and Inoue, K. and Hayase, Y. and Kamimura,
	M. and Yoshino, T.},
  title = {ImpactScale: Quantifying change impact to predict faults in large
	software systems},
  booktitle = {Proceedings of the 27th International Conference on Software Maintenance
	(ICSM 2011)},
  year = {2011},
  pages = {43-52},
  address = {Williamsburg, VI},
  month = {September},
  abstract = {In software maintenance, both product metrics and process metrics
	are required to predict faults effectively. However, process metrics
	cannot be always collected in practical situations. To enable accurate
	fault prediction without process metrics, we define a new metric,
	ImpactScale. ImpactScale is the quantified value of change impact,
	and the change propagation model for ImpactScale is characterized
	by probabilistic propagation and relation-sensitive propagation.
	To evaluate ImpactScale, we predicted faults in two large enterprise
	systems using the effort-aware models and Poisson regression. The
	results showed that adding ImpactScale to existing product metrics
	increased the number of detected faults at 10% effort (LOC) by over
	50%. ImpactScale also improved the predicting model using existing
	product metrics and dependency network measures.},
  file = {:./literature/Paper_260.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.12.29}
}

@INPROCEEDINGS{Koegel2010,
  author = {Koegel, Maximilian and Helming, Jonas},
  title = {{EMFStore}: a model repository for {EMF} models},
  booktitle = {Proceedings of the 32nd ACM/IEEE International Conference on Software
	Engineering -- Volume 2},
  year = {2010},
  series = {ICSE '10},
  pages = {307-308},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Models need to be put under version control to facilitate collaboration
	and to control change. EMFStore is a Software Configuration Management
	system tailored to the specific requirements for versioning models.
	This demo will present how to commit changes, update changes and
	how to perform a merge on a model.},
  acmid = {1810364},
  doi = {http://doi.acm.org/10.1145/1810295.1810364},
  file = {:./literature/Koegel2010EMFStore.pdf:PDF},
  isbn = {978-1-60558-719-6},
  keywords = {EMFStore, model repository, model merging, operation-based, software
	configuration management, version control system, eclipse modeling
	framework},
  location = {Cape Town, South Africa},
  numpages = {2},
  owner = {Stephan},
  timestamp = {2010.12.27}
}

@TECHREPORT{Koegel2010b,
  author = {Koegel, M. and Helming, J. and Narayan, N.},
  title = {Storing and Versioning EMF Models with EMFStore},
  institution = {Institut fuer Informatik, Technische Universitaet Muenchen},
  year = {2010},
  file = {:./literature/Paper_9.PDF:PDF},
  owner = {Steffen},
  review = {Problem:
	
	
	Research Questions:
	
	
	Contribution:
	
	
	Solution:
	
	
	Open Issues:},
  timestamp = {2011.01.01}
}

@INPROCEEDINGS{Koegel2010a,
  author = {Koegel, Maximilian and Herrmannsdoerfer, Markus and Li, Yang and
	Helming, Jonas and David, Joern},
  title = {Comparing State- and Operation-Based Change Tracking on Models},
  booktitle = {Proceedings of the 2010 14th IEEE International Enterprise Distributed
	Object Computing Conference},
  year = {2010},
  series = {EDOC '10},
  pages = {163--172},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid = {1909782},
  doi = {10.1109/EDOC.2010.15},
  file = {:/literature/changeIdentification/D-1-4-A-5_ComparingStateAndOperationBasedChangeTrackingOnModels.pdf:PDF},
  isbn = {978-0-7695-4163-1},
  keywords = {Software Configuration Management, Version Control System, Modeling,
	Model, Model-driven Development, Versioning, Change Tracking, State-based,
	Operation-based, Change-Based, EMFStore},
  numpages = {10},
  url = {http://dx.doi.org/10.1109/EDOC.2010.15}
}

@ARTICLE{Koetsier2000,
  author = {Koetsier, M. and Grefen, P. and Vonk, J.},
  title = {Contracts for cross-organizational workflow management},
  journal = {Electronic Commerce and Web Technologies},
  year = {2000},
  pages = {110--121},
  file = {Koetsier2000.pdf:literature/Koetsier2000.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.10.10}
}

@TECHREPORT{Kofman2003,
  author = {Kofman, M. and Perfons, E.},
  title = {MetaDiff - a Model Comparison Framework},
  institution = {Department of Computer and System Sciences Stockholm University and
	Royal Institute of Technology},
  year = {2003},
  citeulike-article-id = {1289123},
  citeulike-linkout-0 = {http://metadiff.sourceforge.net/docs/metadiff.pdf},
  comment = {Overview MetaDiff framework interesting approach, but paper contains
	a lot of not so interesting stuff like use case diagrams etc.},
  file = {:/literature/changeIdentification/metadiff.pdf:PDF},
  keywords = {diff, model, Read},
  owner = {Steffen},
  posted-at = {2007-05-11 06:04:02},
  priority = {0},
  timestamp = {2012.03.01},
  url = {http://metadiff.sourceforge.net/docs/metadiff.pdf}
}

@INPROCEEDINGS{Kohlbacher2006,
  author = {Kohlbacher, F.},
  title = {The use of qualitative content analysis in case study research},
  booktitle = {Forum Qualitative Sozialforschung/Forum: Qualitative Social Research},
  year = {2006},
  volume = {7},
  number = {1},
  file = {Kohlbacher2006.pdf:literature/Kohlbacher2006.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.10.16}
}

@TECHREPORT{Kolb2003,
  author = {Kolb, Ronny and Bayer, J.},
  title = {Pattern-Based Architecture Analysis and Design of Embedded Software
	Product Lines},
  institution = {Fraunhofer IESE},
  year = {2003},
  month = {Dec},
  file = {:./literature/Empress_D2.1-2.2_Appendix_B_v1.0_Public_Version.pdf:PDF},
  keywords = {architectural design, means, patterns, software product line},
  owner = {Stephan},
  timestamp = {2009.07.27},
  url = {http://www.empress-itea.org/deliverables/D2.1-2.2_Appendix_B_v1.0_Public_Version.pdf}
}

@INPROCEEDINGS{Kolovos2009a,
  author = {Kolovos, Dimitrios S.},
  title = {Establishing Correspondences between Models with the Epsilon Comparison
	Language},
  booktitle = {Proceedings of the 5th European Conference on Model Driven Architecture
	- Foundations and Applications},
  year = {2009},
  series = {ECMDA-FA '09},
  pages = {146-157},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  acmid = {1575011},
  doi = {http://dx.doi.org/10.1007/978-3-642-02674-4_11},
  file = {:/literature/changeIdentification/Establishing Correspondences between Models with epsilon Comparison Language.pdf:PDF},
  isbn = {978-3-642-02673-7},
  keywords = {Read},
  location = {Enschede, The Netherlands},
  numpages = {12},
  owner = {Steffen},
  timestamp = {2012.03.01},
  url = {http://dx.doi.org/10.1007/978-3-642-02674-4_11}
}

@INPROCEEDINGS{Kolovos2009,
  author = {Kolovos, Dimitrios S. and Di Ruscio, Davide and Pierantonio, Alfonso
	and Paige, Richard F.},
  title = {Different models for model matching: An analysis of approaches to
	support model differencing},
  booktitle = {Proceedings of the 2009 ICSE Workshop on Comparison and Versioning
	of Software Models},
  year = {2009},
  series = {CVSM '09},
  pages = {1-6},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid = {1564641},
  doi = {http://dx.doi.org/10.1109/CVSM.2009.5071714},
  file = {:/literature/changeIdentification/05071714.pdf:PDF},
  isbn = {978-1-4244-3714-6},
  keywords = {Rea},
  numpages = {6},
  owner = {Steffen},
  timestamp = {2012.03.01},
  url = {http://dx.doi.org/10.1109/CVSM.2009.5071714}
}

@INPROCEEDINGS{Kolovos2006a,
  author = {Kolovos, Dimitrios S. and Paige, Richard F. and Polack, Fiona A.C.},
  title = {Model comparison: a foundation for model composition and model transformation
	testing},
  booktitle = {Proceedings of the 2006 international workshop on Global integrated
	model management},
  year = {2006},
  series = {GaMMa '06},
  pages = {13-20},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1138308},
  doi = {http://doi.acm.org/10.1145/1138304.1138308},
  file = {:/literature/changeIdentification/p13-kolovos.pdf:PDF},
  isbn = {1-59593-410-3},
  keywords = {Read, model comparison, model composition, model driven development,
	model transformation testing},
  location = {Shanghai, China},
  numpages = {8},
  owner = {Steffen},
  timestamp = {2012.03.01},
  url = {http://doi.acm.org/10.1145/1138304.1138308}
}

@INPROCEEDINGS{Kolovos2008,
  author = {Kolovos, Dimitrios S. and Paige, Richard F. and Polack, Fiona A.
	C.},
  title = {Detecting and Repairing Inconsistencies across Heterogeneous Models},
  booktitle = {Proceedings of the 1st International Conference on Software Testing,
	Verification, and Validation},
  year = {2008},
  pages = {356-364},
  address = {Lillehammer, Norway},
  month = {April},
  file = {:./literature/Paper_206.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.03.15}
}

@INPROCEEDINGS{Kolovos2006b,
  author = {Kolovos, Dimitrios S. and Paige, Richard F. and Polack, Fiona A.
	C.},
  title = {On-Demand Merging of Traceability Links with Models},
  booktitle = {Proceedings ECMDA Traceability Workshop (ECMDA-TW) 2006},
  year = {2006},
  pages = {6-14},
  organization = {Sintef, Trondheim},
  abstract = {Model management operations such as refinement and transformation
	modify existing or produce new models. To assist both engineers and
	tools in tracing the path of changes and decisions, maintenance of
	traceability information is essential. There are two main approaches
	for storing traceability; in the first, traceability information
	is embedded inside the models, while in the second, traces form separate
	models. The former allows users to inspect traceability information
	in a visual manner, but pollutes the models, while the latter keeps
	the models clean, but visualization is troublesome. In this paper,
	we propose a unification of the two approaches via model merging.
	We suggest that traceability information should be maintained in
	separate models, which can be merged with the primary model(s) on
	demand to produce annotated models for inspection purposes. We present
	a concrete example that demonstrates the practicality of our approach.},
  file = {:./literature/Kolovos2006.pdf:PDF},
  keywords = {model traceability},
  owner = {Stephan},
  timestamp = {2010.12.08}
}

@INPROCEEDINGS{Kong2009,
  author = {Leilei Kong and Tao Yuan},
  title = {Extension Features-Driven Use Case Model for requirement traceability},
  booktitle = {Computer Science Education, 2009. ICCSE '09. 4th International Conference
	on},
  year = {2009},
  pages = {866 -870},
  month = {july},
  abstract = {Requirement traceability has been repeatedly proven to be the key
	factor of software project management and software quality, and its
	researches have become an important part of software engineering.
	Use case has been widely applied in software requirement engineering
	and use case driven approach is one of the most important features
	in many software development processes. This paper extends the feather-driven
	use cassoftware development processes. This paper extends the feather-driven
	use case model which is the requirement traceability strategy outlined
	and recommended by the Rational Unified Process. Proposes a model
	named e-FDUCM, which use case is the core of requirement traceability.
	The traceability relationships among need, product feature, software
	requirement, use case, use case section, and artifacts of use case
	realization, test or maintenance phase are given in e-FEUCM. Traceabilitye
	model which is the requirement traceability strategy outlined and
	recommended by the rational unified process. Proposes a model named
	e-FDUCM, which use case is the core of requirement traceability.
	The traceability relationships among need, product feature, software
	requirement, use case, use case section, and artifacts of use case
	realization, test or maintenance phase are given in e-FEUCM. Traceability
	type and relationship is interpreted. Traceability matrix is defined
	as a tool of tracing. Finally, implementation of traceability strategy
	is illustrated.},
  doi = {10.1109/ICCSE.2009.5228208},
  file = {:./literature/Kon2009.pdf:PDF},
  keywords = {e-FDUCM model;e-FEUCM;extension feature-driven use case model;feather-driven
	use case model;maintenance phase;product feature;rational unified
	process;software development process;software engineering;software
	project management;software quality;software requirement engineering;software
	requirement traceability strategy;test phase;traceability matrix;use
	case realization;formal specification;formal verification;program
	diagnostics;program testing;project management;software development
	management;software maintenance;software quality;systems analysis;},
  owner = {Annie},
  timestamp = {2010.02.25}
}

@INPROCEEDINGS{Korel2002,
  author = {B. Korel and L.H. Tahat and B. Vaysburg},
  title = {Model based regression test reduction using dependence analysis},
  booktitle = {Software Maintenance, 2002. Proceedings. International Conference
	on},
  year = {2002},
  pages = {214--223},
  abstract = {Model based testing is a system testing technique used to test software
	systems modeled by formal description languages, e.g., an extended
	finite state machine {(EFSM).} System models are frequently changed
	because of specification changes. Selective test generation techniques
	are used to test the modified parts of the model. However, the size
	of regression test suites still may be very large. In this paper,
	we present a model-based regression testing approach that uses {EFSM}
	model dependence analysis to reduce regression test suites. The approach
	automatically identifies the difference between the original model
	and the modified model as a set of elementary model modifications.
	For each elementary modification, regression test reduction strategies
	are used to reduce the regression test suite based on {EFSM} dependence
	analysis. Our initial experience shows that the approach may significantly
	reduce the size of regression test suites.},
  doi = {10.1109/ICSM.2002.1167768},
  file = {:/literature/RegressionTesting/Model Based Regression Test Reduction Using Dependence Analysis.pdf:PDF},
  isbn = {1063-6773},
  keywords = {extended finite state machine model dependence analysis, finite state
	machines, model based regression test reduction, program testing,
	regression test suites, software maintenance, software system testing},
  owner = {Annie},
  review = {Artefacts: EFSM
	
	
	Modification : Addition and deletion
	
	
	Dependencies: Data and control dependence
	
	sideeffects are considered
	
	
	No case study 
	
	
	scope: System level
	
	
	Regression test suite reduction is perfomed based on affected transitions.
	No classification is given},
  timestamp = {2011.01.04}
}

@INCOLLECTION{Korpi2007,
  author = {Korpi, Jaakko and Koskinen, Jussi},
  title = {Supporting Impact Analysis by Program Dependence Graph Based Forward
	Slicing},
  booktitle = {Advances and Innovations in Systems, Computing Sciences and Software
	Engineering},
  publisher = {Springer Netherlands},
  year = {2007},
  editor = {Elleithy, Khaled},
  pages = {197-202},
  file = {:./literature/Paper_150.PDF:PDF},
  journal = {Advances and Innovations in Systems, Computing Sciences and Software
	Engineering},
  owner = {Steffen},
  review = {useful stuff: overview of slicing tools
	
	
	Problem:
	
	- IA one of central tasks in maintenance
	
	- no IA for Visual Basic
	
	
	Research Questions:
	
	- how can IA for Visual Basic be supported by foward slicing
	
	
	Contribution:
	
	- automated PDG-based forward slicing for Visual Basic
	
	- developed static foward slicer GRACE to conduct IA on Visual Basic
	
	
	Solution:
	
	- apply static forward slicing to capture all possibly affected system
	parts
	
	- GRACE consists of following components:
	
	* parser: translate VB program into AST's and symbol tables
	
	* PDG-generator:
	
	- turn ASTs into graphs
	
	- combine single graphs to system graph
	
	* slicer:
	
	- based on straightforward reachability analysis on PDG
	
	* user interface: enable interaction with tool user
	
	-> granularity of entities: variables
	
	-> granularity of changes:
	
	-> granularity of results: variables, statements, methods, classes
	
	
	Open Issues:
	
	- extend GRACE for other programming languages},
  timestamp = {2011.04.04}
}

@ARTICLE{Koschke2003,
  author = {Koschke, Rainer},
  title = {Software visualization in software maintenance, reverse engineering,
	and reengineering: a research survey},
  journal = {Journal of Software Maintenance and Evolution: Research and Practice},
  year = {2003},
  volume = {15},
  pages = {87-109},
  file = {:./literature/Paper_213.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.25}
}

@INPROCEEDINGS{Koschke1996,
  author = {R. Koschke and E. Plödereder},
  title = {Ansätze des {P}rogrammverstehens},
  booktitle = {Franz Lehner (Ed.) Softwarewartung und Reengineering},
  year = {1996},
  publisher = {Deutscher Universitätsverlag},
  abstract = {Programmverstehen ist der Prozeß des Wissenserwerbs über ein Computerprogramm.
	Es ist die Voraussetzung für Fehlersuche, Erweiterung, Wiederverwendung
	und Dokumentation. Eine Reihe von Ansätzen versucht, das Programmverstehen
	maschinell zu unterstützen. Die gegenwärtigen Ansätze werden in diesem
	Artikel klassifiziert in grundlegende und wissensbasierte Analysen.
	Grundlegende Analysen verfügen über kein Wissen über die Anwendung
	und allgemeine Programmierung; sie basieren lediglich auf Programmiersprachensyntax
	und -semantik. Grundlegende Analysen lassen sich weiter gliedern
	in grundlegende statische und grundlegende dynamische Analysen, abhängig
	davon, ob sie zur Übersetzungsszeit oder zur Laufzeit vorgenommen
	werden. Wissensbasierte Analysen verfügen über Anwendungswissen und
	allgemeines Programmierwissen. Wissensbasierte Analysen lassen sich
	unterscheiden in Parsing-Ansätze, falls sie sich ausschließlich auf
	formale und strukturelle Programmeigenschaften stützen, und informelles
	Schließen, falls sie darüber hinaus auch informelle Information in
	Betracht ziehen. Der Artikel gibt Beispiele zu den verschiedenen
	Analyseformen.},
  file = {:./literature/regensburg96.pdf:PDF},
  keywords = {program comprehension},
  owner = {Robert},
  timestamp = {2007.03.02},
  url = {http://inf4.informatik.uni-stuttgart.de/iste/ps/bauhaus/papers/regensburg96.ps}
}

@INPROCEEDINGS{Koschke2005,
  author = {Rainer Koschke and Jochen Quante},
  title = {On Dynamic Feature Location},
  booktitle = {Proceedings of the 20th IEEE/ACM international Conference on Automated
	software engineering},
  year = {2005},
  volume = {University of Bremen, Germany},
  pages = {86-95},
  address = {New York, NY, USA},
  abstract = {Feature location aims at locating pieces of code that implement a
	given set of features (requirements). It is a necessary first step
	in every program comprehension and maintenance task if the connection
	between features and code has been lost.We have developed a semi-automatic
	technique for feature location using a combination of static and
	dynamic program analysis. Formal concept analysis is used to explore
	the results of the dynamic analysis.We describe new experiences with
	our technique. Specifically, we investigate the gain of information
	and increase of costs when the system under analysis is profiled
	at basic block level rather than routine level as in our earlier
	work. Furthermore, we explore the influence of the scenarios used
	for the dynamic analysis (minimal versus combined scenarios).},
  file = {:./literature/dfl-ase05.pdf:PDF},
  keywords = {restructuring, reverse engineering, reengineering},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.15},
  url = {http://www.iste.uni-stuttgart.de/ps/bauhaus/papers/dfl-ase05.pdf}
}

@ARTICLE{Kotonya2005,
  author = {Kotonya, Gerald and Hutchinson, John},
  title = {Analysing the impact of change in {COTS}-based systems},
  journal = {Lecture Notes in Computer Science},
  year = {2005},
  volume = {3412},
  pages = {212-222},
  file = {:./literature/Paper_120.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- blackbox-nature of COTS software makes IA even more complicated
	than usual
	
	- basic problem is documentation of "blackbox" software like COTS
	
	
	Research Questions:
	
	- how to achieve IA in COTS environments where no (not all) code /
	documentation is available
	
	
	Contribution:
	
	- approach for IA of COTS-based systems relying on ADL and a COTS-oriented
	development process
	
	
	Solution:
	
	- developed COMPOSE method (COMPonent-Oriented Software Engineering)
	for component-based development
	
	* cyclical process that includes verification in every step
	
	* use intermediate modeling layer to map from requirements to components
	
	* use component architecture description language (CADL) to model
	components and system architecture
	
	* link requirements with their refinements (free text -> use case
	-> state chart -> CADL)
	
	- arrange components, requirements and constraints in dependency graph
	
	- distinguish between 3 different types of impact:
	
	* primary impacts: affects model directly related with changed element
	
	* secondary impacts: affects CADL component, connected to a changed
	component by CADL connector
	
	* peripheral impacts: affects components which or not primary/secondary
	category
	
	- propagate changes through entire graph via reachability
	
	-> granularity of entities: components, requirements
	
	-> granularity of changes: add/remove component, property change,
	constraint change
	
	-> granularity of results: components, requirements, connectors
	
	
	Open Issues:
	
	- requires software developed as proposed by COMPOSE process
	
	- allow developer to qualify links between entities},
  timestamp = {2011.04.01}
}

@INPROCEEDINGS{Koziolek2011,
  author = {Heiko Koziolek},
  title = {Sustainability evaluation of software architectures: a systematic
	review},
  booktitle = {QoSA/ISARCS2011},
  year = {2011},
  editor = {Ivica Crnkovic and Judith A. Stafford and Dorina C. Petriu and Jens
	Happe and Paola Inverardi},
  volume = {7th International Conference on the Quality of Software Architectures,
	QoSA 2011 and 2nd International Symposium on Architecting Critical
	Systems, ISARCS 2011. Boulder, CO, USA, June 20-24, 2011, Proceedings},
  pages = {3-12},
  publisher = {ACM},
  ee = {http://doi.acm.org/10.1145/2000259.2000263},
  file = {:./literature/Koziolek2011.pdf:PDF},
  owner = {matthias},
  timestamp = {2013.08.28}
}

@ARTICLE{Krishna2004,
  author = {Krishna, S. and Sahay, S. and Walsham, G.},
  title = {Managing cross-cultural issues in global software outsourcing},
  journal = {Communications of the ACM},
  year = {2004},
  volume = {47},
  pages = {62--66},
  number = {4},
  file = {Krishna2004.pdf:literature/Krishna2004.pdf:PDF},
  owner = {patrickr},
  publisher = {ACM},
  timestamp = {2012.10.15}
}

@BOOK{Kromrey2006,
  title = {Empirische Sozialforschung: Modelle und Methoden der standardisierten
	Datenerhebung und Datenauswertung},
  publisher = {Utb},
  year = {2006},
  author = {Kromrey, H.},
  volume = {1040},
  owner = {patrickr},
  timestamp = {2012.09.04}
}

@INPROCEEDINGS{Kruchten2004,
  author = {Kruchten, Philippe},
  title = {An Ontology of Architectural Design Decisions in Software Intensive
	Systems},
  booktitle = {2nd Groningen Workshop Software Variability},
  year = {2004},
  pages = {54--61},
  month = {October},
  abstract = {Architectural design decisions deserve to be first class entities
	in the process of developing complex software-intensive systems.
	Preserving the graphs of decisions and all their interdependencies
	will support the evolution and maintenance of such systems. In this
	paper we present a possible ontology of architectural design decisions,
	their attributes and relationships, for complex, software-intensive
	systems.},
  citeulike-article-id = {1772013},
  file = {:./literature/Kruchten2004_DesignDecisions.pdf:PDF},
  keywords = {rationale, design decision},
  owner = {Sebastian},
  posted-at = {2010-01-10 15:28:31},
  timestamp = {2013.08.06}
}

@ARTICLE{Kruchten2009,
  author = {Kruchten, P. and Capilla, R. and Dueas, J.C.},
  title = {The Decision View's Role in Software Architecture Practice},
  journal = {IEEE Software},
  year = {2009},
  volume = {26},
  pages = {36-42},
  number = {2},
  abstract = {Software development has to deal with many challenges-increasing system
	complexity, requests for better quality, the burden of maintenance
	operations, distributed production, and high staff turnover, to name
	just a few. Increasingly, software companies that strive to reduce
	their products' maintenance costs demand flexible, easy-to-maintain
	designs. Software architecture constitutes the cornerstone of software
	design, key for facing these challenges. Several years after the
	``software crisis'' began in the mid-1970s, software architecture
	practice emerged as a mature (although still growing) discipline,
	capable of addressing the increasing complexity of new software systems.},
  doi = {10.1109/MS.2009.52},
  file = {:./literature/Kruchten2009DecisionViews.pdf:PDF},
  issn = {0740-7459},
  keywords = {distributed production;maintenance operations;software architecture;software
	crisis;software development;software quality;system complexity;software
	architecture;software maintenance;software metrics;software quality;},
  owner = {Stephan},
  timestamp = {2011.01.11}
}

@INPROCEEDINGS{InterviewGuide, 
author={Hove, S.E. and Anda, B.}, 
booktitle={Software Metrics, 2005. 11th IEEE International Symposium}, 
title={Experiences from conducting semi-structured interviews in empirical software engineering research}, 
year={2005}, 
month={Sept}, 
pages={10 pp.-23}, 
keywords={software engineering;data collection;semistructured interviews;software engineering;Costs;Humans;Inspection;Laboratories;Programming;Project management;Sociology;Software engineering;Software measurement;Software testing}, 
doi={10.1109/METRICS.2005.24}, 
ISSN={1530-1435},}

@INPROCEEDINGS{MethodsSurveyKruchten, 
author={Falessi, D. and Cantone, G. and Kruchten, P.}, 
booktitle={Software Architecture, 2007. WICSA '07. The Working IEEE/IFIP Conference on}, 
title={Do Architecture Design Methods Meet Architects' Needs?}, 
year={2007}, 
month={Jan}, 
pages={5-5}, 
keywords={software architecture;software architecture design methods;Collaborative software;Collaborative work;Computer architecture;Computer industry;Conferences;Control systems;Design methodology;Resilience;Software architecture;Software systems}, 
doi={10.1109/WICSA.2007.23},}

@article{AvgeriouSurvey2014,
title = "Past and future of software architectural decisions â A systematic mapping study ",
journal = "Information and Software Technology ",
volume = "56",
number = "8",
pages = "850 - 872",
year = "2014",
issn = "0950-5849",
doi = "http://dx.doi.org/10.1016/j.infsof.2014.03.009",
url = "http://www.sciencedirect.com/science/article/pii/S0950584914000706",
author = "Dan Tofan and Matthias Galster and Paris Avgeriou and Wes Schuitema",
}

@INCOLLECTION{Kruchten2006,
  author = {Kruchten, Philippe and Lago, Patricia and Vliet, Hans},
  title = {Building Up and Reasoning About Architectural Knowledge},
  booktitle = {Quality of Software Architectures},
  publisher = {Springer Berlin Heidelberg},
  year = {2006},
  editor = {Hofmeister, Christine and Crnkovic, Ivica and Reussner, Ralf},
  volume = {4214},
  series = {Lecture Notes in Computer Science},
  pages = {43-58},
  doi = {10.1007/11921998_8},
  file = {:./literature/kruchten2006.pdf:PDF},
  isbn = {978-3-540-48819-4},
  owner = {Sebastian},
  timestamp = {2014.03.12},
  url = {http://dx.doi.org/10.1007/11921998_8}
}

@ARTICLE{Kruchten1995,
  author = {Kruchten, P. B.},
  title = {{The 4+1 View Model of Architecture}},
  journal = {IEEE Software},
  year = {1995},
  volume = {12},
  pages = {42-50},
  number = {6},
  abstract = {The 4+1 View Model organizes a description of a software architecture
	using five concurrent views, each of which addresses a specific set
	of concerns. Architects capture their design decisions in four views
	and use the fifth view to illustrate and validate them. The logical
	view describes the design's object model when an object-oriented
	design method is used. To design an application that is very data
	driven, you can use an alternative approach to develop some other
	form of logical view, such as an entity-relationship diagram. The
	process view describes the design's concurrency and synchronization
	aspects. The physical view describes the mapping of the software
	onto the hardware and reflects its distributed aspect. The development
	view describes the software's static organization in its development
	environment.},
  doi = {10.1109/52.469759},
  file = {:./literature/Kruchten1995.pdf:PDF},
  issn = {0740-7459},
  keywords = {4+1 View Model;concurrency;data-driven application design;design decisions;design
	object model;development environment;development view;distributed
	aspect;entity-relationship diagram;hardware;object-oriented design
	method;physical view;software architecture;software mapping;software
	static organization;synchronization;validation;distributed processing;entity-relationship
	modelling;object-oriented methods;software engineering;},
  owner = {Stephan},
  timestamp = {2011.01.11}
}

@BOOK{Kuckartz2007,
  title = {Einf{\"u}hrung in die computergest{\"u}tzte Analyse qualitativer
	Daten},
  publisher = {VS Verlag f{\"u}r Sozialwissenschaften},
  year = {2007},
  author = {Kuckartz, U.},
  volume = {3},
  number = {1995},
  owner = {patrickr},
  timestamp = {2012.09.12}
}

@BOOK{Kulpa2008,
  title = {Interpreting the CMMI: a process improvement approach},
  publisher = {Auerbach Publications},
  year = {2008},
  author = {Kulpa, M.K. and Johnson, K.A.},
  file = {Kulpa2008.PDF:literature/Kulpa2008.PDF:PDF},
  owner = {patrickr},
  timestamp = {2012.08.06}
}

@ARTICLE{Kung1995,
  author = {David Kung and Jerry Gao and Pei Hsia and Yasufumi Toyoshima and
	Chris Chen and Young-Si Kim and Young-Kee Song},
  title = {Developing an object-oriented software testing and maintenance environment},
  journal = {Commun. ACM},
  year = {1995},
  volume = {38},
  pages = {75--87},
  number = {10},
  abstract = {The object-oriented {(OO)} paradigm is rapidly gaining acceptance
	in the software industry. However, the powerful features of this
	new paradigm also introduce a new set of {OO} software testing and
	maintenance problems. The pioneering work in identifying these new
	problems includes [7, 10-12, 14, 16, 18]. The problems can be summarized
	as: 1) the understanding problem; 2) the complex interdependency
	problem; 3) the object state behavior testing problem; and 4) the
	tool support problem. Detailed discussions of these problems will
	be provided later. Our industrial experience confirms these discoveries.},
  doi = {10.1145/226239.226256},
  file = {:/literature/RegressionTesting/Developing an object oriented software testing and maintinanece enviornment.pdf:PDF;:Regression Testing/Model based Regression Testing/developing OO software testing and maintinance eviornment.pdf:PDF},
  owner = {Annie},
  timestamp = {2011.01.04},
  url = {http://portal.acm.org/citation.cfm?id=226256}
}

@INPROCEEDINGS{Kung1994,
  author = {Kung, D. and Gao, J. and Hsia, P. and Wen, F.},
  title = {Change Impact Identification in Object Oriented Software Maintenance},
  booktitle = {International Conference on Software Maintenance},
  year = {1994},
  pages = {202-211},
  address = {Victoria, BC, Canada},
  month = {September},
  file = {:./literature/Paper_85.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- regression testing important in software maintenance, however only
	those parts should be tested, that really changed
	
	- OOP software introduces new challenges for maintenance due to more
	dependencies than in functional languages
	
	- understanding combined relations and dependencies between classes
	to understand ripple effects more complicated than in functional
	languages
	
	
	Research Questions:
	
	- what are the differences in changes between OOP and functional languages
	
	- what types of changes exist
	
	
	Contribution:
	
	- taxonomy of code changes to OOP software
	
	- formal model to capture impacts on affected classes, generated from
	source code
	
	
	Solution:
	
	- consider the following types of code changes:
	
	* data change (add/remove/change type/change visibility etc.)
	
	* method change (signature changes, structure changes, component changes)
	
	* class change (same as method + relation changes)
	
	* class library change (add/remove classes, add/remove relationships)
	
	- proposed model consists of 3 diagrams:
	
	* object relation diagram (ORD): sort of UML class diagram
	
	* block branch diagram (BBD): sort of call-graph
	
	* object state diagram (OSD) -> not used and described in the paper
	
	- data change detected in BBDs (diff between code and current BBD)
	
	- method change detected in BBDs (removed/added nodes/edges indicate
	method change)
	
	- library changes detected in ORDs
	
	- use "Class Firewall"-concept to detect all affected classes
	
	- derive 6 types of structure changes from ORD to compute impact:
	
	* new superclass
	
	* new dependent class
	
	* new relationship between classes
	
	* delete superclass
	
	* delete dependent class
	
	* deleting relationship between classes
	
	-> granularity of entities: class, method, variable
	
	-> granularity of changes: atomic changes (add/remove/change relation)
	
	-> granularity of results: class, method, variable
	
	
	Open Issues:
	
	- include various metrics (e.g. complexity metrics)},
  timestamp = {2011.02.23}
}

@MISC{Kung1993,
  author = {David C. Kung and Jerry Gao and Pei Hsia and Jeremy Lin and Yasufumi
	Toyoshima},
  title = {Class Firewall, Test Order, and Regression Testing of Object-Oriented
	Programs},
  year = {1993},
  __markedentry = {[qurat:]},
  file = {:/literature/RegressionTesting/class firewall test order and regression testing of OO programs.pdf:PDF},
  keywords = {code based, class firewall},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@ARTICLE{Kung1996,
  author = {Kung, David C. and Gao, Jerry and Hsia, Pei and Toyoshima, Yasufumi
	and Chen, Cris},
  title = {On regression testing of object-oriented programs},
  journal = {J. Syst. Softw.},
  year = {1996},
  volume = {32},
  pages = {21--40},
  month = {January},
  __markedentry = {[qurat:]},
  acmid = {218155},
  address = {New York, NY, USA},
  doi = {10.1016/0164-1212(95)00047-X},
  file = {:/literature/RegressionTesting/OnRegressionTestingofObject-OrientedPrograms[1].pdf:PDF},
  issn = {0164-1212},
  issue = {1},
  keywords = {Model based, ORD, class firewall approachs},
  numpages = {20},
  owner = {Annie},
  publisher = {Elsevier Science Inc.},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=218153.218155}
}

@INPROCEEDINGS{Kurniawati2004,
  author = {Kurniawati, F. and Jeffery, R.},
  title = {The long-term effects of an EPG/ER in a small software organisation},
  booktitle = {Software Engineering Conference, 2004. Proceedings. 2004 Australian},
  year = {2004},
  pages = {128--136},
  file = {Kurniawati2004.pdf:literature/Kurniawati2004.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@TECHREPORT{Briand2003b,
  author = {L. C. Briand, Y. Labiche, K. Buist, G. Soccar},
  title = {Automating Impact Analysis and Regression Test Selection Based on
	UML Designs-TR},
  institution = {Software Quality Engineering Laboratory, Carleton University},
  year = {2003},
  number = {TR SCE-02-04,},
  month = {August},
  owner = {Annie},
  timestamp = {2011.05.03}
}

@ARTICLE{Lopez1999,
  author = {L{\'o}pez, M.F. and G{\'o}mez-P{\'e}rez, A. and Sierra, J.P. and
	Sierra, A.P.},
  title = {Building a chemical ontology using Methontology and the Ontology
	Design Environment},
  journal = {IEEE Intelligent Systems and their Applications},
  year = {1999},
  volume = {14},
  pages = {37-46},
  number = {1},
  month = {Jan/Feb},
  abstract = {Methontology provides guidelines for specifying ontologies at the
	knowledge level, as a specification of a conceptualization. ODE enables
	ontology construction, covering the entire life cycle and automatically
	implementing ontologies. To meet the challenge of building ontologies,
	we have developed Methontology, a framework for specifying ontologies
	at the knowledge level, and the Ontology Development Environment.
	We present our experience in using Methontology and ODE to build
	the chemical ontology},
  doi = {10.1109/5254.747904},
  file = {:./literature/Lopez1999Methontology.pdf:PDF},
  issn = {1094-7167},
  keywords = {Methontology;ODE;Ontology Design Environment;Ontology Development
	Environment;chemical ontology;knowledge acquisition;knowledge based
	systems;knowledge level;specification;chemical engineering computing;knowledge
	acquisition;knowledge based systems;},
  owner = {Stephan},
  timestamp = {2011.03.15}
}

@ARTICLE{Lowendahl1995,
  author = {L{\o}wendahl, B.R.},
  title = {Organizing the Lillehammer Olympic winter games},
  journal = {Scandinavian Journal of Management},
  year = {1995},
  volume = {11},
  pages = {347--362},
  number = {4},
  file = {Lowendahl1995.pdf:literature/Lowendahl1995.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.22}
}

@ARTICLE{Lacity1994,
  author = {Lacity, M. and Hirschheim, R. and Willcocks, L.},
  title = {Realizing outsourcing expectations incredible expectations, credible
	outcomes},
  journal = {Information System Management},
  year = {1994},
  volume = {11},
  pages = {7--18},
  number = {4},
  owner = {patrickr},
  publisher = {Taylor \& Francis},
  timestamp = {2012.10.30}
}

@ARTICLE{Lago2009,
  author = {Patricia Lago and Henry Muccini and Hans van Vliet},
  title = {A scoped approach to traceability management},
  journal = {Journal of Systems and Software},
  year = {2009},
  volume = {82},
  pages = {168-182},
  number = {1},
  note = {Special Issue: Software Performance -- Modeling and Analysis},
  abstract = {Traceability is the ability to describe and follow the life of a software
	artifact and a means for modeling the relations between software
	artifacts in an explicit way. Traceability has been successfully
	applied in many software engineering communities and has recently
	been adopted to document the transition among requirements, architecture
	and implementation. We present an approach to customize traceability
	to the situation at hand. Instead of automating tracing, or representing
	all possible traces, we scope the traces to be maintained to the
	activities stakeholders must carry out. We define core traceability
	paths, consisting of essential traceability links required to support
	the activities. We illustrate the approach through two examples:
	product derivation in software product lines, and release planning
	in software process management. By using a running software product
	line example, we explain why the core traceability paths identified
	are needed when navigating from feature to structural models and
	from family to product level and backward between models used in
	software product derivation. A feasibility study in release planning
	carried out in an industrial setting further illustrates the use
	of core traceability paths during production and measures the increase
	in performance of the development processes supported by our approach.
	These examples show that our approach can be successfully used to
	support both product and process traceability in a pragmatic yet
	efficient way.},
  doi = {DOI: 10.1016/j.jss.2008.08.026},
  file = {Lago2009 - A scoped approach to traceability management.pdf:literature/Lago2009 - A scoped approach to traceability management.pdf:PDF},
  issn = {0164-1212},
  keywords = {Traceability paths, Software product line, Traceability issues, Software
	process management},
  owner = {Stephan},
  timestamp = {2010.12.08},
  url = {http://www.sciencedirect.com/science/article/B6V0N-4TB182K-2/2/c1cc1372f6a230ac2a32dd6206b7cdd2}
}

@INPROCEEDINGS{Lago2004,
  author = {Lago, P. and Niemela, E. and Van Vliet, H.},
  title = {Tool support for traceable product evolution},
  booktitle = {Software Maintenance and Reengineering, 2004. CSMR 2004. Proceedings.
	Eighth European Conference on},
  year = {2004},
  pages = {261--269},
  file = {Lago2004.pdf:literature/Lago2004.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.31}
}

@INPROCEEDINGS{Lamb2011,
  author = {Lamb, Luis C. and Jirapanthong, Waraporn and Zisman, Andrea},
  title = {Formalizing Traceability Relations for Product Lines},
  booktitle = {Proceedings of the 6th International Workshop on Traceability in
	Emerging Forms of Software Engineering},
  year = {2011},
  pages = {42-45},
  address = {Waikiki, Honolulu, Hawaii},
  month = {May},
  file = {:./literature/Paper_232.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.05.10}
}

@ARTICLE{Lampson1992,
  author = {Butler Lampson and Mart\'{\i}n Abadi and Michael Burrows and Edward
	Wobber},
  title = {Authentication in distributed systems: theory and practice},
  journal = {ACM Transactions on Computer Systems (TOCS)},
  year = {1992},
  volume = {10},
  pages = {265-310},
  number = {4},
  abstract = {We describe a theory of authentication and a system that implements
	it. Our theory is based on the notion of principal and a “speaks
	for” relation between principals. A simple principal either has a
	name or is a communication channel; a compound principal can express
	an adopted role or delegated authority. The theory shows how to reason
	about a principal's authority by deducing the other principals that
	it can speak for; authenticating a channel is one important application.
	We use the theory to explain many existing and proposed security
	mechanisms. In particular, we describe the system we have built.
	It passes principals efficiently as arguments or results of remote
	procedure calls, and it handles public and shared key encryption,
	name lookup in a large name space, groups of principals, program
	loading, delegation, access control, and revocation.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/138873.138874},
  file = {:./literature/auth.pdf:PDF},
  issn = {0734-2071},
  keywords = {software, operationg systems, security and protection, authentication,
	cryptographic controls, access controls, computer communication networks,
	certification authority, delegation, group, interprocess communication,
	key distribution, loading programs, path name, principal, role, secure
	channel, speaks for, trusted computing base},
  owner = {Stephan},
  publisher = {ACM},
  timestamp = {2008.10.13},
  url = {http://courseweb.sp.cs.cmu.edu:8080/~cs612/papers/auth.pdf}
}

@INPROCEEDINGS{Lamsweerde2003,
  author = {Axel van Lamsweerde},
  title = {From System Goals to Software Architectures},
  booktitle = {Formal Methods for Software Architectures},
  year = {2003},
  editor = {Bernado M. and Inverardi P.},
  volume = {2804/2003},
  series = {LNCS},
  pages = {25-43},
  publisher = {Springer},
  abstract = {Requirements and architecture are two essential inter-related products
	in the software lifecycle. Software architecture has long been recognized
	to have a profound impact on non-functional requirements about security,
	fault tolerance, performance, evolvability, and so forth. In spite
	of this, very few techniques are available to date for systematically
	building software architectures from functional and non-functional
	requirements so that such requirements are guaranteed by construction.
	The paper addresses this challenge and proposes a goal-oriented approach
	to architectural design based on the KAOS framework for modeling,
	specifying and analyzing requirements. After reviewing some global
	architectural decisions that are already involved in the requirements
	engineering process, we discuss our architecture derivation process.
	Software specifications are first derived from requirements. An abstract
	architectural draft is then derived from functional specifications.
	This draft is refined to meet domain-specific architectural constraints.
	The resulting architecture is then recursively refined to meet the
	various non-functional goals modelled and analyzed during the requirements
	engineering process.},
  file = {:./literature/Lamsweerde2003.pdf:PDF},
  keywords = {quality goals, software architectures},
  owner = {Stephan},
  timestamp = {2010.06.08}
}

@BOOK{Lamsweerde2009,
  title = {{Requirements Engineering: From System Goals to UML Models to Software
	Specifications}},
  publisher = {Wiley},
  year = {2009},
  author = {van Lamsweerde, Axel},
  month = {March},
  abstract = {{The book presents both the current state of the art in requirements
	engineering and a systematic method for engineering high-quality
	requirements, broken down into four parts. The \_first part\_ introduces
	fundamental concepts and principles including the aim and scope of
	requirements engineering, the products and processes involved, requirements
	qualities to aim at and flaws to avoid, and the critical role of
	requirements engineering in system and software engineering.
	
	The \_second part\_ of the book is devoted to system modeling in the
	specific context of engineering requirements. It presents a multi-view
	modeling framework that integrates complementary techniques for modeling
	the system-as- is and the system-to-be. The \_third part\_ of the
	book reviews goal-based reasoning techniques to support the various
	steps of the KAOS method. The \_fourth part\_ of the book goes beyond
	requirements engineering to discuss the mapping from goal-oriented
	requirements to software specifications and to software architecture.
	
	Online resources will accompany the book and will add value to both
	classroom and self-study by enabling students to build models and
	specifications involved in the book's exercises and case studies,
	helping them to discover the latest RE technology solutions. Instructor
	resources such as slides, solutions, models and animations will be
	available from an accompanying website.}},
  howpublished = {Paperback},
  isbn = {0470012706},
  keywords = {computer-science, model-driven-engineering, requirement-engineering,
	software-engineering, system-engineering},
  owner = {Stephan},
  timestamp = {2010.11.08}
}

@INPROCEEDINGS{Lamsweerde2001,
  author = {van Lamsweerde, A.},
  title = {Goal-Oriented Requirements Engineering: A Guided Tour},
  booktitle = {Proceedings Fifth IEEE International Symposium on Requirements Engineering},
  year = {2001},
  pages = {249-262},
  publisher = {IEEE},
  abstract = {Goals capture, at different levels of abstraction, the various objectives
	the system under consideration should achieve. Goal-oriented requirements
	engineering is concerned with the use of goals for eliciting, elaborating,
	structuring, specifying, analyzing, negotiating, documenting, and
	modifying requirements. This area has received increasing attention.
	The paper reviews various research efforts undertaken along this
	line of research. The arguments in favor of goal orientation are
	first briefly discussed. The paper then compares the main approaches
	to goal modeling, goal specification and goal-based reasoning in
	the many activities of the requirements engineering process. To make
	the discussion more concrete, a real case study is used to suggest
	what a goal-oriented requirements engineering method may look like.
	Experience, with such approaches and tool support are briefly discussed
	as well.},
  citeseerurl = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.1528},
  doi = {10.1109/ISRE.2001.948567},
  file = {:./literature/AvLamswerde01_Goals.pdf:PDF},
  keywords = {formal specification, software tools, systems analysiscase study,
	goal modeling, goal specification, goal-based reasoning, goal-oriented
	requirements engineering, requirements documentation, requirements
	specification, software tools},
  owner = {Stephan},
  timestamp = {2009.02.10},
  url = {http://www.isys.ucl.ac.be/staff/stephane/EGMI2110Slide/Avl01.pdf}
}

@INPROCEEDINGS{Langelier2005,
  author = {Langelier, Guillaume and Sahraoui, Houari and Poulin, Pierre},
  title = {Visualization-based Analysis of Quality for Large-scale Software
	Systems},
  booktitle = {Proceedings of the 20th IEEE/ACM international Conference on Automated
	software engineering (ASE '05)},
  year = {2005},
  file = {:./literature/Paper_38.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	
	Research Questions:
	
	
	Contribution:
	
	
	Solution:
	
	
	Open Issues:},
  timestamp = {2011.02.04}
}

@INPROCEEDINGS{Laski1992,
  author = {J. Laski and W. Szermer},
  title = {Identification of program modifications and its applications in software
	maintenance},
  booktitle = {Software Maintenance, 1992. Proceerdings., Conference on},
  year = {1992},
  pages = {282--290},
  abstract = {It is pointed out that a major problem in software maintenance is
	the revalidation of a modified code. It is economically desirable
	to restrict that process only to those parts of the program that
	are affected by the modifications. Towards that goal, a formal method
	is needed to identify the modifications in an automatic way. Such
	a method is proposed in the present work. The modifications are localized
	within clusters in the flow graphs of the original and modified programs.
	Both flow graphs are transformed into reduced flow graphs, between
	which an isomorphic correspondence is established. Cluster-nodes
	in the reduced graphs encapsulate modifications to the original program.
	An algorithm to derive the reduced flow graphs has been implemented
	as an extension to the recently developed system for testing and
	debugging {(STAD} 1.0) and early experiments with the algorithm are
	reported. Potential applications in regression testing and reasoning
	about the program are discussed},
  doi = {10.1109/ICSM.1992.242533},
  file = {:/literature/RegressionTesting/identifiction of program modification and its application in software maintinance.pdf:PDF},
  keywords = {cluster nodes, flow graphs, formal method, isomorphic correspondence,
	program modifications identification, program testing, reasoning,
	reduced graphs, regression testing, revalidation, software maintenance,
	{STAD} code baseds},
  owner = {Annie},
  timestamp = {2011.01.04}
}

@INPROCEEDINGS{Laski1992a,
  author = {Laski, J. and Szermer, W.},
  title = {Identification of program modifications and its applications in software
	maintenance},
  booktitle = {Software Maintenance, 1992. Proceerdings., Conference on},
  year = {1992},
  pages = {282 -290},
  month = {nov},
  __markedentry = {[qurat:]},
  abstract = {It is pointed out that a major problem in software maintenance is
	the revalidation of a modified code. It is economically desirable
	to restrict that process only to those parts of the program that
	are affected by the modifications. Towards that goal, a formal method
	is needed to identify the modifications in an automatic way. Such
	a method is proposed in the present work. The modifications are localized
	within clusters in the flow graphs of the original and modified programs.
	Both flow graphs are transformed into reduced flow graphs, between
	which an isomorphic correspondence is established. Cluster-nodes
	in the reduced graphs encapsulate modifications to the original program.
	An algorithm to derive the reduced flow graphs has been implemented
	as an extension to the recently developed system for testing and
	debugging (STAD 1.0) and early experiments with the algorithm are
	reported. Potential applications in regression testing and reasoning
	about the program are discussed},
  doi = {10.1109/ICSM.1992.242533},
  file = {:/literature/RegressionTesting/00242533.pdf:PDF},
  keywords = {code based, STAD 1.0; cluster nodes; flow graphs; formal method; isomorphic
	correspondence; program modifications identification; reasoning;
	reduced graphs; regression testing; revalidation; software maintenance;
	program testing; software maintenance;},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@INPROCEEDINGS{LaToza2010,
  author = {LaToza, Thomas D. and Myers, Brad a.},
  title = {{Hard-to-answer questions about code}},
  booktitle = {Evaluation and Usability of Programming Languages and Tools on -
	PLATEAU '10},
  year = {2010},
  pages = {1-6},
  doi = {10.1145/1937117.1937125},
  file = {:./literature/LaToza2010.pdf:PDF},
  isbn = {9781450305471},
  keywords = {developer questions,experimentation,human factors,program comprehension},
  owner = {Sebastian},
  timestamp = {2014.03.19},
  url = {http://portal.acm.org/citation.cfm?doid=1937117.1937125}
}

@BOOK{Lauesen2005,
  title = {User Interface Design: A Software Engineering Perspective},
  publisher = {Addison-Wesley},
  year = {2005},
  author = {Soren Lauesen},
  pages = {624},
  address = {Boston, MA, USA},
  abstract = {Why is it that some computing systems appear simple and intuitive
	to use, while others confuse the users trying to work with them?
	For some software designers the interface is still seen as an add-on
	when the rest of the program has been written while human-computer
	interaction specialists consider programming the final task after
	numerous interface prototypes have been designed and evaluated. This
	book bridges the gap between the communities by showing how to design
	screens in a systematic way so that they are easy to understand and
	support the user interface efficiently. To do so, it draws on experience
	from programmers as well as usability specialists. Rather than just
	showing the reader how to design an interface, the book details how
	to actually make a fully functional interface putting theory into
	practice and showing the problems a designer faces when working in
	a real-world situation.},
  file = {:./literature/UIDpre.pdf:PDF},
  isbn = {0321181433},
  keywords = {software engineering, user interface design, virtual windows},
  owner = {Stephan},
  timestamp = {2008.08.04},
  url = {http://books.google.de/books?id=8-LhbEfLSGsC}
}

@INPROCEEDINGS{Law2003a,
  author = {Law, James and Rothermel, Gregg},
  title = {Whole Program Path-Based Dynamic Impact Analysis},
  booktitle = {Proceedings of the International Conference on Software Engineering
	(2003)},
  year = {2003},
  pages = {308-318},
  file = {:./literature/Paper_33.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- results gained from static slicing and call-graphs lack precision
	
	- approaches to expensive and not-safe
	
	- call graphs overestimate impacts
	
	
	Research Questions:
	
	- overcome time/space limitations of existing IA approaches (both
	dynamic and static)
	
	
	Contribution:
	
	- new IA technique based on whole path profiling -> Path Impact
	
	- Path Impact not safe, but efficient
	
	
	Solution:
	
	- collect dynamic path information at level of procedure / method
	calls
	
	- every method called after a changed method is considered as potentially
	impacted (and all methods the changed one returns into)
	
	- store this information in traces
	
	- compress traces to whole path DAGs (use SEQUITUR algorithm: http://de.wikipedia.org/wiki/Sequitur)
	
	-> granularity of entities: methods
	
	-> granularity of changes: changes to methods
	
	-> granularity of results: methods
	
	
	Open Issues:
	
	- scaleability for large systems},
  timestamp = {2011.02.04}
}

@INPROCEEDINGS{Law2003b,
  author = {Law, James and Rothermel, Gregg},
  title = {Incremental Dynamic Impact Analysis for Evolving Software Systems},
  booktitle = {Proceedings of the 14th International Symposium on Software Reliability
	Engineering (ISSRE'03)},
  year = {2003},
  pages = {430-441},
  month = {November},
  file = {:./literature/Paper_51.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- PathImpact useful to compute changes, however the entire data set
	has to be recomputed once a change was implemented
	
	- computing this data set takes a lot of time
	
	
	Research Questions:
	
	- how to avoid the entire re-computation by collecting data on the
	fly
	
	
	Contribution:
	
	- new algorithm to collect data required for PathImpact incrementally
	
	- does not require source code
	
	
	Solution:
	
	- new version of PathImpact: EvolveImpact
	
	- tag each test execution with unique keys
	
	- keys appear at the beginning of each execution trace
	
	- use keys to remove traces from the trace-DAG containing this key
	
	-> granularity of entities: methods
	
	-> granularity of changes: atomic changes to classes and methods
	
	-> granularity of results: methods
	
	
	Open Issues:
	
	- approach not efficient for small number of changes (rebuilding the
	whole DAG was more efficient)},
  timestamp = {2011.02.09}
}

@ARTICLE{Lazovik2007,
  author = {Lazovik, A. and Ludwig, H.},
  title = {Managing process customizability and customization: Model, language
	and process},
  journal = {Web Information Systems Engineering--WISE 2007},
  year = {2007},
  pages = {373--384},
  file = {Lazovik2007.pdf:literature/Lazovik2007.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.07.23}
}

@INPROCEEDINGS{Lee2000,
  author = {Lee, M. and Offutt, A. J. and Alexander, R. T.},
  title = {Algorithmic analysis of the impacts of changes to object-oriented
	software},
  booktitle = {Proceedings of the 34th International Conference on Technology of
	Object-Oriented Languages and Systems (TOOLS 34)},
  year = {2000},
  pages = {61-70},
  address = {Santa Barbara, CA , USA},
  month = {July},
  file = {:./literature/Paper_149.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- seemingly small changes can result in ripple-effects spanning entire
	system
	
	- developers need to understand how a change will affect the system
	
	- OO adds new challenges due to many dependencies within class-concept
	
	
	Research Questions:
	
	
	Contribution:
	
	- algorithm to evaluate proposed changes to a system
	
	- metrics to evaluate change impacts
	
	
	Solution:
	
	- distinguish between 4 different types of impacted/non-impacted entities:
	
	* contaminated: impacted by a change
	
	* clean: not impacted
	
	* semi-contaminated: impacted by change proposal or other entities
	but does not impact the end node
	
	* semi-clean: not impacted, but propagates change from impacted entity
	to end node
	
	- assign different weights to the 4 different types
	
	- assign different weights to relationships among entities (e.g. inheritance
	= 4, aggregation = 2)
	
	- total change impact weight = weight of impact type + weight of relation
	between entities
	
	- use OO data depenendency graphs and their transitive closure, consists
	of 3 graphs:
	
	* intra-method data dependency graph: used to calc. impact to entities
	inside method
	
	* inter-method data dependency graph: used to calc. change dependencies
	between methods
	
	* OO system dependency graph: used to calc. change impact at system
	level
	
	- first calculate impact in class, then calculate impacts between
	classes
	
	-> granularity of entities: class, method
	
	-> granularity of changes: no details given
	
	-> granularity of results: class
	
	- implemented in ChAT-tool
	
	* consists of parser, analyzer and viewer
	
	
	Open Issues:},
  timestamp = {2011.04.05}
}

@PHDTHESIS{Lee1998,
  author = {Lee, Michelle L.},
  title = {Change Impact Analysis of Object-Oriented Software},
  school = {Graduate Faculty of George Mason University},
  year = {1998},
  address = {Fairfax, Virginia},
  file = {:./literature/PhD_5.pdf:PDF},
  owner = {Steffen},
  review = {useful stuff: impact rules, dependencies between OO code
	
	
	- thesis adresses assessing the ripple effect in OO software is more
	difficult than in procedural software, due to variety and sometimes
	hidden dependencies 
	
	- contribution of thesis are set of OO data dependency graphs, analysis
	algorithms and evaluation metrics, implemented in ChaT tool
	
	- algorithms compute transitive closure of impacts, based on OO data
	dependency graph (OODDG) which is based on control flow and data
	flow graphs
	
	- analyze relationships among components and save relationships in
	component relationship graph
	
	- relationships are weighted according to type of relation, different
	relationships have different quantity measures to model change propagation
	
	- establish a set of rules, based on dependencies and relationship
	types
	
	
	- scope of analysis: code
	
	- tool: ChaT
	
	- language: C++
	
	- scalability: -
	
	- granularity
	
	* changes: +/-/inh. class, +/-/vis./r./sig. method, +/-/typ./val.
	variable
	
	* artifacts: class, method, variable
	
	* results: class, method, variable
	
	- technique: DG, ER
	
	- analysis style: global
	
	- evaluation
	
	* size: 29 KLOC
	
	* precision: -
	
	* recall: -
	
	* time: -},
  timestamp = {2011.02.19}
}

@ARTICLE{Lee2010,
  author = {Lee, W.-T. and Deng, W.-Y. and Lee, J. and Lee, S.-J.},
  title = {Change impact analysis with a goal-driven traceability-based approach},
  journal = {International Journal of Intelligent Systems},
  year = {2010},
  volume = {25},
  pages = {878-908},
  month = {August},
  file = {:./literature/Paper_176.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- traceability maintenance of requirements nasty and time consuming,
	therefore links ofter out of date
	
	- establishment of traces not integrated into development process
	
	- manual impact analysis tedious and time consuming
	
	
	Research Questions:
	
	- how to handle traceability among requirements automatically to enable
	impact analysis
	
	
	Contribution:
	
	- goal-driven, traceability approach for IA on requirements
	
	
	Solution:
	
	- following classification for "goals"
	
	* competence: whether the goal is satisfied or only to a certain degree
	
	* ridig goal: minimum requirement a system must fulfill
	
	* soft goal: goals stakeholders care for and can be satisfied to a
	certain degree
	
	* view: whether a goal is system or actor specific
	
	* content: the actual content and functionality of a goal
	
	- establish traceability relations between goals and use cases
	
	* of type "evolution", "dependency" and "satisfaction"
	
	 - goal 2 use case = evolution
	
	 - goal 2 goal | use case 2 use case = dependency
	
	 - use case 2 goal = satisfaction
	
	- impacts propagate across traceability links
	
	-> granularity of entities: goal, use case
	
	-> granularity of changes:
	
	-> granularity of results: goal, use case
	
	
	Open Issues:},
  timestamp = {2011.03.14}
}

@ARTICLE{Lehman1980,
  author = {Lehman, M.M.},
  title = {Programs, life cycles, and laws of software evolution},
  journal = {Proceedings of the IEEE},
  year = {1980},
  volume = {68},
  pages = {1060-1076},
  number = {9},
  month = {Sept.},
  abstract = {By classifying programs according to their relationship to the environment
	in which they are executed, the paper identifies the sources of evolutionary
	pressure on computer applications and programs and shows why this
	results in a process of never ending maintenance activity. The resultant
	life cycle processes are then briefly discussed. The paper then introduces
	laws of Program Evolution that have been formulated following quantitative
	studies of the evolution of a number of different systems. Finally
	an example is provided of the application of Evolution Dynamics models
	to program release planning.},
  file = {:./literature/01456074.pdf:PDF},
  issn = {0018-9219},
  keywords = {life cycle, software evolution},
  owner = {Stephan},
  timestamp = {2008.04.29},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1456074}
}

@INPROCEEDINGS{Lehnert2011a,
  author = {Lehnert, Steffen},
  title = {A Taxonomy for Software Change Impact Analysis},
  booktitle = {Proceedings of the 12th International Workshop on Principles of Software
	Evolution and the 7th annual ERCIM Workshop on Software Evolution
	(IWPSE-EVOL 2011)},
  year = {2011},
  pages = {41-50},
  address = {Szeged, Hungary},
  month = {September},
  publisher = {ACM},
  file = {:./literature/iwpse07-lehnert.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.06.30}
}

@TECHREPORT{Lehnert2011b,
  author = {Lehnert, Steffen},
  title = {A Review of Software Change Impact Analysis},
  institution = {Ilmenau University of Technology, Department of Software Systems
	/ Process Informatics},
  year = {2011},
  month = {December},
  file = {:./literature/Paper_190.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.12.15}
}

@MASTERSTHESIS{Lehnert2010,
  author = {Lehnert, Steffen},
  title = {{Softwarearchitectural Design and Realization of a Repository for
	Comprehensive Model Traceability (in German: Softwarearchitektur-Entwurf
	und Realisierung eines Repositories f{\"u}r Modell-{\"u}bergreifende
	Traceability)}},
  school = {Ilmenau University of Technology},
  year = {2010},
  type = {Diploma thesis},
  address = {Ilmenau, Germany},
  month = {November},
  file = {:./literature/DALehnert2010.pdf:PDF},
  keywords = {EMFTrace, traceability, model repository},
  owner = {Steffen},
  timestamp = {2011.02.11}
}

@INPROCEEDINGS{Lehnert2013a,
  author = {Lehnert, Steffen and Farooq, Qurat-Ul-Ann and Riebisch, Matthias},
  title = {Rule-based Impact Analysis for Heterogeneous Software Artifacts},
  booktitle = {Proceedings of the 17th European Conference on Software Maintenance
	and Reengineering (CSMR2013)},
  year = {2013},
  pages = {209-218},
  address = {Genova, Italy},
  month = {March},
  file = {:./literature/Paper_258.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.11.22}
}

@INPROCEEDINGS{Lehnert2012a,
  author = {Lehnert, Steffen and Farooq, Qurat-Ul-Ann and Riebisch, Matthias},
  title = {A Taxonomy of Change Types and its Application in Software Evolution},
  booktitle = {Proceedings of the 19th Annual IEEE International Conference on the
	Engineering of Computer Based Systems},
  year = {2012},
  pages = {98-107},
  file = {:./literature/ecbs2012.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.12.28}
}

@ARTICLE{Lehnert2012b,
  author = {Lehnert, Steffen and Riebisch, Matthias},
  title = {Tackling the Challenges of Evolution in Multiperspective Software
	Design and Implementation},
  journal = {Softwaretechnik Trends},
  year = {2012},
  volume = {32},
  pages = {27-28},
  number = {2},
  month = {May},
  address = {Bad Honnef, Germany},
  booktitle = {Joint proceedings of the Design for Future Workshop 2012 and the
	14th Workshop on Software Reengineering (WSR)},
  file = {:/literature/Paper_209.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.10}
}

@MASTERSTHESIS{Leino2001,
  author = {Virve Leino},
  title = {Documenting Requirements Traceability Information: A Case Study},
  school = {Helsinki University of Technology},
  year = {2001},
  abstract = {The literature lists many benefits of requirements traceability and
	standards suggest that it should be practiced. However, available
	literature concentrates on industries developing complex and large
	systems with several thousands of requirements. Thus, the companies
	developing systems with only approximately a hundred requirements
	face the challenge to define what traceability information to document
	and how. The goals of this thesis were to introduce requirements
	traceability and to offer guidelines for documenting traceability
	information for these companies. The thesis is part of the QURE (Quality
	Through Requirement) project at Helsinki University of Technology.
	
	The thesis begins with an introduction of traceability classes, relations
	and benefits of documenting them. It also presents techniques and
	tools to document traceability information. The theory part ends
	with discussion of the costs and problems of practicing requirements
	traceability.
	
	The case study part of the thesis consists of an analysis of requirements
	traceability and good practices developed for documenting traceability
	information in a case company. In addition, improvement actions that
	were taken by the company are presented.
	
	The thesis ends with a discussion of the theoretical implications
	of the work, the most important of which is the observation that
	pre-traceability is the first that the target group companies could
	document and benefit from whereas there can be many problems in documenting
	post-traceability information.},
  file = {:./literature/tracing-report.pdf:PDF},
  owner = {Elke},
  timestamp = {2011.06.17},
  url = {http://www.soberit.tkk.fi/qure/reports/tracing-report.pdf}
}

@INPROCEEDINGS{Letelier2002,
  author = {Letelier, Patricio},
  title = {A Framework for Requirements Traceability in {UML}-based Projects},
  booktitle = {Proceedings 1st Int. Workshop on Traceability in Emerging Forms of
	SE (TEFSE'02)},
  year = {2002},
  pages = {32-41},
  address = {Edinburgh, UK},
  __markedentry = {[Steffen:]},
  abstract = {Requirements traceability al lows us to assure the continuous concordance
	between the stakeholders requirements and the artifacts produced
	along the software development process. Although the important role
	of requirements traceability is widely recognized, the application
	level and consensus about associated practices are quite variable
	from one software development team to another. UML appears as an
	opportunity to establish a common framework for requirements traceability.
	In this work we present a reference metamodel for requirements traceability,
	that is based on UML and integrates as much textual specifications
	as UML model elements, obtaining a homogeneous representation for
	al l the software development artifacts and traceability links among
	them. Thanks to the UML extension mechanisms, we have obtained in
	a natural way that our approach be adaptable according to the project
	needs. We have included an example il lustrating how to use our framework
	in a smal l project, taking Rational Unified Process (RUP) as a software
	development process.},
  file = {:./literature/Letelier.pdf:PDF},
  keywords = {traceability links, traceability framework, requirements, UML},
  owner = {Stephan},
  timestamp = {2008.07.03}
}

@ARTICLE{Letovsky1987,
  author = {Stanley Letovsky},
  title = {Cognitive processes in program comprehension},
  journal = {J. Syst. Softw.},
  year = {1987},
  volume = {7},
  pages = {325-339},
  number = {4},
  abstract = {This paper reports on an empirical study of the cognitive processes
	involved in program comprehension. Verbal protocols were gathered
	from professional programmers as they were engaged in a program-understanding
	task. Based on analysis of these protocols, several types of interesting
	cognitive events were identified. These include asking questions
	and conjecturing facts about the code. We describe these event types
	and use them to derive a computational model of the programmers'
	mental processes.},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1016/0164-1212(87)90032-X},
  issn = {0164-1212},
  keywords = {program comprehension},
  owner = {Robert},
  publisher = {Elsevier Science Inc.},
  timestamp = {2008.07.15},
  url = {http://books.google.de/books?hl=de&lr=&id=sswoYivNQVUC&oi=fnd&pg=PA58&ots=aeIhO0gdYG&sig=6PfCbvaoyWTLbDGSzpFjm_6PGbs}
}

@ARTICLE{LeTraon2000,
  author = {Le Traon, Y. and Jeron, T. and Jezequel, J.-M. and Morel, P.},
  title = {Efficient object-oriented integration and regression testing},
  journal = {Reliability, IEEE Transactions on},
  year = {2000},
  volume = {49},
  pages = {12 -25},
  number = {1},
  month = {mar},
  __markedentry = {[qurat:]},
  doi = {10.1109/24.855533},
  file = {:/literature/RegressionTesting/efficient object oriented integration and regression testing.pdf:PDF},
  issn = {0018-9529},
  keywords = {model based, design-for-testability approach;integration strategies;object-oriented
	design;object-oriented integration;optimal stub minimization;quadratic
	complexity;regression testing;test dependency graph;unified modeling
	language;object-oriented methods;program testing;software reliability;},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@INPROCEEDINGS{Leung1989,
  author = {Leung, H.K.N. and White, L.},
  title = {Insights into regression testing [software testing]},
  booktitle = {Software Maintenance, 1989., Proceedings., Conference on},
  year = {1989},
  pages = {60 -69},
  month = {oct},
  __markedentry = {[qurat:]},
  doi = {10.1109/ICSM.1989.65194},
  file = {:/literature/RegressionTesting/Insights into Regression Testing .pdf:PDF},
  keywords = {code based, corrective regression testing;program design;regression
	number;regression testability;regression testing problem;retest strategy;test
	classification phase;test plan design;test plan update problem;test
	selection problem;testing number;testing set;workable metrics;program
	testing;software engineering;},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@ARTICLE{Li2012a,
  author = {Li, Bixin and Sun, Xiaobing and Leung, Hareton and Zhang, Sai},
  title = {A survey of code-based change impact analysis techniques},
  journal = {Software Testing, Verification and Reliability},
  year = {2012},
  file = {:./literature/Paper_261.pdf:PDF},
  owner = {Steffen},
  timestamp = {2013.03.09}
}

@INPROCEEDINGS{Li1996,
  author = {Li, Li and Offutt, A. Jefferson},
  title = {Algorithmic Analysis of the Impact of Changes on Object-Oriented
	Software},
  booktitle = {Proceedings of the International Conference on Software Maintenance},
  year = {1996},
  pages = {171-184},
  address = {Monterey, CA , USA},
  month = {November},
  file = {:./literature/Paper_83.pdf:PDF},
  institution = {International Conference on Software Maintenance},
  owner = {Steffen},
  review = {Problem:
	
	- maintaining becomes more difficult and expensive when software evolves
	and ages
	
	- changes have impact and ripple effects on many parts of a system
	
	
	Research Questions:
	
	- what types of changes occur in OO systems
	
	- how do these affect other classes in the system
	
	- how can IA guide testing
	
	- how do characteristics of OO software influence change propagation
	
	
	Contribution:
	
	- taxonomy of typical OOP change types
	
	- algorithm to detect all affected class
	
	
	Solution:
	
	- define affected software entities as follows:
	
	* affected class set
	
	* affected method set
	
	* affected field set (data)
	
	- algorithm for IA computes transitive closure
	
	* for each changed class do: put all related classes into set of "affected
	classes"
	
	* combine all "affected sets" of the whole system
	
	- computation of total effects comprised of following sub-computations:
	
	* find effects within a class
	
	* find effects among "clients" (i.e. related classes)
	
	* find effects caused by inheritance
	
	- definition of changes to methods and member data (e.g. add/remove
	and so on, see Figure 7)
	
	-> granularity of entities: classes
	
	-> granularity of changes: atomic changes (add/remove method/variable/relationship)
	
	-> granularity of results: classes
	
	
	Open Issues:
	
	- metric system to measure impacts
	
	- analysis tool that implements the algorithm},
  timestamp = {2011.02.23}
}

@ARTICLE{Li2012,
  author = {Li, Yang and Maalej, Walid},
  title = {Which Traceability Visualization Is Suitable in This Context? A Comparative
	Study},
  journal = {Lecture Notes in Computer Science},
  year = {2012},
  volume = {7195},
  pages = {194-210},
  file = {:./literature/Paper_249.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.08.15}
}

@ARTICLE{Li2013,
  author = {Li, Zengyang and Liang, Peng and Avgeriou, Paris},
  title = {{Application of knowledge-based approaches in software architecture:
	A systematic mapping study}},
  journal = {Information and Software Technology},
  year = {2013},
  volume = {55},
  pages = {777--794},
  number = {5},
  month = may,
  doi = {10.1016/j.infsof.2012.11.005},
  file = {:./literature/li2013.pdf:PDF},
  issn = {09505849},
  keywords = {architecting activity,knowledge-based approach,software architecture},
  owner = {Sebastian},
  timestamp = {2013.12.03},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0950584912002315}
}

@INPROCEEDINGS{Liang2005,
  author = {Liang, Hui},
  title = {Regression Testing of Classes Based on TCOZ Specification},
  booktitle = {Proceedings of the 10th IEEE International Conference on Engineering
	of Complex Computer Systems},
  year = {2005},
  pages = {450--457},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[qurat:]},
  acmid = {1078899},
  doi = {10.1109/ICECCS.2005.71},
  file = {:/literature/RegressionTesting/regression testing of classes based on TCoz specification.pdf:PDF},
  isbn = {0-7695-2284-X},
  keywords = {Read, Relevant, formal specification baseds},
  numpages = {8},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=1078029.1078899}
}

@INCOLLECTION{Liang2010,
  author = {Liang, Peng and Jansen, Anton and Avgeriou, Paris},
  title = {Collaborative Software Architectingcollaborative software architecting
	Through Knowledge Sharing},
  booktitle = {Collaborative Software Engineering},
  publisher = {Springer Berlin Heidelberg},
  year = {2010},
  editor = {Mistrík, Ivan and Grundy, John and Hoek, André and Whitehead, Jim},
  pages = {343-367},
  doi = {10.1007/978-3-642-10294-3_17},
  file = {:./literature/Liang2010.pdf:PDF},
  isbn = {978-3-642-10293-6},
  keywords = {Software architecture; Collaborative architecting; Architecting process;
	Architectural knowledge; Knowledge sharing; Collaborative software
	engineering},
  language = {English},
  owner = {Sebastian},
  timestamp = {2014.03.19},
  url = {http://dx.doi.org/10.1007/978-3-642-10294-3_17}
}

@BOOK{Lientz1980,
  title = {Software Maintenance Management: A Study of the Maintenance of Computer
	Application Software in 487 Data Processing Organizations},
  publisher = {Addison Wesley Longman},
  year = {1980},
  author = {Bennett P. Lientz and E. Burton Swanson},
  address = {Boston, MA, USA},
  keywords = {software maintenance, maintenance costs},
  owner = {Stephan},
  timestamp = {2009.04.28}
}

@ARTICLE{Lif2001,
  author = {Magnus Lif and Eva Olsson and Jan Gulliksen and Bengt Sandblad},
  title = {Workspaces Enhance Efficiency -- Theories, Concepts and a Case Study},
  journal = {Information Technology \& People},
  year = {2001},
  volume = {14},
  pages = {261-272},
  number = {3},
  abstract = {Traditional process-oriented system development methods often result
	in fragmentary user interfaces with information presented in various
	windows without considerations of requirements for simultaneous viewing.
	Opening, closing, moving and resizing these windows attracts the
	users' attention away from the actual work. User interface design
	according to the workspace metaphor could provide skilled professional
	users with an efficient, customised user interface to administrative
	information systems. This can improve work performance and facilitate
	efficient navigation between workspaces. A case study in co-operation
	with the Swedish National Tax Board (RSV) describes practical use
	of the workspace metaphor.},
  file = {:./literature/workspaces.pdf:PDF},
  keywords = {metaphors, user studies, interfaces, design, computer workstations},
  owner = {Stephan},
  timestamp = {2008.08.01},
  url = {http://www.emeraldinsight.com/Insight/ViewContentServlet?Filename=/published/emeraldfulltextarticle/pdf/1610140302.pdf}
}

@BOOK{Liggesmeyer2002,
  title = {Software-Qualität, Testen, Analysieren und Verifizieren von Software},
  publisher = {Spektrum, Akad. Verl., ISBN 3-8274-1118-1},
  year = {2002},
  author = {Peter Liggesmeyer},
  pages = {523},
  month = {August},
  abstract = {Einerseits ist eine definiert hohe Software-Qualität in vielen Anwendungsbereichen
	unverzichtbar. Andererseits ist sie aufgrund steigender Software-Umfänge
	und -Komplexitäten im gegebenen Zeit- und Kostenrahmen zunehmend
	schwieriger zu erreichen. Dieses Buch stellt den aktuellen Wissenstand
	über die Techniken, Methoden, Prinzipien und organisatorischen Aspekte
	der Software-Qualitätssicherung - soweit das in einem Buch möglich
	ist - vollständig dar. Beschrieben werden Testtechniken, automatische
	statische Analysen, die Software-Messung, Review- und Inspektionstechniken,
	formale Ansätze, Techniken zur Überprüfung objektorientierter und
	eingebetteter Software sowie Prüfstrategien, Prüfprozesse und Werkzeuge.
	Das Buch richtet sich gleichermaßen an Praktiker sowie an Informatik-Dozenten
	und -Studierende. Es kann "von vorn nach hinten" gelesen werden oder
	als Nachschlagewerk dienen. Jedes Kapitel ist ein allein verständliches
	"kleines Buch für sich". Es beginnt jeweils mit einer kurzen Inhaltsangabe
	zur Orientierung und schließt mit einer Bewertung und einer Checkliste,
	die insbesondere dem Praktiker Umsetzungshinweise gibt.},
  keywords = {software quality, software test, software analysis},
  language = {german},
  owner = {Robert},
  timestamp = {2008.07.15},
  url = {http://www.amazon.de/Software-Qualit%C3%A4t-Testen-Analysieren-Verifizieren-Software/dp/3827411181}
}

@PHDTHESIS{Lilienthal08,
  author = {Carola Lilienthal},
  title = {Komplexität von Softwarearchitekturen, Stile und Strategien},
  school = {Universität Hamburg},
  year = {2008},
  address = {Von-Melle-Park 3, 20146 Hamburg},
  abstract = {In dieser Arbeit untersuche ich, wo Komplexität bei der Softwareentwicklung
	auftritt, und konzentriere mich auf Architekturkomplexität, die in
	der statischen Struktur von Softwaresystemen, der Softwarearchitektur,
	enthalten ist. In der Softwaretechnik existiert bereits ein umfassendes
	Repertoire an Architekturkonzepten und Architekturstilen, um die
	Komplexität von Softwarearchitekturen zu lindern. Trotzdem scheitern
	viele Projekte, und Entwicklungsteams beklagen sich darüber, dass
	ihr Softwaresystem nicht mehr wartbar und weiterentwickelbar ist.
	
	Um Architekturkomplexität greifbar zu machen, ziehe ich Grundsätze
	aus der kognitiven Psychologie heran, die beschreiben, wie Menschen
	mit komplexen Strukturen umgehen. Dabei wird deutlich, wie objektorientierte
	Programmiersprachen und Architekturstile diese Grundsätze berücksichtigen
	und wo Lücken zu erkennen sind.
	
	Auf dieser Grundlage habe ich vierundzwanzig Fallstudien an Softwaresystemen
	in Industrie und Wissenschaft durchgeführt. Bei zweiundzwanzig Fallstudien
	konnte ich die Softwaresysteme mit dem Analysewerkzeug Sotograph
	untersuchen und die Architektur mit dem jeweiligen Entwicklungsteam
	diskutieren. In einigen Fällen habe ich zusätzlich ein Interview
	durchgeführt, um weitere Fragen zu klären. Die Ergebnisse aus den
	Fallstudien zeigen das weite Spektrum der heute in Softwarearchitekturen
	vorhandenen Komplexität und lassen ihre Ursachen sichtbar werden.
	Dabei wird deutlich, dass der Architekturstil einen entscheidenden
	Einfluss auf die Komplexität einer Softwarearchitektur hat.
	
	Parallel zu den Fallstudien habe ich ein Modell für Architekturkomplexität
	entwickelt. Die drei Faktoren, auf die ich Architekturkomplexität
	zurückführe, sind: Mustertreue, Modularität und Geordnetheit. Aus
	diesen drei Faktoren leite ich Kriterien und Fragen ab. Für sechs
	Fragen definiere ich Maße, die eine quantitative Auswertung erlauben.
	Anhand des Modells für Architekturkomplexität werden die Ergebnisse
	aus den Architekturanalysen und aus den Interviews präsentiert und
	interpretiert.
	
	Um die Ergebnisse konstruktiv nutzbar zu machen, stelle ich drei Stadien
	der architekturzentrierten Softwareentwicklung vor: Entwerfen, Erhalten
	und Erneuern von Architektur. Diese Stadien verlangen nach gut abgestimmten
	Strategien, wie Entwicklungsteams Architekturkomplexität reduzieren
	
	können. Schließlich biete ich einen Leitfaden dafür an, wie die Strategien
	in den drei Stadien der architekturzentrierten Softwareentwicklung
	geplant und eingesetzt werden sollen, so dass Entwicklungsteams abhängig
	von ihrer Situation die passende Strategie auswählen können.},
  file = {:./literature/Lilienthal2008.pdf:PDF},
  keywords = {software architecture , architectural styles , architecture-centric
	software development},
  language = {ger},
  owner = {matthias},
  timestamp = {2013.01.28},
  url = {http://ediss.sub.uni-hamburg.de/volltexte/2008/3725}
}

@ARTICLE{Lim1999,
  author = {Lim, CS and Mohamed, M.Z.},
  title = {Criteria of project success: an exploratory re-examination},
  journal = {International journal of project management},
  year = {1999},
  volume = {17},
  pages = {243--248},
  number = {4},
  file = {Lim1999.pdf:literature/Lim1999.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2013.01.02}
}

@PHDTHESIS{Limon2009,
  author = {Lim{\'o}n, A.E.},
  title = {An advanced traceability schema as a baseline to improve supporting
	lifecycle processes},
  school = {Universidad Polit{\'e}cnica de Madrid},
  year = {2009},
  file = {Limon2009.pdf:literature/Limon2009.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.08.06}
}

@INPROCEEDINGS{Limon2005,
  author = {Lim{\'o}n, A. E. and Garbajosa, J.},
  title = {The need for a unifying traceability scheme},
  booktitle = {Proceedings ECMDA Traceability Workshop (ECMDA-WS) 2005},
  year = {2005},
  pages = {47-56},
  address = {Sintef, Trondheim},
  file = {Limon2005.pdf:literature/Limon2005.pdf:PDF},
  keywords = {traceability},
  owner = {patrickr},
  review = {Problem:
	
	- lack of commonly accepted traceability type classification
	
	
	Research Questions:
	
	
	Contribution:
	
	- analysis: existing traceability specification scheme
	
	- propose: general traceability specification scheme
	
	
	Solution:
	
	- 
	
	
	Open Issues:},
  timestamp = {2012.07.31}
}

@ARTICLE{Lin2004,
  author = {Lin, Yuehua and Zhang, Jing and Gray, Jeff},
  title = {Model Comparison: A Key Challenge for Transformation Testing and
	Version Control in Model Driven Software Development},
  journal = {Best Practices for model Driven Software Development},
  year = {2004},
  volume = {OOPSLA/GPCE Workshop},
  citeulike-article-id = {977924},
  file = {:/literature/changeIdentification/10.1.1.91.5709.pdf:PDF},
  keywords = {Read, model, transformation},
  owner = {Steffen},
  posted-at = {2006-12-07 13:36:09},
  priority = {2},
  timestamp = {2012.03.01}
}

@ARTICLE{Lindvall1997,
  author = {Lindvall, Mikael},
  title = {Evaluating Impact Analysis - A Case Study},
  journal = {Empirical Software Engineering},
  year = {1997},
  volume = {2},
  pages = {152-158},
  number = {2},
  file = {:./literature/Paper_116.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- different maintenance activities have different focus and require
	different "output" of IA approaches (e.g. cost estimation needs "number
	of changes", developers need "what to change...")
	
	
	Research Questions:
	
	- how well did developers predict changes (i.e. number of classes,
	right classes)
	
	
	Contribution:
	
	- early IA on modul/submodel level
	
	- quantiy how good prof. developers predict real impact
	
	-> granularity of entities: class
	
	-> granularity of changes: no details given
	
	-> granularity of results: class
	
	
	Result:
	
	- developers not able to determine impact reliable
	
	- only about 30% precision but beliefed to be 95% right
	
	- intuition can be useful, but should not be the only source
	
	
	Open Issues:},
  timestamp = {2011.03.14}
}

@MISC{Lindvall1994,
  author = {Mikael Lindvall},
  title = {A study of Traceability in Object-Oriented System Development},
  howpublished = {Licentiate Thesis, Linköping University, Institute of Technology,
	Sweden},
  year = {1994},
  abstract = {We regard a software system as consisting not only of its source code,
	but also of its documented models. Traceability is defined as the
	ability to trace the dependent items within a model and the ability
	to trace the correspondent items in other models. A common use of
	the term traceability is requirements traceability which is the ability
	to trace a requirement via the different models to its implementation
	in the source code. Traceability is regarded as a quality factor
	that facilitates maintenance of a software system. 
	
	The thesis is the result from a case study performed on a large commercial
	software system developed with an object-oriented methodology and
	largely implemented in C++ and by using a relational database. A
	number of concrete traceability examples collected from the project
	are the result of a thorough investigation of the various models
	that were produced during the project. The examples are thoroughly
	analyzed and discussed, forming the main contribution of this research.
	Insight and knowledge as regards traceability and object-oriented
	modeling is the result from the work with the examples.},
  file = {:./literature/licentiateThesis.pdf:PDF},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.15},
  url = {http://informatix.ida.liu.se/labs/aslab/people/mikli/licentiateThesis.ps}
}

@INPROCEEDINGS{Lindvall1998a,
  author = {Lindvall, Mikael and Runesson, Magnus},
  title = {The Visibility of Maintenance in Object Models: An Empirical Study},
  booktitle = {Proceedings of the International Conference on Software Maintenance},
  year = {1998},
  series = {ICSM '98},
  pages = {54-62},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid = {853293},
  file = {:/literature/changeIdentification/lindvall98visibility.pdf:PDF},
  isbn = {0-8186-8779-7},
  keywords = {Rea},
  owner = {Steffen},
  review = {changes
	
	
	AttributeChangedClasses
	
	MethodChangedClasses
	
	InheritanceChangedClasses
	
	CommunicationChangedClasses
	
	VisiblyChangedClasses},
  timestamp = {2012.03.01},
  url = {http://dl.acm.org/citation.cfm?id=850947.853293}
}

@ARTICLE{Lindvall1998b,
  author = {Lindvall, M. and Sandahl, K},
  title = {Traceability aspects of impact analysis in object-oriented systems},
  journal = {Journal of Software Maintenance: Research and Practice},
  year = {1998},
  volume = {10},
  pages = {37-57},
  month = {January},
  abstract = {Impact analysis is an essential activity as cost and effort estimation
	is based on its outcome. Impact analysis, as performed in an industrial
	object-oriented system, has been analysed and evaluated in this case
	study. Preceding the design phase of the fourth release of the PMR
	system (PMR R4), the consequences of a set of new requirements were
	analysed. Traceability links were established between each new requirement
	and the objects predicted to be changed in the design object model,
	which represent the C++ classes in the system. The impact analysis
	as performed in this study was successful in the sense that the software
	engineers in the study prefer this way of working. When asked, they
	claim they are sure the number of objects to be changed is correct,
	while they are less sure about the number of man-hours required.
	The analysis of the impact analysis shows that individual objects
	are often predicted almost correctly, but that the number of actually
	changed objects is often greater than the number of predicted objects.
	The study also shows that tracing by interviewing knowledgeable software
	engineers is far more common than consulting object models and other
	kinds of documentation. A factor that prohibits software engineers
	using object models more extensively is lack of detailed information.
	We see a promising potential for using traceability, together with
	the use of existing object models, to achieve a more structured impact
	analysis process and accurate prediction.},
  keywords = {* impact analysis;
	
	 * traceability;
	
	 * evaluation;
	
	 * object-orientation;
	
	 * case-study;
	
	 * industrial project},
  owner = {Steffen},
  review = {Problem:
	
	
	Research Questions:
	
	
	Contribution:
	
	
	Solution:
	
	-> granularity of entities:
	
	-> granularity of changes:
	
	-> granularity of results:
	
	
	Open Issues:},
  timestamp = {2011.03.14}
}

@ARTICLE{Lindvall1996,
  author = {Lindvall, Mikael and Sandahl, Kristian},
  title = {Practical implications of traceability},
  journal = {Softw. Pract. Exper.},
  year = {1996},
  volume = {26},
  pages = {1161-1180},
  month = {October},
  abstract = {Traceability defined as the ability to trace dependent items within
	a model and the ability to trace correspondent items in other models
	is advocated as a desirable property of a software development process.
	Potential benefits of good traceability are clearer documentation,
	more focussed development, increased ease of system understanding,
	and more precise impact analysis of proposed changes. An industry-scale
	project applying the analysis and design method Objectory has been
	examined and documented with a number of traceability examples generated
	from the perspective of a maintainer attempting to understand the
	system. Four representative examples and a categorization of traceability
	are presented in this study in order to provide a concrete empirical
	basis for the applications of traceability to systems development.},
  acmid = {241708},
  address = {New York, NY, USA},
  doi = {10.1002/(SICI)1097-024X(199610)26:10<1161::AID-SPE58>3.3.CO;2-O},
  file = {:./literature/Lindvall1996.pdf:PDF},
  issn = {0038-0644},
  issue = {10},
  keywords = {analysis of object models, case-study, object-oriented analysis and
	design, objectory, traceability},
  numpages = {20},
  owner = {Stephan},
  publisher = {John Wiley \& Sons, Inc.},
  timestamp = {2010.12.09}
}

@MISC{Link2006,
  author = {Johannes Link},
  title = {Evolutionäre Softwarearchitektur},
  howpublished = {JAX 2006},
  year = {2006},
  note = {Präsentation},
  abstract = {Vortrag auf JAX 2006},
  file = {:./literature/jax_link_PAF4.pdf:PDF},
  keywords = {evolutionäre Softwarearchitektur},
  owner = {Stephan},
  timestamp = {2008.04.02}
}

@INCOLLECTION{Liu2007,
  author = {Liu, Hehui and Li, Zhongjie and Zhu, Jun and Tan, Huafang},
  title = {Business Process Regression Testing},
  booktitle = {Service-Oriented Computing Ã¢â‚¬â€œ ICSOC 2007},
  publisher = {Springer Berlin / Heidelberg},
  year = {2007},
  editor = {KrÃƒÂ¤mer, Bernd and Lin, Kwei-Jay and Narasimhan, Priya},
  volume = {4749},
  series = {Lecture Notes in Computer Science},
  pages = {157-168},
  note = {10.1007/978-3-540-74974-5_13},
  affiliation = {IBM China Research Laboratory, Beijing 100094, China},
  file = {:/literature/RegressionTesting/BPRT.pdf:PDF},
  isbn = {978-3-540-74973-8},
  keyword = {Computer Science},
  keywords = {WSRT},
  owner = {Steffen},
  review = {+changes of the concurrent controlflows and their paths are considered.
	
	
	+BPEL has
	
	 +Atomic Constructs
	
	 +receive, reply, assign
	
	
	 +structured constructs
	
	
	 +while
	
	 +sequence
	
	 +switch 
	
	 +flow constructs
	
	 +synchronisation
	
	 +concurrency
	
	
	A test path table is constructed
	
	
	Diffrerences (addition, deletion, modification) are identified in
	two versions of BPEL.
	
	
	Test paths are selected according to the modifications.
	
	
	For synchronisation case, a special treatement is provided. 
	
	
	No dependencies are considered.},
  timestamp = {2012.03.01},
  url = {http://dx.doi.org/10.1007/978-3-540-74974-5_13}
}

@INPROCEEDINGS{Liu2004,
  author = {Lin Liu and Eric Yu},
  title = {Designing information systems in social context: a goal and scenario
	modelling approach},
  booktitle = {Information Systems: The 14th International Conference on Advanced
	Information Systems Engineering (CAiSE*02)},
  year = {2004},
  volume = {29},
  number = {2},
  pages = {187-203},
  address = {Oxford, UK, UK},
  month = {April},
  publisher = {Elsevier Science Ltd.},
  abstract = {In order to design a better information system, a designer would like
	to have notations to visualize how design experts' know-how can be
	applied according to one's specific social and technology situation.
	We propose the combined use of a goal-oriented requirements language
	(GRL) and a scenario-oriented notation Use Case Maps (UCM) for representing
	design knowledge of information systems. Goal-oriented modelling
	is used throughout the requirements and design process. In GRL, goals
	are used to depict business objectives and system requirements, both
	functional and non-functional. Tasks are used to represent different
	ways for achieving goals. Means-ends reasoning is used to explore
	alternative solutions and their operationalizations into implementable
	system constructs. Social context is modelled in terms of dependency
	relationships among agents and roles. Scenarios expressed in UCM
	are used to describe elaborated business processes or workflow. The
	complementary use of goal-oriented modelling with GRL and scenario
	modelling with UCM is illustrated with an example of designing a
	web-based training system.},
  doi = {http://dx.doi.org/10.1016/S0306-4379(03)00052-8},
  file = {:./literature/ISj03.pdf:PDF},
  issn = {0306-4379},
  keywords = {Information system design, Goal-oriented requirements analysis, Scenario-based
	notation, GRL},
  owner = {Stephan},
  review = {neither scenario-based nor goal modeling alone sufficient for supporting
	the requirements and design process
	
	
	goal-oriented requirements language (GRL) and scenario-based Use Case
	Maps (UCM) used together
	
	
	GRL: intentional elements, intentional links, actors
	
	intentional elements: goal, task, softgoal, resource, belief
	
	
	NFRs represented as softgoals},
  timestamp = {2008.04.14},
  url = {http://www.cs.toronto.edu/~liu/publications/ISj03.pdf}
}

@INPROCEEDINGS{Liu2001,
  author = {Lin Liu and Eric Yu},
  title = {From Requirements to Architectural Design -- Using Goals and Scenarios},
  booktitle = {From Software Requirements to Architectures Workshop (STRAW 2001)},
  year = {2001},
  address = {Toronto, Canada},
  month = {May},
  abstract = {To strengthen the connection between requirements and design during
	the early stages of architectural design, a designer would like to
	have notations to help visualize the incremental refinement of an
	architecture from initially abstract descriptions to increasingly
	concrete components and interactions, all the while maintaining a
	clear focus on the relevant requirements at each step. We propose
	the combined use of a goal-oriented language GRL and a scenarios-oriented
	architectural notation UCM. Goals are used in the refinement of functional
	and non-functional requirements, the exploration of alternatives,
	and their operationalization into architectural constructs. The scenario
	notation is used to depict the incremental elaboration and realization
	of requirements into architectural design. The approach is illustrated
	with an example from the telecom domain.},
  file = {:./literature/STRAW01.pdf:PDF},
  keywords = {URN, GRL, UCM, goal-oriented language, use case maps, architectural
	design, non-functional requirements, screnario-oriented design},
  owner = {Stephan},
  review = {explains Goal Requirments Language and Use Case Maps and how they
	can be used to go from requirements to architectural design},
  timestamp = {2009.01.09},
  url = {http://www.cs.toronto.edu/pub/eric/STRAW01-R2A.pdf}
}

@INPROCEEDINGS{Lobsitz1996,
  author = {Lobsitz, RH},
  title = {A method for assembling a project-specific software process definition},
  booktitle = {System Sciences, 1996., Proceedings of the Twenty-Ninth Hawaii International
	Conference on,},
  year = {1996},
  volume = {1},
  pages = {722--730},
  organization = {IEEE},
  file = {Lobsitz1996.pdf:literature/Lobsitz1996.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.23}
}

@ARTICLE{Lock1999,
  author = {Lock, Simon and Kotonya, Gerald},
  title = {An Integrated, Probabilistic Framework for Requirement Change Impact
	Analysis},
  journal = {Australasian Journal of Information Systems},
  year = {1999},
  volume = {6},
  pages = {38-63},
  number = {2},
  month = {September},
  booktitle = {Proceedings of the 4th Australian conference on Requirements Engineering},
  file = {:./literature/Paper_159.PDF:PDF},
  owner = {Steffen},
  review = {Problem:
	
	
	Research Questions:
	
	
	Contribution:
	
	
	Solution:
	
	-> granularity of entities:
	
	-> granularity of changes:
	
	-> granularity of results:
	
	
	Open Issues:},
  timestamp = {2011.05.11}
}

@MASTERSTHESIS{Looman2009,
  author = {Looman, S.A.M.},
  title = {Impact Analysis of Changes in Functional Requirements in the Behavioral
	View of Software Architectures},
  school = {University of Twente, Faculty of Electrical Engineering, Mathematics
	and Computer Science},
  year = {2009},
  file = {:./literature/Master_1.PDF:PDF},
  owner = {Steffen},
  review = {- IA process for architectures, based on functional requirements
	
	- requirements transformed into formal behavior descriptions
	
	- those descriptions state which requirements are present or should
	be absent in the architecture
	
	- failed descriptions indicate change impacts
	
	
	- scope of analysis: architecture and requirements
	
	- tool: implemented with Alloy
	
	- language: AADL
	
	- scalability: -
	
	- granularity
	
	* changes: +/-/chg. requirement, +/- requirement predicate, +/-/chg.
	component
	
	* artifacts: requirement, component
	
	* results: requirement, component
	
	- technique: traceability
	
	- analysis style:
	
	- evaluation
	
	* size: -
	
	* precision: -
	
	* recall: -
	
	* time: -},
  timestamp = {2011.01.05}
}

@ARTICLE{Lopez2012,
  author = {Claudia López and Víctor Codocedo and Hernán Astudillo and Luiz Marcio
	Cysneiros},
  title = {Bridging the gap between software architecture rationale formalisms
	and actual architecture documents: An ontology-driven approach },
  journal = {Science of Computer Programming},
  year = {2012},
  volume = {77},
  pages = {66 - 80},
  number = {1},
  note = {<ce:title>System and Software Solution Oriented Architectures</ce:title>
	},
  abstract = {Documenting software architecture rationale is essential to reuse
	and evaluate architectures, and several modeling and documentation
	guidelines have been proposed in the literature. However, in practice
	creating and updating these documents rarely is a primary activity
	in most software projects, and rationale remains hidden in casual
	and semi-structured records, such as e-mails, meeting notes, wikis,
	and specialized documents. This paper describes the \{TREx\} (Toeska
	Rationale Extraction) approach to recover, represent and explore
	rationale information from text documents, combining: (1) pattern-based
	information extraction to recover rationale; (2) ontology-based representation
	of rationale and architectural concepts; and (3) facet-based interactive
	exploration of rationale. Initial results from TREx’s application
	suggest that some kinds of architecture rationale can be semi-automatically
	extracted from a project’s unstructured text documents, namely decisions,
	alternatives and requirements. The approach and some tools are illustrated
	with a case study of rationale recovery for a financial securities
	settlement system.},
  doi = {http://dx.doi.org/10.1016/j.scico.2010.06.009},
  file = {:./literature/lopez2012.pdf:PDF},
  issn = {0167-6423},
  keywords = {Design rationale},
  owner = {Sebastian},
  timestamp = {2013.07.26},
  url = {http://www.sciencedirect.com/science/article/pii/S0167642310001218}
}

@INPROCEEDINGS{Lormans2004,
  author = {Lormans, M. and van Dijk, H. and Van Deursen, A. and Nocker, E. and
	de Zeeuw, A.},
  title = {Managing evolving requirements in an outsourcing context: an industrial
	experience report},
  booktitle = {Software Evolution, 2004. Proceedings. 7th International Workshop
	on Principles of},
  year = {2004},
  pages = {149--158},
  organization = {IEEE},
  file = {Lormans2004.pdf:literature/Lormans2004.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.11.15}
}

@UNPUBLISHED{Loether2005,
  author = {Cindy Löther},
  title = {Integration von Usability in den Software-Entwicklungs-Prozess},
  note = {Seminararbeit},
  month = {Juli},
  year = {2005},
  file = {:./literature/ausarbeitung-loether.pdf:PDF},
  keywords = {Usability, Entwicklungsprozess, User Interface},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://ebus.informatik.uni-leipzig.de/www/media/lehre/uiseminar05/ausarbeitung-loether.pdf}
}

@ARTICLE{DeLucia2007,
  author = {Andrea De Lucia and Fasano, Fausto and Oliveto, Rocco and Tortora,
	Genoveffa},
  title = {Recovering traceability links in software artifact management systems
	using information retrieval methods},
  journal = {ACM Trans. Softw. Eng. Methodol.},
  year = {2007},
  volume = {16},
  number = {4, Article 13},
  month = {September},
  acmid = {1276934},
  address = {New York, NY, USA},
  articleno = {13},
  doi = {http://doi.acm.org/10.1145/1276933.1276934},
  file = {:./literature/DeLucia2007.pdf:PDF},
  issn = {1049-331X},
  issue = {4},
  keywords = {Software artifact management, impact analysis, latent semantic indexing,
	traceability management},
  owner = {Stephan},
  publisher = {ACM},
  timestamp = {2010.12.27}
}

@MASTERSTHESIS{Lucke2005,
  author = {Carsten Lucke},
  title = {Architektur grafischer Bedienoberflächen},
  school = {Fachhochschule Brandenburg},
  year = {2005},
  type = {Diploma thesis},
  month = {Sept.},
  abstract = {Die vorliegende Diplomarbeit beschäftigt sich mit dem Entwurf und
	der Realisierung prototypischer Komponenten (siehe Glossar: Anhang
	A auf Seite 107) für die Architektur graﬁscher Bedienoberﬂächen betrieblicher
	Informationssysteme. Die angestellten Untersuchungen setzen auf den
	Erfahrungen auf, die bei der sd&m AG in den letzten Jahren zum Thema
	Client-Architekturen gemacht wurden. 
	
	Auf Basis von JavaServer Faces wird eine Web Client Architektur entwickelt,
	die häuﬁg auftretende Problemstellungen und Anforderungen adressiert
	und Lösungsmöglichkeiten bereitstellt. Dabei wird besonderes Augenmerk
	darauf gelegt, Schnittstellen und Komponenten zu entwerfen, die für
	Web- und Native Clients gleichermaßen geeignet sind.},
  file = {:./literature/architecture-of-user-interfaces_diploma-thesis_carsten-lucke.pdf:PDF},
  keywords = {Quasar Web Client Architektur, GUI, Webprogrammierung, komponentenbasierte
	Architektur},
  owner = {Stephan},
  timestamp = {2009.03.17}
}

@ARTICLE{Luhmann1962,
  author = {Luhmann, N.},
  title = {Funktion und Kausalit{\"a}t},
  journal = {K{\"o}lner Zeitschrift f{\"u}r Soziologie und Sozialpsychologie},
  year = {1962},
  volume = {14},
  pages = {617--644},
  number = {4},
  owner = {patrickr},
  review = {Definition von Variablen (Qual. Analyse):
	
	
	"Variablen sind Begriffe, die planmäßig unbestimmt bleiben; sie sind
	Leerstellen, die aber nicht beliebig, sondern nur in bestimmter Weise,
	durch begrenzte Möglichkeiten ausgefüllt werden können."},
  timestamp = {2012.09.04}
}

@ARTICLE{Lundin1995,
  author = {Lundin, R.A. and S{\"o}derholm, A.},
  title = {A theory of the temporary organization},
  journal = {Scandinavian Journal of management},
  year = {1995},
  volume = {11},
  pages = {437--455},
  number = {4},
  file = {Lundin1995.pdf:literature/Lundin1995.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.19}
}

@ARTICLE{Luo2003,
  author = {Luo, Z. and Sheth, A. and Kochut, K. and Arpinar, B.},
  title = {Exception handling for conflict resolution in cross-organizational
	workflows},
  journal = {Distributed and Parallel databases},
  year = {2003},
  volume = {13},
  pages = {271--306},
  number = {3},
  file = {Luo2003.pdf:literature/Luo2003.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.10.10}
}

@TECHREPORT{Luettich2008,
  author = {Michael Lüttich and René Fiege},
  title = {Anwendung von Axiomatic Design für den Entwurf Serviceorientierter
	Architeckturen},
  institution = {TU-Ilmenau},
  year = {2008},
  month = {April},
  abstract = {Zu den Architekturzielen der Serviceorientierung gehören u. a. eine
	geringe Kopplung, hohe Autonomie, angemessene Granularität sowie
	gute Wiederverwendbarkeit und Komponierbarkeit von Services. Zurzeit
	existieren jedoch noch keine standardisierten Vorgehensmodelle zur
	Entwicklung serviceorientierter Architekturen, welche die Erreichung
	der genannten Architekturziele explizit berücksichtigen und fördern.
	In diesem Punkt besitzt die Entwurfsmethodik Axiomatic Design das
	Potenzial, die Entwicklung einer SOA in den Phasen der Analyse und
	des Entwurfs wesentlich zu unterstützen. Axiomatic Design entstammt
	ursprünglich dem technischen Bereich (Mechanical Engineering), ist
	aber so generisch gestaltet, dass es den strukturierten Entwurf beliebiger
	Objekte und Systeme ermöglicht. Gegenstand dieses Berichtes ist es
	deshalb, Axiomatic Design für den Entwurf serviceorientierter Architekturen
	anzupassen und anzuwenden. Hierfür werden die Entwurfskonstrukte
	und Entwurfsschritte von Axiomatic Design in die SOA-Welt übertragen
	und die der Methode zugrunde liegenden Prinzipien geeignet für den
	Architekturentwurf interpretiert. Das erarbeitete Vorgehen wird an
	einem konkreten Beispiel demonstriert, wobei eine Möglichkeit zur
	Darstellung von SOA-Entwürfen mit der Unified Modeling Language entwickelt
	wird. Abschließend wird der Beitrag von Axiomatic Design im Entwurf
	serviceorientierter Architekturen kritisch geprüft. Hierzu wird der
	Einfluss der Methode auf die Qualität der Entwurfsergebnisse im Hinblick
	auf Kopplung, Kohäsion und Granularität der Services untersucht.
	Für diese Analyse werden im Rahmen eines Messkonzepts Komplexitätsmetriken
	für die Beurteilung der drei genannten Aspekte definiert.},
  file = {:./literature/IBzWI_2008-02.pdf:PDF},
  keywords = {axiomatic design, service oriented architecture, SOA, design, architectural
	goals},
  owner = {Stephan},
  review = {Axiomatic Design used to complement Analysis and Design phase of an
	SOA
	
	
	top-down-decomposition of system functionality
	
	
	bottom-up-synthesis of services for SOA
	
	
	couplings between services marked explicitly with the help of a design
	matrix based on Axiomatic Design},
  timestamp = {2008.04.10},
  url = {http://www.db-thueringen.de/servlets/DerivateServlet/Derivate-14094/IBzWI_2008-02.pdf}
}

@INPROCEEDINGS{Lytra2012,
  author = {Ioanna Lytra and Huy Tran and Uwe Zdun},
  title = {Constraint-Based Consistency Checking between Design Decisions and
	Component Models for Supporting Software Architecture Evolution},
  booktitle = {16th European Conference on Software Maintenance and Reengineering,
	CSMR 2012, Szeged, Hungary, March 27-30, 2012},
  year = {2012},
  editor = {Tom Mens and Anthony Cleve and Rudolf Ferenc},
  pages = {287-296},
  publisher = {IEEE},
  file = {:./literature/Lytra-CSMR2012.pdf:PDF},
  owner = {matthias},
  timestamp = {2013.09.19},
  url = {http://doi.ieeecomputersociety.org/10.1109/CSMR.2012.36}
}

@INPROCEEDINGS{Lytra2013a,
  author = {Ioanna Lytra and Huy Tran and Uwe Zdun},
  title = {Supporting Consistency between Architectural Design Decisions and
	Component Models through Reusable Architectural Knowledge Transformations},
  booktitle = {Software Architecture - 7th European Conference, ECSA 2013, Montpellier,
	France, July 1-5, 2013. Proceedings},
  year = {2013},
  volume = {7957},
  series = {Lecture Notes in Computer Science},
  pages = {224-239},
  publisher = {Springer},
  file = {:./literature/Lytra-ECSA2013.pdf:PDF},
  owner = {matthias},
  timestamp = {2013.09.19},
  url = {http://dx.doi.org/10.1007/978-3-642-39031-9_20}
}

@INPROCEEDINGS{Lytra2013,
  author = {Ioanna Lytra and Uwe Zdun},
  title = {Supporting architectural decision making for systems-of-systems design
	under uncertainty},
  booktitle = {Proceedings of the First International Workshop on Software Engineering
	for Systems-of-Systems, Montpellier, France, July 2, 2013},
  year = {2013},
  pages = {43-46},
  publisher = {ACM},
  file = {:./literature/Lytra-Soses2013.pdf:PDF},
  owner = {matthias},
  timestamp = {2013.09.19},
  url = {http://doi.acm.org/10.1145/2489850.2489859}
}

@ARTICLE{Mader2010a,
  author = {M{\"a}der, P. and Cleland-Huang, J.},
  title = {A visual traceability modeling language},
  journal = {Model Driven Engineering Languages and Systems},
  year = {2010},
  pages = {226--240},
  abstract = {Software traceability is effort intensive and must be applied strategically
	in order to maximize its benefits and justify its costs. Unfortunately,
	development tools provide only limited support for traceability,
	and as a result users often construct trace queries using generic
	query languages which require intensive knowledge of the data-structures
	in which artifacts are stored. In this paper, we propose a usage-centered
	traceability process that utilizes UML class diagrams to define traceability
	strategies for a project and then visually represents trace queries
	as constraints upon subsets of the model. The Visual Trace Modeling
	Language (VTML) allows users to model queries while hiding the underlying
	technical details and data structures. The approach has been demonstrated
	through a prototype system and and evaluated through a preliminary
	experiment to evaluate the expressiveness and readability of VTML
	in comparison to generic SQL queries.},
  file = {Mader2010a - A Visual Traceability Modeling Language.PDF:literature/Mader2010a - A Visual Traceability Modeling Language.PDF:PDF},
  owner = {tobiask},
  publisher = {Springer},
  timestamp = {2012.04.13}
}

@BOOK{Maeder2010,
  title = {Rule-Based Maintenance of Post-Requirements Traceability},
  publisher = {MV-Verlag, M\"{u}nster},
  year = {2010},
  author = {M\"{a}der, Patrick},
  owner = {Steffen},
  timestamp = {2011.10.28}
}

@INPROCEEDINGS{Maeder2007a,
  author = {M\"{a}der, Patrick and Philippow, Ilka and Riebisch, Matthias},
  title = {A Traceability Link Model for the Unified Process},
  booktitle = {Proceedings of the 8th ACIS International Conference on Software
	Engineering, Artificial Intelligence, Networking, and Parallel/Distributed
	Computing},
  year = {2007},
  pages = {700-705},
  address = {Qingdao},
  __markedentry = {[Steffen:]},
  file = {:./literature/Paper_215.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.25}
}

@INCOLLECTION{Mader2010,
  author = {M\"ader, Patrick},
  title = {(Halb-) Automatische Pflege von Anforderungs-Traceability},
  booktitle = {Sammelband „Ausgezeichnete Informatikdissertationen"},
  year = {2010},
  volume = {Volume D-10},
  pages = {131-140},
  abstract = {Die Nachvollziehbarkeit (engl. Traceability) der Umsetzung von Anforderungen
	
	über die verschiedenen Entwicklungsstadien eines Systems wirkt sich
	in vielen
	
	Aspekten positiv auf die Qualität des durchgeführten Entwicklungsprozesses
	aus. Diese
	
	gängige Lehrmeinung wird auch dadurch unterstrichen, dass Traceability
	bei der
	
	Entwicklung sicherheitskritischer Systeme vorgeschrieben ist. Ein
	immenses Problem
	
	ist der hohe manuelle Aufwand für die Erstellung und Aufrechterhaltung
	der nötigen
	
	Beziehungen (Traceability Links).
	
	Im Rahmen der hier vorgestellten Dissertation [Mäd09] wurde ein Verfahren
	entwickelt,
	
	implementiert und evaluiert, welches einen Teil des manuellen Aufwands
	
	für die Aufrechterhaltung von Traceability in rechentechnischen Aufwand
	umwandelt.
	
	Experimente haben gezeigt, dass mit diesem Ansatz eine drastische
	Senkung des
	
	manuellen Aufwands möglich ist. Die Qualität der automatisiert gepflegten
	Beziehungen
	
	war gleichwertig oder besser als die manuelle Pflege durch den Systementwickler.
	
	Die insgesamt deutlich reduzierten Kosten für die Aufrechterhaltung
	von Traceability-
	
	Beziehungen können ein entscheidender Schritt zu einem weitreichenden
	Einsatz in
	
	der industriellen Entwicklung von Systemen sein. Die Ergebnisse ermöglichen
	außerdem
	
	einen Fortschritt bei der Entwicklung von Werkzeugen zur besseren
	Unterstützung
	
	von Softwareentwicklungsprozessen.},
  file = {:./literature/GIDISS2009_maeder.pdf:PDF},
  owner = {elkeb},
  timestamp = {2011.07.01}
}

@PHDTHESIS{Maeder2009,
  author = {M\"ader, P.},
  title = {Rule-Based Maintenance of Post-Requirements Traceability},
  school = {TU Ilmenau},
  year = {2009},
  address = {Ilmenau, Germany},
  abstract = {Traceability relations support stakeholders in understanding the dependencies
	between artifacts created during the development of a software system.
	Traceability relations thus enable engineers to perform many development-related
	tasks, such as: (a) confirming the implementation of requirements;
	(b) analyzing the impact of changing requirements; and (c) supporting
	regression tests after changes. To ensure that all these benefits
	can be real- ized, it is necessary to have an up-to-date set of traceability
	relations between the estab- lished artifacts. That goal requires,
	not only the creation of the relations during the initial development
	process, but also the maintenance of these relations after changes
	to the asso- ciated artifacts. Researchers have found the necessity
	to establish and maintain traceability manually to be the main reason
	for its rare use in industrial projects.
	
	In this thesis an approach is developed that supports the (semi-)
	automated update of traceability relations between requirements,
	analysis and design models of software sys- tems expressed in UML.
	This is made possible by analyzing change events that have been captured
	while working within a third-party UML modeling tool. Within the
	captured flow of events, development activities comprised of several
	events are recognized. These development activities are expressed
	as predefined rules. Rules consist of masks requiring an event with
	certain properties. Once recognized, the corresponding rule gives
	a directive to update impacted traceability relations to prevent
	its decay. The approach is intended as a complement to those approaches
	that initially create a set of traceability relations using manual
	or automated techniques. Limitations of the approach are that only
	predefined activities can be recognized and these are unlikely to
	reflect all possible development ap- proaches, so it is necessary
	to customize the rules to project specifics.
	
	A prototype implementation of the approach, called traceMAINTAINER,
	is available and can be used currently with two different UML modeling
	tools. This prototype also provides support for the customization
	of existing and the creation of new rules. traceMAINTAINER enabled
	the evaluation of the approach in several initial studies and its
	usage in two in- dustrial evaluation projects at Siemens. A larger
	experiment, involving sixteen students of the TU Ilmenau, showed
	that the eight subjects using the approach spent approximately 71
	% less manual effort on maintaining traceability relations than the
	subjects within the group that performed unsupported manual maintenance.
	The quality of the maintenance was comparable among both treatments.},
  file = {:./literature/ThesisMaeder.pdf:PDF},
  keywords = {post-requirements traceability, rule-based traceability, maintenance
	of traceability links},
  owner = {Stephan},
  review = {Referenzen die interessant sein könnten:
	
	
	Dorfman & Flynn 1984: Arts - an Automated Requirements Traceability
	System
	
	!Maletic et al. 2005: An XML-based approach to support the evolution
	of model-to-model traceability links
	
	Mens & D'Hondt 2000: Automating support for software evolution in
	UML
	
	Mens et al. 2005: A framework for managing consistency of evolving
	UML models
	
	Pfleeger & Bohner 1990: A framework of software maintenance metrics
	
	Prechelt 2001: Kontrollierte Experimente in der SWT
	
	Russek 2004: Open Quasar development of open source components with
	the aid of Quasar
	
	Smith 1999: Designing Maintainable Software
	
	Spanoudakis & Zisman 2005: Software traceability: A roadmap
	
	!Marta et al. 2008: Continuous and automated evolution of architecture-to-implementation
	traceability links
	
	Lehman & Ramil 2003: Software evolution - Background, Theory, Practice
	
	Cleland-Huang et al. 2006: Grand Challenges in Traceability (Tech
	Report COET-GCT-06-01, University of Kentucky)
	
	
	-----------------------------
	
	Elke},
  timestamp = {2009.11.27}
}

@CONFERENCE{Mader2009b,
  author = {M\"ader, Patrick and Gotel, Orlena and Philippow, Ilka},
  title = {Motivation Matters in the Traceability Trenches},
  booktitle = {Proc. of 17th Int'l Requirements Engineering Conference (RE09)},
  year = {2009},
  pages = {143-148},
  file = {:./literature/05328607.pdf:PDF},
  owner = {Elke},
  timestamp = {2011.06.09}
}

@INPROCEEDINGS{Maeder2009c,
  author = {M\"ader, P. and Gotel, O. and Philippow, I.},
  title = {Getting back to basics: Promoting the use of a traceability information
	model in practice},
  booktitle = {Traceability in Emerging Forms of Software Engineering, 2009. TEFSE
	'09. ICSE Workshop on},
  year = {2009},
  pages = {21 -25},
  month = {may},
  abstract = {It is widely assumed that following a process is a good thing if you
	want to achieve and exploit the benefits of traceability on a software
	development project. A core component of any such process is the
	definition and use of a traceability information model. Such models
	provide guidance as to those software development artifacts to collect
	and those relations to establish, and are designed to ultimately
	support required project analyses. However, traceability still tends
	to be undertaken in rather ad hoc ways in industry, with unpredictable
	results. We contend that one reason for this situation is that current
	software development tools provide little support to practitioners
	for building and using customized project-specific traceability information
	models, without which even the simplest of processes are problematic
	to implement and gain the anticipated benefits from. In this paper,
	we highlight the typical decisions involved in creating a basic traceability
	information model, suggest a simple UML-based representation for
	its definition, and illustrate its central role in the context of
	a modeling tool. The intent of this paper is to re-focus attention
	on very practical ways to apply traceability information models in
	practice so as to encourage wider adoption.},
  doi = {10.1109/TEFSE.2009.5069578},
  file = {:./literature/05069578.pdf:PDF},
  keywords = {UML-based representation;customized project-specific traceability
	information models;software development artifacts;software development
	project;software development tools;Unified Modeling Language;project
	management;software tools;},
  owner = {elkeb},
  timestamp = {2011.07.01}
}

@INPROCEEDINGS{Maeder2008,
  author = {Patrick M\"ader and Orlena Gotel and Ilka Philippow},
  title = {Rule-Based Maintenance of Post-Requirements Traceability Relations},
  booktitle = {Proceedings of the 2008 16th IEEE International Requirements Engineering
	Conference (RE '08)},
  year = {2008},
  pages = {23-32},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {An accurate set of traceability relations between software development
	artifacts is desirable to support evolutionary development. However,
	even where an initial set of traceability relations has been established,
	their maintenance during subsequent development activities is time
	consuming and error prone, which results in traceability decay. This
	paper focuses solely on the problem of maintaining a set of traceability
	relations in the face of evolutionary change, irrespective of whether
	generated manually or via automated techniques, and it limits its
	scope to UML-driven development activities post-requirements specification.
	The paper proposes an approach for the automated update of existing
	traceability relations after changes have been made to UML analysis
	and design models. The update is based upon predefined rules that
	recognize elementary change events as constituent steps of broader
	development activities. A prototype traceMaintainer has been developed
	to demonstrate the approach. Currently, traceMaintainer can be used
	with two commercial software development tools to maintain their
	traceability relations. The prototype has been used in two experiments.
	The results are discussed and our ongoing work is summarized.},
  doi = {http://dx.doi.org/10.1109/RE.2008.24},
  file = {:./literature/maeder-RuleBasedTraceability.pdf:PDF},
  isbn = {978-0-7695-3309-4},
  keywords = {change, post-requirements traceability, rule-based traceability, traceability
	maintanence},
  owner = {Stephan},
  timestamp = {2009.01.26}
}

@INPROCEEDINGS{Maeder2008a,
  author = {M\"ader, P. and Gotel, O. and Philippow, I.},
  title = {Enabling Automated Traceability Maintenance by Recognizing Development
	Activities Applied to Models},
  booktitle = {23rd IEEE/ACM International Conference on Automated Software Engineering,
	2008. ASE 2008.},
  year = {2008},
  pages = {49-58},
  month = {Sept.},
  publisher = {IEEE},
  abstract = {For anything but the simplest of software systems, the ease and costs
	associated with change management can become critical to the success
	of a project. Establishing traceability initially can demand questionable
	effort, but sustaining this traceability as changes occur can be
	a neglected matter altogether. Without conscious effort, traceability
	relations become increasingly inaccurate and irrelevant as the artifacts
	they associate evolve. Based upon the observation that there are
	finite types of development activity that appear to impact traceability
	when software development proceeds through the construction and refinement
	of UML models, we have developed an approach to automate traceability
	maintenance in such contexts. Within this paper, we describe the
	technical details behind the recognition of these development activities,
	a task upon which our automated approach depends, and we discuss
	how we have validated this aspect of the work to date.},
  doi = {10.1109/ASE.2008.15},
  file = {:./literature/PID667099_camera_ready.pdf:PDF},
  keywords = {Unified Modeling Language, management of change, project management,
	software development management, software engineering, software maintenance,
	UML models, Unified Modeling Language, automated traceability maintenance,
	change management, software development, software systems, traceability
	relations},
  owner = {Stephan},
  timestamp = {2009.02.17}
}

@INPROCEEDINGS{Maeder2007,
  author = {Patrick M\"ader and Ilka Philippow and Matthias Riebisch},
  title = {Customizing Traceability Links for the Unified Process},
  booktitle = {Proceedings Third International Conference on the Quality of Software-Architectures
	(QOSA2007)},
  year = {2007},
  volume = {4880},
  series = {LNCS},
  address = {Medford MA, USA},
  month = {July},
  publisher = {Springer},
  abstract = {Traceability links are generally recognised as helpful means for improving
	the effectiveness of evolutionary development processes. However,
	their practical usage in analysis and design is still unsatisfying,
	especially due to the high effort required for creation, maintenance
	and verification of the links, and due to lacking or missing methods
	and tools for their management.
	
	In this paper a concept for the systematic management of traceability
	is introduced, adapted for the and integrated into the Unified Process
	as one of the widely accepted software development methods. As an
	extension, requirements templates are applied to facilitate a tool
	supported analysis of natural language texts in use case descriptions.
	Template-based analyses enable a determination of types of terms
	and a check of their correct application as well as a recognition
	of implicit connections between development artefacts. A rule set
	is defined as a first step towards a powerful support of traceability
	handling. In the ongoing project the rule set is enhanced by heuristics
	and semantic-based rules to a whole framework of methods and rules.},
  doi = {10.1007/978-3-540-77619-2_4},
  file = {:./literature/TraceabilityUnifiedProcess.pdf:PDF},
  keywords = {Traceability Link, Traceability Model, Evolutionary Development, Requirements
	Engineering, Object-Oriented Methods, Requirements Templates, Unified
	Process, Glossary},
  owner = {Matthias},
  timestamp = {2008.07.15}
}

@INPROCEEDINGS{Maeder2006,
  author = {Patrick M\"ader and Matthias Riebisch and Ilka Philippow},
  title = {Maintaining Traceability Links during Evolutionary Software Development},
  booktitle = {Proceedings 8. Workshop Software-Reengineering},
  year = {2006},
  volume = {26},
  number = {3},
  series = {Softwaretechnik-Trends},
  pages = {89-90},
  address = {Bad-Honnef},
  month = {May 3-5},
  file = {:./literature/wsr06paper_maeder.pdf:PDF},
  keywords = {traceability link, evolutionary software development},
  owner = {Robert},
  timestamp = {2007.06.11},
  url = {http://www.theoinf.tu-ilmenau.de/~Matthias/home/publ/wsr06paper_maeder.pdf}
}

@INPROCEEDINGS{Maeder2006b,
  author = {M\"ader, Patrick and Riebisch, Matthias and Philippow, Ilka},
  title = {Traceability for Managing Evolutionary Change},
  booktitle = {Proceedings of the 15th International Conference on Software Engineering
	and Data Engineering (SEDE-2006)},
  year = {2006},
  pages = {1-8},
  address = {Los Angeles, California, USA},
  month = {July},
  file = {:./literature/SEDE2006-068-R.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.10.21}
}

@INPROCEEDINGS{Mueller2000,
  author = {Hausi A. M\"uller and Jens H. Jahnke and Dennis B. Smith and Margaret-Anne
	D. Storey and Scott R. Tilley and Kenny Wong},
  title = {Reverse engineering: a roadmap},
  booktitle = {Proceedings of the Conference on The Future of Software Engineering,
	ICSE '00},
  year = {2000},
  pages = {47-60},
  month = {June},
  abstract = {By the early 1990s the need for reengineering legacy systems was already
	acute, but recently the demand has increased significantly with the
	shift toward web-based user interfaces. The demand by all business
	sectors to adapt their information systems to the Web has created
	a tremendous need for methods, tools, and infrastructures to evolve
	and exploit existing applications efficiently and cost-effectively.
	Reverse engineering has been heralded as one of the most promising
	technologies to combat this legacy systems problem. 
	
	This paper presents a roadmap for reverse engineering research for
	the first decade of the new millennium, building on the program comprehension
	theories of the 1980s and the reverse engineering technology of the
	1990s.},
  citeseerurl = {citeseer.ist.psu.edu/muller00reverse.html},
  file = {:./literature/finalmuller.pdf:PDF},
  keywords = {Software engineering, reverse engineering, data reverse engineering,
	program understanding, program comprehension, software analysis,
	software evolution, software maintenance, software reengineering,
	software migration, software tools, tool adoption, tool evaluation},
  owner = {Stephan},
  review = {current (2000) research on code level, but code does not contain all
	information
	
	-> to get the big picture focus research on the more significant levels
	of the business processes and the software architecture
	
	
	research issues:
	
	- patterns of change
	
	- reconstruct mappings between application and implementation domain
	
	- tool support for mappings
	
	- software comprehension on various levels of abstraction and maintain
	mappings between these levels
	
	
	- data reverse engineering: what information is stored and how can
	this information be used in a different context
	
	-> can be used to assess the overall quality of sofware systems
	
	-> to major activities: data analysis and conceptual abstraction
	
	
	data reverse engineering tools need to be customizable, support iteration,
	bidirectional mapping processes
	
	
	- resolve lack of reverse engineering skills
	
	-> tools need to be better integrated with common development environments
	
	
	interesting references:
	
	[20] Reverse engineering and design recovery: A taxonomy -> Chikofsky1990
	
	[13] Migrating Legacy Systems... (book)
	
	[8] Program Understanding...
	
	[16] Antipatterns: Refactoring Software, Architectures, and Projects
	in Crisis
	
	[30] Fowler: Refactoring... (book)
	
	[42] Reconstructing sofware architecture from evailable evidence -
	higher abstraction level -> Kazman1999
	
	[46] ...laws of software evolution -> Lehman1980},
  timestamp = {2008.04.17},
  url = {http://www.cs.ucl.ac.uk/staff/A.Finkelstein/fose/finalmuller.pdf}
}

@TECHREPORT{Maalej2009,
  author = {Walid Maalej and Wie Fang},
  title = {Results of the Survey On Tool Integration
	
	In Software Engineering 2009},
  institution = {TU München},
  year = {2009},
  file = {:./literature/TechReport_Tool_Integration_2009.pdf:PDF},
  owner = {elkeb},
  timestamp = {2011.11.23}
}

@INPROCEEDINGS{Mader2011,
  author = {Mader, P. and Egyed, A.},
  title = {Do software engineers benefit from source code navigation with traceability?;
	An experiment in software change management},
  booktitle = {Automated Software Engineering (ASE), 2011 26th IEEE/ACM International
	Conference on},
  year = {2011},
  pages = {444-447},
  month = {Nov},
  doi = {10.1109/ASE.2011.6100095},
  issn = {1938-4300},
  keywords = {management of change;program debugging;program diagnostics;software
	maintenance;software management;source coding;mainstream development
	environments;software change management;software engineers;source
	code navigation;third-party development projects;traceability benefit
	basic maintenance tasks;Automation;Industries;Maintenance engineering;Navigation;Software
	maintenance;Unified modeling language}
}

@ARTICLE{Madhavji1991,
  author = {Madhavji, N.H. and Schafer, W.},
  title = {Prism-methodology and process-oriented environment},
  journal = {Software Engineering, IEEE Transactions on},
  year = {1991},
  volume = {17},
  pages = {1270--1283},
  number = {12},
  file = {Madhavji1991.pdf:literature/Madhavji1991.pdf:PDF},
  owner = {patrickr},
  publisher = {IEEE},
  timestamp = {2012.07.23}
}

@ARTICLE{Mahdian2009,
  author = {Alireza Mahdian and Anneliese Amschler Andrews and Orest Jacob Pilskalns},
  title = {Regression testing with UML software designs: A survey},
  journal = {J. Softw. Maint. Evol.},
  year = {2009},
  volume = {21},
  pages = {253--286},
  number = {4},
  abstract = {The unified modeling language {(UML)} designs come in a variety of
	different notations. {UML} designs can be quite large and interactions
	between various notations and the models they define can be difficult
	to assess. During the design phase, and between successive releases
	of systems, designs change. The impact of such changes and the resulting
	effect on behavior can be non-obvious and difficult to assess. This
	survey article explores techniques for such re-evaluation that can
	be classified as regression testing and suggests regression testing
	criteria for designs. These might vary depending on testing objectives
	and include both selective and regenerative regression testing approaches.
	The article provides a concise overview of regression testing approaches
	related to various {UML} design notations including use cases, class
	diagrams, sequence diagrams, activity diagrams, and statecharts,
	as well as combinations of these models. It discusses {UML-related}
	techniques involving cost and prioritization during selective regression
	testing. Finally, it evaluates these techniques with respect to inclusiveness,
	precision, efficiency, generality, accountability, and safety. An
	example is used throughout to illustrate how the techniques work.
	Copyright Ã‚Â© 2009 John Wiley \& Sons, Ltd.},
  file = {:/literature/RegressionTesting/403_ftp.pdf:PDF},
  keywords = {design testing, regression testing, software testing, comparative},
  owner = {Annie},
  shorttitle = {Regression testing with {UML} software designs},
  timestamp = {2011.01.04},
  url = {http://portal.acm.org/citation.cfm?id=1573935.1573937&coll=GUIDE&dl=GUIDE&CFID=54491404&CFTOKEN=93053143}
}

@INPROCEEDINGS{Maia2010,
  author = {Maia, M. C. O. and Bittencourt, R. A. and de Figueiredo, J. C. A.
	and Guerrero, D. D. S.},
  title = {The Hybrid Technique for Object-Oriented Software Change Impact Analysis},
  booktitle = {Proceedings of the 14th European Conference on Software Maintenance
	and Reengineering (CSMR '10)},
  year = {2010},
  pages = {252-255},
  address = {Madrid, Spain},
  month = {March},
  file = {:./literature/Paper_158.PDF:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- IA techniques which miss impacted elements can cause financial losses
	and result in delays etc.
	
	- most static/dynamic IA techniques produce too many false-positives
	and negative-positives
	
	
	Research Questions:
	
	- how to combine static and dynamic IA to improve detection of impacted
	entities and reduce false positives
	
	
	Contribution:
	
	- hybrid technique using static and dynamic IA to improve recall
	
	
	Solution:
	
	- IA method consists of 3 steps
	
	* static analysis: identify structural dependencies
	
	 - use DFS to identify SIS
	
	 - extract dependency graph from code
	
	 - use fixed distance to cut-off branches
	
	* dynamic analysis: dependencies derived from execution traces (execution
	after sequences)
	
	 - also collect variable read/write
	
	 - enhance this with frequency of succession relations (count calls)
	
	 - use a successor-stop-distance to stop counting successive calls
	at a certain distance (assumption: closer methods are more likely
	to be impacted)
	
	* join and rank results from both steps
	
	 - based on impact factor gained in 2nd step
	
	 - impact factor is probability of an entitiy being the sucessor of
	an event in the change set obtained by dyn. analysis
	
	-> granularity of entities: class, method, variable
	
	-> granularity of changes: add/remove/modification of class/method/variable
	
	-> granularity of results:
	
	- implemented in tool SD-Impala
	
	
	Open Issues:
	
	- include additional entities such as database schemes and software
	features into IA},
  timestamp = {2011.04.05}
}

@INPROCEEDINGS{Malavolta2011,
  author = {Malavolta, Ivano and Muccini, Henry and Rekha, V. Smrithi},
  title = {Supporting architectural design decisions evolution through model
	driven engineering},
  booktitle = {Proceedings of the Third International Workshop on Software Engineering
	for Resilient Systems},
  year = {2011},
  pages = {63-77},
  file = {:./literature/Software-Engineering-for-Resilient-Systems.pdf:PDF},
  owner = {Steffen},
  timestamp = {2014.03.14}
}

@INPROCEEDINGS{Maletic2003,
  author = {Jonathan I. Maletic and Ethan V. Munson and Andrian Marcus and Tien
	N. Nguyen},
  title = {Using a hypertext model for traceability link conformance analysis},
  booktitle = {Proceedings of the 2nd International Workshop on Traceability in
	Emerging Forms of Software Engineering (TEFSE2003)},
  year = {2003},
  pages = {47-54},
  abstract = {A number of techniques for semi-automated traceability link recovery
	between source code and documentation have recently been proposed
	to support the reverse engineering and maintenance of legacy systems.
	This is only the first step in supporting the long term maintainability
	of such systems. A crucial issue, after recovering traceability links
	is analyzing their general conformance over time. That is, as a system
	is changed during evolution the validity and conformance of the links
	may change. Thus, conformance analysis must be performed to identify
	possible non-conformance of the links. The paper presents a holistic
	view of how to combine link recovery with conformance analysis that
	is facilitated by a formal hypertext model. This hypertext model
	not only supports complex linking structures (e.g., multi links)
	but also supports versioning of individual links. Such a model preserves
	and maintains over time the results of the reverse engineered traceability
	links.},
  file = {:./literature/Maletic2003.pdf:PDF},
  keywords = {traceability, causal link type},
  owner = {Stephan},
  timestamp = {2011.01.25}
}

@INPROCEEDINGS{Malishevsky2002,
  author = {Malishevsky, Alexey G. and Rothermel, Gregg and Elbaum, Sebastian},
  title = {Modeling the Cost-Benefits Tradeoffs for Regression Testing Techniques},
  booktitle = {Proceedings of the International Conference on Software Maintenance
	(ICSM'02)},
  year = {2002},
  pages = {204-213},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[qurat:]},
  acmid = {879817},
  file = {:/literature/RegressionTesting/modelling cost benefit trade offs for regression testing techniques.pdf:PDF},
  isbn = {0-7695-1819-2},
  keywords = {cost mode comparative studyy.},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=876882.879817}
}

@ARTICLE{Manning2008,
  author = {Manning, S.},
  title = {Embedding projects in multiple contexts--a structuration perspective},
  journal = {International Journal of Project Management},
  year = {2008},
  volume = {26},
  pages = {30--37},
  number = {1},
  file = {Manning2008.pdf:literature/Manning2008.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.19}
}

@BOOK{Manolescu2006,
  title = {Pattern Languages of Program Design 5},
  publisher = {{Addison-Wesley} Professional},
  year = {2006},
  author = {Dragos Manolescu and Markus Voelter and James Noble},
  month = may,
  isbn = {0321321944},
  owner = {Stephan},
  timestamp = {2010.12.31}
}

@INPROCEEDINGS{Mansour:2007:UBR:1647636.1647654,
  author = {Mansour, Nashat and Takkoush, Husam},
  title = {UML based regression testing for OO software},
  booktitle = {Proceedings of the 11th IASTED International Conference on Software
	Engineering and Applications},
  year = {2007},
  pages = {96--101},
  address = {Anaheim, CA, USA},
  publisher = {ACTA Press},
  acmid = {1647654},
  isbn = {978-0-88986-706-2},
  keywords = {design-level testing, object-oriented regression testing, regression
	test selection},
  location = {Cambridge, Massachusetts},
  numpages = {6},
  owner = {Steffen},
  timestamp = {2012.03.01},
  url = {http://portal.acm.org/citation.cfm?id=1647636.1647654}
}

@ARTICLE{Mansour2011,
  author = {Nashat Mansour and Husam Takkoush and Ali Nehme},
  title = {UML-based regression testing for OO software},
  journal = {Journal of Software Maintenance and Evolution: Research and Practice},
  year = {2011},
  volume = {23},
  pages = {51--68},
  number = {1},
  doi = {10.1002/smr.508},
  issn = {{1532060X}},
  owner = {Annie},
  timestamp = {2011.04.08},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/smr.508/abstract}
}

@ARTICLE{Mansour2010,
  author = {Nashat Mansour and Husam Takkoush and Ali Nehme},
  title = {UML-based regression testing for OO software},
  journal = {Journal of Software Maintenance and Evolution: Research and Practice},
  year = {2010},
  pages = {n/a},
  file = {:/literature/RegressionTesting/Model based Regression Testing of OO software.pdf:PDF;:/literature/RegressionTesting/UML BASED REGRESSION TESTING FOR OO SOFTWARE.pdf:PDF},
  issn = {1532-0618},
  keywords = {design-level testing, object-oriented regression testing, regression
	test selection, software maintenance, {UML},MBRT},
  owner = {Annie},
  review = {Scope: System Level and Unit Level
	
	
	Artifacts: IOD, SD, CD
	
	
	Change Types,: No specific change types are considered. 
	
	
	Traceability: is not explicitly specified. Testcases corresponding
	to a model are traced by name.
	
	
	Test Suite Classification: Affected
	
	
	Tool support: No
	
	
	Case study: YES ( Test cases, 3 different applications size of max
	test cases in application is 90 )},
  timestamp = {2011.01.04},
  url = {http://dx.doi.org/10.1002/smr.508}
}

@ARTICLE{Maentylae2006,
  author = {Mika V. Mäntylä and Casper Lassenius},
  title = {Subjective evaluation of software evolvability using code smells:
	An empirical study},
  journal = {Empirical Software Engineering},
  year = {2006},
  volume = {11},
  pages = {395-431},
  number = {3},
  month = {September},
  abstract = {This paper presents the results of an empirical study on the subjective
	evaluation of code smells that identify poorly evolvable structures
	in software. We propose use of the term software evolvability to
	describe the ease of further developing a piece of software and outline
	the research area based on four different viewpoints. Furthermore,
	we describe the differences between human evaluations and automatic
	program analysis based on software evolvability metrics. The empirical
	component is based on a case study in a Finnish software product
	company, in which we studied two topics. First, we looked at the
	effect of the evaluator when subjectively evaluating the existence
	of smells in code modules. We found that the use of smells for code
	evaluation purposes can be difficult due to conflicting perceptions
	of different evaluators. However, the demographics of the evaluators
	partly explain the variation. Second, we applied selected source
	code metrics for identifying four smells and compared these results
	to the subjective evaluations. The metrics based on automatic program
	analysis and the human-based smell evaluations did not fully correlate.
	Based upon our results, we suggest that organizations should make
	decisions regarding software evolvability improvement based on a
	combination of subjective evaluations and code metrics. Due to the
	limitations of the study we also recognize the need for conducting
	more refined studies and experiments in the area of software evolvability.},
  doi = {10.1007/s10664-006-9002-8},
  file = {:./literature/Maentylae2006.pdf:PDF},
  keywords = {Code smells, Subjective evaluation, Perceived evaluation, Maintainability,
	Evolvability, Code metrics, Software metrics, Human factors},
  owner = {Stephan},
  timestamp = {2008.07.31},
  url = {http://faculty.ksu.edu.sa/ghazy/Documents/Emp%20SWE%2006/Subjective%20evaluation%20of%20software%20evolvability%20using%20code%20sm.pdf}
}

@INPROCEEDINGS{Mao2005,
  author = {Mao, Chengying and Lu, Yansheng},
  title = {Regression Testing for Component-based Software Systems by Enhancing
	Change Information},
  booktitle = {Proceedings of the 12th Asia-Pacific Software Engineering Conference},
  year = {2005},
  pages = {611--618},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[qurat:]},
  acmid = {1122210},
  doi = {10.1109/APSEC.2005.95},
  file = {:/literature/RegressionTesting/01607201.pdf:PDF},
  isbn = {0-7695-2465-6},
  keywords = {code based, component-based software system, regression testing, labeled
	method call graph, change information, test case selection},
  numpages = {8},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=1121989.1122210}
}

@INPROCEEDINGS{Maoz:2011:ASD:2025113.2025140,
  author = {Maoz, Shahar and Ringert, Jan Oliver and Rumpe, Bernhard},
  title = {ADDiff: semantic differencing for activity diagrams},
  booktitle = {Proceedings of the 19th ACM SIGSOFT symposium and the 13th European
	conference on Foundations of software engineering},
  year = {2011},
  series = {ESEC/FSE '11},
  pages = {179--189},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {2025140},
  doi = {http://doi.acm.org/10.1145/2025113.2025140},
  file = {:/literature/changeIdentification/ADDiff Semantic Differencing for ActivityDiagrams.pdf:PDF},
  isbn = {978-1-4503-0443-6},
  keywords = {activity diagrams, diagrams, software evolution},
  location = {Szeged, Hungary},
  numpages = {11},
  owner = {Steffen},
  timestamp = {2012.03.01},
  url = {http://doi.acm.org/10.1145/2025113.2025140}
}

@INPROCEEDINGS{Marco2006,
  author = {Antinisca Di Marco and Raffaela Mirandola},
  title = {Model Transformation in Software Performance Engineering},
  booktitle = {Quality of Software Architectures},
  year = {2006},
  editor = {Hofmeister, Christiane et al.},
  volume = {4214/2006},
  series = {LNCS},
  pages = {95-110},
  publisher = {Springer},
  abstract = {Nowadays it is widely recognized the crucial role played in the software
	development process by the analysis of extra-functional properties
	(and especially performance) at the architectural level. To foster
	this kind of quantitative analysis we envisage the need to transform
	the performance model generation and analysis into a rigorous and
	sound discipline. To this end we intend to exploit the knowledge
	(acquired by other disciplines) in the area of model transformation,
	and import both reasoning and methodologies in the software performance
	engineering. In this paper we investigate the area of performance
	model derivation and analysis focusing on model transformation; we
	propose an initial taxonomy for the area of performance analysis
	at software architecture level and we delineate our suggestions towards
	a software performance model driven engineering.},
  doi = {10.1007/11921998_11},
  file = {:./literature/marco2006.pdf:PDF},
  keywords = {model transformation, software engineering, non-functional poperties,
	performance analysis, software architecture},
  owner = {Stephan},
  timestamp = {2008.04.10},
  url = {http://www.springerlink.com/content/03726625328n627g/fulltext.pdf}
}

@INPROCEEDINGS{Marcus2003,
  author = {Andrian Marcus and Jonathan I. Maletic},
  title = {Recovering Documentation-to-Source-Code Traceability Links using
	Latent Semantic Indexing},
  booktitle = {International Conference on Software Engineering (ICSE'03)},
  year = {2003},
  pages = {125-135},
  address = {Los Alamitos, CA, USA},
  publisher = {IEEE},
  abstract = {An information retrieval technique, latent semantic indexing, is used
	to automatically identify traceability links from system documentation
	to program source code. The results of two experiments to identify
	links in existing software systems (i.e., the LEDA library, and Albergate)
	are presented. These results are compared with other similar type
	experimental results of traceability link identification using different
	types of information retrieval techniques. The method presented proves
	to give good results by comparison and additionally it is a low cost,
	highly flexible method to apply with regards to preprocessing and/or
	parsing of the source code and documentation.},
  doi = {http://doi.ieeecomputersociety.org/10.1109/ICSE.2003.1201194},
  file = {:./literature/MarcusICSE03.pdf:PDF},
  issn = {0270-5257},
  keywords = {traceability, latent semantic indexing},
  owner = {Stephan},
  timestamp = {2009.10.14},
  url = {http://wwwedit.cs.wayne.edu/~amarcus/papers/icse03.pdf}
}

@INPROCEEDINGS{Marcus2005,
  author = {Marcus, Andrian and Xie, Xinrong and Poshyvanyk, Denys},
  title = {When and How to Visualize Traceability Links?},
  booktitle = {Proceedings of the 3rd international workshop on Traceability in
	emerging forms of software engineering (TEFSE '05)},
  year = {2005},
  pages = {56-61},
  __markedentry = {[Steffen:]},
  file = {:./literature/Paper_214.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.25}
}

@TECHREPORT{MarcusAlanen2003,
  author = {Marcus Alanen, Ivan Porres},
  title = {Difference and Union of Models},
  institution = {Turku Centre for Computer Science},
  year = {2003},
  number = {952-12-1165-2},
  file = {:/literature/changeIdentification/TR527.pdf:PDF},
  keywords = {Read},
  owner = {Annie},
  review = {Changes
	
	
	Changes are modelled in form of change operations
	
	
	//element modifications
	
	
	e=element
	
	t=type
	
	
	+ new (e, t)
	
	+del (e,t)
	
	
	//feature modifications
	
	
	Modification of a feature of type f of an element with UUID e. Where
	
	necessary, ut refers to another element et . Depending on the type
	of feature,
	
	this might mean one of the following modifications.
	
	
	
	+ set(u,f,vo, vn): Set the value of e.f from vo to vn, for an attribute
	of
	
	primitive type.
	
	
	+ insert(u, f,ut): Add a link from e.f to et , for an unordered feature.
	
	
	+ remove(u,f,ut): Remove a link from e.f to et , for an unordered
	feature.
	
	
	+ insertAt(u,f,ut,i) : Add a link from e.f to et , at index i, for
	an ordered
	
	feature.
	
	
	+removeAt(u,f,ut,i): Remove a link from e f to et , which is at index
	i,
	
	for an ordered feature.},
  timestamp = {2011.10.21}
}

@INPROCEEDINGS{Marinescu2004,
  author = {Marinescu, R. and Ratiu, D.},
  title = {Quantifying the Quality of Object-Oriented Design: the Factor-Strategy
	Model},
  booktitle = {Proceedings 11th Working Conference on Reverse Engineering, (WCRE
	2004)},
  year = {2004},
  pages = {192 - 201},
  publisher = {IEEE},
  abstract = {The quality of a design has a decisive impact on the quality of a
	software product; but due to the diversity and complexity of design
	properties (e.g., coupling, encapsulation), their assessment and
	correlation with external quality attributes (e.g., maintenance,
	portability) is hard. In contrast to traditional quality models that
	express the "goodness" of design in terms of a set of metrics, the
	novel Factor-Strategy model proposed by This work, relates explicitly
	the quality of a design to its conformance with a set of essential
	principles, rules and heuristics. This model is based on a novel
	mechanism, called detection strategy, that raises the abstraction
	level in dealing with metrics, by allowing to formulate good-design
	rules and heuristics in a quantifiable manner, and to detect automatically
	deviations from these rules. This quality model provides a twofold
	advantage: (i) an easier construction and understanding of the model
	as quality is put in connection with design principles rather than
	"raw numbers"; and (ii) a direct identification of the real causes
	of quality flaws. We have validated the approach through a comparative
	analysis involving two versions of a industrial software system.},
  doi = {10.1109/WCRE.2004.31},
  file = {:./literature/Marinescu2004.pdf:PDF},
  issn = {1095-1350 },
  keywords = {coupling; design principles; design rules; detection strategy; encapsulation;
	factor-strategy model; heuristics; industrial software system; maintenance;
	object-oriented metrics; portability; quality factors; quality model;
	object-oriented methods; software maintenance; software metrics;
	software quality},
  owner = {Stephan},
  review = {Factor-Strategy quality model proposed to overcome problems as Factor-Criteria
	Metrics (FCM)
	
	
	goal: make mapping of qualities to metrics more explicit
	
	
	approach: map qualities to detection strategies
	
	
	detections strategies relate design principles, rules, heuristics,
	bad smells to metrics
	
	
	-> mapping to metrics more transparent
	
	
	akin to our Goal Solution Scheme approach},
  timestamp = {2010.05.28}
}

@INPROCEEDINGS{Marques2008,
  author = {Marques, Andr\'{e} Gon\c{c}alves and Moreira, Ana and Ara\'{u}jo,
	Jo\, {a}o},
  title = {Multi-dimensional composition by objective in aspect-oriented requirements
	analysis},
  booktitle = {Proceedings of the 13th international workshop on Software architectures
	and mobility (EA'08)},
  year = {2008},
  pages = {19-26},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {This paper focuses on composition of requirements artefacts in Aspect-Oriented
	Requirements Engineering (AORE). Our goal is to equip the Aspect-Oriented
	Requirements Analysis (AORA) approach [1, 2] with an enhanced composition
	mechanism. The AORA approach consists in the identification, modularization
	and composition of crosscutting concerns. But the AORA composition
	[3] operates at a coarser granularity level and its reduced number
	of operators results in limited composition expressiveness. The core
	of the work presented in this paper is the description of a composition
	language and approach that enables a multi-dimensional composition
	of artefacts based on Objectives, therefore stating the purpose or
	the goal of the composition. This approach provides a composition
	process with a well-defined syntax and semantics, as well as a tool
	support integrated to the AORA original tool [3, 4].},
  doi = {http://doi.acm.org/10.1145/1370828.1370834},
  file = {:./literature/ea03e-marques.pdf:PDF},
  isbn = {978-1-60558-032-6},
  keywords = {aspect-oriented requirements analyses, multidimensional composition},
  location = {Leipzig, Germany},
  owner = {Stephan},
  timestamp = {2009.03.17}
}

@ARTICLE{Martinez-Ruiz2008,
  author = {Mart{\'\i}nez-Ruiz, T. and Garc{\'\i}a, F. and Piattini, M.},
  title = {Towards a SPEM v2. 0 extension to define process lines variability
	mechanisms},
  journal = {Software Engineering Research, Management and Applications},
  year = {2008},
  pages = {115--130},
  file = {Martinez-Ruiz2008.pdf:literature/Martinez-Ruiz2008.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  review = {Problem / Goal
	
	* SPEM variability support is limited to methods but does not support
	variability for process
	
	
	Research Question
	
	* 
	
	
	Contribution
	
	* SPEM extension to support process variability -> process lines /
	process variability
	
	* 
	
	
	Solution
	
	* Introduce variation points and variants
	
	* extend SPEM -> add variability element to core
	
	
	Open Issues
	
	* variability is missing in other SPEM sections
	
	* cross cuting concerns (security, usability etc.)},
  timestamp = {2012.07.19}
}

@ARTICLE{Martinez-Ruiz2012,
  author = {Mart{\'\i}nez-Ruiz, T. and M{\"u}nch, J. and Garc{\'\i}a, F. and
	Piattini, M.},
  title = {Requirements and constructors for tailoring software processes: a
	systematic literature review},
  journal = {Software Quality Journal},
  year = {2012},
  pages = {1--32},
  file = {Martinez-Ruiz2012.pdf:literature/Martinez-Ruiz2012.pdf:PDF},
  keywords = {Process Tailoring},
  owner = {patrickr},
  publisher = {Springer},
  review = {Problem / Goal
	
	* generic process reference models -> must be tailored to meet project
	and organization specific needs
	
	
	Research Question
	
	* Find approaches for software process tailoring/adaption
	
	Q1: Which process elements are used for adaption
	
	Q2: What kind of tailoring operations exist?
	
	Q3: What process modelling notation is used to support process tailoring?
	
	Q4: How are processes tailored to meet project and organization specific
	needs?
	
	
	Contribution
	
	* Describe state-of-the-art in process tailoring
	
	* Requirements for a process tailoring notation
	
	
	
	Solution
	
	A1: Variability in activities/tasks, artifacts, resources, control
	flow, product flow; Variations on consistency, crosscutting, single
	
	*Varying single process elements
	
	** Frequence of single elements on which variations applies: Activities(28),
	Artifacts (21), Roles (16), Tasks (8), Subprocesses (4), Ressource
	(3), Steps (2), Techniques & Practices (1)
	
	** Correlations:
	
	*** roles vary when activities vary
	
	*** task variations are part of activity variations
	
	*** steps always vary with tasks
	
	*** artifacts vary with with activities or tasks
	
	*** ressources, tequniques, and practices always vary according to
	activities, tasks, artifacts and roles
	
	*** sub-processes vary according to activities
	
	*Varying process structuring elements
	
	** Frequence of structure element variations: Control Flow (17), Grouping
	(9), , Process strucutre (7), Data flow (4), Other (2)
	
	A2: Optional variation, alternative variation (at process point),
	alternative points of variation, mandatory variation elements, mandatory
	variation places, variants evolution, constraints, dependencies,
	variations accross contained elements, variability propagation
	
	* variation through process modification operations:
	
	** direct variations: element insertion or deletion (26), element
	modification (14), relationships between elements (9), element replacing
	(4)
	
	** indirect variations: patterns (8), parameterization (6), inheritance
	(4), encapsulation (2), decision nodes (1)
	
	* variation through variant-rich processes (process-lines): 
	
	** types of variability: optional (27), mandatory (16), alternative
	(7)
	
	* mapping between process modification and process-lines: Deletion/Insertion
	-> Optional, Replacement -> Alternative, Modification -> Mandatory
	
	A3: differentiate common and variable parts, variability standardization
	
	* process modeling notations: workflow (4), code language (3), formal
	definition (3), petri nets (2), standard notation (1), activity diagram
	(1), spearmint (1), bpel (1), spem (1), UML state machine (1), little
	JIL (1), generic (1), not specified (11)
	
	* process reference models: v-model xt (5), rup (3), CMMI (1), software
	lifeycle process - ISO 12207 (2), SPICE - ISO 15504 (1), 
	
	A4: 
	
	operational choices for tailoring process: assistance during tailoring
	process (19), different tailoring steps (9), abstraction levels (7),
	tailoring process tests (4), user viewpoints (1), others (5), not
	defined (9)
	
	assistence: tool support (10), knowledge store (8), tailoring rules
	(8), inclusion of rationales (3)
	
	
	Conclusion / Open Issues},
  timestamp = {2012.07.19}
}

@INPROCEEDINGS{Martin2005,
  author = {C. Martin and A. Scheidig and T. Wilhelm and C. Schroeter and H.-J.
	Boehme and H.-M. Gross},
  title = {A new control architecture for mobile interaction robots},
  booktitle = {Proceedings of the 2nd European Conference on Mobile Robots, (ECMR
	2005)},
  year = {2005},
  pages = {224-229},
  publisher = {Stampalibri},
  file = {:./literature/Martin-ECMR-05a.pdf:PDF},
  keywords = {robot software architecture},
  owner = {Stephan},
  timestamp = {2011.01.03}
}

@ARTICLE{Martin1996,
  author = {Robert C. Martin},
  title = {Granularity},
  journal = {Engineering Notebook, C++ Report},
  year = {1996},
  file = {:./literature/granularity.pdf:PDF},
  keywords = {software engineering, granularity},
  owner = {Robert},
  timestamp = {2007.07.29},
  url = {http://www.objectmentor.com/resources/articles/granularity.pdf}
}

@INCOLLECTION{Martins2005,
  author = {Martins, Eliane and Vieira, Vanessa},
  title = {Regression Test Selection for Testable Classes},
  booktitle = {Dependable Computing - EDCC 5},
  publisher = {Springer Berlin / Heidelberg},
  year = {2005},
  editor = {Dal Cin, Mario and KaÃƒÂ¢niche, Mohamed and Pataricza, AndrÃƒÂ¡s},
  volume = {3463},
  series = {Lecture Notes in Computer Science},
  pages = {453-470},
  note = {10.1007/11408901_33},
  affiliation = {Institute of Computing Ã¢â‚¬â€œ Unicamp, Av. Albert Einstein 1251,
	Campinas, ZC, 13083-970 SP, Brazil},
  file = {:/literature/RegressionTesting/Regression Test Selection for Testable Classes.pdf:PDF},
  keywords = {activity diagram for a class,},
  owner = {Annie},
  timestamp = {2011.04.18},
  url = {http://dx.doi.org/10.1007/11408901_33}
}

@PHDTHESIS{Matinlassi2006,
  author = {Mari Matinlassi},
  title = {Quality-Driven Software Architecture Model Transformation},
  school = {University of Oulu},
  year = {2006},
  address = {Finland},
  month = {September},
  file = {:./literature/ThesisMatinlassi.pdf:PDF},
  owner = {Stephan},
  timestamp = {2009.11.27}
}

@INPROCEEDINGS{Matinlassi2003,
  author = {Mari Matinlassi and Eila Niemel\"a},
  title = {The impact of maintainability on component-based software systems},
  booktitle = {Proceedings 29th Euromicro Conference, 2003},
  year = {2003},
  pages = { 25-32},
  month = {Sept.},
  publisher = {IEEE},
  abstract = {There is a great deal of inconsistency and vagueness in the treatment
	of and terminology involved with software maintainability. This is
	exacerbated by the fact that there are a number of different dimensions
	of maintainability, each requiring specific treatment. The trends
	of increasing systems functionality and increasing systems complexity
	have given rise to new dimensions of maintainability since ISO/IEC
	defined maintainability as "the capability of the software to be
	modified" in 1996. We introduce the framework of maintainability
	and the techniques that promote maintainability in three abstraction
	levels; system, architecture and component. In the system dimension,
	the maintainability requirement is considered from a business-related
	point of view. In architecture, maintainability means a set of quality
	attributes, e.g. extensibility and flexibility. At the component
	level, maintainability focuses on modifiability, integrability and
	testability.},
  file = {:./literature/Matinlassi2003.pdf:PDF},
  issn = {1089-6503 },
  keywords = { formal specification, object-oriented programming, software architecture,
	software maintenance, software reusability IEC defined maintainability,
	ISO, abstraction levels, business-related viewpoint, component-based
	software systems, software architecture, software maintainability
	requirement, systems complexity, systems functionality},
  owner = {Stephan},
  review = {interesting view on quality attributes divided into runtime qualities
	and evolution qualities
	
	
	good discussion of maintainability subcharacteristics - very similar
	to evolvability subcharacteristics of Breivold et. al
	
	
	characteristics which are techniques but not quality attributes
	
	- traceability
	
	- variability
	
	- monitorability
	
	- tailorability},
  timestamp = {2009.12.01}
}

@TECHREPORT{Matinlassi2002,
  author = {Matinlassi, Mari and Niemel\"a, Eila and Dobrica Liliana},
  title = {Quality-Driven Architecture Design and Quality Analysis Method. A
	Revolutionary Initiation Approach to a Product Line Architecture},
  institution = {Technical Research Centre of Finland, VTT Publications 456},
  year = {2002},
  abstract = {The role of software architecture had changed. The use of modern software
	technologies and practices enables turning the focus of system development
	to the quality aspects of software instead of functional properties.
	Architecture addresses the quality issues of software and, therefore,
	it must be developed and documented properly. In particular, there
	is a need for high level architectural descriptions. The top down
	nature of software architecture design induces this need. In this
	report, the authors introduce a quality-driven architecture design
	and analysis (QADA) method. Quality-driven is about utilizing architectural
	styles and patterns as a means of designing high-quality architectures.
	QADA takes a revolutionary approach to the initiation process of
	a new product line. That is, the development of a complete product-line
	architecture and a set of components before developing the first
	product in a new domain. QADA considers architecture on two levels
	of abstraction: conceptual and concrete.},
  file = {:./literature/P456.pdf:PDF},
  keywords = {software development tools, software engineering, architecture, applications
	programs, design analysis, software product line, architecture design
	and analysis methods, quality attributes, service architecture, software
	architecture, QADA},
  owner = {Stephan},
  timestamp = {2008.04.02}
}

@INBOOK{Matthews2002,
  chapter = {Basic A* Pathfinding Made Simple},
  pages = {105-113},
  title = {AI Game Programming Wisdom},
  publisher = {Charles River Media},
  year = {2002},
  editor = {Steve Rabin},
  author = {James Matthews},
  volume = {1},
  owner = {Steffen},
  timestamp = {2013.10.17}
}

@ARTICLE{Mayrhauser1999b,
  author = {Anneliese von Mayrhauser and Stephen Lang},
  title = {A Coding Scheme to Support Systematic Analysis of Software Comprehension},
  journal = {IEEE Transactions on Software Engineering},
  year = {1999},
  volume = {25},
  pages = {526-540},
  number = {4},
  abstract = {Protocol Analysis is a valuable tool for gaining qualitative data
	from observations of programmer behavior during software maintenance.
	However, there are some major drawbacks with Protocol Analysis as
	it is currently practiced. Firstly, Protocol Analysis requires a
	daunting amount of effort at each stage of analysis. Secondly, the
	results from one Protocol Analysis are often difficult to compare
	with results from another. This paper describes a coding scheme,
	AFECS, designed to reduce the effort required to perform Protocol
	Analysis and to resolve the problem of noncomparable results. AFECS
	uses codes that consist of expandable and flexible segments. This
	allows AFECS to be tailored to the requirements of a variety of research
	studies, while maintaining a degree of consistency. Explicit segmentation
	also makes AFECS easy to use. An example shows AFECS' use and ability
	to adapt to diverse research questions.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/32.799950},
  file = {:./literature/00799950.pdf:PDF},
  issn = {0098-5589},
  keywords = {protocols, reverse engineering, software maintenance, systems re-engineeringAFECS,
	coding scheme, diverse research questions, explicit segmentation,
	flexible segments, programmer behaviour, protocol analysis, qualitative
	data, research studies, software comprehension, software maintenance,
	systematic analysis},
  owner = {Robert},
  publisher = {IEEE Computer Society},
  timestamp = {2008.07.15}
}

@INPROCEEDINGS{Mayrhauser1993,
  author = {A. von Mayrhauser and K. Olender},
  title = {Efficient testing of software modifications},
  booktitle = {Test Conference, 1993. Proceedings., International},
  year = {1993},
  pages = {859--864},
  abstract = {As software products evolve, regression testing is a necessary part
	of the development process. We present methods to automate and analyze
	change tracking for requirements and test cases so we may partially
	automate the process of revising the regression test suite for the
	modified software, and eliminate the necessity to rerun test cases
	that are unaffected by the modifications},
  doi = {10.1109/TEST.1993.470615},
  file = {:/literature/RegressionTesting/Efficient Testing of software Modifications.pdf:PDF},
  keywords = {automatic testing, modified software, program testing, regression
	testing, software maintenance, software modifications, software products,
	requirement based approachs},
  owner = {Annie},
  timestamp = {2011.01.04}
}

@ARTICLE{Mayrhauser1996,
  author = {A. von Mayrhauser and A.m. Vans},
  title = {Identification of Dynamic Comprehension Processes During Large Scale
	Maintenance},
  journal = {IEEE Transactions on Software Engineering},
  year = {1996},
  volume = {22},
  pages = {424-437},
  number = {6},
  abstract = {We present results of observing professional maintenance engineers
	working with industrial code at actual maintenance tasks. Protocol
	analysis is used to explore how code understanding might differ for
	small versus large scale code. The experiment confirms that cognition
	processes work at all levels of abstraction simultaneously as programmers
	build a mental model of the code. Analysis focused on dynamic properties
	and processes of code understanding. Cognition processes emerged
	at three levels of aggregation representing lower and higher level
	strategies of understanding. They show differences in what triggers
	them and how they achieve their goals. Results are useful for defining
	information which maintenance engineers need for their work and for
	documentation and development standards.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/32.508315},
  file = {:./literature/00508315.pdf:PDF},
  issn = {0098-5589},
  keywords = {reverse engineering, software maintenanceabstraction, aggregation,
	code understanding, cognition processes, dynamic comprehension processes,
	dynamic properties, industrial code, large scale maintenance, professional
	maintenance engineers, protocol analysis},
  owner = {Robert},
  publisher = {IEEE Computer Society},
  timestamp = {2008.07.15}
}

@ARTICLE{Mayrhauser1995,
  author = {Anneliese von Mayrhauser and A. Marie Vans},
  title = {Program Comprehension During Software Maintenance and Evolution},
  journal = {Computer},
  year = {1995},
  volume = {28},
  pages = {44-55},
  number = {8},
  month = {Aug},
  abstract = {Code cognition models examine how programmers understand program code.
	The authors survey the current knowledge in this area by comparing
	six program comprehension models: the Letovsky (1986) model; the
	Shneiderman and Mayer (1979) model; the Brooks (1983) model; Soloway,
	Adelson and Ehrlich's (1988) top-down model; Pennington's (1987)
	bottom-up model; and the integrated metamodel of von Mayrhauser and
	Vans (1994). While these general models can foster a complete understanding
	of a piece of code, they may not always apply to specialized tasks
	that more efficiently employ strategies geared toward partial understanding.
	We identify open questions, particularly considering the maintenance
	and evolution of large-scale code. These questions relate to the
	scalability of existing experimental results with small programs,
	the validity and credibility of results based on experimental procedures,
	and the challenges of data availability.},
  address = {Los Alamitos, CA, USA},
  doi = {http://dx.doi.org/10.1109/2.402076},
  file = {:./literature/00402076.pdf:PDF},
  issn = {0018-9162},
  keywords = {human factors, large-scale systems, reverse engineering, software
	maintenancebottom-up model, code cognition models, data availability,
	experimental procedures, integrated metamodel, large-scale code,
	partial understanding, program code understanding, program comprehension
	models, scalability, software evolution, software maintenance, specialized
	tasks, top-down models},
  owner = {Robert},
  publisher = {IEEE Computer Society Press},
  timestamp = {2008.07.15}
}

@ARTICLE{Mayrhauser1999a,
  author = {von Mayrhauser, Anneliese and Zhang, Ning},
  title = {Automated regression testing using DBT and Sleuth, command based,
	not model based},
  journal = {Journal of Software Maintenance},
  year = {1999},
  volume = {11},
  pages = {93-116},
  month = {March},
  __markedentry = {[qurat:]},
  acmid = {311781},
  address = {New York, NY, USA},
  doi = {10.1002/(SICI)1096-908X(199903/04)11:2<93::AID-SMR188>3.3.CO;2-X},
  file = {:/literature/RegressionTesting/automated regression testing using DBT and sleuth.pdf:PDF},
  issn = {1040-550X},
  issue = {2},
  keywords = {Sleuth, automated test generation, black-box testing, domain-based
	testing, regression testing, system testing},
  numpages = {24},
  owner = {Annie},
  publisher = {John Wiley \& Sons, Inc.},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=311779.311781}
}

@BOOK{Mayring2010,
  title = {Qualitative Inhaltsanalyse. Grundlagen und Techniken},
  publisher = {Beltzverlag Weinheim und Basel},
  year = {2010},
  author = {Mayring, P.},
  owner = {patrickr},
  timestamp = {2012.10.04}
}

@INPROCEEDINGS{Mayring2000,
  author = {Mayring, P.},
  title = {Qualitative content analysis},
  booktitle = {Forum Qualitative Sozialforschung/Forum: Qualitative Social Research},
  year = {2000},
  volume = {1},
  number = {2},
  file = {Mayring2000.pdf:literature/Mayring2000.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.10.05}
}

@BOOK{Mayring2008,
  title = {Die Praxis der Qualitativen Inhaltsanalyse},
  publisher = {Beltz},
  year = {2008},
  author = {Mayring, P. and Gl{\"a}ser-Zikuda, M.},
  owner = {patrickr},
  timestamp = {2012.10.05}
}

@TECHREPORT{McCall1977,
  author = {McCall, J. A. and Richards, P. K. and Walters, G. F.},
  title = {Factors in Software Quality},
  institution = {Rome Air Development Center},
  year = {1977},
  number = {RADC TR-77-369},
  address = {Rome, NY, USA},
  keywords = {software quality, Factor Criteria Metric},
  owner = {Stephan},
  timestamp = {2008.10.31}
}

@INPROCEEDINGS{McGee2011,
  author = {McGee, Sharon and Greer, De},
  title = {Software requirements change taxonomy: Evaluation by case study},
  booktitle = {Proceedings of the 19th IEEE International Requirements Engineering
	Conference (RE 2011)},
  year = {2011},
  pages = {25-34},
  address = {Trento},
  month = {September},
  file = {:./literature/Paper_191.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.12.28}
}

@INPROCEEDINGS{McGee2009,
  author = {McGee, Sharon and Greer, Des},
  title = {A Software Requirements Change Source Taxonomy},
  booktitle = {Proceedings of the Fourth International Conference on Software Engineering
	Advances (ICSEA '09)},
  year = {2009},
  pages = {51-58},
  address = {Porto},
  month = {September},
  file = {:./literature/Paper_192.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.12.28}
}

@BOOK{McKean2005,
  title = {The New Oxford American Dictionary},
  publisher = {Oxford University Press},
  year = {2005},
  author = {Erin {McKean}},
  edition = {2},
  month = {May},
  isbn = {0195170776},
  owner = {Stephan},
  timestamp = {2010.12.31}
}

@INPROCEEDINGS{McNair2007,
  author = {McNair, Andrew and German, Daniel M. and Weber-Jahnke, Jens},
  title = {Visualizing Software Architecture Evolution using Change-sets},
  booktitle = {Proceedings of the 14th Working Conference on Reverse Engineering
	(WCRE '07)},
  year = {2007},
  pages = {130-139},
  address = {Vancouver, BC},
  month = {October},
  file = {:./literature/Paper_75.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- visualization of software important to undestand evolution
	
	- current vis. approaches assume that evolution can be displayed as
	unbroken sequence of time
	
	
	Research Questions:
	
	
	Contribution:
	
	- lightweight approach for examining effect of change-sets on system
	architecture
	
	- "Motive" tool implementing this approach:
	
	* visualize "net-effect" of a change-set on architecture
	
	* export visualization to CASE tools which support GDL or GXL
	
	
	Solution:
	
	- indicate evolution of architecture by evolution of entities
	
	- annotate each entity/relationship with state information such as
	added, removed, phantom, changed, unchanged etc.
	
	- show the impact of a change-set on the architecture through "architectural
	impact views"
	
	* standard UML/ER diagram enhanced with impacts (by using special
	colors, overlays, annotations etc.)
	
	- impact of change-sets not precomputed due to size and number of
	change-sets
	
	- define peroid of interest (time interval) for which the impacts
	should be computed
	
	* all change records within this interval are called "total-set"
	
	- basic algorithm:
	
	* takes modification records (MR) from total-set and from change-set
	as input
	
	* outputs entities and relations annotated with net effects of the
	MRs in the change-set
	
	- algorithm works as follows:
	
	* analyze state of system at starting version
	
	* build a "current list" of entities and relations, add a empty annotation
	lists to each entity to keep track of changes
	
	* for each MR in the total-set, do:
	
	 - each entity in "current list" with changed metadata will be added
	to the appropriate annotation list
	
	 - add each entity which was added in the MR to the "current list"
	and create an empty annotation list
	
	 - if the MR is in the change-set: for every entity in the "current-list"
	which was added/changed by this MR, add the event into appropriate
	annotation list
	
	* inspect the annotation list of all entities in the "current list":
	
	 - if the list is empty, mark this entity as "unchanged"
	
	 - if first annotation says "added" and last annotation says "deleted",
	mark as "phantom"
	
	 - if first annotation is "added", mark as "added"
	
	 - if first annotation is "deleted", mark as "deleted"
	
	 - if it contains "added", "removed" or "modified"
	
	- developed prototype tool, called "Motive":
	
	* preprocess data from CVS to compute impact of MRs in a change-set
	-> database of MRs
	
	* scan files modified by MR and update architecture accordingly
	
	* compare entities & relationships between 2 consecutive MRs
	
	-> granularity of entities: UML classes, packages and components
	
	-> granularity of changes: add/remove/modify
	
	-> granularity of results: UML classes, packages and components
	
	
	Open Issues:
	
	- no detection of moving and renaming of entities},
  timestamp = {2011.02.19}
}

@ARTICLE{Medvidovic2000,
  author = {Nenad Medvidovic and Richard N. Taylor},
  title = {A classification and comparison framework for software architecture
	description languages},
  journal = {IEEE Transactions on Software Engineering},
  year = {2000},
  volume = {26},
  pages = {70-93},
  number = {1},
  month = {Jan},
  abstract = {Software architectures shift the focus of developers from lines-of-code
	to coarser-grained architectural elements and their overall interconnection
	structure. Architecture description languages (ADLs) have been proposed
	as modeling notations to support architecture-based development.
	There is, however, little consensus in the research community on
	what is an ADL, what aspects of an architecture should be modeled
	in an ADL, and which of several possible ADLs is best suited for
	a particular problem. Furthermore, the distinction is rarely made
	between ADLs on one hand and formal specification, module interconnection,
	simulation and programming languages on the other. This paper attempts
	to provide an answer to these questions. It motivates and presents
	a definition and a classification framework for ADLs. The utility
	of the definition is demonstrated by using it to differentiate ADLs
	from other modeling notations. The framework is used to classify
	and compare several existing ADLs, enabling us, in the process, to
	identify key properties of ADLs. The comparison highlights areas
	where existing ADLs provide extensive support and those in which
	they are deficient, suggesting a research agenda for the future.},
  doi = {10.1109/32.825767},
  file = {:./literature/TSE-ADL.pdf:PDF},
  issn = {0098-5589},
  keywords = {formal specification, software architecture, specification languagesarchitecture-based
	development, classification framework, formal specification, interconnection
	structure, modeling notations, module interconnection, programming
	languages, simulation, software architecture description languages},
  owner = {Stephan},
  review = {Comparison of different ADLs according to specified framework
	
	- ACME (stricly not an ADL but an interchange language) 
	
	- Aesop, C2, Darwin, MetaH, Rapide, SADL, UniCon, Weaves, Wright
	
	
	- no ADL fullfills all criteria
	
	
	citation regarding evolvability:
	
	"Since evolution (i.e., maintenance) is the single costliest software
	development activity, system evolvability becomes a key aspect of
	architecture-based development. ADLs need to augment evolution support
	at the level of components and connectors with features for their
	incremental addition, removal, replacement, and reconnection in a
	configuration."
	
	
	interesting references regarding the extension of UML as an ADL:
	
	41: Medvidovic and Rosenblum: Assessing the Suitability of a Standard
	Design Method for Modeling Software Architectures.
	
	60: Robbins, Medvidovic, Redmiles, and Rosenblum: Integrating Architecture
	Description Languages with a Standard Design Method.},
  timestamp = {2008.04.02},
  url = {http://www.cs.ucy.ac.cy/courses/EPL603/TSE-ADL.pdf}
}

@ARTICLE{Meehan2002,
  author = {Meehan, B. and Richardson, I.},
  title = {Identification of software process knowledge management},
  journal = {Software Process: Improvement and Practice},
  year = {2002},
  volume = {7},
  pages = {47--55},
  number = {2},
  file = {Meehan2002.PDF:literature/Meehan2002.PDF:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@INPROCEEDINGS{Mehta2001,
  author = {Mehta, Alok and Heineman, George T.},
  title = {Evolving legacy systems features using regression test cases and
	components},
  booktitle = {Proceedings of the 4th International Workshop on Principles of Software
	Evolution},
  year = {2001},
  series = {IWPSE '01},
  pages = {190--193},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[qurat:]},
  acmid = {602507},
  doi = {http://doi.acm.org/10.1145/602461.602507},
  file = {:/literature/RegressionTesting/evolving-legacy-system-features using regression test cases and components.pdf:PDF},
  isbn = {1-58113-508-4},
  keywords = {lagacy code based, component based software engineering (CBSE), feature
	engineering, legacy systems, program slicing, refactoring, software
	evolution, source code renovation, testing},
  location = {Vienna, Austria},
  numpages = {4},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://doi.acm.org/10.1145/602461.602507}
}

@ARTICLE{Mei2009,
  author = {Lijun Mei and W. K. Chan and T. H. Tse and Robert G. Merkel},
  title = {Tag-Based Techniques for Black-Box Test Case Prioritization for Service
	Testing},
  journal = {Quality Software, International Conference on},
  year = {2009},
  volume = {0},
  pages = {21-30},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/QSIC.2009.12},
  file = {:/literature/RegressionTesting/05381531.pdf:PDF},
  issn = {1550-6002},
  keywords = {WSRT},
  owner = {Steffen},
  publisher = {IEEE Computer Society},
  timestamp = {2012.03.01}
}

@INPROCEEDINGS{Mei2009a,
  author = {Mei, Lijun and Zhang, Zhenyu and Chan, W. K. and Tse, T. H.},
  title = {Test case prioritization for regression testing of service-oriented
	business applications},
  booktitle = {Proceedings of the 18th international conference on World wide web},
  year = {2009},
  series = {WWW '09},
  pages = {901--910},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1526830},
  doi = {http://doi.acm.org/10.1145/1526709.1526830},
  file = {:/literature/RegressionTesting/p901-mei.pdf:PDF},
  isbn = {978-1-60558-487-4},
  keywords = {WSDL, XPath, service orientation, test case prioritization, WSRT},
  location = {Madrid, Spain},
  numpages = {10},
  owner = {Steffen},
  review = {the tags embedded in XML msgs are used to reorder regression test
	cases},
  timestamp = {2012.03.01},
  url = {http://doi.acm.org/10.1145/1526709.1526830}
}

@ARTICLE{Meinefeld1997,
  author = {Meinefeld, W.},
  title = {Ex-ante-Hypothesen in der Qualitativen Sozialforschung: zwischen'fehl
	am Platz'und'unverzichtbar'},
  journal = {Zeitschrift f{\"u}r Soziologie},
  year = {1997},
  volume = {26},
  pages = {22--34},
  number = {1},
  file = {Meinefeld1997.pdf:literature/Meinefeld1997.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.09.04}
}

@INCOLLECTION{Mellegard2010,
  author = {Melleg\r{a}rd, Niklas and Staron, Miroslaw},
  title = {Improving Efficiency of Change Impact Assessment Using Graphical
	Requirement Specifications: An Experiment},
  booktitle = {Product-Focused Software Process Improvement},
  publisher = {Springer Berlin / Heidelberg},
  year = {2010},
  volume = {6156},
  pages = {336-350},
  file = {:./literature/Paper_139.PDF:PDF},
  journal = {Lecture Notes in Computer Science},
  owner = {Steffen},
  review = {Problem:
	
	- graphical representation for requirements often considered as needed
	
	- not clear if graph. repr. does really improve IA on requirements
	
	
	Research Questions:
	
	- do graph. requirements improve / easen IA
	
	- does this affect IA on requirements specification
	
	
	Contribution:
	
	- experiment to measure the efficiency and accuracy of IA on graph.
	requirements
	
	
	Solution:
	
	- experiment conducted with 18 students
	
	- examine differences between traditional text-based requirements
	and requirements models (graph.)
	
	- used domain specific modeling language for requirements: gRAM (graph.
	Req. Abstraction Model)
	
	* ensure consistency and traceability among requirements
	
	* use 4 levels of requirements-abstraction:
	
	 - product-req.
	
	 - feature-req.
	
	 - function-req.
	
	 - component-req.
	
	* use 3 types of traceability-links: owns, satisfies, depends-on
	
	- time, accuracy and perceived confidence measured
	
	- results:
	
	* less time (37%)
	
	* more confidence
	
	* less accuracy
	
	* large difference in variance
	
	
	Open Issues:
	
	- perform same/similar study in industrial context
	
	- examine consistency among different abstraction levels of gRAM
	
	- examine effectiveness and correctness of traceability},
  timestamp = {2011.04.04}
}

@INPROCEEDINGS{Memon2003,
  author = {Atif Memon and Ishan Banerjee and Nada Hashmi and Adithya Nagarajan},
  title = {DART: A Framework for Regression Testing "Nightly/daily Builds" of
	GUI Applications},
  booktitle = {Software Maintenance, IEEE International Conference on},
  year = {2003},
  volume = {0},
  pages = {410},
  address = {Los Alamitos, {CA,} {USA}},
  publisher = {{IEEE} Computer Society},
  abstract = {{"Nightly/daily} building and smoke testing" have become widespread
	since they often reveal bugs early in the software development process.
	During these builds, software is compiled, linked, and (re)tested
	with the goal of validating its basic functionality. Although successful
	for conventional software, smoke tests are difficult to develop and
	automatically rerun for software that has a graphical user interface
	{(GUI).} In this paper, we describe a framework called {DART} {(Daily}
	Automated Regression Tester) that addresses the needs of frequent
	and automated re-testing of {GUI} software. The key to our success
	is automation: {DART} automates everything from structural {GUI}
	analysis, test case generation, test oracle creation, to code instrumentation,
	test execution, coverage evaluation, regeneration of test cases,
	and their re-execution. Together with the operating system?s task
	scheduler, {DART} can execute frequently with little input from the
	developer/tester to retest the {GUI} software. We provide results
	of experiments showing the time taken and memory required for {GUI}
	analysis, test case and test oracle generation, and test execution.
	We also empirically compare the relative costs of employing different
	levels of detail in the {GUI} test cases.},
  annote = {Complete {PDF} document was either not available or accessible. Please
	make sure you're logged in to the digital library to retrieve the
	complete {PDF} document.},
  doi = {http://doi.ieeecomputersociety.org/10.1109/ICSM.2003.1235451},
  file = {:/literature/RegressionTesting/DART A Framework for Regression Testing â€œNightlydaily Buildsâ€? of GUI.pdf:PDF},
  keywords = {not relevant},
  owner = {Annie},
  review = {Scope: GUI Testing
	
	
	Artifacts: Event flow graph, Integration Tree},
  shorttitle = {{DART}},
  timestamp = {2011.01.04}
}

@ARTICLE{Memon2005,
  author = {Atif Memon and Adithya Nagarajan and Qing Xie},
  title = {Automating regression testing for evolving {GUI} software: Research
	Articlesrir},
  journal = {Journal of Software Maintenance and Evolution: Research and Practice},
  year = {2005},
  volume = {17},
  pages = {27{\textendash}64},
  month = jan,
  note = {{ACM} {ID:} 1075049},
  abstract = {With the widespread deployment of broadband connections worldwide,
	software development and maintenance are increasingly being performed
	by multiple engineers, often working around-the-clock to maximize
	code churn rates. To ensure rapid quality assurance of such software,
	techniques such as {\textquoteleft}nightly/daily building and smoke
	testing{\textquoteright} have become widespread since they often
	reveal bugs early in the software development process. During these
	builds, a development version of the software is checked out from
	the source code repository tree, compiled, linked, and (re)tested
	with the goal of (re)validating its basic functionality. Although
	successful for conventional software, smoke tests are difficult to
	develop and automatically re-run for software that has a graphical
	user interface {(GUI).} In this paper, we describe a framework called
	{DART} {(Daily} Automated Regression Tester) that addresses the needs
	of frequent and automated re-testing of {GUI} software. The key to
	our success is automation: {DART} automates everything from structural
	{GUI} analysis, smoke-test-case generation, test-oracle creation,
	to code instrumentation, test execution, coverage evaluation, regeneration
	of test cases, and their re-execution. Together with the operating
	system's task scheduler, {DART} can execute frequently with little
	input from the developer/tester to re-test the {GUI} software. We
	provide results of experiments showing the time taken and memory
	required for {GUI} analysis, test case and test oracle generation,
	and test execution. We empirically compare the relative costs of
	employing different levels of detail in the {GUI} test oracle. We
	also show the events and statements covered by the smoke test cases.
	Copyright {\textcopyright} 2005 John Wiley \& Sons, {Ltd.A} preliminary
	report of this work appeared in the Proceedings International Conference
	on Software Maintenance [1]},
  doi = {10.1002/smr.v17:1},
  file = {:/literature/RegressionTesting/atif memon.pdf:PDF},
  issn = {{1532-060X}},
  keywords = {daily/nightly builds, event-flow graphs, graphical user interfaces,
	gui regression testing, gui testing, smoke testing, software quality,
	use interface testing, not relevant,},
  owner = {Annie},
  shorttitle = {Automating regression testing for evolving {GUI} software},
  timestamp = {2011.04.19},
  url = {http://portal.acm.org/citation.cfm?id=1075046.1075049}
}

@ARTICLE{Mens:2002:SSS:567176.567178,
  author = {Mens, T.},
  title = {A State-of-the-Art Survey on Software Merging},
  journal = {IEEE Trans. Softw. Eng.},
  year = {2002},
  volume = {28},
  pages = {449--462},
  number = {5},
  month = may,
  acmid = {567178},
  address = {Piscataway, NJ, USA},
  doi = {10.1109/TSE.2002.1000449},
  file = {:/literature/TomMens01000449.pdf:PDF},
  issn = {0098-5589},
  issue_date = {May 2002},
  keywords = {software merging, large-scale software development, merge conflicts,
	conflict detection, conflict resolution},
  numpages = {14},
  publisher = {IEEE Press},
  url = {http://dx.doi.org/10.1109/TSE.2002.1000449}
}

@INPROCEEDINGS{Mens2003,
  author = {Mens, Tom and Buckley, Jim and Zenger, Matthias and Rashid, Awais},
  title = {Towards a Taxonomy of Software Evolution},
  booktitle = {Proceedings of the 2nd International Workshop on Unanticipated Software
	Evolution},
  year = {2003},
  address = {Warsaw, Poland},
  month = {April},
  file = {:./literature/Paper_108.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	
	Research Questions:
	
	
	Contribution:
	
	
	Solution:
	
	
	Open Issues:},
  timestamp = {2011.03.08}
}

@INPROCEEDINGS{Mens1998,
  author = {Tom Mens and Kim Mens},
  title = {Assessing the Evolvability of Software Architectures},
  booktitle = {Workshop on Object-Oriented Technology (ECOOP '98)},
  year = {1998},
  volume = {1543/1998},
  series = {LNCS},
  pages = {54-55},
  address = {London, UK},
  publisher = {Springer-Verlag},
  abstract = {The quality of object-oriented architectures is measured by characteristics
	such as modularity, extensibility, flexibility, adaptability and
	reusability. It is recognised that software systems featuring these
	characteristics are much easier to evolve and maintain. However,
	rather than measuring (either qualitatively or quantitatively) and
	improving these characteristics, and thus indirectly improving the
	evolutionary aspects of software systems, we propose to address the
	problems of architectural evolution directly.},
  doi = {10.1007/3-540-49255-0},
  file = {:./literature/WP_1998_ECOOP_OOAEWS.pdf:PDF},
  isbn = {3-540-65460-7},
  keywords = {evolvability characteristics, evolution, reuse contracts},
  owner = {Stephan},
  timestamp = {2008.08.04}
}

@INPROCEEDINGS{Mens2003b,
  author = {Mens, Tom and Van Der Straeten, Ragnhild and Simmonds, Jocelyn},
  title = {Maintaining Consistency between UML Models with Description Logic
	Tools},
  booktitle = {Proceedings of the Workshop on Consistency Problems in UML-based
	Software Development at the 6th International Conference on the Unified
	Modeling Language (UML '2003)},
  year = {2003},
  pages = {71-77},
  address = {San Francisco},
  file = {:./literature/Paper_205.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.03.15}
}

@INPROCEEDINGS{Mens2005,
  author = {Mens, T. and Wermelinger, M. and Ducasse, S. and Demeyer, S. and
	Hirschfeld, R. and Jazayeri, M.},
  title = {Challenges in software evolution},
  booktitle = {Eighth International Workshop on Principles of Software Evolution},
  year = {2005},
  pages = {13-22},
  month = {Sept.},
  abstract = {Today's information technology society increasingly relies on software
	at all levels. Nevertheless, software quality generally continues
	to fall short of expectations, and software systems continue to suffer
	from symptoms of aging as they are adapted to changing requirements
	and environments. The only way to overcome or avoid the negative
	effects of software aging is by placing change and evolution in the
	center of the software development process. In this article we describe
	what we believe to be some of the most important research challenges
	in software evolution. The goal of this document is to provide novel
	research directions in the software evolution domain.},
  doi = {10.1109/IWPSE.2005.7},
  file = {:./literature/Mens2005IWPSE-Challenges.pdf:PDF},
  issn = {1550-4077},
  keywords = {formal specification, formal verification, software maintenance, software
	quality information technology society, requirements analysis, software
	aging, software development process, software evolution, software
	quality, software system},
  owner = {Stephan},
  review = {challanges for evolution:
	
	
	software aging: quality of software systems gradually degrade as the
	system evolves ->
	
	- tool and techniques to preserve or improve the quality characteristics
	of software systems
	
	
	- develop and support a common application framework for doing joint
	software evolution research
	
	
	refactoring until now only on code level -> shift to "model evolution"
	
	- software evolution techniques on higher levels of abstraction needed
	to support evolution of higher-level artifacts (analysis and design
	models, software architectures, requirements specificatins)
	
	
	- achieve co-evolution between different types of artifacts or different
	representations of them (e.g. source code - design models, structural
	and behavioural design models)
	
	
	- new formalisms to support activities specific to software evolution
	(as example refactoring)
	
	
	- more direct and explicit support for software evolution by languages
	(programming or modeling)
	
	
	- support for multi-language systems by software evolution techniques
	
	
	- integration of evolution into development process models (iterativ,
	incremental, agile) -> staged model
	
	
	- new ways of recording the evolution of software - version management
	with support for more information than provided like from CVS
	
	
	- integration of different kinds of data and facilitation of large
	quantities of data
	
	
	- predictive models considering uncertainty
	
	
	- support of runtime adaption of systems while they are running
	
	
	interesting references:
	
	- Buckley2005 -> taxonomy of software change
	
	- Tichelaar2000 -> language independent refactoring
	
	- Rajlich2000 -> staged model},
  timestamp = {2008.04.17}
}

@ARTICLE{Merilinna2012,
  author = {Merilinna, Janne and Yrjönen, Anton and Räty, Tomi},
  title = {NFR+ framework method to support bi-directional traceability of non-functional
	requirements.},
  journal = {Computer Science - Research and Development},
  year = {2012},
  volume = {27},
  pages = {1-15},
  number = {2},
  added-at = {2012-05-03T00:00:00.000+0200},
  biburl = {http://www.bibsonomy.org/bibtex/284d66027e65fa4f2cd1dbd1683001d5a/dblp},
  doi = {10.1007/s00450-012-0205-5},
  ee = {http://dx.doi.org/10.1007/s00450-012-0205-5},
  file = {:./literature/nfr_plus_2012.pdf:PDF},
  interhash = {88b00b8bc9e26b6585bf51151c3cab63},
  intrahash = {84d66027e65fa4f2cd1dbd1683001d5a},
  issn = {1865-2034},
  keywords = {Domain-specific modeling; Requirements engineering; Quality-driven
	development},
  language = {English},
  owner = {Sebastian},
  publisher = {Springer-Verlag},
  timestamp = {2013.07.26},
  url = {http://dblp.uni-trier.de/db/journals/ife/ife27.html#MerilinnaYR12}
}

@ARTICLE{Mernik2005,
  author = {Mernik, Marjan and Heering, Jan and Sloane, Anthony M.},
  title = {When and How to Develop Domain-specific Languages},
  journal = {ACM Comput. Surv.},
  year = {2005},
  volume = {37},
  pages = {316--344},
  number = {4},
  month = dec,
  acmid = {1118892},
  address = {New York, NY, USA},
  doi = {10.1145/1118890.1118892},
  file = {:./literature/mernik2005.pdf:PDF},
  issn = {0360-0300},
  issue_date = {December 2005},
  keywords = {Domain-specific language, application language, domain analysis, language
	development system},
  numpages = {29},
  owner = {matthias},
  publisher = {ACM},
  timestamp = {2013.12.17},
  url = {http://doi.acm.org/10.1145/1118890.1118892}
}

@TECHREPORT{Meyer2004,
  author = {Bertolt Meyer},
  title = {Was ist Wissen? Zum Wissensbegriff im Wissensmanagement: Ein Definitionsversuch.},
  institution = {Diskussionspapier des Lehrstuhls Organisations- und Sozialpsychologie,
	Humboldt-Universität zu Berlin.},
  year = {2004},
  abstract = {Im Wissensmanagement soll eine Ressource "gemanaged" werden, deren
	Natur von Philosophie und Wissenschaft seit über 2000 Jahren diskutiert
	wird. Dieser Text soll einen Überblick über verschiedene Ansätze
	und Definitionsversuche bieten, die kritisch gewichtet werden und
	in eine für das Wissensmanagement sinnvolle Definition zusammengeführt
	werden.},
  file = {:./literature/meyer2004.pdf:PDF},
  keywords = {knowledge management},
  owner = {Robert},
  timestamp = {2007.03.07},
  url = {http://amor.cms.hu-berlin.de/~h04440am/public/Wissensbegriff%20im%20WM.pdf}
}

@ARTICLE{Meyerson1996,
  author = {Meyerson, D. and Weick, K.E. and Kramer, R.M.},
  title = {Swift trust and temporary groups},
  journal = {Trust in organizations: Frontiers of theory and research},
  year = {1996},
  volume = {166},
  pages = {195},
  owner = {patrickr},
  timestamp = {2012.10.19}
}

@INPROCEEDINGS{Mezini1998,
  author = {Mira Mezini and Karl J. Lieberherr},
  title = {Adaptive Plug-and-Play Components for Evolutionary Software Development},
  booktitle = {Conference on Object-Oriented Programming: Systems, Languages, and
	Applications (OOPSLA)},
  year = {1998},
  pages = {97-116},
  month = {October},
  abstract = {In several works on design methodologies, design patterns, and programming
	language design, the need for program entities that capture the patterns
	of collaboration between several calsses has been recognized. The
	idea is that in general the unit of reuse is not a single class,
	but a slice of behavior affecting a set of collaborating classes.
	The absence of large-scale compnents for expressing these collaborations
	makes object-oriented programs more difficult to maintain and reuse,
	because functionality is spread over several methods and it becomes
	difficult to get the "big picture". In this paper, we propose Adaptive
	Plug and Play Components to serve this need. These components are
	designed such that they not only facilitate the construction of complex
	software by making the collaborations explicit, but they do so in
	a manner that supports the evolutionary nature of both structure
	and behavior.},
  citeseerurl = {http://citeseer.ist.psu.edu/mezini98adaptive.html},
  file = {:./literature/cameraRed-last.pdf:PDF},
  keywords = {component based development, evolutionary development, plug-and-play
	components},
  owner = {Stephan},
  timestamp = {2008.04.29},
  url = {http://ftp.ccs.neu.edu/pub/people/lieber/appcs.pdf}
}

@ARTICLE{Midler1995,
  author = {Midler, C.},
  title = {"Projectification" of the firm: the Renault case},
  journal = {Scandinavian Journal of Management},
  year = {1995},
  volume = {11},
  pages = {363--375},
  number = {4},
  file = {Midler1995.pdf:literature/Midler1995.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.24}
}

@INPROCEEDINGS{Miguel2003,
  author = {de Miguel, M.A.},
  title = {QoS modeling language for high quality systems},
  booktitle = {Proceedings of the Eighth IEEE International Workshop on Object-Oriented
	Real-Time Dependable Systems (WORDS'03)},
  year = {2003},
  pages = {210-216},
  month = {15-17 Jan.},
  publisher = {IEEE Computer Society},
  abstract = {We introduce the main elements of UML (Unified Modeling Language)
	extension to support QoS specifications, which are the basic constructors
	of QoS-aware models. Different types of languages are used to specify
	QoS systems, the most common include extensions of Interface Description
	Languages, UML extensions and metamodels, and mathematical models.
	QoS specification methods support the description of QoS concepts
	that are used for different purposes: i) generation of code for the
	management of QoS concepts (e.g., negotiation, access to resource
	managers), ii) specification of QoS-aware architectures, and iii)
	management of QoS information in QoS reflective infrastructures (e.g.,
	QoS adaptable systems). QoS-aware models support the description
	of software architectures with quality requirements. The extensions
	included in this paper are part of an initial submission of OMG (Object
	Management Group) RFP "UML profile for quality of service and fault
	tolerance characteristics and mechanisms".},
  doi = {10.1109/WORDS.2003.10002},
  file = {:./literature/01218085.pdf:PDF},
  keywords = { formal specification, object-oriented programming, quality of service,
	specification languages OMG, Object Management Group, QoS management,
	QoS specification, QoS-aware model, UML extension, UML metamodel,
	Unified Modeling Language, fault tolerance, high quality system,
	interface description language, mathematical model, modeling language,
	quality of service, software architecture},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1218085}
}

@INPROCEEDINGS{Mikic-Rakic2003,
  author = {Mikic-Rakic, Marija and Medvidovic, Nenad},
  title = {Toward a Framework for Classifying Disconnected Operation Techniques},
  booktitle = {Proceedings of the ICSE Workshops on Architecting Dependable Systems
	(WADS 2003)},
  year = {2003},
  pages = {65-70},
  address = {Portland, Oregon},
  month = {May},
  abstract = {Distributed, decentralized, and mobile systems are highly dependent
	on the underlying network. Due to network connectivity failures,
	these systems must address the problem of disconnected operation,
	i.e., continued functioning in the absence or near-absence of network
	accessibility. A number of existing approaches provide support for
	disconnected operation by employing different techniques. What is
	currently missing, however, is a general understanding of the applicability
	of these techniques to different kinds of software systems, and the
	manner in which they affect the overall system dependability. This
	paper strives to improve that understanding. We present a framework
	for classifying disconnected operation solutions and assess several
	representative approaches according to the proposed classification.
	This study highlights several pertinent areas that are currently
	not supported, helping to motivate our future work.},
  file = {:./literature/mikicRakic.pdf:PDF},
  keywords = {dependability, availability, distributed system},
  owner = {Stephan},
  review = {most commonly used techniques for disconnected operations
	
	-> techniques for availability (!)
	
	Caching
	
	- locally storing remote data once it has been accessed
	
	Hoarding
	
	- prefetching likely needed remote data
	
	Queueing Remote Procedure Calls
	
	- buffering remote, non-blocking requests and responses
	
	Deployment and redeployment
	
	- installing, updating. or relocating a distributed software system
	
	Replica reconciliation
	
	- synchronizing changes of different local copies
	
	Code mobility
	
	- dynamic change of bindings between code fragments and executing
	locations},
  timestamp = {2008.07.29},
  url = {http://www.cs.kent.ac.uk/events/conf/2003/wads/Proceedings/mikicRakic.pdf}
}

@BOOK{Miles1964,
  title = {On temporary systems},
  publisher = {National Training Laboratories, National Education Association},
  year = {1964},
  author = {Miles, M.B.},
  owner = {patrickr},
  timestamp = {2012.10.19}
}

@MASTERSTHESIS{Milvich2005,
  author = {Michael Milvich},
  title = {Ein Semantisches Web für die {U}niversitätsbibliothek {H}eidelberg},
  school = {Fachhochschule Karlsruhe},
  year = {2005},
  file = {:./literature/Semantisches_Web.pdf:PDF},
  keywords = {semantic web},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.15},
  url = {http://archiv.ub.uni-heidelberg.de/volltextserver/volltexte/2006/6203/pdf/Semantisches_Web.pdf},
  volume = {Master Thesis, Fachhochschule Karlsruhe, Hochschule für Technik}
}

@INPROCEEDINGS{Mirarab2007,
  author = {Mirarab, Siavash and Hassouna, Alaa and Tahvildari, Ladan},
  title = {Using Bayesian Belief Networks to Predict Change Propagation in Software
	Systems},
  booktitle = {Proceedings of the 15th IEEE International Conference on Program
	Comprehension (ICPC '07)},
  year = {2007},
  pages = {177-188},
  address = {Banff, Alberta, Canada},
  month = {June},
  file = {:./literature/Paper_123.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- growing size of software causes more work when maintaining system
	
	- changes propagate across different modules / components
	
	
	Research Questions:
	
	- given a change, which other elements will change as well
	
	- how to predict changes reliable and in early phases
	
	
	Contribution:
	
	- approach based on bayesian networks to predict change
	
	- approach has 2 datasources:
	
	* change history from version control system
	
	* program dependency data
	
	
	Solution:
	
	- overall solution consists of two steps:
	
	* data extraction
	
	 - extract changes and dependencies from repositories
	
	 - use static coupling-measures to extract dependencies
	
	 * use IR heuristics to limit the number of dependencies
	
	 - extract co-change patterns from version control repositories
	
	* network generation and change prediction
	
	 - use 3 different models for prediction:
	
	 * bayesian dependency model (BDM)
	
	 * bayesian history model (BHM)
	
	 * bayesian dependency and history model (BDHM)
	
	 - building the model consists of following steps:
	
	 * build common model
	
	 * remove cyclic dependencies
	
	 * use paramter learning to incorporate history information into the
	model
	
	 - use bayesian inference to predict changes from the network model
	
	 * apply EPIS sampling algorithm
	
	-> granularity of entities: adoptable
	
	-> granularity of changes: adoptable
	
	-> granularity of results: adoptable
	
	
	Open Issues:},
  timestamp = {2011.04.01}
}

@ARTICLE{Mnkandla2005,
  author = {Mnkandla, E. and Dwolatzky, B. and Mlotshwa, S.},
  title = {Tailoring agile methodologies to the southern african environment},
  journal = {Extreme Programming and Agile Processes in Software Engineering},
  year = {2005},
  pages = {1267--1269},
  file = {Mnkandla2005.pdf:literature/Mnkandla2005.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@MASTERSTHESIS{Mohamad2010,
  author = {Mohamad, R. N.},
  title = {A Change Impact Analysis Approach Using Visualization Method},
  school = {Malaysia University of Technology, Faculty of Computer Science and
	Information Systems},
  year = {2010},
  file = {:./literature/Master_5.pdf:PDF},
  owner = {Steffen},
  review = {useful stuff: list of C++ class relations / dependencies, review on
	software visualization (including taxonomy)
	
	
	- aim of study is to improve comprehension by applying IA
	
	- support IA by visualizing software and its dependencies, use traceability
	to trace changes across software
	
	- build on CATIA tool which performs IA to visualize its results (see
	{Ibrahim2005a,Ibrahim2005b,Ibrahim2006})
	
	- provides graph-view for impacted elements
	
	
	- scope of analysis: code
	
	- tool: CIA-V
	
	- language: C++
	
	- scalability: -
	
	- granularity
	
	* changes:
	
	* artifacts: package, class, method
	
	* results: package, class, method
	
	- technique: traceability, slicing
	
	- analysis style: exploratory
	
	- evaluation
	
	* size: 4 KLOC
	
	* precision:
	
	* recall:
	
	* time:},
  timestamp = {2011.04.01}
}

@INPROCEEDINGS{Moonen2002,
  author = {Moonen, Leon},
  title = {Lightweight Impact Analysis using Island Grammars},
  booktitle = {Proceedings of the 10th International Workshop on Program Comprehension},
  year = {2002},
  pages = {219-228},
  month = {December},
  file = {:./literature/Paper_91.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- IA plays central role in software maintenance
	
	- traditional IA techniques are too expensive
	
	
	Research Questions:
	
	- use more lightweight IA approaches to reduce costs of IA:
	
	* what parts of a system are affected
	
	* what must be done
	
	
	Contribution:
	
	- lightweight IA approach based on island grammars
	
	- reusable, generative framework for IA
	
	
	Solution:
	
	- "ISCAN"-tool developed:
	
	 * use "extract-query-view"-approach
	
	 * parser consists of 2 steps:
	
	 - source model extraction
	
	 - island markup: tagging items to be analyzed
	
	 -> store results in repository
	
	 * apply analysis tools on the repository to generate statistics and
	presentation (hypertext)
	
	- use syntactical analysis based on island grammars for parser
	
	- island grammars consist of 2 parts:
	
	* detailed productions describing language constructs of interest
	(= islands)
	
	* liberal productions forming the remainder of input (= water)
	
	-> brush aside non interesting parts to speed up analysis
	
	- express island grammars in SDF (syntax definition formalism)
	
	- encode patterns as islands and anti-pattern as water
	
	* patterns extract data fields from source code
	
	* anti-patterns skip the rest
	
	-> granularity of entities: COBOL data fields
	
	-> granularity of changes: no details
	
	-> granularity of results: COBOL data fields
	
	
	Open Issues:
	
	- extend parser to recognize assignments and expressions as islands},
  timestamp = {2011.02.23}
}

@INPROCEEDINGS{Moreira2005,
  author = {Moreira, A. and Rashid, A. and Araujo, J.},
  title = {Multi-dimensional separation of concerns in requirements engineering},
  booktitle = {Proceedings. 13th IEEE International Conference on Requirements Engineering},
  year = {2005},
  pages = { 285-296},
  month = {Aug.-2 Sept.},
  publisher = {IEEE Computer Society},
  abstract = {Existing requirements engineering approaches manage broadly scoped
	requirements and constraints in a fashion that is largely two-dimensional,
	where functional requirements serve as the base decomposition with
	non-functional requirements cutting across them. Therefore, crosscutting
	functional requirements are not effectively handled. This in turn
	leads to architecture trade-offs being mainly guided by the non-functional
	requirements, so that the system quality attributes can be satisfied.
	In this paper, we propose a uniform treatment of concerns at the
	requirements engineering level, regardless of their functional, non-functional
	or crosscutting nature. Our approach is based on the observation
	that concerns in a system are, in fact, a subset, and concrete realisations,
	of abstract concerns in a meta concern space. One can delineate requirements
	according to these abstract concerns to derive more system-specific,
	concrete concerns. We introduce the notion of a compositional intersection,
	which allows us to choose appropriate sets of concerns in our multi-dimensional
	separation as a basis to observe trade-offs among other concerns.
	This provides a rigorous analysis of requirements-level trade-offs
	as well as important insights into various architectural choices
	available to satisfy a particular functional or non-functional concern.},
  doi = {10.1109/RE.2005.46},
  file = {:./literature/RE_2005.pdf:PDF},
  keywords = {systems analysis compositional intersection, multidimensional separation,
	requirements engineering, non-functional requirements},
  owner = {Stephan},
  timestamp = {2008.05.29},
  url = {http://www.comp.lancs.ac.uk/computing/aop/papers/RE_2005.pdf}
}

@MISC{Morgan2006,
  author = {Gabriel Morgan},
  title = {Design for Flexibility},
  howpublished = {online},
  month = {Oct},
  year = {2006},
  note = {Last retrieved: 29 Oct 2010},
  keywords = {flexibility},
  owner = {Stephan},
  timestamp = {2010.10.29},
  url = {http://blogs.msdn.com/b/gabriel_morgan/archive/2006/10/03/design-for-flexibility.aspx}
}

@ARTICLE{Morris1987,
  author = {Morris, P. and Hough, G.},
  title = {The anatomy of major projects},
  year = {1987},
  owner = {patrickr},
  publisher = {Wiley},
  timestamp = {2012.10.22}
}

@MASTERSTHESIS{Motschmann2012,
  author = {Daniel Motschmann},
  title = {{Multikriterielle Suche in einem Eclipse-basierten Repository für
	Software-Architekten}},
  school = {Ilmenau University of Technology},
  year = {2012},
  type = {Diplomarbeit},
  month = {March},
  file = {:./literature/Master_8.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.10.17}
}

@TECHREPORT{Motschmann2011,
  author = {Daniel Motschmann},
  title = {{Benutzerschnittstelle und Interaktionskonzept für das Modellierungswerkzeug
	{EMFfit}}},
  institution = {Ilmenau University of Technology},
  year = {2011},
  type = {Studienarbeit},
  month = {May},
  file = {:./literature/Paper_252.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.10.17}
}

@INPROCEEDINGS{Muccini2007,
  author = {Henry Muccini},
  title = {Using Model Differencing for Architecture-level Regression Testing},
  booktitle = {Proceedings of the 33rd EUROMICRO Conference on Software Engineering
	and Advanced Applications},
  year = {2007},
  pages = {59--66},
  publisher = {{IEEE} Computer Society},
  abstract = {Regression testing can be systematically applied at the software architecture
	level in order to reduce the cost of retesting modified systems,
	and also to assess the regression testability of the evolved system.
	With the advent of model-based specification and analysis of software
	architectures, regression testing at the architectural level can
	be handled by analyzing how the architectural model evolves when
	moving from an initial to a subsequent version. This paper analyzes
	how model differencing, a recent research topic in the model-based
	community, can be employed for implementing model-based architecture-level
	regression testing.},
  file = {:/literature/RegressionTesting/Using Model Differencing for Architecture-level Regression Testing.pdf:PDF},
  isbn = {0-7695-2977-1},
  owner = {Annie},
  review = {scope: black lntegration testing of components for architecture based
	systems
	
	Artefacts: Sequence dagrams state machines and componnet diagrams
	
	Change Types: Addition, Deletion and Change
	
	
	TC Classification: Retestable and New
	
	
	Tool Support: Yes prototype
	
	
	Case study, yes (15 Components, number of testcases not specified)},
  timestamp = {2011.01.04},
  url = {http://portal.acm.org/citation.cfm?id=1302497.1302995&coll=GUIDE&dl=GUIDE&CFID=54491404&CFTOKEN=93053143}
}

@ARTICLE{Muccini2006,
  author = {Henry Muccini and Marcio Dias and Debra J. Richardson},
  title = {Software architecture-based regression testing},
  journal = {Journal of Systems and Software},
  year = {2006},
  volume = {79},
  pages = {1379--1396},
  number = {10},
  month = oct,
  abstract = {Software architectures are becoming centric to the development of
	quality software systems, being the first concrete model of the software
	system and the base to guide the implementation of software systems.
	When architecting dependable systems, in addition to improving system
	dependability by means of construction (fault-tolerant and redundant
	mechanisms, for instance), it is also important to evaluate, and
	thereby confirm, system dependability. There are many different approaches
	for evaluating system dependability, and testing has been always
	an important one, being fault removal one of the means to achieve
	dependable systems. Previous work on software architecture-based
	testing has shown it is possible to apply conformance testing techniques
	to yield some confidence on the implemented system conformance to
	expected, architecture-level, behaviors. This work explores how regression
	testing can be systematically applied at the software architecture
	level in order to reduce the cost of retesting modified systems,
	and also to assess the regression testability of the evolved system.
	We consider assessing both "low-level" and "high-level" evolution,
	i.e., whether a slightly modified implementation conforms to the
	initial architecture, and whether the implementation continues to
	conform to an evolved architecture. A better understanding on how
	regression testing can be applied at the software architecture level
	will help us to assess and identify architecture with higher dependability.},
  doi = {10.1016/j.jss.2006.02.059},
  file = {:/literature/RegressionTesting/SARTE_JSS_WADS2005.pdf:PDF},
  issn = {0164-1212},
  keywords = {Architecture-based analysis and testing, Dependable systems, regression
	testing, Software architecture},
  owner = {Annie},
  review = {already reviewed their first paper},
  timestamp = {2011.01.04},
  url = {http://www.sciencedirect.com/science/article/B6V0N-4K42DG3-3/2/825f3f3f14be141c2ed2a08f2a245215}
}

@INPROCEEDINGS{Muccini2005a,
  author = {Henry Muccini and Marcio Dias and Debra J. Richardson},
  title = {Reasoning About Software Architecture-Based Regression Testing Through
	a Case Study},
  booktitle = {Proceedings of the 29th Annual International Computer Software and
	Applications Conference - Volume 02},
  year = {2005},
  pages = {189--195},
  publisher = {{IEEE} Computer Society},
  abstract = {Two main issues need to be covered when dealing with the dependability
	of component-based systems: quality assurance of reusable software
	components and quality assurance of the assembled component-based
	system. By focussing on the assembly, a software architecturespecification
	of a component-based system allows to explicitly model the structure
	and required system behavior by specifying how components and connectors
	are intended to interact. Software architecture-based conformance
	testing techniques can yield confidence on the implementation conformance
	to expected structural and behavioral properties as specified in
	the architectural models. In this paper we explore software architecture-based
	regression testing methods that enable reuse of earlier saved results
	to test if a different assembly of components conforms to the evolved
	software architecture. The approach is presented through a running
	example.},
  file = {:/literature/RegressionTesting/Reasoning about Software Architecture-based Regression Testing through a casestudy.pdf:PDF},
  isbn = {0-7695-2413-3},
  owner = {Annie},
  review = {already reviewed},
  timestamp = {2011.01.04},
  url = {http://portal.acm.org/citation.cfm?id=1090944.1091204&coll=GUIDE&dl=GUIDE&CFID=54491404&CFTOKEN=93053143}
}

@INPROCEEDINGS{Muccini2005,
  author = {Henry Muccini and Marcio S. Dias and Debra J. Richardson},
  title = {Towards software architecture-based regression testing},
  booktitle = {Proceedings of the 2005 workshop on Architecting dependable systems},
  year = {2005},
  pages = {1--7},
  address = {St. Louis, Missouri},
  publisher = {{ACM}},
  abstract = {When architecting dependable systems, in addition to improving system
	dependability by means of construction (fault-tolerant and redundant
	mechanisms, for instance), it is also important to evaluate, and
	thereby confirm, system dependability. There are many different approaches
	for evaluating system dependability, and testing always has been
	an important {one.Previous} work on software architecture testing
	has shown it is possible to apply conformance-testing techniques
	to yield confidence that the behavior of an implemented system conforms
	to the expected behavior of the software architecture, specified
	with Architecture Description {Languages.In} this work, we explore
	how regression testing can be systematically applied at the software
	architecture level in order to reduce the cost of retesting modified
	systems, and also to assess the regression testability of the evolved
	system. We consider assessing both "top-down" and "bottom-up" evolution,
	i.e., whether a slightly modified implementation conforms to the
	initial architecture, and whether the (modified) implementation conforms
	an evolved architecture. A better understanding on how regression
	testing can be applied at the software architecture level will help
	us to assess and identify architecture with higher dependability.},
  doi = {10.1145/1083217.1083223},
  file = {:/literature/RegressionTesting/Towards Software Architecture-based Regression Testing through a Case Study.pdf:PDF},
  isbn = {1-59593-124-4},
  keywords = {architecture-based testing and analysis, dependable systems, regression
	testing (rt), software architecture (sa)},
  owner = {Annie},
  timestamp = {2011.01.04},
  url = {http://portal.acm.org/citation.cfm?id=1083217.1083223&coll=GUIDE&dl=GUIDE&CFID=54491404&CFTOKEN=93053143}
}

@BOOK{Mueller2003,
  title = {Communication of information technology project sponsors and managers
	in buyer-seller relationships},
  publisher = {Dissertation. com},
  year = {2003},
  author = {Mueller, R.},
  file = {Mueller2003.pdf:literature/Mueller2003.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.10.18}
}

@ARTICLE{Murphy2001,
  author = {Murphy, Gail C. and Notkin, David and Sullivan, Kevin},
  title = {Software Reflexion Models: Bridging the Gap between Design and Implementation},
  journal = {IEEE Transactions on Software Engineering},
  year = {2001},
  volume = {27},
  pages = {364-380},
  number = {4},
  month = {April},
  booktitle = {IEEE Transactions on Software Engineering},
  file = {:./literature/Paper_27.PDF:PDF},
  owner = {Steffen},
  review = {seems to be the same as Murphy1995, however some additions/changes
	might have been made},
  timestamp = {2011.01.26}
}

@INPROCEEDINGS{Murphy1995,
  author = {Murphy, Gail C. and Notkin, David and Sullivan, Kevin},
  title = {Software Reflexion Models: Bridging the Gap betwen Source and High-Level
	Models},
  booktitle = {Proceedings of the 3rd ACM SIGSOFT symposium on Foundations of software
	engineering (SIGSOFT '95)},
  year = {1995},
  pages = {18-28},
  address = {Washington, D.C., USA},
  month = {October},
  file = {:./literature/Paper_23.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- code and abstract models often not synchronized
	
	- difficult to reason about code when viewing models (and vice versa)
	when both not correct
	
	
	Research Questions:
	
	- find similarities and point out differences between code and models
	
	
	Contribution:
	
	- reflexion model approach computing "reflexion model" from code and
	models which shows similarities / differences
	
	
	Solution:
	
	- approach evaluated with MS Excel and NetBSD Linux
	
	- mapping between code and models (reflexion model) through Z language
	(http://de.wikipedia.org/wiki/Z-Notation)
	
	- model entities mapped to source entities, model relations mapped
	to code relations (entities and relations mapped as tuples)
	
	
	Open Issues:},
  timestamp = {2011.01.16}
}

@CONFERENCE{Murta2006,
  author = {Murta, Leonardo G. P. and van der Hoek, André and Werner, Cláudia
	M. L.},
  title = {ArchTrace: Policy-Based Support for Managing Evolving Architecture-to-Implementation
	Traceability Links},
  booktitle = {Proceedings of the 21st IEEE/ACM International Conference on Automated
	Software Engineering (ASE’06)},
  year = {2006},
  pages = {135-144},
  address = {Tokyo},
  month = {September},
  file = {:./literature/Paper_20.pdf:PDF},
  journal = {21st IEEE/ACM International Conference onAutomated Software Engineering
	(ASE’06)},
  owner = {Steffen},
  review = {Problem:
	
	- architecture and code not static, they evolve and change
	
	- little research on synchonizing code and architecture to perform
	IA
	
	
	Research Questions:
	
	
	Contribution:
	
	- keep architecture and code synchronized
	
	- automatic update of traceability relations on architecture/code-update
	
	- provide navigation from any code to related models and vice versa
	
	
	Solution:
	
	- use specified set of traceability management policies (atomic elements)
	
	- new policies can be added through new plugins (each policy is a
	new java class)
	
	- 4 policy classes: architectural evol. pol., code evol. pol., pre-trace
	pol. und post-trace pol.
	
	- policies not meant to operate entirely without user
	
	- use of xADL 2.0 for architecture and Subversion for Code
	
	- continious updates of all links
	
	- implemented in ArchTrace tool
	
	
	Open Issues:
	
	- evolution of traceability links supported, but not generation of
	links
	
	- no specified traceability (meta-)model
	
	- not clear how approach performs on on non-mature projects (only
	tested with rather finished software)},
  timestamp = {2011.01.07}
}

@INPROCEEDINGS{Muskens2005,
  author = {Muskens, J. and Bril, R. J. and Chaudron, M. R. V.},
  title = {Generalizing Consistency Checking between Software Views},
  booktitle = {Proceedings of the 5th Working IEEE/IFIP Conference on Software Architecture
	(WICSA 2005)},
  year = {2005},
  pages = {169-180},
  address = {Pittsburgh, PA, USA},
  file = {:./literature/Paper_203.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.03.15}
}

@TECHREPORT{Muvuti2004,
  author = {Muvuti, Fadzai and Lungu, Mbamwabi Ntheye},
  title = {Service Oriented Architecture for a Software Traceability System},
  institution = {Department of Computer Science, University of Cape Town},
  year = {2004},
  abstract = {In order to improve software development and keep up with the fast
	pace of business, standards and methodologies for determining and
	endorsing effective software development processes have been introduced
	and put into effect on software projects. Accordingly, many tools
	that interpret these standards and methodologies have been developed
	and employed. Although there is active development and research in
	the area of requirements traceability, the desired level of acceptance
	has not been achieved, and the most widely reported reason for this
	in the industry, is that of: ‘poor and immature integration technology’.
	This has resulted in existing tools often suffering problems due
	to poor integration and inflexibility with other technologies, which
	undermines the usefulness, usability and longevity of the Requirements
	Traceability provided by these tools. The panacea, at least in the
	confines of this project, is to employ a new technology: ’Web Services’
	as the underlying framework, to address these problems. The motivation
	for employing the web services architecture for this project is to
	allow personalized customization of a traceability solution, hence
	providing a ubiquitous software development process that incorporates
	standards as well as software engineering industry best practices.},
  file = {:./literature/Technical_Report.pdf:PDF},
  owner = {Elke},
  timestamp = {2011.05.27},
  url = {http://pubs.cs.uct.ac.za/archive/00000189/}
}

@ARTICLE{Myers2003,
  author = {Myers, Christopher R.},
  title = {Software systems as complex networks: Structure, function, and evolvability
	of software collaboration graphs},
  journal = {Physical Review E},
  year = {2003},
  volume = {68},
  pages = {046116},
  number = {4},
  month = {Oct},
  abstract = {Software systems emerge from mere keystrokes to form intricate functional
	networks connecting many collaborating modules, objects, classes,
	methods, and subroutines. Building on recent advances in the study
	of complex networks, I have examined software collaboration graphs
	contained within several open-source software systems, and have found
	them to reveal scale-free, small-world networks similar to those
	identified in other technological, sociological, and biological systems.
	I present several measures of these network topologies, and discuss
	their relationship to software engineering practices. I also present
	a simple model of software system evolution based on refactoring
	processes which captures some of the salient features of the observed
	systems. Some implications of object-oriented design for questions
	about network robustness, evolvability, degeneracy, and organization
	are discussed in the wake of these findings.},
  doi = {10.1103/PhysRevE.68.046116},
  file = {:./literature/Myers2003_softwarenet.pdf:PDF},
  keywords = {software collaboration graphs, evolvability},
  numpages = {15},
  owner = {Stephan},
  publisher = {American Physical Society},
  review = {only for Part III Section V
	
	
	evolvability
	
	- carefully planned genericity and associated decoupling
	
	- use of polymorphism and encapsulation
	
	
	- "cooperative action of several, more generic [...] constituents,
	rather than the specific action of a single, complex component"
	
	
	in biology:
	
	- degeneracy important for evolution
	
	-> ability of different elements to perform similar (or perhaps identical)
	funcitons
	
	-> similar to polymorphism in OO},
  timestamp = {2008.07.08},
  url = {http://www.tc.cornell.edu/~myers/papers/Myers2003_softwarenet.pdf}
}

@ARTICLE{Mylopoulos1992,
  author = {John Mylopoulos and Lawrence Chung and Brian A. Nixon},
  title = {Representing and Using Nonfunctional Requirements: A Process-Oriented
	Approach},
  journal = {IEEE Transactions on Software Engineering},
  year = {1992},
  volume = {18},
  pages = {483-497},
  number = {6},
  month = {June},
  abstract = {The paper proposes a comprehensive framework for representing and
	using nonfunctional requirements during the development process.
	The framework consists of five basic components which provide for
	the representation of nonfunctional requirements in terms of interrelated
	goals. Such goals can be refined through refinement methods and can
	be evaluated in order to determine the degree to which a set of nonfunctional
	requirements is supported by a particular design. Evidence for the
	power of the framework is provided through the study of accuracy
	and performance requirements for information systems.},
  citeseerurl = {citeseer.ist.psu.edu/mylopoulos92representing.html},
  doi = {10.1109/32.142871},
  file = {:./literature/00142871.pdf:PDF},
  keywords = {formal specification, management information systemsdevelopment process,
	information systems, nonfunctional requirements, performance requirements,
	process-oriented approach, refinement methods},
  owner = {Stephan},
  timestamp = {2008.04.15}
}

@PHDTHESIS{Naab2012,
  author = {Naab, Matthias},
  title = {Enhancing Architecture Design Methods for Improved Flexibility in
	Long-Living Information Systems},
  school = {Technische Universität Kaiserslautern},
  year = {2012},
  file = {:./literature/phd_matthias_naab.pdf:PDF},
  owner = {Sebastian},
  timestamp = {2013.07.26}
}

@INPROCEEDINGS{Nadi2010,
  author = {Nadi, Sarah and Holt, Ric and Mankovskii, Serge},
  title = {Does the Past Say It All? Using History to Predict Change Sets in
	a {CMDB}},
  booktitle = {Proceedings of the 14th European Conference on Software Maintenance
	and Reengineering},
  year = {2010},
  pages = {97-106},
  address = {Madrid, Spain},
  month = {March},
  file = {:./literature/Paper_155.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- essential to control changes to avoid huge costs
	
	- many software projects managed by configuration management database
	(CMDB)
	
	
	Research Questions:
	
	- are current/future changes similar to past changes
	
	
	Contribution:
	
	- IA method relying on historical change data to suggest impacts
	
	
	Solution:
	
	- extract historcal change data from configuration management DBS
	and not from version control systems
	
	- use support and confidence measures to assess how closely two entities
	are related
	
	* support: # of changes together
	
	* confidence: # of changes together / # of changes to the entity
	
	* store both values in separate matrices
	
	- use 3 different filters to prune results:
	
	* support threshold: define a min. support value
	
	* confidence threshold: define a min. confidence value
	
	* exponential forgetting:
	
	 - use concept of half-life to forget coupling information
	
	-> granularity of entities: variable
	
	-> granularity of changes: change order reports gathered from CMDB
	
	-> granularity of results: variable
	
	- implemented in DRACA tool
	
	
	Open Issues:
	
	- conducted case study almost useless as investigated change sets
	contained only 1 element in most cases (60% of all records)
	
	- DRACA should not just propose affected entities, but also best time
	for change
	
	- improve heuristics used for filtering results},
  timestamp = {2011.04.05}
}

@INPROCEEDINGS{Nakamura2005,
  author = {Nakamura, Taiga and Basili, Victor R.},
  title = {Metrics of Software Architecture Changes Based on Structural Distance},
  booktitle = {Proceedings of the 11th IEEE International Software Metrics Symposium
	(METRICS'05)},
  year = {2005},
  pages = {8-17},
  address = {Como, Italy},
  month = {September},
  file = {:./literature/Paper_117.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.04.01}
}

@MASTERSTHESIS{Nasir2008,
  author = {Muhammad Iftikhar Nasir and Rizwan Iqbal},
  title = {Evolvability of Software Systems},
  school = {Department of Computer Science, School of Engineering, Blekinge Institute
	of Technology},
  year = {2008},
  address = {Ronneby, Sweden},
  month = {Oct},
  abstract = {Software evolvability, meeting the future requirements of the customer
	is one of the emerging challenges which software industry is facing
	nowadays. Software evolvability is the ability of software system
	to accommodate future requirements. Studies have shown that software
	evolvability has large economic benefits but at the same time it’s
	difficult to assess. Over the time many methods have been derived
	to assess the software evolvability. Software evolvability depends
	upon various characteristics of the software system. 
	
	
	In this paper we will discuss different characteristics of the software
	systems on which software evolvability depends. We will also have
	a look on hierarchy of these characteristics based on their role
	in the evolvability of software system. Moreover we will find out
	that what level of qualifications is appropriate for an expert to
	assess the software evolvability of a software system.},
  file = {:./literature/Thesis_MCS_2008_36.pdf:PDF},
  keywords = {software evolvability, software evolvability characteristics priority,
	assessment of software evolvability, qualification of an expert},
  owner = {Stephan},
  timestamp = {2009.03.30},
  url = {http://www.bth.se/fou/cuppsats.nsf/all/b4150d997aa9e1abc125750c0078f6c8/$file/Thesis%20MCS%202008%2036.pdf}
}

@INPROCEEDINGS{Naslavsky2007,
  author = {Leila Naslavsky and Debra J. Richardson},
  title = {Using traceability to support model-based regression testing},
  booktitle = {Proceedings of the twenty-second IEEE/ACM international conference
	on Automated software engineering},
  year = {2007},
  pages = {567--570},
  address = {Atlanta, Georgia, {USA}},
  publisher = {{ACM}},
  abstract = {Model-driven development is leading to increased use of models in
	conjunction with source code in software testing. Model-based testing,
	however, introduces new challenges for testing activities, which
	include creation and maintenance of traceability information among
	test-related artifacts. Traceability is required to support activities
	such as selective regression testing. In fact, most model-based testing
	automated approaches often concentrate on the test generation and
	execution activities, while support to other activities is limited
	(e.g. model-based selective regression testing, coverage analysis
	and behavioral result evaluation)},
  doi = {10.1145/1321631.1321744},
  file = {:/literature/RegressionTesting/Using Traceability to Support Model-Based Regression Testing.pdf:PDF},
  isbn = {978-1-59593-882-4},
  keywords = {model-based testing, model-driven development, traceability, MDRT},
  owner = {Annie},
  timestamp = {2011.01.04},
  url = {http://portal.acm.org/citation.cfm?id=1321631.1321744&coll=GUIDE&dl=ACM&CFID=54491404&CFTOKEN=93053143}
}

@INPROCEEDINGS{Naslavsky2010,
  author = {L. Naslavsky and H. Ziv and D.J. Richardson},
  title = {MbSRT2:Model-Based Selective Regression Testing with Traceability},
  booktitle = {Software Testing, Verification and Validation (ICST), 2010 Third
	International Conference on},
  year = {2010},
  pages = {89--98},
  abstract = {Widespread adoption of model-centric development has created opportunities
	for software testing, with {Model-Based} Testing {(MBT).} {MBT} supports
	the generation of test cases from models and the demonstration of
	model and source-code compliance. Models evolve, much like source
	code. Thus, an important activity of {MBT} is selective regression
	testing, which selects test cases for retest based on model modifications,
	rather than source-code modifications. This activity explores relationships
	between model elements and test cases that traverse those elements
	to locate retest able test cases. We contribute an approach and prototype
	to model-based selective regression testing, whereby fine-grain traceability
	relationships among entities in models and test cases are persisted
	into a traceability infrastructure throughout the test generation
	process: the relationships represent reasons for test case creation
	and are used to select test cases for re-run. The approach builds
	upon existing regression test selection techniques and adopts scenarios
	as behavioral modeling perspective. We analyze precision, efficiency
	and safety of the approach through case studies and through theoretical
	and intuitive reasoning.},
  doi = {10.1109/ICST.2010.61},
  file = {:/literature/RegressionTesting/MbSRT2  Model-based Selective Regression Testing with Traceability.pdf:PDF},
  keywords = {behavioral modeling perspective, fine-grain traceability infrastructure,
	intuitive reasoning, {MbSRT2,} model based selective regression testing,
	model centric development, model-based reasoning, program diagnostics,
	program testing, regression analysis, software testing, source code
	compliance, test case creation, test generation process, MDRT},
  owner = {Annie},
  shorttitle = {{MbSRT2}},
  timestamp = {2011.01.04}
}

@INPROCEEDINGS{Naslavsky2009,
  author = {L. Naslavsky and H. Ziv and D.J. Richardson},
  title = {A model-based regression test selection technique},
  booktitle = {. ICSM 2009. IEEE International Conference on Software Maintenance,
	2009},
  year = {2009},
  pages = {515--518},
  abstract = {Throughout their life cycle, software artifacts are modified, and
	selective regression testing is used to identify the negative impact
	of modifications. Code-based regression test selection retests test
	cases sub-set that traverse code modifications. It uses recovered
	relationships between code parts and test cases that traverse them
	to locate test cases for retest when code is modified. Broad adoption
	of model-centric development has created opportunities for software
	testing. It enabled driving testing processes at higher abstraction
	levels and demonstrating code to model compliance by means of {Model-Based}
	Testing {(MBT).} Models also evolve, so an important activity of
	{MBT} is selective regression testing. It selects test cases for
	retest based on model modification, so it relies on relationships
	between model elements and test cases that traverse those elements
	to locate test cases for retest. We contribute an approach and prototype
	that during test case generation creates fine-grained traceability
	relationships between model elements and test cases, which are used
	to support model-based regression test selection.},
  doi = {10.1109/ICSM.2009.5306338},
  file = {:/literature/RegressionTesting/A model-based regression test selection technique.pdf:PDF},
  isbn = {1063-6773},
  keywords = {code-based regression test selection technique, model-based regression
	test selection, model-based testing, program testing, regression
	analysis, selective regression testing, software artifacts, software
	testing, test case generation, MDRT},
  owner = {Annie},
  timestamp = {2011.01.04}
}

@INPROCEEDINGS{Nehaniv2006,
  author = {Nehaniv, C.L. and Hewitt, J. and Christianson, B. and Wernick, P.},
  title = {What Software Evolution and Biological Evolution Don't Have in Common},
  booktitle = {Second International IEEE Workshop on Software Evolvability, SE '06},
  year = {2006},
  pages = {58-65},
  month = {Sept. },
  publisher = {IEEE Computer Society},
  abstract = {Understanding software change as an evolutionary process analogous
	to biological evolution is an increasingly popular approach to software
	evolvability but requires some caution. Issues of evolvability make
	sense not only for biological and evolutionary computation systems,
	but also in the realms of artifacts, culture, and software systems.
	Persistence through time with variation (while possibly spreading)
	is an analogue to variation (with heritability). Thus discrete individual
	replicators are not strictly necessary for an evolutionary dynamic
	to take place. Studying identified properties that give biological
	and artifact evolution the capacity to produce complex adaptive variation
	could shed light on how to enhance the evolvability of software systems
	in general and of evolutionary computation in particular. Evolution
	and evolvability can be compared in different domains. But the evolution
	of software systems is also very unlike that of biological entities
	whose existence, persistence, development, and integrity as single
	individuals is actively maintained by the activity of the entities
	themselves over a long evolutionary history. Integrity of software
	systems - i.e. the assumption that they are well-defined, coherent
	individuals that develop - is presupposed by nearly all software
	process approaches and limits their effectiveness. Understanding
	the long-term evolvability of software systems as they undergo "descent
	with modification" thus requires much more than a traditional Darwinian
	approach. We compile and discuss differences and similarities between
	software evolution and other instances evolution toward this end.},
  doi = {10.1109/SOFTWARE-EVOLVABILITY.2006.18},
  file = {:./literature/900971.pdf:PDF},
  keywords = {evolution (biological), software prototypingbiological evolution,
	discrete individual replicators, evolutionary computation, software
	evolution, software system integrity, software understanding},
  owner = {Stephan},
  timestamp = {2008.07.08},
  url = {https://uhra.herts.ac.uk/dspace/bitstream/2299/910/1/900971.pdf}
}

@INPROCEEDINGS{Nelson1997,
  author = {Nelson, K.M. and Nelson, H.J. and Ghods, M.},
  title = {Technology flexibility: conceptualization, validation, and measurement},
  booktitle = {Proceedings of the Thirteeth Hawaii International Conference on System
	Sciences},
  year = {1997},
  volume = {3},
  pages = {76-87},
  month = {Jan},
  publisher = {IEEE},
  abstract = {This research investigates technology flexibility, which is the technology
	characteristic that allows or enables adjustments and other changes
	to the business process. Technology flexibility has two dimensions,
	structural and process flexibility, encompassing both the actual
	technology application and the people and processes that support
	it. The flexibility of technology that supports business processes
	can greatly influence the organization's capacity for change. Existing
	technology can present opportunities for or barriers to business
	process flexibility through structural characteristics such as language,
	platform and design. Technology can also indirectly affect flexibility
	through the relationship between the technology maintenance organization
	and the business process owners, change request processing, and other
	response characteristics. These indirect effects reflect a more organizational
	perspective of flexibility. This paper asks the question, “what makes
	technology flexible?” This question is addressed by developing and
	validating a measurement model of technology flexibility. Constructs
	and definitions of technology flexibility are developed by examining
	the concept of flexibility in other disciplines, and the demands
	imposed on technology by business processes. The purpose of building
	a measurement model is to show validity for the constructs of technology
	flexibility. This paper discusses the theory of technology flexibility,
	develops constructs and determinants of this phenomenon, and proposes
	a methodology for the validation and study of the flexibility of
	emerging technologies.},
  doi = {10.1109/HICSS.1997.661572},
  file = {:./literature/Nelson1997.pdf:PDF},
  issn = {1060-3425},
  keywords = {DP management, business data processing, information technology, management
	of changebusiness process, business process flexibility, management
	of change, measurement, organization, people, process flexibility,
	research, structural flexibility, technology flexibility, technology
	maintenance},
  owner = {Stephan},
  timestamp = {2008.10.09}
}

@MASTERSTHESIS{Neugebauer2011,
  author = {Stefan Neugebauer},
  title = {Softwarearchitektur-{E}ntwurf f\"{u}r {A}nwendungen auf {M}ehrkern-{P}rozessorarchitekturen},
  school = {Ilmenau University of Technology},
  year = {2011},
  type = {diploma thesis},
  note = {(to appear)},
  comment = {to appear},
  owner = {Stephan},
  timestamp = {2011.02.09}
}

@CONFERENCE{Neumueller2006,
  author = {Neum\"uller, C. and Gr\"unbacher, P.},
  title = {Automating Software Traceability in Very Small Companies: A Case
	Study and Lessons Learned},
  booktitle = {Automated Software Engineering, 2006. ASE '06. 21st IEEE/ACM International
	Conference on},
  year = {2006},
  pages = {145 -156},
  month = {sept.},
  abstract = {There is a wide consensus on the benefits of software traceability.
	However, traceability techniques are still not commonly used in industry
	$typically only in larger companies and if mandated by standards
	such as the CMMI or ISO 15504. Success stories in small companies
	are quite rare. However, small companies represent a significant
	share of the IT industry and a better understanding of their needs
	is essential for the research community. This paper presents APIS,
	a traceability environment we developed and introduced in a very
	small software company. We discuss the traceability approach and
	report on key lessons learned. We have found in the project that
	comparably simple automation techniques are surprisingly effective.
	We believe that the lessons learned in this project are relevant
	for researchers and practitioners facing similar challenges},
  doi = {10.1109/ASE.2006.25},
  file = {:./literature/04019570.pdf:PDF},
  issn = {1527-1366},
  keywords = {APIS traceability environment;IT industry;software company;software
	traceability;program diagnostics;software architecture;software tools;},
  owner = {Elke},
  review = {Elke
	
	Tailoring the traceability strategy to the specific needs
	
	and development context is key to success.
	
	
	Beschreibt eigene Entwicklung angepaßt an konkrete Anwändungsfälle},
  timestamp = {2011.06.06}
}

@BOOK{Nielsen1993,
  title = {Usability Engineering},
  publisher = {Academic Press},
  year = {1993},
  author = {Jakob Nielsen},
  pages = {362},
  series = {Interactive Technologies},
  address = {Boston, USA},
  abstract = {Written by the author of the bestselling HyperText & HyperMedia, this
	book is an excellent guide to the methods of usability engineering.
	It emphasizes cost effective methods that will help developers improve
	user interfaces immediately. Step-by-step information on which methods
	to use at various stages during the development life cycle are included,
	along with how to run a usability test.},
  keywords = {usability engineering, user interface design},
  owner = {Stephan},
  timestamp = {2008.08.01},
  url = {http://books.google.de/books?id=o1IqPH0a2fYC}
}

@INPROCEEDINGS{Nikula2005,
  author = {Nikula, U. and Sajaniemi, J.},
  title = {Tackling the complexity of requirements engineering process improvement
	by partitioning the improvement task},
  booktitle = {Software Engineering Conference, 2005. Proceedings. 2005 Australian},
  year = {2005},
  pages = {48--57},
  file = {Nikula2005.pdf:literature/Nikula2005.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@INPROCEEDINGS{Noda1999,
  author = {Noda, N. and Kishi, T.},
  title = {On aspect-oriented design-an approach to designing quality attributes},
  booktitle = {Proceedings. Sixth Asia Pacific Software Engineering Conference,
	1999. (APSEC '99)},
  year = {1999},
  pages = {230-237},
  publisher = {IEEE Computer Society},
  abstract = {It is difficult to design software to meet its goal on quality attributes,
	because there are many factors related to quality attributes, and
	the relationships between these factors and quality attributes are
	quite complicated. However, we do not have a systematic way to design
	software considering quality attributes. Consequently, we have many
	troubles in the attainment of required quality attributes in actual
	software development. We are examining a design method, aspect oriented
	design (AOD) based on the idea of “aspect orientedness” proposed
	in the programming community as aspect oriented programming. In AOD,
	aspects corresponding to quality attributes are considered separately,
	and software architectures suitable for each aspect are designed
	independently and woven into the final architecture. The authors
	introduce their approach and demonstrate the effectiveness of the
	approach using an example.},
  doi = {10.1109/APSEC.1999.809607},
  file = {:./literature/05090230.pdf:PDF},
  keywords = {software architecture, software quality, software reliabilityAOD,
	aspect oriented design, aspect oriented programming, aspect orientedness,
	programming community, quality attribute design, quality software
	design, software architectures, software development},
  owner = {Stephan},
  timestamp = {2008.05.29}
}

@MASTERSTHESIS{Noroozi2008,
  author = {Reza Noroozi},
  title = {Modellgetriebene Entwicklung aller SOA-Schichten},
  school = {Hochschule für Angewandte Wissenschaften Hamburg},
  year = {2008},
  month = {Jan},
  abstract = {Diese Diplomarbeit beschreibt einen Ansatz, Schichten einer SOA mit
	Hilfe von Methoden der modellgetriebene Softwareentwicklung zu realisieren.
	Dabei wird definiert welche der Schichten sich modellgetrieben entwickeln
	lassen. Hierzu werden die Opensource Werkzeuge AndroMDA und openArchitectureWare,
	die der Unterstützung von modellgetriebener Softwareentwicklung dienen,
	auf ihre Praxistauglichkeit evaluiert. Als Ergebnis der Untersuchung
	soll beurteilt werden, welches Werkzeug für die Umsetzung des im
	Rahmen dieser Arbeit zu entwickelnden Konzepts am zweckmäßigsten
	ist. Dieses Werkzeug wird schließlich verwendet um einen Prototypen
	zu realisieren.
	
	
	This thesis describes a concept of how to develop layers of a Service
	Orientated Software Architecture with the help of methods of model
	driven Software Development. In this context it will be defined which
	of these layers can be developed in a model driven way. Therefore,
	it will be evaluated how practically useful the tools AndroMDA and
	openArchitectureWare are, which are for the support of model driven
	architecture. The result of the evaluation will be, to choose the
	tool that is most efficient in the frame of the concept that is to
	be developed in this paper. Finally, this tool will be used to realise
	a prototype.},
  file = {:./literature/Noroozi_Abschlussarbeit.pdf:PDF},
  keywords = {Modellgetriebene Softwareentwicklung, modellgetriebene Architektur,
	Modellierung, serviceorientierte Architektur, Webservice
	
	Model driven software development, model driven architecture, modelling,
	service-oriented architecture, web service},
  owner = {Stephan},
  timestamp = {2008.04.10},
  url = {http://opus.haw-hamburg.de/volltexte/2008/465/pdf/Noroozi_Abschlussarbeit.pdf}
}

@TECHREPORT{Noy2001,
  author = {Natalya F. Noy and Deborah L. McGuinness},
  title = {Ontology Development 101: A Guide to Creating Your First Ontology},
  institution = {Stanford Knowledge Systems Laboratory},
  year = {2001},
  number = {KSL-01-05},
  address = {Stanford University, Stanford, CA, 94305},
  file = {:./literature/ontology101.pdf:PDF},
  keywords = {ontology development},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://www.smi.stanford.edu/projects/protege/publications/ontology_development/ontology101.pdf}
}

@ARTICLE{Nurcan2005,
  author = {Nurcan, S. and Edme, M.H.},
  title = {Intention-driven modeling for flexible workflow applications},
  journal = {Software Process: Improvement and Practice},
  year = {2005},
  volume = {10},
  pages = {363--377},
  number = {4},
  file = {Nurcan2005.pdf:literature/Nurcan2005.pdf:PDF},
  owner = {patrickr},
  publisher = {Wiley Online Library},
  timestamp = {2012.12.11}
}

@INPROCEEDINGS{Nurmuliani2006,
  author = {Nurmuliani, N. and Zowghi, Didar and Williams, Susan P.},
  title = {Requirements Volatility and Its Impact on Change Effort: Evidence-based
	Research in Software Development Projects},
  booktitle = {Proceedings of the 11th Australian Workshop on Requirements Engineering},
  year = {2006},
  address = {Adelaide, Australia},
  file = {:./literature/Paper_16.PDF:PDF},
  journal = {Proceeding of 11th Australian Workshop on Requirements 
	
	Engineering},
  owner = {Steffen},
  review = {Problem:
	
	
	Research Questions:
	
	
	Contribution:
	
	
	Solution:
	
	
	Open Issues:},
  timestamp = {2011.01.05}
}

@INPROCEEDINGS{Nuseibeh2000,
  author = {Bashar Nuseibeh and Steve Easterbrook},
  title = {Requirements engineering: a roadmap},
  booktitle = {Proceedings of the Conference on The Future of Software Engineering,
	ICSE '00},
  year = {2000},
  pages = {35-46},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {This paper presents an overview of the field of software systems requirements
	engineering (RE). It describes the main areas of RE practice, and
	highlights some key open research issues for the future.},
  doi = {http://doi.acm.org/10.1145/336512.336523},
  file = {:./literature/ICSE2000.pdf:PDF},
  isbn = {1-58113-253-0},
  keywords = {requirements engineering},
  location = {Limerick, Ireland},
  owner = {Stephan},
  review = {introduction of requirements engineering (RE) as branch of systems
	engineering
	
	
	activities: elicitation, modelling, communicating, agreeing, evolving
	
	
	description of different techniques for elicitation
	
	
	modelling approaches: enterprise, data, behavioural, domain, non-functional
	requirements
	
	
	challanges:
	
	- managing inconsistency, change
	
	- new techniques for modelling and analysing properties of the environment
	
	- deal with evolving models
	
	- richer models for non-functional requirements
	
	- reuse of requirements models
	
	- understanding of impact of architectural choices and on prioritization
	and evolution of requirements},
  timestamp = {2008.04.17},
  url = {http://www.sis.uncc.edu/~seoklee/teaching/Papers/ICSE2000.pdf}
}

@PHDTHESIS{ONeal2003,
  author = {O'Neal, James Steven},
  title = {Analyzing the impact of changing software requirements: A traceability-based
	methodology},
  school = {Louisiana State University},
  year = {2003},
  file = {:./literature/PhD_7.pdf:PDF},
  owner = {Steffen},
  review = {- thesis proposes predictive requirements impact analysis based on
	traceability: TIAM
	
	- TIAM uses traceability links and requirements change impact metric
	to assess impact of requirements change
	
	- O'Neal defines work product requirements trace model (WoRM) which
	provides information required for proposed methodolgy
	
	* consist of work product information model (WIM) and requirements
	change information model (RIM)
	
	* WIM encapsulates information on work products which build the software,
	RIM represents associations between requirements changes and severity
	of requirements changes
	
	* WIM stores external information about each work product: time it
	took to create WP, complexity of WP, development phase in which WP
	was created
	
	* RIM weights each trace between WP with a influence function, according
	to values such as week, average, strong
	
	- TIAM operates with different classes of requirements changes, where
	each class has a certain impact
	
	- TIAM also identiﬁes potentially impacted work products by generating
	a set of potentially impacted work products for each requirement
	change
	
	- TIAM operates in several steps:
	
	* predict impact set based on requirements traceability (based on
	information of WP, which are grouped by technique of fuzzy compability
	classes)
	
	* order sets according to their impact value (low to high requirement
	impact)
	
	* evluate risk of implementing requirements based on its rank
	
	
	problem here: WP can be part of > 1 phases, how to sort?
	
	
	- scope of analysis:
	
	- tool: -
	
	- language: -
	
	- scalability: -
	
	- granularity
	
	* changes: - 
	
	* artifacts: requirements, misc. artifacts
	
	* results: requirements
	
	- technique: TR
	
	- analysis style: -
	
	- evaluation
	
	* size: 120 artifacts, 1100 traces
	
	* precision: -
	
	* recall: -
	
	* time: -},
  timestamp = {2011.08.24}
}

@INPROCEEDINGS{ONeal2001,
  author = {O'Neal, James Steven and Carver, D. L.},
  title = {Analyzing the impact of changing requirements},
  booktitle = {Proceedings of the IEEE International Conference on Software Maintenance},
  year = {2001},
  pages = {190-195},
  address = {Florence, Italy},
  month = {November},
  file = {:./literature/Paper_183.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- determining impact of requirements change crucial for project management
	
	
	Research Questions:
	
	- determining the affect of a change on completed work
	
	- comparing changes to requirements based on their severity
	
	
	Contribution:
	
	- IA method for requirements based on traceability
	
	- method to prioritize requirements changes based on impact metric
	
	- case study which shows effectiveness of approach
	
	
	Solution:
	
	- categorize changes into varying groups of impact and order groups
	according to severity of impact (high, low etc.)
	
	- impact metric predicts required effort to rework/change existing
	work products
	
	- approach relies on traces established between requirements and work
	products which implement them
	
	- forward traces and external properties of work products are core
	of proposed metric, properties are:
	
	* complexity of work product
	
	* effort to create work product in person hours
	
	* development phase in which work product was created
	
	* influence of source work product on target work product
	
	- developers determine level of attributes associated with work products
	and traces
	
	- impact analysis consists of two phases:
	
	* use impact metric to calculate required effort to change existing
	work product
	
	* group changes into fuzzy compatibility classes according to differences
	in the metric, by ranking the mean of impact metrics on the classes
	
	
	Open Issues:
	
	- improve computation of metric
	
	- reconsider number of attributes},
  timestamp = {2011.08.24}
}

@BOOK{Oberle2006,
  title = {Semantic management of middleware},
  publisher = {Springer Verlag},
  year = {2006},
  author = {Daniel Oberle},
  volume = {1},
  pages = {268},
  address = {New York},
  abstract = {Current middleware solutions, e.g., application servers and Web services,
	are very complex software products that are hard to tame because
	of intricacies of distributed systems. Their functionalities have
	mostly been developed and managed with the help of administration
	tools and corresponding configuration files, recently in XML. Though
	this constitutes flexibility for developing and administrating a
	distributed application, the conceptual model underlying the different
	configurations is only implicit.
	
	
	To remedy such problems, Semantic Management of Middleware contributes
	an ontology-based approach to support the development and administration
	of middleware-based applications. The ontology is an explicit conceptual
	model with formal logic-based semantics. Its descriptions may therefore
	be queried, may foresight required actions, or may be checked to
	avoid inconsistent system configurations.
	
	
	This book builds a rigorous approach towards giving the declarative
	descriptions of components and services a well-defined meaning by
	specifying ontological foundations and by showing how such foundations
	may be realized in practical, up-and-running systems.},
  doi = {10.1007/0-387-27631-9},
  keywords = {Semantic Web, Ontology of Plans, Core Software Ontology, Ontology
	of Information Objects, Main Question, Effort Without, Software Library,
	Analyzing Message Contexts, Core Ontology of Web Services, Core Ontology
	of Software Components, Detecting Loops, Modelling None, Selecting
	Service Functionality, Automatic Generation of Web Service Descriptions,
	Daniel Oberle, Java Management Extensions, Thin Object, Ease of Use,
	Java Remote Method Invocation, Management Information Bases, Situation
	Description, Steffen Staab, Suggested Improvement, World Wide Web
	Consortium, Language Support},
  language = {englisch},
  owner = {Robert},
  timestamp = {2008.07.16}
}

@ARTICLE{Offutt2002,
  author = {Offutt, J.},
  title = {Quality attributes of Web software applications},
  journal = {IEEE Software},
  year = {2002},
  volume = {19},
  pages = {25-32},
  number = {2},
  month = {Mar/Apr},
  abstract = {Web applications have very high requirements for numerous quality
	attributes. This article discusses some of the technological challenges
	of building today's complex Web software applications, their unique
	quality requirements, and how to achieve them.},
  doi = {10.1109/52.991329},
  file = {:./literature/00991329.pdf:PDF},
  issn = {0740-7459},
  keywords = {Internet, information resources, software quality, Web software applications,
	quality attributes},
  owner = {Stephan},
  review = {very common description of quality attributes that have to be addressed
	by web applications
	
	
	most important criteria:
	
	- reliability
	
	- usability
	
	- security
	
	additional criteria:
	
	- availability
	
	- scalability
	
	- maintainability
	
	- time to market},
  timestamp = {2008.04.17}
}

@ARTICLE{Ohst2003,
  author = {Ohst, Dirk and Welle, Michael and Kelter, Udo},
  title = {Differences between versions of UML diagrams},
  journal = {SIGSOFT Softw. Eng. Notes},
  year = {2003},
  volume = {28},
  pages = {227--236},
  month = {September},
  acmid = {940102},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/949952.940102},
  file = {:/literature/changeIdentification/p227-ohst.pdf:PDF},
  issn = {0163-5948},
  issue = {5},
  keywords = {Read, UML diagrams, configuration, design transaction, differences,
	fine-grained data model, software engineering environments, versions},
  numpages = {10},
  owner = {Steffen},
  publisher = {ACM},
  review = {changes
	
	
	model is treated as a graph
	
	
	+interanode differences (differences within node of the graph, for
	example, the name of a state in
	
	a state chart might change, or an additional attribute
	
	could be added/deleted from a class)
	
	
	+differences in structure of a graph.Nodes are 
	
	+shifted
	
	+structural shift
	
	+internode shift
	
	+position shift
	
	+created
	
	+removed},
  timestamp = {2012.03.01},
  url = {http://doi.acm.org/10.1145/949952.940102}
}

@INPROCEEDINGS{Oktaba2006,
  author = {Oktaba, H.},
  title = {3.2 MoProSoft{\textregistered}: A Software Process Model for Small
	Enterprises},
  booktitle = {International Research Workshop for Process Improvement in Small
	Settings},
  year = {2006},
  pages = {93},
  file = {:literature/Blowers2005.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@INPROCEEDINGS{Olaf2005,
  author = {Olaf Zimmermann, Niklas Schlimm, Günter Waller, Marc Pestel},
  title = {Analysis and Design Techniques for Service-Oriented Development and
	Integration},
  booktitle = {INFORMATIK 2005 — Informatik LIVE! Band 2, Beiträge der 35. Jahrestagung
	der Gesellschaft für Informatik e.V. (GI)},
  year = {2005},
  abstract = {Service-Oriented Architectures (SOAs) have been established as an
	IT strategy to support the on demand goal of business agility. Web
	services standards and their implementations are key enablement technologies
	for SOA which are maturing rapidly. There is a growing body of successful
	implementations of these technologies. However, experience of solving
	the wider business and architectural issues involved in designing
	a high-quality SOA for a particular enterprise still stands at an
	early stage. In this paper, we motivate the need for service modeling
	methodologies as means of tackling the external design of a business-focused
	SOA, identify some of the available candidate assets, and discuss
	how existing artefacts such as UML analysis diagrams can be leveraged
	for service modeling.},
  file = {:./literature/INF05-ServiceModelingv11.pdf:PDF},
  keywords = {analysis, design, service-oriented development, integration, SOA},
  owner = {Stephan},
  timestamp = {2008.04.10},
  url = {http://www.perspectivesonwebservices.de/download/INF05-ServiceModelingv11.pdf}
}

@INPROCEEDINGS{Oliveto2010,
  author = {Oliveto, Rocco and Gethers, Malcom and Poshyvanyk, Denys and De Lucia,
	Andrea},
  title = {On the Equivalence of Information Retrieval Methods for Automated
	Traceability Link Recovery},
  booktitle = {Proceedings of the IEEE 18th International Conference on Program
	Comprehension (ICPC 2010)},
  year = {2010},
  pages = {68-71},
  address = {Braga, Minho},
  month = {June},
  file = {:./literature/Paper_268.pdf:PDF},
  owner = {Steffen},
  timestamp = {2013.10.22}
}

@INPROCEEDINGS{Olsson2002,
  author = {Thomas Olsson and John Grundy},
  title = {Supporting Traceability and Inconsistency Management between Software
	Artifacts},
  booktitle = {Proceedings of the IASTED International Conference on Software Engineering
	and Applications},
  year = {2002},
  pages = {63-78},
  __markedentry = {[Steffen:]},
  abstract = {Software artefacts at different levels of abstraction are closely
	inter-related. Developers require support for managing these inter-relationships
	as artefacts evolve during development. We describe a conceptual
	architecture and prototype for supporting traceability and inconsistency
	management between software requirements descriptions, UML-style
	use case models and black-box test plans. Key information models
	are extracted from each of these different kinds of software artefacts
	and elements in different models are implicitly or explicitly linked.
	Changes to one software artefact are detected and propagated to related
	artefacts in different information models and inform developers of
	change impacts.},
  file = {:./literature/Olsson2002.pdf:PDF},
  keywords = {traceability, inconsistency management, requirements encoding, use
	case models, test plans},
  owner = {Stephan},
  timestamp = {2009.01.26}
}

@PHDTHESIS{Omerovic2011,
  author = {Omerovic, Aida},
  title = {PREDIQT: A Method for Model-based Prediction of Impacts of Architectural
	Design Changes on System Quality},
  school = {Faculty of Mathematics and Natural Sciences at the University of
	Oslo},
  year = {2011},
  month = {August},
  file = {:./literature/PhD_8.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.30}
}

@STANDARD{OMG2011,
  title = {Requirements Interchange Format (ReqIF)},
  organization = {OMG},
  author = {OMG},
  revision = {1.0.1},
  month = {April},
  year = {2011},
  url = {http://www.omg.org/spec/ReqIF/1.0.1},
  file = {OMG2011 - ReqIF.pdf:literature/OMG2011 - ReqIF.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.04.13}
}

@STANDARD{OMG2008,
  title = {Software \& Systems Process Engineering Metamodel (SPEM)},
  organization = {OMG},
  author = {OMG},
  revision = {2.0},
  month = {April},
  year = {2008},
  file = {OMG2008 - SPEM.pdf:literature/OMG2008 - SPEM.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.04.13}
}

@ARTICLE{Onoma1998,
  author = {Akira Onoma and Wei Tsai and Mustafa Poonawala and Hiroshi Suganuma},
  title = {Regression testing in an industrial environment},
  journal = {Communications of ACM},
  year = {1998},
  volume = {41},
  pages = {81--86},
  number = {5},
  abstract = {An abstract is not available.},
  file = {:/literature/RegressionTesting/Regression Testing in an Industrial Enviornment.pdf:PDF},
  issn = {0001-0782},
  keywords = {industrial perspective important},
  owner = {Annie},
  timestamp = {2011.01.04},
  url = {http://dx.doi.org/10.1145/274946.274960}
}

@INPROCEEDINGS{Orso2003,
  author = {Orso, Alessandro and Apiwattanapong, Taweesup and Harrold, Mary Jean},
  title = {Leveraging Field Data for Impact Analysis and Regression Testing},
  booktitle = {Proceedings of the 9th European software engineering conference held
	jointly with 11th ACM SIGSOFT international symposium on Foundations
	of software engineering (ESEC/FSE'03)},
  year = {2003},
  pages = {128-137},
  address = {Helsinki, Finland},
  file = {:./literature/Paper_42.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- program testing and analysis under development conditions not realistic
	
	- real world factors (different hardware, different users "DAU", etc.)
	have a big influence
	
	
	Research Questions:
	
	- how to gather "field data" (from real users, real world conditions
	etc.) to evaluate software and perform IA
	
	
	Contribution:
	
	- investigate the use of "Gamma"-approach to support IA and regression
	testing
	
	
	Solution:
	
	- developer instruments program to collect dynamic data (i.e. execution
	data) in a lightweight manner
	
	- users execute program and send back execution data (coverage data
	at block & method levels)
	
	- compute dynamic slice based on execution data of entities that traverse
	a changed (or to be changed) entity
	
	- one can estimated the impact of a change on users (from their data),
	stating "how many % of the users will be impacted by a change"
	
	-> granularity of entities: methods
	
	-> granularity of changes: changed methods
	
	-> granularity of results: methods
	
	
	Open Issues:
	
	- own IA approach relies on approximation of static slicing, therefore
	larger impacts sets than required are computed},
  timestamp = {2011.02.04}
}

@INPROCEEDINGS{Orso2004b,
  author = {Orso, Alessandro and Apiwattanapong, Taweesup and Law, James and
	Rothermel, Gregg and Harrold, Mary Jean},
  title = {An Empirical Comparison of Dynamic Impact Analysis Algorithms},
  booktitle = {Proceedings of the 26th International Conference on Software Engineering
	(ICSE'04)},
  year = {2004},
  pages = {491-500},
  address = {Edinburgh, Scotland},
  file = {:./literature/Paper_30.pdf:PDF},
  journal = {Proc. of the International Conf. on Software Engineering (ICSE'04)},
  owner = {Steffen},
  review = {goal of paper:
	
	- comparison of path impact and coverage impact algorithm for IA (both
	dynamic IA approaches)
	
	
	cirteria for evaluation:
	
	- precision
	
	- memory consumption
	
	- execution time},
  timestamp = {2011.02.04}
}

@ARTICLE{Orso2007,
  author = {Orso, Alessandro and Do, Hyunsook and Rothermel, Gregg and Harrold,
	Mary Jean and Rosenblum, David S.},
  title = {Using component metadata to regression test component-based software:
	Research Articles},
  journal = {Softw. Test. Verif. Reliab.},
  year = {2007},
  volume = {17},
  pages = {61--94},
  month = {June},
  acmid = {1255355},
  address = {Chichester, UK},
  doi = {10.1002/stvr.v17:2},
  file = {:/literature/RegressionTesting/using component meta data to support regression testing of component based software.pdf:PDF},
  issn = {0960-0833},
  issue = {2},
  keywords = {Read, Relevant, component metadata, component-based software, regression
	test selection, regression testing, code and component metas},
  numpages = {34},
  owner = {Annie},
  publisher = {John Wiley and Sons Ltd.},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=1255354.1255355}
}

@ARTICLE{Orso2004a,
  author = {Orso, Alessandro and Shi, Nanjuan and Harrold, Mary Jean},
  title = {Scaling regression testing to large software systems},
  journal = {SIGSOFT Softw. Eng. Notes},
  year = {2004},
  volume = {29},
  pages = {241--251},
  month = {October},
  __markedentry = {[qurat:]},
  acmid = {1029928},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1041685.1029928},
  file = {:/literature/RegressionTesting/Scaling Regression Testing to Large Software Systems.pdf:PDF},
  issn = {0163-5948},
  issue = {6},
  keywords = {Read, Relevant, regression testing, software evolution, software maintenance,
	test selection, testing,code baseds},
  numpages = {11},
  owner = {Annie},
  publisher = {ACM},
  timestamp = {2011.10.20},
  url = {http://doi.acm.org/10.1145/1041685.1029928}
}

@INPROCEEDINGS{Ortiz2006,
  author = {Guadalupe Ortiz and Juan Hernandez},
  title = {Toward UML Profiles for Web Services and their Extra-Functional Properties},
  booktitle = {International Conference on Web Services, 2006. ICWS '06},
  year = {2006},
  pages = {889-892},
  month = {September},
  abstract = {Web service technologies offer a successful way for interoperability
	among applications. Now it is important to face how to model systems
	based on service functionality and also how to add extra-functional
	properties to them. This is the reason why we propose first of all
	a versatile and simple UML profile based on the service component
	architecture specification for modeling services and, secondly, a
	new UML profile is proposed in order to model and reuse extra-functional
	properties in the named models. Besides, the property profile provides
	enough information to enable property code and description generation
	at a later stage.},
  doi = {10.1109/ICWS.2006.130},
  file = {:./literature/04032108.pdf:PDF},
  keywords = {Unified Modeling Language, Web services, software architecture, software
	reusabilityUML property profile, Unified Modeling Language, Web service
	technology, application interoperability, description generation,
	service component architecture specification, service functionality,
	service modeling},
  owner = {Stephan},
  timestamp = {2008.04.11},
  url = {http://ieeexplore.ieee.org/iel5/4031979/4031980/04032108.pdf?tp=&isnumber=&arnumber=4032108}
}

@INPROCEEDINGS{Oshana1998,
  author = {Oshana, R.},
  title = {An industrial application of Cleanroom software engineering-benefits
	through tailoring},
  booktitle = {System Sciences, 1998., Proceedings of the Thirty-First Hawaii International
	Conference on},
  year = {1998},
  volume = {6},
  pages = {122--131},
  file = {Oshana1998.pdf:literature/Oshana1998.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@ARTICLE{Oshana1998a,
  author = {Oshana, R.S.},
  title = {Tailoring cleanroom for industrial use},
  journal = {Software, IEEE},
  year = {1998},
  volume = {15},
  pages = {46--55},
  number = {6},
  file = {Oshana1998a.pdf:literature/Oshana1998a.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@INPROCEEDINGS{Ossher2000,
  author = {Harold Ossher and William Harrison and Peri Tarr},
  title = {Software engineering tools and environments: a roadmap},
  booktitle = {Proceedings of the Conference on The Future of Software Engineering,
	ICSE '00},
  year = {2000},
  pages = {261-277},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Tools and environments to aid developers in producing software have
	existed, in one form or another, since the early days of computer
	programming. They are becoming increasingly crucial as the demand
	for software increases, time-to-market decreases, and diversity and
	complexity grow beyond anything imagined a few decades ago. In this
	paper, we briefly review some of the history of tools and environments
	in software engineering, and then discuss some key challenges that
	we believe the field faces over the next decade.},
  doi = {http://doi.acm.org/10.1145/336512.336569},
  file = {:./literature/finalossher.pdf:PDF},
  isbn = {1-58113-253-0},
  keywords = {Tools, programming support environments, software engineering environments,
	process-centered software engineering environments, integration,
	separation of concerns},
  location = {Limerick, Ireland},
  owner = {Stephan},
  review = {challenges for tool support
	
	
	major challenge:
	
	- find ways to build and integrate tools so that they, or capabilities
	within them, can be easily adapted for use in new contexts
	
	
	- software and tools facilitating rapid initial development and later
	adaption and integration in new contexts
	
	
	- multidimensional separation of concerns
	
	
	sep. of. concerns a process with several activities:
	
	- identification of concerns
	
	-> up-front or in retrospect identification, tool support needed
	
	-> identification must be done consistently
	
	- encapsulation of concerns (modularization mechanisms)
	
	- integration of concerns
	
	
	further challenges:
	
	- morphogenic software 
	
	- manage hidden assumptions, dependencies, and interactions
	
	- model checking while adapting
	
	
	- tool support for non-traditional lifecycles
	
	
	interesting references:
	
	[20] Dynamically Discovering Likely Program Invariants... -- dependencies
	(-)
	
	[26] Software Architecture: Perspectives on an Emerging Discipline
	(book)
	
	[37] Aspect Oriented Programming -> Kiczales1997
	
	[39] Adaptive Plug-and-Play Components... -- Evolutionäre SW-Entwicklung
	-> Mezini1998
	
	[44] Specifying Subject-Oriented Compositions -- Integration of concerns
	
	[45] Multi-Dimensional Separation of Concerns... -> Ossher2000a},
  timestamp = {2008.04.17},
  url = {http://www.cs.ucl.ac.uk/staff/A.Finkelstein/fose/finalossher.pdf}
}

@ARTICLE{Ossher2001,
  author = {Ossher, Harold and Tarr, Peri},
  title = {Using multidimensional separation of concerns to (re)shape evolving
	software},
  journal = {Commun. ACM},
  year = {2001},
  volume = {44},
  pages = {43-50},
  number = {10},
  address = {New York, NY, USA},
  citeulike-article-id = {3878312},
  doi = {http://dx.doi.org/10.1145/383845.383856},
  file = {:./literature/001_p43-ossher.pdf:PDF},
  issn = {0001-0782},
  keywords = {decomposition, remodularization, aspect-oriented development},
  owner = {Stephan},
  publisher = {ACM},
  timestamp = {2009.03.17},
  url = {http://dx.doi.org/10.1145/383845.383856}
}

@INPROCEEDINGS{Ossher2000a,
  author = {Harold Ossher and Peri Tarr},
  title = {Multi-Dimensional Separation of Concerns and The Hyperspace Approach},
  booktitle = {Proceedings of the Symposium on Software Architectures and Component
	Technology: The State of the Art in Software Development},
  year = {2000},
  publisher = {Kluwer},
  abstract = {Separation of concerns is at the core of software engineering, and
	has been for decades. This has led to the invention of many interesting,
	and effective, modularization approaches. Yet many of the problems
	it is supposed to alleviate are still with us, including dangerous
	and expensive invasive change, and obstacles to reuse and component
	integration. A key reason is that one needs different decompositions
	according to different concerns at different times, but most languages
	and modularization approaches support only one “dominant” kind of
	modularization (e.g., by class in object-oriented languages). Once
	a system has been decomposed, extensive refactoring and reengineering
	are needed to remodularize it. 
	
	Multi-dimensional separation of concerns allows simultaneous separation
	according to multiple, arbitrary kinds (dimensions) of concerns,
	with on-demand remodularization. Concerns can overlap and interact.
	This paper discusses multi-dimensional separation of concerns in
	general, our particular approach to providing it, called hyperspaces,
	and our support for hyperspaces in Java™, called Hyper/J™.},
  citeseerurl = {http://citeseer.ist.psu.edu/ossher00multidimensional.html},
  file = {:./literature/sac2000-HyperJ.pdf:PDF},
  keywords = {Separation of concerns, software decomposition and composition, modularization,
	evolution, traceability, limited impact of change},
  owner = {Stephan},
  review = {multi-dimensional separation of concerns
	
	------------------------------------------------
	
	
	- multiple, arbitrary dimensions of concern
	
	- separation along these dimensions simultaneously
	
	- ability to handle new concerns and dimensions dynamically
	
	- overlapping and interacting concerns (not orthogonal)
	
	
	- a dimension of concern is an approach to decomposing, organizing,
	and structuring software according to concerns
	
	
	advantages:
	
	- break the "tyranny of the Dominant Decomposition"
	
	- avoid scattering and tangling
	
	- on demand remodularization (non-invasive)
	
	
	the Hyperspace approach
	
	------------------------------
	
	a unit is a syntactic construct in a language describing an artifact
	
	
	explicit identification, encapsulation, and integration of concerns
	
	
	a hyperspace is a concern space
	
	- organizes the units in the body of software to separate all concerns
	
	- describes various kinds of interrelationships among concerns
	
	- indicates how software components and systems can be built and integrated
	from the units that address these concerns
	
	
	- organized in an multi-dimensional matrix
	
	- any single concern within some dimension defines a hyperplane
	
	- uniform treatment of all kinds of concerns
	
	
	concern specifications
	
	- identify the dimensions and their concerns
	
	- specify the coordinates of each unit within the matrix
	
	
	hyperslices
	
	- sets of units that are declarative complete
	
	-> must declare everything to which they refer
	
	-> eliminates coupling between hyperslices
	
	- building blocks that can be integrated to form larger building blocks
	
	
	relations among concerns
	
	- 2 distinct classes: context-sensitive (syntax check or style check)
	and context-insensitive (overlap) relationships
	
	- "binding" relationship for integration of hyperslices (implementations
	are bound to declarations) -> named correspondence
	
	- correspondence is context-sensitive
	
	
	hypermodule
	
	- integration context for correspondence
	
	- comprises a set of hyperslices being integrated and a set of integration
	relationships
	
	- composite hyperslice
	
	- can be nested
	
	- a software system as a whole is also a hypermodule, subject to completeness
	constraints
	
	
	- "compatability" of corresponding units (if implementation unit satisfies
	a declaration) involves syntactic and semantic issues -> future work
	
	
	Hyper/J
	
	---------
	
	implementation of the hyperspace approach for Java
	
	
	developing steps
	
	- create project specification
	
	- create concern mapping
	
	- create hypermodules},
  timestamp = {2008.04.29},
  url = {http://www.st.informatik.tu-darmstadt.de/pages/seminars/aose/sac2000-HyperJ.pdf}
}

@INPROCEEDINGS{Otoya1999,
  author = {Otoya, S. and Cerpa, N.},
  title = {An experience: a small software company attempting to improve its
	process},
  booktitle = {Software Technology and Engineering Practice, 1999. STEP'99. Proceedings},
  year = {1999},
  pages = {153--160},
  file = {Otoya1999.pdf:literature/Otoya1999.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@INCOLLECTION{P.G.2010,
  author = {P.G., Sapna and Mohanty, Hrushikeshautom},
  title = {Automated Test Scenario Selection Based on Levenshtein Distance},
  booktitle = {Distributed Computing and Internet Technology},
  publisher = {Springer Berlin / Heidelberg},
  year = {2010},
  editor = {Janowski, Tomasz and Mohanty, Hrushikesha},
  volume = {5966},
  series = {Lecture Notes in Computer Science},
  pages = {255-266},
  note = {10.1007/978-3-642-11659-9_28},
  affiliation = {University of Hyderabad Hyderabad India},
  file = {:/literature/RegressionTesting/Automated Test Scenario Selection Based on Levenshtein istance.pdf:PDF},
  keywords = {new},
  owner = {Annie},
  timestamp = {2011.04.18},
  url = {http://dx.doi.org/10.1007/978-3-642-11659-9_28}
}

@INPROCEEDINGS{Pacione2004,
  author = {Pacione, Michael J. and Roper, Marc and Wood, Murray},
  title = {A Novel Software Visualisation Model to Support Software Comprehension},
  booktitle = {Proceedings of the 11th Working Conference on Reverse Engineering},
  year = {2004},
  pages = {70-79},
  file = {:./literature/Paper_37.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	
	Research Questions:
	
	
	Contribution:
	
	
	Solution:
	
	
	Open Issues:},
  timestamp = {2011.02.04}
}

@CONFERENCE{Padberg2007,
  author = {Padberg, Frank and Tichy, Walter F.},
  title = {Empirische Methodik in der Softwaretechnik im Allgemeinen und bei
	der Software-Visualisierung im Besonderen},
  booktitle = {Gesellschaft f\"ur Informatik (Ed.), Software Engineering 2007 -
	Beitr\"age zu den Workshops},
  year = {2007},
  pages = {211-222},
  file = {:./literature/gi-proc-106-025.pdf:PDF},
  owner = {elkeb},
  timestamp = {2011.11.17}
}

@INPROCEEDINGS{Paech2002,
  author = {Barbara Paech and Allen H. Dutoit and Daniel Kerkow and Antje von
	Knethen},
  title = {Functional requirements, non-functional requirements, and architecture
	should not be separated - A position paper},
  booktitle = {Proceedings of the International Workshop on Requirements Engineering:
	Foundations for Software Quality, REFSQ'02},
  year = {2002},
  abstract = {Requirements engineering approaches have for a long time mainly focused
	on functional requirements. During the last 5 years, several approaches
	dealing specifically with non-functional requirements have emerged.
	They support the elicitation, documentation, verification and validation
	of non-functional requirements: sometimes only concentrating on the
	non-functional requirements, sometimes in conjunction with functional
	requirements, and sometimes in conjunction with architecture. The
	position we put forward in this paper is that functional requirements,
	non-functional requirements, and architecture must be treated together.},
  file = {:./literature/EMPRESS_05.pdf:PDF},
  keywords = {non-functional requirements, functional requirements, architecture},
  owner = {Stephan},
  review = {functional requirements, non-functional requirements and architecture
	should not be treated seperately
	
	
	pre EMPRESS position paper},
  timestamp = {2009.07.24},
  url = {file:///Users/Stephan/Desktop/neue%20Paper%200907/EMPRESS/www.empress-itea.org/publications/EMPRESS_05.pdf}
}

@INPROCEEDINGS{Paech2004,
  author = {Paech, Barbara and Kerkow, D.},
  title = {Non-Functional Requirements Engineering - Quality is Essential},
  booktitle = {Proceedings 10th Anniversary International Workshop on Requirements
	Engineering. Foundation for Software Quality, (REFSQ '04)},
  year = {2004},
  series = {Essener Informatik Beiträge Bd. 9},
  pages = {237-250},
  organization = {Universität Duisburg-Essen},
  abstract = {The purpose of this paper is to review the state-of-the-art in the
	engineering of NFR, and to define an agenda for future NFR research.
	Therefore we define the requirements on a NFR method, compare this
	with current approaches and sketch ideas how to fill the gap between
	the current methods and our requirements. The main challenge for
	future research in our view is to improve the understanding of the
	notion quality.},
  file = {:./literature/NFRE-Quality_is_Essential.pdf:PDF},
  keywords = {non-functional requirements, quality, EMPRESS},
  owner = {Stephan},
  review = {good description of the state-of-the-art about non-functional requirements
	engineering in 2004},
  timestamp = {2009.07.24},
  url = {http://www-swe.informatik.uni-heidelberg.de/research/publications/pub/2004_REFSQ.pdf}
}

@INPROCEEDINGS{Paech2003,
  author = {Paech, Barbara and von Knethen, Antje and Doerr, Joerg and Bayer,
	J. and Kerkow, D. and Kolb, Ronny and Trendowicz, Adam and Punter,
	Teade},
  title = {An experience-based approach for integrating architecture and requirements
	engineering},
  booktitle = {Second International SofTware Requirements to Architecture Workshop,
	(STRAW '03)},
  year = {2003},
  pages = {142-149},
  abstract = {Deriving requirements and architecture in concert implies the joint
	elicitation and specification of the problem and the structure of
	the solution. In this paper we argue that such an integrated process
	should be fundamentally based on experience. We sketch an approach
	developed in the context of the EMPRESS project that shows how different
	kinds of experience-based artifacts, such as questionnaires, checklists,
	architectural patterns, and rationale, can beneficially be applied.},
  file = {:./literature/EMPRESS_19.pdf:PDF},
  keywords = {requirement, specification, experience, pattern, software architecture,
	elicitation, non-functional requirement},
  owner = {Stephan},
  review = {description of main results of EMPRESS:
	
	
	- meta-model for quality model
	
	- checklists
	
	- means and patterns},
  timestamp = {2009.07.24},
  url = {http://www.empress-itea.org/publications/EMPRESS_19.pdf}
}

@ARTICLE{Paige2011,
  author = {Paige, Richard F. and Drivalos, Nikolaos and Kolovos, Dimitrios S.
	and Fernandes, Kiran J. and Power, Christopher and Olsen, Goran K.
	and Zschaler, Steffen},
  title = {Rigorous Identification and Encoding of Trace-Links in Model-Driven
	Engineering},
  journal = {Software and Systems Modeling},
  year = {2011},
  volume = {10},
  pages = {469-487},
  number = {4},
  file = {:./literature/Paper_228.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.05.10}
}

@INPROCEEDINGS{Paige2008,
  author = {Paige, Richard F. and Olsen, G\oran K. and Kolovos, Dimitrios S.
	and Zschaler, Steffen and Power, Christopher},
  title = {Building Model-Driven Engineering Traceability Classifications},
  booktitle = {Proceedings of the ECMDA Traceability Workshop},
  year = {2008},
  pages = {49-58},
  __markedentry = {[Steffen:]},
  file = {:./literature/Paper_227.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.05.09}
}

@ARTICLE{Palisi1970,
  author = {Palisi, B.J.},
  title = {Some suggestions about the transitory-permanence dimension of organizations},
  journal = {British Journal of Sociology},
  year = {1970},
  pages = {200--206},
  owner = {patrickr},
  publisher = {JSTOR},
  timestamp = {2012.10.19}
}

@BOOK{Pallmer2012,
  title = {Ein Prozessmodell zur Qualit{\"a}tsverbesserung der Brandschutzplanung
	im Lebenszyklus einer Immobilie},
  publisher = {Technische Universit{\"a}t Darmstadt, Institut f{\"u}r Baubetrieb},
  year = {2012},
  author = {Leif Pallmer},
  volume = {D 59},
  series = {Schriftenreihe des Instituts f{\"u}r Baubetrieb},
  address = {Darmstadt, Deutschland},
  month = {Januar},
  note = {Darmstadt, TU, Diss., 2011},
  abstract = {Konsequente und lebenszyklusorientierte Planungsl{\"o}sungen im Brandschutz
	k{\"o}nnen, wenn sie rechtzeitig in die Planung eingebracht werden,
	f{\"u}r den Bauherrn Termin- und Betriebssicherheit steigern, die
	Nutzungsflexibilit{\"a}t erh{\"o}hen und gleichzeitig Investitionskosten
	senken. In praxi ist jedoch festzustellen, dass in der Planungsphase
	trotz vorhandener Kontrollinstrumente eine Vielzahl von M{\"a}ngeln
	entstehen und auf die Folgephasen wirken sowie Wertsch{\"o}pfungspotentiale
	hinsichtlich der Betrachtung des Lebenszyklus einer Immobilie in
	aller Regel unausgesch{\"o}pft bleiben.
	
	Als Beitrag zur lebenszyklus{\"u}bergreifenden Qualit{\"a}tsverbesserung
	von Hochbauimmobilien formuliert die vorliegende Arbeit ein ganzheitlich
	ausgerichtetes Prozessmodell f{\"u}r die Brandschutzplanung. In das
	Prozessmodell flie{\ss}en Erkenntnisse aus durchgef{\"u}hrten umfangreichen
	empirischen Studien mit theoriegeleiteten Ergebnissen ein.
	
	Zun{\"a}chst werden die allgemeinen Anforderungen an die Brandschutzplanung
	sowie die interdisziplin{\"a}ren und integralen Schnittstellen im
	Prozesssystem durch eine empirische Untersuchung erfasst und einer
	Schwachstellenanalyse unterzogen. Aus den gewonnenen Erkenntnissen
	werden diverse Ans{\"a}tze zur Verbesserung der Prozessqualit{\"a}t
	abgeleitet und in das im Zuge der Untersuchung aufgestellte Prozessmodell
	implementiert. Das Prozessmodell ist hierarchisch aufgebaut und beschreibt
	den Brandschutzplanungsprozess detailliert bis hin zur Leistungsphase
	7 der HOAI. Schwerpunkte sind hierbei unter anderem die deutliche
	Ausweitung des Leistungsbildes f{\"u}r Planungsleistungen, die Integration
	und Sch{\"a}rfung einer brandschutzorientieren Bedarfsplanung oder
	die Integration der Anforderungen des Betriebes durch zielgenaue
	Einbindung von Know-how-Tr{\"a}gern der Objektphase.
	
	Erstmals wird in Deutschland der vollst{\"a}ndige Brandschutzplanungsprozess
	aus Sicht der Projektabwicklung in Form einer detaillierten Prozesskette
	aufgestellt und in ein Handlungsmodell mit konkretem Ma{\ss}nahmenkatalog
	und zahlreichen Unterst{\"u}tzungswerkzeugen {\"u}berf{\"u}hrt. Durch
	deren Anwendung erfahren Planung, Steuerung und Qualit{\"a}tssicherung
	des Brandschutzes in der Planungsphase unter Ber{\"u}cksichtigung
	einer integralen Planungsabsicht in Effektivit{\"a}t und Effizienz
	eine deutliche Verbesserung.},
  file = {Pallmer2012.pdf:literature/Pallmer2012.pdf:PDF},
  keywords = {Bauprojekt, Bauprozesssteuerung, Baubetrieb, Projektmanagement, Designmanagement,
	Brandschutz, Brandschutzplanung, Lebenszyklusansatz, Prozessoptimierung,
	Vorgehensmodell},
  owner = {patrickr},
  timestamp = {2012.10.05},
  url = {http://tuprints.ulb.tu-darmstadt.de/2987/}
}

@ARTICLE{Papazoglou2007a,
  author = {Mike P. Papazoglou and Willem-Jan van den Heuvel},
  title = {Service oriented architectures: approaches, technologies and research
	issues},
  journal = {The VLDB Journal},
  year = {2007},
  volume = {16},
  pages = {389-415},
  number = {3},
  month = {July},
  abstract = {Service-oriented architectures (SOA) is an emerging approach that
	addresses the requirements of loosely coupled, standards-based, and
	protocol- independent distributed computing. Typically business operations
	running in an SOA comprise a number of invocations of these different
	components, often in an event-driven or asynchronous fashion that
	reflects the underlying business process needs. To build an SOA a
	highly distributable communications and integration backbone is required.
	This functionality is provided by the Enterprise Service Bus (ESB)
	that is an integration platform that utilizes Web services standards
	to support a wide variety of communications patterns over multiple
	transport protocols and deliver value-added capabilities for SOA
	applications. This paper reviews technologies and approaches that
	unify the principles and concepts of SOA with those of event-based
	programing. The paper also focuses on the ESB and describes a range
	of functions that are designed to offer a manageable, standards-based
	SOA backbone that extends middleware functionality throughout by
	connecting heterogeneous components and systems and offers integration
	services. Finally, the paper proposes an approach to extend the conventional
	SOA to cater for essential ESB requirements that include capabilities
	such as service orchestration, “intelligent” routing, provisioning,
	integrity and security of message as well as service management.
	The layers in this extended SOA, in short xSOA, are used to classify
	research issues and current research activities.},
  address = {Secaucus, NJ, USA},
  doi = {http://dx.doi.org/10.1007/s00778-007-0044-3},
  file = {:./literature/SOA-ApproachesTechnologiesResearchIssues.pdf:PDF},
  issn = {1066-8888},
  keywords = {Service oriented architecture, Asynchronous and event-driven processing,
	Application and service integration, Enterprise bus, Web services},
  owner = {Stephan},
  publisher = {Springer-Verlag New York, Inc.},
  review = {paper is a review of technologies and approaches for SOA, focusses
	on key capabilities of an ESB, describes xSOA
	
	
	service roles:
	
	---------------
	
	service provider: determine architectural decisions and design
	
	service requester is esposed to the complexity of discovering, exploring,
	negotiating and reserving services
	
	
	service aggregator: acts as application services provider and as service
	requester
	
	
	service broker: groups required services, trusted party
	
	- broker-sanctioned providers are guaranteed to offer services that
	are in compliance with local regulations and create a more trusted
	relationship
	
	- a service registry (UDDI operator) is a specialized instance of
	a service broker
	
	
	enterprise service bus (ESB):
	
	-----------------------------------
	
	
	2 options to overcome technology and information model mismatches
	
	- build the client model to exactly conform to the characteristics
	of every server module
	
	- insert a layer of communication
	
	
	first approach:
	
	- point-to-point topology
	
	- tighter coupling
	
	- not scalable, very complex
	
	
	second approach: (ESB)
	
	- integration layer
	
	- loose coupling
	
	- break up integration logic into distinct easily manageable pieces
	
	
	4 primary aspects to be addressed:
	
	- service enablement
	
	- service orchestration
	
	- deployment
	
	- management
	
	
	ESB:
	
	- open, standards-based message bus
	
	- implementation backbone for an SOA
	
	- broker functionality
	
	- provides integration services: connectivity, routing messages, data
	transformation
	
	
	in brokered SOA:
	
	- only dependency between provider and client of service is the service
	contract (WSDL description)
	
	- for lightweight arrangement server and client need to be fully decoupled
	(not just loosly coupled) -> no contract, only relationship is indirect
	through ESB
	
	
	key capabilities:
	
	- leveraging existing assets (integrate legacy software)
	
	- service communication (protocol transformation)
	
	- dynamic connectivity
	
	- topic/content-based routing (grouping messages according topics/
	subscription on constraints of actual properties of business events)
	-> WS-Notification
	
	- endpoint discovery with multiple quality of service (select best
	endpoint at runtime) -> WS-PolicyFramework
	
	- integration (of a variety of systems not directly supporting service-style
	interactions)
	
	- transformation (of messages and data formats)
	
	- reliable messaging (asynchronus store-and-forward delivery, guaranteed
	delivery)
	
	- security (point-to-point (SSL), end-to-end (en-/decryption of XML
	content)) -> WS-Security
	
	- long running process and transaction (provide certain transactional
	guarantees)
	
	- management and monitoring (dynamic load balancing, fail-over; monitor
	health, capacity, performance)
	
	- scalability
	
	
	technical requirements:
	
	- integration of presentation-tier -> portlets (JSR 168), Web Service
	for Remote Portals (WSRP)
	
	- application connectivity -> JCA
	
	- application integration
	
	- process integration
	
	- data integration
	
	
	ESB fuse four types of technologies:
	
	- integration brokers
	
	- application servers
	
	- business process management
	
	- adapters (to bridge interoperability, to provide connectivity, semantic
	disambiguation and translation services)
	
	
	Extended SOA (xSOA):
	
	-----------------------------
	
	- service foundation (ESB capabilities such as routing, translation,
	discovery)
	
	- service composition (-> BPEL, WS-Choreography)
	
	- service management and monitoring
	
	
	--> see Papazoglou2007},
  timestamp = {2008.05.05}
}

@ARTICLE{Papazoglou2006,
  author = {Michael P. Papazoglou and Willem-Jan van den Heuvel},
  title = {Service-oriented design and development methodology},
  journal = {International Journal of Web Engineering and Technology},
  year = {2006},
  volume = {2},
  pages = {412-442},
  number = {4},
  abstract = {Service Oriented Architectures (SOA) are rapidly emerging as the premier
	integration and architectural approach in contemporary, complex,
	heterogeneous computing environments. SOA is not simply about deploying
	software: it also requires that organisations evaluate their business
	models, come up with service-oriented analysis and design techniques,
	deployment and support plans, and carefully evaluate partner/customer/supplier
	relationships. Since SOA is based on open standards and is frequently
	realised using Web Services (WS), developing meaningful WS and business
	process specifications is an important requirement for SOA applications
	that leverage WS. Designers and developers cannot be expected to
	oversee a complex service-oriented development project without relying
	on a sound design and development methodology. This paper provides
	an overview of the methods and techniques used in service-oriented
	design and development. The aim of this paper is to examine a service
	development methodology from the point of view of both service producers
	and requesters and review the range of elements in this methodology
	that are available to them.},
  doi = {10.1504/IJWET.2006.010423},
  file = {:./literature/papazogloump-2006-88.pdf:PDF},
  keywords = {ervice oriented computing, service oriented architectures, SOA, business
	processes, web services, design methodologies, development methodologies,
	service development, life cycle development, choreography, service
	integration, service interoperability},
  owner = {Stephan},
  review = {presents a service-based development methodology
	
	
	service-oriented design and development
	
	- identify services
	
	- organize services in a manageable hierarchy of composite services
	
	- choreograph services together to support business processes
	
	
	subdivision of business domain
	
	*************************
	
	-> business processes -> business services -> infrastructure services
	-> component-based service realizations (-> operational systems)
	
	infrastructure services: integration through rooting, protocol mediation,
	transformation, maintenance -> often ESB
	
	important: level of granularity
	
	
	development life cycle:
	
	******************
	
	iterative and incremental
	
	planning -> analysis & design -> construction & testing -> provisioning
	-> deployment -> execution & monitoring -> analysis & design ...
	
	
	planning:
	
	-----------
	
	- feasibility study
	
	- analyse goals, rules
	
	- conceptualize requirements
	
	- review the current technology landscape
	
	- similar to RUP
	
	
	analysis:
	
	----------
	
	- business case analysis
	
	- consider implementation alternatives
	
	- as-is model
	
	- to-be model
	
	4 main activities: process identification, process scoping, business
	gap analysis, process realization
	
	
	identification:
	
	- understand business process
	
	- analyse application functionality
	
	- develop logical model
	
	- apply principles coupling and cohesion
	
	
	scoping:
	
	- unbundling functionality into separate (sub-) business processes
	
	- scope: aggregation of aspects including process start and end, process
	users, inputs, outputs
	
	
	business gap analysis:
	
	- incrementally adding mor implementation details to an abstract service
	
	- gap analysis strategy developed resulting in recommendation for
	development work, reuse or purchase of web services
	
	
	realization:
	
	- 4 option: green-field development, top-down development, bottom-up
	development, meet-in-the-middle development
	
	- combination possible
	
	- service development solutions need to target specific focal points
	of the enterprise
	
	- use of reference models
	
	- separation of specification from implementation
	
	- examine the diversity of realization alternatives
	
	- use of quality metrics to determine quality
	
	- result: business architecture
	
	
	design:
	
	---------
	
	- identify services
	
	- transformation of conceptual processes and services into set of
	related platform-agnostic interfaces
	
	- twin-track development: 1) produce services 2) assemble (compose)
	services
	
	
	concerns:
	
	- granularity
	
	- reusability -> design services more generic, abstract from differences
	
	- composability
	
	
	specification of services:
	
	1) structural specification
	
	2) behavioural specification
	
	
	steps for 1&2:
	
	- describe service interfaces
	
	- specify operation parameters
	
	- design messaging and transport protocol
	
	- fuse port types (see WSDL), bindings and actual location (a URI)
	
	
	3) policy specification -> policies for security, authorization
	
	
	specification of business processes:
	
	1) derive process structure
	
	- identify, group and describe activities that together implement
	a business process
	
	- describe activity dependencies, conditions or synchronisation (implicit/explicit
	dependencies)
	
	- describe the implementation of the business process -> BPEL
	
	
	2) link it to business roles
	
	- identify responsibilities and the roles performing them
	
	
	3) specify non-functional characteristics
	
	- Service Level Agreements
	
	
	construction & testing:
	
	---------------------------
	
	- coding WS -> creating new or transfoming existing applications
	
	- tests -> dynamic testing
	
	
	provisioning:
	
	----------------
	
	- service metering, service rating, service billing
	
	- service governance (central or distributed) -> does service conform
	to privacy rules, does not comprise intellectual property
	
	- service certification
	
	
	deployment:
	
	--------------
	
	- according to realization option
	
	
	execution & monitoring:
	
	-----------------------------
	
	- binding, run-time invocation
	
	- monitoring the life cycle
	
	
	design and development principles:
	
	****************************
	
	
	key principles: coupling and cohesion
	
	
	service coupling:
	
	- degree of interdependenc between two business processes
	
	- should be minimised -> reducing number of connections between services
	
	- low coupling indicates well-partitioned system
	
	3 dimension: representational coupling, identity coupling, communication
	protocol coupling
	
	
	service cohesion:
	
	- degree of the strength of functional relatedness of operations within
	a service
	
	- should be increased
	
	guidelines:
	
	- functional service cohesion: only one problem-related task, operations
	must be highly related
	
	- communicational service cohesion: process cleanly decoupled from
	other processes (their activities are hardly related to other processes'
	activities)
	
	- logical service cohesion: all services of a process contribute to
	tasks fo the same general category
	
	
	granularity:
	
	- refers to scope of functionality exposed by a service
	
	- aspire coarse-grained services that are structured to meet specific
	business needs
	
	- larger granularities are compositions of smaller grained components
	
	- fine-grained messages increase network traffic},
  timestamp = {2008.04.02}
}

@INPROCEEDINGS{Parnas1994,
  author = {Parnas, D.L.},
  title = {Software Aging},
  booktitle = {Proceedings 16th International Conference on Software Engineering,
	(ICSE '94)},
  year = {1994},
  pages = {279-287},
  month = {may.},
  publisher = {IEEE},
  abstract = {Programs, like people, get old. We can't prevent aging, but we can
	understand its causes, take steps to limits its effects, temporarily
	reverse some of the damage it has caused, and prepare for the day
	when the software is no longer viable. A sign that the software engineering
	profession has matured will be that we lose our preoccupation with
	the first release and focus on the long-term health of our products.
	Researchers and practitioners must change their perception of the
	problems of software development. Only then will software engineering
	deserve to be called engineering.},
  doi = {10.1109/ICSE.1994.296790},
  file = {:./literature/Parnas1994.pdf:PDF},
  issn = {0270-5257},
  keywords = {long term product health;product release;professional maturity;software
	aging;software development problems;software engineering profession;software
	viability;professional aspects;software engineering;},
  owner = {Stephan},
  timestamp = {2010.09.30}
}

@ARTICLE{Parnas1972,
  author = {Parnas, D.L.},
  title = {On the criteria to be used in decomposing systems into modules},
  journal = {Commun. ACM},
  year = {1972},
  volume = {15},
  pages = {1053-1058},
  number = {12},
  abstract = {This paper discusses modularization as a mechanism for improving the
	flexibility and comprehensibility of a system while allowing the
	shortening of its development time. The effectiveness of a "modularization"
	is dependent upon the criteria used in dividing the system into modules.
	A system design problem is presented and both a conventional and
	unconventional decomposition are described. It is shown that the
	unconventional decompositions have distinct advantages for the goals
	outlined. The criteria used in arriving at the decompositions are
	discussed. The unconventional decomposition, if implemented with
	the conventional assumption that a module consists of one or more
	subroutines, will be less efficient in most cases. An alternative
	approach to implementation which does not have this effect is sketched.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/361598.361623},
  file = {:./literature/parnas1972criteria.pdf:PDF},
  issn = {0001-0782},
  keywords = {KWIC index, modularity, modules, software, software design, software
	engineering},
  owner = {Matthias},
  publisher = {ACM Press},
  timestamp = {2008.07.16}
}

@INPROCEEDINGS{Paul2001,
  author = {Paul, Ray and Yu, Lian and Tsai, Wei-Tek and Bai, Xiaoying},
  title = {Scenario-Based Functional Regression Testing},
  booktitle = {Proceedings of the 25th International Computer Software and Applications
	Conference on Invigorating Software Development},
  year = {2001},
  series = {COMPSAC '01},
  pages = {496--},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[qurat:]},
  acmid = {675391},
  file = {:/literature/RegressionTesting/scenerio based functional regression testing.pdf:PDF},
  isbn = {0-7695-1372-7},
  keywords = {Read, Relevant, test scenario based approachs},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=645983.675391}
}

@ARTICLE{Pedreira2007,
  author = {Pedreira, O. and Piattini, M. and Luaces, M.R. and Brisaboa, N.R.},
  title = {A systematic review of software process tailoring},
  journal = {ACM SIGSOFT Software Engineering Notes},
  year = {2007},
  volume = {32},
  pages = {1--6},
  number = {3},
  file = {Pedreira2007.pdf:literature/Pedreira2007.pdf:PDF},
  owner = {patrickr},
  publisher = {ACM},
  review = {Problem / Goal
	
	* Identify approaches, methodologies, tools for process tailoring
	
	* Analyze process tailoring experiences in case-study reports
	
	
	Research Question
	
	* What are the main existing approaches, methods, and tools for software
	process tailoring? 
	
	* What are the better-known tailoring guidelines for soft-ware process
	tailoring and standard compliance? 
	
	* Are there any real case studies of software process tailor-ing available?
	
	
	Contribution
	
	* Organize software process tailoring mechanisms by following criteria
	
	** level where it takes place: oragnizational/company level (65%),
	project level (35%)
	
	** degree of formalization of tailoring method: formal (67 %), informal
	(33)
	
	** case studies -> experiences in real (c.f. PT types)
	
	** company size: large (20%), small (80%)
	
	
	Solution
	
	* 
	
	
	Open Issues
	
	*},
  timestamp = {2012.07.20}
}

@INPROCEEDINGS{Perez2005,
  author = {Perez, J. and Ali, Nour and Carsí, Jose Ángel and Ramos, I.},
  title = {Dynamic Evolution in Aspect-Oriented Architectural Models},
  booktitle = {Software Architecture: Proceedings 2nd European Workshop on Software
	Architecture (EWSA 2005)},
  year = {2005},
  volume = {3527},
  series = {LNCS},
  pages = {59-76},
  month = {Jun},
  publisher = {Springer},
  abstract = {This paper presents a solution to the evolution problem of software
	architectures. This solution is provided by PRISMA. PRISMA is an
	architecture modeling approach that integrates the advantages of
	Component-Based Software Development (CBSD) and Aspect-Oriented Software
	Development (AOSD). This integration is reflected in its model and
	in its Architecture Description Language (ADL). In this paper, PRISMA
	is presented as a framework to evolve aspect-oriented and component-based
	architectures by requirements-driven evolution. The evolution is
	supported by means of a meta-level and the reflexive properties of
	PRISMA ADL which have been implemented as a middleware. In addition,
	it is demonstrated how the evolution services of the PRISMA meta-level
	permit the run-time evolution of software architectures using an
	industrial case study, the TeachMover Robot.},
  doi = {10.1007/11494713_5},
  file = {:./literature/Perez2005.pdf:PDF},
  keywords = {evolution, aspect-oriented development, architectural model},
  owner = {Stephan},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Perez2003,
  author = {Perez, J. and Ramos, I. and Jaen, J. and Letelier, P. and Navarro,
	E.},
  title = {PRISMA: towards quality, aspect oriented and dynamic software architectures},
  booktitle = {Proceedings Third International Conference on Quality Software, 2003},
  year = {2003},
  pages = {59-66},
  month = {Nov.},
  publisher = {IEEE Computer Society},
  abstract = {The development of software systems must be done using platforms that
	allow the description of quality, complex, distributed, dynamic and
	reusable architectural models. We present in this paper PRISMA, an
	architectural modelling approach based on aspects and components
	that uses a component definition language (components, connectors
	and systems) to define architectural types at a high abstraction
	level and a configuration language to design the architecture of
	software systems. The component definition language increases reuse
	allowing importation of COTS and reduces complexity by integrating
	two modern software development approaches: component-based software
	development and aspect-oriented software development. The configuration
	language designs the architecture of software systems by creating
	and interconnecting instances of the defined types including possible
	imported COTS. PRISMA has a metalevel with reflexive properties for
	these two languages. For this reason, the types of PRISMA may evolve
	and the topologies of PRISMA may be reconfigured dynamically.},
  doi = {10.1109/QSIC.2003.1319086},
  file = {:./literature/01319086.pdf:PDF},
  issn = { },
  keywords = { object-oriented programming, software architecture, software quality
	COTS, PRISMA topology, aspect oriented software architecture, aspect-oriented
	software development, complex software architectural model, component
	definition language, component-based software development, configuration
	language, distributed software architectural model, dynamic software
	architecture, high abstraction level, metalevel, reusable software
	architectural model, software evolution, software quality, software
	reuse, software system architecture design},
  owner = {Stephan},
  review = {introducing an architectural modelling approach for component-based
	and aspect-oriented software development
	
	
	uses two defined languages: component definition language, configuration
	language
	
	motivation similar to MDA --> Model Compiler Techniques used to generate
	implementation code
	
	
	architectural model consists of different aspects: functional, distribution,
	coordination, quality, context-awareness, evolution
	
	
	defined main types: systems, connectors, components, in/out ports,
	in/out roles, interfaces
	
	
	QRL used for quality attributes (not NOFUN): no example :(
	
	
	description how main types (interfaces, components etc.) are modeled
	
	examples for component definition language and configuration language},
  timestamp = {2008.04.14},
  url = {http://ieeexplore.ieee.org/iel5/9215/29226/01319086.pdf?arnumber=1319086}
}

@ARTICLE{Perretti2006,
  author = {Perretti, F. and Negro, G.},
  title = {Filling empty seats: how status and organizational hierarchies affect
	exploration versus exploitation in team design.},
  journal = {Academy of Management Journal},
  year = {2006},
  volume = {49},
  pages = {759--777},
  number = {4},
  file = {Perretti2006.pdf:literature/Perretti2006.pdf:PDF},
  owner = {patrickr},
  publisher = {Academy of Management},
  timestamp = {2012.10.22}
}

@INPROCEEDINGS{Perry2006,
  author = {Perry, D.E. and Grisham, P.S.},
  title = {{Architecture and Design Intent in Component \& COTS Based Systems}},
  booktitle = {Fifth International Conference on Commercial-off-the-Shelf (COTS)-Based
	Software Systems (ICCBSS'05)},
  year = {2006},
  pages = {155-164},
  publisher = {IEEE},
  doi = {10.1109/ICCBSS.2006.6},
  file = {:./literature/Perry2006.pdf:PDF},
  isbn = {0-7695-2515-6},
  owner = {Sebastian},
  timestamp = {2014.03.19},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1595759}
}

@ARTICLE{Perry1992,
  author = {Dewayne E. Perry and Alexander L. Wolf},
  title = {Foundations for the Study of Software Architectures},
  journal = {ACM SIGSOFT Software Engineering Notes},
  year = {1992},
  volume = {17},
  pages = {40-52},
  number = {4},
  abstract = {The purpose of this paper is to build the foundation for software
	architecture. We first develop an intuition for software architecture
	by appealing to several well-established architectural disciplines.
	On the basis of this intuition, we present a model of software architecture
	that consists of three components: elements, form, and rationale.
	Elements are either processing, data, or connecting elements. Form
	is defined in terms of the properties of, and the relationships among,
	the elements --- that is, the constraints on the elements. The rationale
	provides the underlying basis for the architecture in terms of the
	system constraints, which most often derive from the system requirements.
	We discuss the components of the model in the context of both architectures
	and architectural styles and present an extended example to illustrate
	some important architecture and style considerations. We conclude
	by presenting some of the benefits of our approach to software architecture,
	summarizing our contributions, and relating our approach to other
	current work.},
  citeseerurl = {http://citeseer.ist.psu.edu/perry92foundation.html},
  doi = {http://doi.acm.org/10.1145/141874.141884},
  file = {:./literature/perrywolf.pdf:PDF},
  keywords = {software architecture},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://www.ics.uci.edu/~andre/ics223w2006/perrywolf.pdf}
}

@INPROCEEDINGS{Petrenko2009,
  author = {Petrenko, Maksym and Rajlich, V\'{a}clav},
  title = {Variable Granularity for Improving Precision of Impact Analysis},
  booktitle = {Proceedings of the IEEE 17th International Conference on Program
	Comprehension (ICPC '09)},
  year = {2009},
  pages = {10-19},
  address = {Vancouver, BC},
  month = {May},
  file = {:./literature/Paper_147.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- conducting IA with fixed granularity is insufficient
	
	
	Research Questions:
	
	- how can variable be used to increase precision of IA
	
	
	Contribution:
	
	- new, iterative IA process that supports variability in granularity
	to increase precision
	
	
	Solution:
	
	- software = set of components (class, method, field, etc.) + dependencies
	
	- use several marks to annotate nodes: changed, propagates, next,
	inspected, blank
	
	- if impacted element found: programmer decides if impact propagates
	at same, coarser or finer level of granularity
	
	- all children of impacted element will be marked, if the programmer
	increases granularity (e.g. from "class" to "method")
	
	- the parent element will be marked, of the programmer decreases granularity
	(e.g. from "variable" to "method")
	
	- if no granularity is sufficient, the programmer can select entire
	code fragments
	
	* encompassing component (class, method) will be marked and used for
	further impact propagation
	
	- extend JRipples tool with this variable approach (program dependency
	based)
	
	-> granularity of entities: variable, method, class, code fragments
	
	-> granularity of changes: no details given
	
	-> granularity of results: variable, method, class, code fragments
	
	
	Open Issues:
	
	- investigate how IA process can be guided by heuristics
	
	- investigate how typology of changes can guide IA
	
	- investigate influence of different types of dependencies on IA},
  timestamp = {2011.04.04}
}

@INPROCEEDINGS{Pfleeger1990,
  author = {Pfleeger, S.L. and Bohner, S.A.},
  title = {A framework for software maintenance metrics},
  booktitle = {Software Maintenance, 1990., Proceedings., Conference on},
  year = {1990},
  pages = {320 -327},
  month = {nov},
  abstract = {The authors introduce a software maintenance process model that emphasizes
	impact analysis and forms a framework for software maintenance metrics
	support. Schedule, resource, and other constraints frequently subvert
	efforts to build and maintain a software product. using direct graphs,
	the authors suggest traditional process and product metrics, as well
	as new impact analysis metrics that address software work-product
	traceability and inter-work-product dependencies. Management can
	use these and other metrics to understand and control the maintenance
	process dynamically. As changes are requested, measurements can be
	made, impact assessed, and implementation decisions made. Moreover,
	the more the impact is understood, the better the change can be controlled;
	hence risks are minimized},
  doi = {10.1109/ICSM.1990.131381},
  file = {:./literature/00131381.pdf:PDF},
  keywords = {direct graphs;impact analysis metrics;inter-work-product dependencies;software
	maintenance metrics;software maintenance process model;software work-product
	traceability;software maintenance;software metrics;},
  owner = {elkeb},
  timestamp = {2012.04.18}
}

@ARTICLE{Pfleeger2001,
  author = {Pfleeger, Shari Lawrence and Kitchenham, Barbara A.},
  title = {Principles of survey research part 1: turning lemons into lemonade},
  journal = {SIGSOFT Softw. Eng. Notes},
  year = {2001},
  volume = {26},
  pages = {16--18},
  month = {November},
  acmid = {505535},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/505532.505535},
  file = {:./literature/pfleeger2001.pdf:PDF},
  issn = {0163-5948},
  issue = {6},
  numpages = {3},
  owner = {elkeb},
  publisher = {ACM},
  timestamp = {2011.06.27},
  url = {http://doi.acm.org/10.1145/505532.505535}
}

@INBOOK{Philippow2004,
  pages = {184-199},
  title = {{I}ntegration von {F}eature {M}odellen in die evolutionäre {W}eiterentwicklung
	von {S}oftware {P}roduktlinien {A}rchitekturen},
  publisher = {Multikonferenz Wirtschaftsinformatik (MKWI), Universität Duisburg-Essen,
	Band 1},
  year = {2004},
  editor = {Adelsberger, H.H. and Eicker, S. and Krcmar, H. and Pawlowski, J.M.
	and Pohl, K. and Rombach, D. and Wulf, V.},
  author = {Philippow, Ilka and Riebisch, Matthias and Pashov, Ilian},
  month = {Mar},
  abstract = {Software-Produktlinien erfordern stabile Systemarchitekturen, die
	über mehrere Jahre an sich Veränderungen der Domäne angepasst werden
	können. Meist führen solche Anpassungen in einem zunehmenden Qualitätsverslust
	der Systemarchitektur der Produktlinie, bis diese ohne ein umfassendes
	Refactoring nicht mehr weiter verändert werden kann. Dies ist mit
	einem großen Risiko und hohen Kosten verbunden. In diesem Beitrag
	wird die Idee verfolgt, durch kleine Refactoring-Schritte eine kontinuierliche
	Anpassung der Produktlinien-Architektur an sich ändernde Anforderungen
	der Domäne vorzunehmen, wobei die Risiken verringert, ein evolutionärer
	Prozess erreicht und die Periode bis zur Notwendigkeit eines umfassenden
	Refactoring signifikant erhöht werden soll. Diese evolutionären Veränderung
	der Produktlinienarchitektur wird durch parallele Entwicklungen von
	konkreten Kundenapplikationen auf der Basis der betrachteten Produktlinie
	initiiert. Die Ziele der einzelnen Refactoring-Schritte werden dabei
	unter Nutzung von Featuremodellen bestimmt.},
  file = {:./literature/MKWI-PhilippowRiebischPashov.pdf:PDF},
  keywords = {feature models, evolutionary development, software product lines},
  language = {german},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://www.theoinf.tu-ilmenau.de/~Matthias/home/publ/MKWI-PhilippowRiebischPashov.pdf}
}

@ARTICLE{Pikkarainen2006,
  author = {Pikkarainen, M. and Salo, O.},
  title = {A practical approach for deploying agile methods},
  journal = {Extreme Programming and Agile Processes in Software Engineering},
  year = {2006},
  pages = {213--214},
  file = {Pikkarainen2006.pdf:literature/Pikkarainen2006.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@INPROCEEDINGS{Pilskalns2006,
  author = {Orest Pilskalns and Gunay Uyan and Anneliese Andrews},
  title = {Regression Testing UML Designs},
  booktitle = {Proceedings of the 22nd IEEE International Conference on Software
	Maintenance},
  year = {2006},
  pages = {254--264},
  publisher = {{IEEE} Computer Society},
  abstract = {As Model Driven Architectures {(MDAs)} gain in popularity, several
	techniques that test the {UML} models have been proposed. These techniques
	aim at early detection and correction of faults to reduce the overall
	cost of correcting them later in the software life-cycle. Recently,
	[12, 2] proposed an approach to test the {UML} design models to check
	for inconsistencies. They create an aggregate model which merges
	information from Class Diagrams, Sequence Diagrams and {OCL} statements,
	then generate test cases to identify inconsistencies. Since designs
	change often in the early stages of the software life-cycle, we need
	a regression testing approach that can be performed on the {UML}
	model. By classifying design changes, and then further classifying
	the test cases, we provide a set of rules about how to reuse part
	of the existing test cases, and generate new ones to ensure all affected
	parts of the system are tested adequately. The approach is a safe
	and efficient selective retest strategy. A case-study is reported
	to demonstrate the benefits.},
  file = {:/literature/RegressionTesting/regression testing UML designs.pdf:PDF},
  isbn = {0-7695-2354-4},
  keywords = {MDRT},
  owner = {Annie},
  timestamp = {2011.01.04},
  url = {http://portal.acm.org/citation.cfm?id=1172962.1173002&coll=GUIDE&dl=GUIDE&CFID=54491404&CFTOKEN=93053143}
}

@PHDTHESIS{Pinheiro1996a,
  author = {Francisco A. C. Pinheiro},
  title = {Design of a Hyper-Environment for Tracing Object-Oriented Requirements},
  school = {Oxford University Computing Laboratory},
  year = {1996},
  address = {Oxford, UK},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.16}
}

@ARTICLE{Pinheiro1996,
  author = {Francisco A. C. Pinheiro and Joseph Goguen},
  title = {An Object-Oriented Tool for Tracing Requirements},
  journal = {IEEE Software},
  year = {1996},
  volume = {13},
  pages = {52-66},
  number = {2},
  month = {Mar},
  abstract = {Large scale development demands tracing requirements and other objects
	in the face of continuous evolution. Requirements change in nature,
	scope, content, and form to become more consistent, accurate, complete,
	and clear. We present a tracing tool that supports evolution and
	that treats requirements and relations among them as objects.},
  doi = {10.1109/52.506462},
  file = {:./literature/506462.pdf:PDF},
  keywords = {formal specification, object-oriented programming, systems analysiscontinuous
	evolution, large scale development, object oriented tool, requirements
	tracing, tracing requirements, tracing tool},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.16}
}

@ARTICLE{Pino2008,
  author = {Pino, F.J. and Garc{\'\i}a, F. and Piattini, M.},
  title = {Software process improvement in small and medium software enterprises:
	a systematic review},
  journal = {Software Quality Journal},
  year = {2008},
  volume = {16},
  pages = {237--261},
  number = {2},
  file = {Pino2008.pdf:literature/Pino2008.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@INPROCEEDINGS{Pirklbauer2010,
  author = {Pirklbauer, Guenter and Fasching, Christian and Kurschl, Werner},
  title = {Improving Change Impact Analysis with a Tight Integrated Process
	and Tool},
  booktitle = {Proceedings of the Seventh International Conference on Information
	Technology},
  year = {2010},
  pages = {956-961},
  address = {Las Vegas, Nevada, USA},
  month = {April},
  file = {:./literature/Paper_151.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- IA requires detailed process with guidelines and solid tool support
	
	
	Research Questions:
	
	
	Contribution:
	
	- developed process and tool for IA
	
	- approach supports different visualization techniques to support
	IA
	
	
	Solution:
	
	- process consists of 6 steps:
	
	* determine SIS
	
	* calculate EIS
	
	 - use 3 parameters for determining entities:
	
	 * dependency type
	
	 * minimal importance
	
	 * maximum dependency depth
	
	* definition of final context
	
	 - analyst adds / removes entities from EIS
	
	* label changed artifacts
	
	 - add change request ID when committing to the versioning system
	
	* determine AIS
	
	 - gather entities after change implementation based on their ID-labels
	
	* quality analysis and improvement
	
	 - compare EIS with AIS
	
	-> granularity of entities: no information given
	
	-> granularity of changes: no information given
	
	-> granularity of results: no information given
	
	
	Open Issues:},
  timestamp = {2011.03.14}
}

@ARTICLE{Pitsis2003,
  author = {Pitsis, T.S. and Clegg, S.R. and Marosszeky, M. and Rura-Polley,
	T.},
  title = {Constructing the Olympic dream: a future perfect strategy of project
	management},
  journal = {Organization Science},
  year = {2003},
  volume = {14},
  pages = {574--590},
  number = {5},
  file = {Pitsis2003.pdf:literature/Pitsis2003.pdf:PDF},
  owner = {patrickr},
  publisher = {INFORMS},
  timestamp = {2012.10.19}
}

@INPROCEEDINGS{Pizka2004,
  author = {Markus Pizka and Andreas Bauer},
  title = {A Brief Top-Down and Bottom-Up Philosophy on Software Evolution},
  booktitle = {Proceedings 7th International Workshop on Principles of Software
	Evolution, (IWPSE'04)},
  year = {2004},
  pages = {131-136},
  publisher = {IEEE},
  abstract = {The decision on whether to proceed top-down or bottom-up during software
	development has a strong and underestimated impact on the quality
	of the final product including its later evolvability. Various examples
	for both strategies taken from such different domains as operating
	systems and computer games provide evidence that bottom-up developed
	systems are more suitable for future evolution. The reasons for this
	range from the increased compositionality of bottom-up developed
	artefacts at the technical level up to a greater independence from
	certain requirements which constitute the most transient part of
	a software system. Besides those advantages concerning evolvability,
	the negative effects of bottom-up orientation can not be ignored.
	Furthermore, proceeding bottom-up contradicts most conventional development
	processes. We regard this as a clear indication for the need of new
	development processes to improve the construction of evolvable software.},
  doi = {http://doi.ieeecomputersociety.org/10.1109/IWPSE.2004.1334777},
  file = {:./literature/Pizka04.pdf:PDF},
  issn = {1550-4077},
  keywords = {software maintenance, software quality, bottom-up philosophy, evolvable
	software, software development, software evolution, software quality,
	software system, top-down philosophy, software evolvability},
  owner = {Stephan},
  review = {a bottom-up (BU) approach is favoured against a top-down (TD) approach
	for software evolvability
	
	
	BU: usually for operating systems
	
	+ increased compositionality of artifacts
	
	+ increased stability of derived concepts
	
	+ greater independence of requirements
	
	+ quickly provides rudimentary running system
	
	+ decisions based on more stable technical platform (hardly influenced
	by requirements)
	
	- contradicts most development approaches
	
	- systems might fail to match requirements, users forced to adapt
	
	
	TD: usually for information systems
	
	+ more likely to match requirements
	
	- may miss technical reality
	
	- "big-bang nature", running system at the end of development
	
	- high impact of changing requirements on entire system
	
	
	evolution
	
	- generally independent from technical aspects as chosen programming
	language
	
	- but driven by changing environment
	
	- more changed requirements (55%) than technical changes (25%)
	
	
	-> BU constructed systems more evolvable (e.g. Unix-based OS)
	
	-> more BU consideration early in the development process
	
	
	(own opinion: start TD and BU -> meet-in-the-middle)},
  timestamp = {2010.02.11}
}

@UNPUBLISHED{Plaumann2012,
  author = {Sabine Plaumann},
  title = {Untersuchung von Projektmanagementwerkzeugen hinsichtlich Traceability},
  year = {2012},
  file = {:literature/Hauptseminar_Plaumann.pdf:PDF},
  owner = {elkeb},
  review = {Hauptseminarsarbeit},
  timestamp = {2012.12.07}
}

@INPROCEEDINGS{Pohl1996a,
  author = {Pohl, K.},
  title = {{PRO}-{ART}: Enabling Requirements {P}re-Traceability},
  booktitle = {Proceedings of the Second International Conference on Requirements
	Engineering, ICRE},
  year = {1996},
  pages = {76-84},
  month = {Apr},
  publisher = {IEEE Computer Society},
  abstract = {Requirements traceability is essential for developing software systems
	of high quality. Whereas the traceability of the refinement, deployment,
	and use of a requirement is called post-traceability, the traceability
	of a requirement back to its origin is named pre-traceability. We
	present a requirements engineering environment, called PRO-ART, which
	enables requirements pre-traceability, PRO-ART is based on three
	main contributions: a three-dimensional framework for requirements
	engineering which defines the kind of information to be recorded;
	a trace-repository for structuring the trace information and enabling
	selective trace retrieval; a novel tool interoperability approach
	which enables (almost) automated trace capture. In addition, we report
	on experiences made with the first prototypical implementation of
	PRO-ART and the resulting redesign and re-implementation, called
	PRO-ART 2.0, which mainly addresses scalability problems faced with
	in real applications.},
  citeseerurl = {http://citeseer.ist.psu.edu/122559.html},
  doi = {10.1109/ICRE.1996.491432},
  file = {:./literature/00491432.pdf:PDF},
  keywords = {software quality, software tools, systems analysisPRO-ART 2.0, PRO-ART
	requirements engineering environment, automated trace capture, high-quality
	software systems development, requirements pre-traceability, requirements
	traceability, scalability problems, selective trace retrieval, three-dimensional
	requirements engineering framework, tool interoperability approach,
	trace information structuring, trace-repository},
  owner = {Robert},
  timestamp = {2008.07.16}
}

@BOOK{Pohl1996b,
  title = {Process-Centered Requirements Engineering},
  publisher = {John Wiley \& Sons, Inc.},
  year = {1996},
  author = {Pohl, Klaus},
  address = {New York, NY, USA},
  abstract = {This book presents frameworks, models, and tool environments for process-centered
	requirements engineering. First, it gives a comprehensive overview
	of the state of research and practice in the field. Then, a two-pronged
	solution strategy is developed. A conceptual modelling framework
	describes the process along the three dimensions of representation
	(from informal to formal), specification completeness, and stakeholder
	agreement. From the special problems found in creative processes
	such as requirements engineering, the book derives a novel characterization
	of process-centered engineering environments and elaborates the architecture
	of a new generation of process-integrated CASE tools. The concepts
	have been validated in PRO-ART, a prototypical process-centered requirements
	engineering environment developed in the Esprit project NATURE.},
  isbn = {0863801935},
  owner = {Elke},
  timestamp = {2011.06.09},
  url = {http://portal.acm.org/citation.cfm?id=524343}
}

@BOOK{Pohl2005,
  title = {Software Product Line Engineering: Foundations, Principles, and Techniques},
  publisher = {Springer-Verlag Berlin Heidelberg},
  year = {2005},
  author = {Pohl, Klaus and Böckle, Günter and van der Linden, Frank},
  abstract = {This textbook addresses students, professionals, lecturers and researchers
	interested in software product line engineering. With more than 100
	examples and about 150 illustrations, the authors describe in detail
	the essential foundations, principles and techniques of software
	product line engineering. The authors are professionals and researchers
	who significantly influenced the software product line engineering
	paradigm and successfully applied software product line engineering
	principles in industry. They have structured this textbook around
	a comprehensive product line framework. Software product line engineering
	has proven to be the paradigm for developing a diversity of software
	products and software-intensive systems in shorter time, at lower
	cost, and with higher quality. It facilitates platform-based development
	and mass customisation. The authors elaborate on the two key principles
	behind software product line engineering: (1) the separation of software
	development in two distinct processes, domain and application engineering,
	(2) the explicit definition and management of the variability of
	the product line across all development artefacts. As a student,
	you will find a detailed description of the key processes, their
	activities and underlying techniques for defining and managing software
	product line artefacts. As a researcher or lecturer, you will find
	a comprehensive discussion of the state of the art organised around
	the comprehensive framework. As a professional, you will find guidelines
	for introducing this paradigm in your company and an overview of
	industrial experiences with software product line engineering.},
  keywords = {software engineering, software product lines},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://portal.acm.org/citation.cfm?id=1095605#}
}

@TECHREPORT{Pohl1994,
  author = {K. Pohl and R. Dömges and M. Jarke},
  title = {PRO-ART: PROcess based Approach to Requirements Traceability},
  institution = {RWTH Aachen, Germany},
  year = {1994},
  type = {NATURE Report},
  number = {94-07},
  abstract = {Requirements Traceability is crucial for the success of system development
	activities. What does it take to capture, maintain and use requirements
	information? Based on a three dimensional framework and a tool interoperability
	approach we present a requirements engineering environment (PRO-ART)
	which enables the content oriented capture of requirements information.
	The demonstration shows how 
	
	- traceability can be used during the requirements engineering process;
	
	
	- requirements information is captured during process execution by
	our tool environment; e.g., the interrelation of informal specifiations
	and semi-formal notations like SA and ER diagrams; 
	
	- changes can be propagated in the current specification using the
	trace information.},
  citeseerurl = {http://citeseer.ist.psu.edu/100083.html},
  file = {:./literature/NATURE-94-07-App1.pdf:PDF},
  keywords = {requirements traceability},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {ftp://ftp.informatik.rwth-aachen.de/pub/NATURE/NATURE-94-07-App1.ps.Z},
  volume = {HIER FEHLT NOCH WAS}
}

@INPROCEEDINGS{Popescu2010b,
  author = {Popescu, Daniel},
  title = {Impact analysis for event-based components and systems},
  booktitle = {Proceedings of the 32nd ACM/IEEE International Conference on Software
	Engineering},
  year = {2010},
  volume = {2},
  address = {New York, USA},
  file = {:./literature/Paper_70.pdf:PDF},
  owner = {Steffen},
  review = {--> early version of Popescu2010a
	
	
	Problem:
	
	- current systems consist of middleware where no source code is available
	
	- source code of middleware would render dependency graphs unusable
	due to their size
	
	- current dependency analsis cannot recover message-concept from source
	code
	
	- current IA approaches not able to determine impact on messages
	
	
	Research Questions:
	
	- reduce effort for maintenance of message based systems though specialized
	IA technique
	
	
	Contribution:
	
	- "Helios" to compute message dependency graphs
	
	- new IA approach relying on dependencies between (inter-system /
	inter-component)-message
	
	
	Solution:
	
	- utilize control- and data flow to identify incoming / outgoing message
	interfaces
	
	- distinguish between inter- and intra-component messages
	
	- each component can act as message sink / source
	
	- utilize several message types, whereas each component listens /
	produces certain messages
	
	- Helios computes interprocedural call graph for each component (ICG)
	
	- annotate ICG with message interface information
	
	-> granularity of entities: system-components
	
	-> granularity of changes: no details given
	
	-> granularity of results: system-components
	
	
	Open Issues:
	
	- current version of Helios not able to identify message sinks / sources
	(aka message interfaces) by íts own},
  timestamp = {2011.02.17}
}

@INPROCEEDINGS{Popescu2010a,
  author = {Popescu, Daniel and Garcia, Joshua and Bierhoff, Kevin and Medvidovic,
	Nenad},
  title = {Helios: Impact Analysis for Event-Based Systems},
  booktitle = {Proceedings of the 32nd International Conference on Software Engineering
	(ICSE)},
  year = {2010},
  file = {:./literature/Paper_61.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- traditional IA techniques such as dependency analysis are of little
	use in event-based systems
	
	- impacts harder to determine in event-based systems as each component
	may interact with all other components
	
	
	Research Questions:
	
	- how can messages between components used to determine impacts on
	other components
	
	
	Contribution:
	
	- new technique combining the following approaches used to compute
	a "message dependency graph":
	
	* control flow dependency analysis
	
	* state-based dependency analysis
	
	* structural analysis
	
	
	Solution:
	
	- build dependency graph from source code
	
	- consider 2 types of dependencies between components:
	
	* inter-comp.: dependencies between two components due to send/received
	message between them
	
	 * computed through considering incoming/outgoing component interfaces
	and systems overall structure
	
	 - match typed messages of sinks and sources
	
	* intra-comp.: how are outgoing messages of a component influenced
	by incoming messages to the same component
	
	 * computed through calculating a component call graph annotated with
	message types and access permission information
	
	 - analyse control flow to create dependency graph
	
	 - add nodes for each message type to the graph and link interfaces
	which call specific message types with these nodes
	
	- merge inter/intra dependencies into system message dependency graph
	
	- include state-based dependencies into the system dependency graph
	(through annotation of source code)
	
	-> granularity of entities: system-components
	
	-> granularity of changes: no details given
	
	-> granularity of results: system-components
	
	
	Open Issues:
	
	- integrate subject-based message filtering (string matching, i.e.
	each message is named by a string)
	
	- integrate content-based message filtering (filtering over the whole
	message content)},
  timestamp = {2011.02.10}
}

@BOOK{Porst2001,
  title = {Fragebogen - Ein Arbeitsbuch},
  publisher = {VS Verlag f\"ur Sozialwissenschaften, Wiesbaden},
  year = {2001},
  author = {Rolf Porst},
  owner = {elkeb},
  review = {in TU-Bibo erhältlich in verschiedenen Auflagen
	
	sehr gutes Buch},
  timestamp = {2011.11.24}
}

@BOOK{Posch2004,
  title = {Basiswissen Softwarearchitektur: Verstehen, entwerfen, wiederverwenden},
  publisher = {{dpunkt.verlag}},
  year = {2004},
  author = {Torsten Posch and Klaus Birken and Michael Gerdom},
  edition = {1},
  isbn = {3898642704},
  keywords = {software architecture, architectural design, influence factors, design
	principles, architectural documentation, architectural evaluation,
	architect's toolbox, software product line},
  owner = {Stephan},
  timestamp = {2010.12.31}
}

@ARTICLE{Poshyvanyk2009,
  author = {Poshyvanyk, Denys and Marcus, Andrian and Ferenc, Rudolf and Gyim\'{o}thy,
	Tibor},
  title = {Using information retrieval based coupling measures for impact analysis},
  journal = {Empirical Software Engineering},
  year = {2009},
  volume = {14},
  pages = {5-32},
  number = {1},
  file = {:./literature/Paper_127.pdf:PDF},
  owner = {Steffen},
  review = {[>>> Interesting: cited two papers how to conduct a case study <<<]
	
	
	Problem:
	
	- existing coupling measures are too narrow and limited (only based
	on structure)
	
	- different dimensions must be covered by a solid coupling measure
	
	
	Research Questions:
	
	- how can coupling assist with IA
	
	
	Contribution:
	
	- new set of coupling measures for OO classes
	
	- coupling measure based on IR techniques
	
	- apply coupling measure for IA
	
	- comparison of proposed coupling measure against existing measures
	
	
	Solution:
	
	- use overlappings in identifiers (names) and commonts to detect similarities
	using IR techniques
	
	* latent semantic idexing
	
	* exploit the fact that classes are related conceptually -> conceptual
	coupling
	
	* no use of word stemming, abreviation expansion, word replacement
	
	- extract comments, identifiers and structural information from source
	code
	
	- LSI creates term-by-document matrix which captures distribution
	of words in methods
	
	- represent each document as a vector in the LSI subspace
	
	- compute cosine to measure conceptual coupling between methods
	
	- use coupling measures to rank classes for IA
	
	-> granularity of entities: class, method
	
	-> granularity of changes: no details
	
	-> granularity of results: class
	
	
	Open Issues:
	
	- limited case study should be extended
	
	- only 20% precision on average, too low},
  timestamp = {2011.04.01}
}

@INPROCEEDINGS{Potts1993,
  author = {Colin Potts and Kenji Takahashi},
  title = {An active hypertext model for system requirements},
  booktitle = {IWSSD '93: Proceedings of the 7th international workshop on Software
	specification and design},
  year = {1993},
  pages = {62-68},
  address = {Los Alamitos, CA, USA},
  month = {Dec},
  publisher = {IEEE Computer Society Press},
  abstract = {We are developing tools to support a conversational metaphor for requirements
	definition and analysis. Our conversational model consists of three
	components: (1) a hypertextual representation of requirements and
	their interrelations, (2) an issue-based speech act model, and (3)
	a typology of changes. These components act together in a model we
	call the 'inquiry cycle'. We discuss requirements analysis activities
	supported by the conversational model, including information retrieval
	and navigation, rationale management, and agenda management. We have
	implemented a prototype active hypertext system, and we have applied
	our model and implementation to the requirements for an ATM banking
	system, an example we use in the paper for illustration.},
  doi = {10.1109/IWSSD.1993.315512},
  file = {:./literature/iwssd7PottsTakahashi.pdf:PDF},
  isbn = {0-8186-4360-9 (PAPER)},
  keywords = {automatic teller machines, bank data processing, hypermedia, information
	retrieval, natural language interfaces, software tools, speech, systems
	analysis ATM banking system, active hypertext model, agenda management,
	change typology, conversational metaphor, information navigation,
	information retrieval, inquiry cycle, issue-based speech act model,
	rationale management, requirements analysis, requirements definition,
	system requirements},
  location = {Redondo Beach, California},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://www.cc.gatech.edu/fac/Colin.Potts/pubs/1993/iwssd7/iwssd7PottsTakahashi.pdf}
}

@ARTICLE{Leite2000,
  author = {do Prado Leite, Julio Cesar Sampaio and Hadad, Graciela D. S. and
	Doorn, Jorge Horacio and Kaplan, Gladys N.},
  title = {A Scenario Construction Process},
  journal = {Requirements Engineering},
  year = {2000},
  volume = {5},
  pages = {38-61},
  abstract = {Scenario is a description technique that has been attracting a lot
	of attention from practitioners and from researchers. Several disciplines
	have been using scenarios for some time now, but recently the information
	system community has dedicated special attention to the possibilities
	that this description technique provides to enhance understandability
	of task-related descriptions and communicability among stakeholders.
	This paper aims its attention at a particular scenario construction
	process, but while doing so it tackles important problems regarding
	scenario management, in particular scenario organisation. Our scenarios
	are described in a structured way, using a simple conceptual model
	together with a form-oriented language. We have been using this representation
	for some time now, and our results are based on several case studies
	conducted with real-world problems.  },
  affiliation = {Pontifícia Universidade Católica do Rio de Janeiro, Rio de Janeiro,
	Brazil BR},
  doi = {10.1007/PL00010342},
  file = {:./literature/Leite2000.pdf:PDF},
  issn = {0947-3602},
  issue = {1},
  keyword = {Computer Science},
  keywords = {scenario description},
  owner = {Stephan},
  publisher = {Springer London},
  timestamp = {2010.11.15},
  url = {http://dx.doi.org/10.1007/PL00010342}
}

@ARTICLE{Prat1997,
  author = {Prat, N.},
  title = {Goal formalisation and classification for requirements engineering},
  journal = {Proceedings of Requirements Engineering: Foundation for Software
	Quality},
  year = {1997},
  owner = {patrickr},
  timestamp = {2012.12.18}
}

@INPROCEEDINGS{Preiss2001,
  author = {Otto Preiss and Alain Wegmann and Jason Wong},
  title = {On Quality Attribute Based Software Engineering},
  booktitle = {Proceedings. 27th Euromicro Conference, 2001},
  year = {2001},
  pages = {114-120},
  address = {Warsaw, Poland},
  month = {September},
  publisher = {IEEE Xplore},
  abstract = {Software components are an incarnation of architectural means to better
	cope with the variety of quality aspects of software systems. Unfortunately,
	architectural artifacts appear somewhat magically sometimes, and
	so do components. Components are not a major extension to OO in the
	programming language or functional modeling sense, but a basis to
	address many of the quality requirements, be they discernable or
	non-discernable at system runtime. CBSE, being the discipline of
	engineering with components, is a promising basis to more explicitly
	and systematically design with and for quality attributes. After
	defining the context and classifying quality attributes, we first
	illustrate the important relationship of quality attributes to use
	case realizations. Second, we argue for components as the fulcrum
	point for the realization of functional and extra-functional roles.
	Third we identify ongoing research directions that we consider conducive
	towards a software engineering process that supports the design for
	functional and extra-functional requirements},
  doi = {10.1109/EURMIC.2001.952445},
  file = {:./literature/00952445.pdf:PDF},
  keywords = {object-oriented programming, software qualityarchitectural artifacts,
	case realizations, extra-functional roles, functional roles, quality
	attribute based software engineering, software components},
  owner = {Stephan},
  timestamp = {2008.04.02}
}

@ARTICLE{Prencipe2001,
  author = {Prencipe, A. and Tell, F.},
  title = {Inter-project learning: processes and outcomes of knowledge codification
	in project-based firms},
  journal = {Research Policy},
  year = {2001},
  volume = {30},
  pages = {1373--1394},
  number = {9},
  file = {Prencipe2001.pdf:literature/Prencipe2001.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.22}
}

@ARTICLE{Pretschner:2004:MBT:1008455.1008462,
  author = {Pretschner, Alexander and L\"{o}tzbeyer, Heiko and Philipps, Jan},
  title = {Model based testing in incremental system development},
  journal = {J. Syst. Softw.},
  year = {2004},
  volume = {70},
  pages = {315--329},
  month = {March},
  acmid = {1008462},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1016/S0164-1212(03)00076-1},
  file = {:/literature/RegressionTesting/Model based testing in incremental system development.pdf:PDF},
  issn = {0164-1212},
  issue = {3},
  issue_date = {March 2004},
  keywords = {cleanroom SW engineering, constraint logic programming, extreme programming,
	incremental development, rapid prototyping, reactive systems, test
	case generation},
  numpages = {15},
  owner = {Steffen},
  publisher = {Elsevier Science Inc.},
  timestamp = {2012.03.01},
  url = {http://dx.doi.org/10.1016/S0164-1212(03)00076-1}
}

@INPROCEEDINGS{Pretschner2001,
  author = {Alexander Pretschner and Heiko Loetzbeyer and Jan Philipps},
  title = {Model Based Testing in Evolutionary Software Development},
  booktitle = {Proceedings of the 12th International Workshop on Rapid System Prototyping},
  year = {2001},
  pages = {155},
  publisher = {{IEEE} Computer Society},
  abstract = {Abstract: The spiraling nature of evolutionary software development
	processes produces executable parts of the system at the end of each
	loop. We argue that these parts should consist not only of programming
	language code, but of executable graphical system models. As a main
	benefit of the use of more abstract, yet formal, modeling languages,
	we present a method for model based test sequence generation for
	reactive systems on the grounds of Constraint Logic Programming and
	its implementation in the {CASE} tool {AutoFocus.Keywords.} Cleanroom
	{SW} Engineering, Constraint Logic Programming, Extreme Programming,
	Incremental Development, Rapid Prototyping, Reactive Systems, Test
	Case Generation.},
  file = {:/literature/RegressionTesting/Model based testing in evolutionary software development.pdf:PDF},
  owner = {Annie},
  timestamp = {2011.01.04},
  url = {http://portal.acm.org/citation.cfm?id=883730}
}

@INPROCEEDINGS{Protsyk2007,
  author = {Protsyk, Petro and Zhereb, Konstantin},
  title = {A Criteria-Based Approach to Classifying Traceability Solutions},
  booktitle = {Proceedings of IEEE International EAST-WEST DESIGN \& TEST SYMPOSIUM
	(EWDTS'07)},
  year = {2007},
  pages = {622-628},
  address = {Yerevan, Armenia},
  month = {September},
  file = {:./literature/Paper_233.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.05.10}
}

@INPROCEEDINGS{Punter2003,
  author = {Punter, T. and Ciolkowski, M. and Freimut, B. and John, I.},
  title = {Conducting on-line surveys in software engineering},
  booktitle = {International Symposium on Empirical Software Engineering, 2003.
	ISESE 2003. Proceedings.},
  year = {2003},
  pages = { 80 - 88},
  month = {sept.-1 oct.},
  abstract = {One purpose of empirical software engineering is to enable an understanding
	of factors that influence software development. Surveys are an appropriate
	empirical strategy to gather data from a large population (e.g.,
	about methods, tools, developers, companies) and to achieve an understanding
	of that population. Although surveys are quite often performed, for
	example, in social sciences and marketing research, they are underrepresented
	in empirical software engineering research, which most often uses
	controlled experiments and case studies. Consequently, also the methodological
	support how to perform such studies in software engineering is rather
	low. However, with the increasing pervasion of the Internet it is
	possible to perform surveys easily and cost-effectively over Internet
	pages (i.e., on-line), while at the same time the interest in performing
	surveys is growing. The purpose of this paper is twofold. First we
	want to arise the awareness of on-line surveys and discuss methods
	how to perform these in the context of software engineering. Second,
	we report our experience in performing on-line surveys in the form
	of lessons learned and guidelines.},
  doi = {10.1109/ISESE.2003.1237967},
  file = {:./literature/Punter2003.pdf:PDF},
  issn = { },
  keywords = { Internet; controlled experiments; empirical strategy; engineering
	research; methodological support; online surveys; software development;
	software engineering; Internet; formal specification; formal verification;
	software engineering; user modelling;},
  owner = {elkeb},
  timestamp = {2011.06.27}
}

@INPROCEEDINGS{Punter2002,
  author = {Punter, Teade and Trendowicz, Adam and Kaiser, Peter},
  title = {Evaluating Evolutionary Software Systems},
  booktitle = {Proceedings of the 4th International Conference on Product Focused
	Software Process Improvement, PROFES '02},
  year = {2002},
  number = {2559},
  series = {LNCS},
  pages = {258-272},
  address = {London, UK},
  publisher = {Springer},
  abstract = {Non-functional requirements (NFRs) of software-intensive systems that
	are under continuous evolution should be evaluated during early development
	phases in order to be able to improve those systems and achieve ‘time-to-market’.
	However, current evaluations are often done during late stages, like
	coding and testing. In this paper we propose an approach to evaluate
	NFRs earlier. The requirements for this approach are the use of flexible
	and reusable quality models, which can deal with little data, that
	are transparent and measurement-based. Our approach, called Prometheus,
	is a way of modeling NFRs that should cope with those requirements.
	Prometheus applies the quality modeling concept from the SQUID approach,
	the probability concept of Bayesian Belief Nets (BBNs) and the specification
	concepts of the Goal Question Metric (GQM) approach.},
  file = {:./literature/EMPRESS_13.pdf:PDF},
  isbn = {3-540-00234-0},
  keywords = {bayesian belief nets, evaluation of non-functional requirements},
  owner = {Stephan},
  review = {evaluation of nfr with bayesian belief nets},
  timestamp = {2009.07.24},
  url = {http://www.empress-itea.org/publications/EMPRESS_13.pdf}
}

@INPROCEEDINGS{Qu2012,
  author = {Qu, Xiao and Acharya, Mithun and Robinson, Brian},
  title = {Configuration Selection Using Code Change Impact Analysis for Regression
	Testing},
  booktitle = {Proceedings of the 28th IEEE International Conference on Software
	Maintenance},
  year = {2012},
  address = {Riva del Garda, Italy},
  month = {September},
  file = {:./literature/Paper_255.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.08.08}
}

@INPROCEEDINGS{Quartela2006,
  author = {Quartela, D. and Steen, M.W.A. and Pokraev, S. and van Sindererf,
	M.},
  title = {A conceptual framework for service modelling},
  booktitle = {10th IEEE International Enterprise Distributed Object Computing Conference,
	2006. EDOC '06},
  year = {2006},
  series = {IEEE CNF},
  pages = {319-330},
  address = {Washington, DC, USA},
  month = {Oct},
  publisher = {IEEE Computer Society},
  abstract = {This paper presents a conceptual framework for service modelling.
	This framework provides a conceptual basis for the modelling and
	reasoning about services, and the operations, such as composition
	and discovery, that are performed on them at design and run-time.
	In particular, the framework should facilitate the use of different
	service description languages tailored to different service aspects,
	such as the behaviour of a service and the information it manipulates,
	or design tasks, such as modelling, analysis and implementation.
	The idea is that models produced by these languages can be mapped
	onto a single, common conceptual framework, thereby facilitating
	one to relate these models, e.g., to verify consistency or conformance.
	Therefore, a requirement on the framework is to capture all elementary
	and generic service properties that are relevant during the service
	development process. We capture these properties by analysing existing
	service definitions and from earlier experience.},
  doi = {10.1109/EDOC.2006.5},
  file = {:./literature/04031219.pdf:PDF},
  keywords = {service modelling, SOA, service-oriented},
  owner = {Stephan},
  timestamp = {2008.04.10},
  url = {http://ieeexplore.ieee.org/iel5/4031176/4031177/04031219.pdf}
}

@INPROCEEDINGS{Queille1994,
  author = {Queille, Jean-Pierre and Voidrot, Jean-Francois and WiIde, Norman
	and Munro, Malcom},
  title = {The Impact Analysis Task in Software Maintenance: A Model and a Case
	Study},
  booktitle = {Proceedings of the International Conference on Software Maintenance},
  year = {1994},
  pages = {234-242},
  address = {Victoria, BC, Canada},
  month = {September},
  file = {:./literature/Paper_112.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- no clear separation / distinction between IA and program comprehension
	
	
	Research Questions:
	
	- what is IA
	
	- what separates IA from program understanding
	
	- what must be done to accomplish IA
	
	
	Contribution:
	
	- defintiion of IA
	
	- model for IA relying on propagation rules
	
	
	Solution:
	
	- proposed model uses static analysis to build a dependency graph
	
	- dependency graph is combined with closeness information of textual
	entities
	
	- define rules which are used to propagate changes through the graph
	
	- implemented in prototype IAS tool
	
	- IA process consists of:
	
	* identifying initial impact set
	
	* develop forest of impacts:
	
	 - identify candidate impacts
	
	 - access all candidates and analyze if change is required
	
	 - execute the change if required
	
	-> granularity of entities:
	
	-> granularity of changes:
	
	-> granularity of results:
	
	
	Open Issues:
	
	- fully develop prototype tool
	
	- user interface for IA},
  timestamp = {2011.04.01}
}

@ARTICLE{Rabade2006,
  author = {R{\'a}bade, L.A. and Alfaro, J.A.},
  title = {Buyer--supplier relationship's influence on traceability implementation
	in the vegetable industry},
  journal = {Journal of Purchasing and Supply Management},
  year = {2006},
  volume = {12},
  pages = {39--50},
  number = {1},
  file = {Rabade2006.pdf:literature/Rabade2006.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.11.15}
}

@INPROCEEDINGS{Rath2008,
  author = {R\'{a}th, Istvan and Bergmann, Gabor and Okr\"{o}s, Andras and Varr\'{o},
	Daniel},
  title = {Live Model Transformations Driven by Incremental Pattern Matching},
  booktitle = {Proceedings of the 1st international conference on Theory and Practice
	of Model Transformations},
  year = {2008},
  series = {ICMT '08},
  pages = {107-121},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  acmid = {1424875},
  doi = {http://dx.doi.org/10.1007/978-3-540-69927-9_8},
  file = {:/literature/changeIdentification/Live Model Transformations Driven by.pdf:PDF},
  isbn = {978-3-540-69926-2},
  keywords = {Read},
  location = {Zurich, Switzerland},
  numpages = {15},
  owner = {Steffen},
  timestamp = {2012.03.01},
  url = {http://dx.doi.org/10.1007/978-3-540-69927-9_8}
}

@INPROCEEDINGS{Rath2009,
  author = {R\'{a}th, Istvan and Varr\'{o}, Gergely and Varr\'{o}, Daniel},
  title = {Change-Driven Model Transformations},
  booktitle = {Proceedings of the 12th International Conference on Model Driven
	Engineering Languages and Systems},
  year = {2009},
  series = {MODELS '09},
  pages = {342-356},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  acmid = {1691355},
  doi = {http://dx.doi.org/10.1007/978-3-642-04425-0_26},
  file = {:/literature/changeIdentification/82333.pdf:PDF},
  isbn = {978-3-642-04424-3},
  keywords = {Read ,Incremental model transformation, change models, change-driven
	transformations},
  location = {Denver, CO},
  numpages = {15},
  owner = {Steffen},
  review = {Changes
	
	
	+Every model element is either a entity or relation in the mm
	
	 + creation of entity
	
	 +creation of relation
	
	
	 +deletion of entity/relation
	
	
	 +update
	
	 +setname
	
	 +set value
	
	
	 +move
	
	 moveEntity(change of containment hirerachy)
	
	 setRelationSource
	
	 setRelationTarget},
  timestamp = {2012.03.01},
  url = {http://dx.doi.org/10.1007/978-3-642-04425-0_26}
}

@MISC{Radhakrishnan2006,
  author = {Rakesh Radhakrishnan},
  title = {Synergizing Methodologies to Achieve Architecture Targets (Towards
	SOA)},
  month = {Jan},
  year = {2006},
  abstract = {Contemporary Enterprise IT Architect’s are perplexed with the different
	Tactics, Techniques and Tools – such as Architectural Framework/Methodologies
	from MDA, RUP, TOGAF, ITIL, Prince 2, etc., and Techniques – such
	as Meta Model Repository based EII, Patterns (Architecture and Design),
	Abstraction Layers, ABB/SBB, Description, Specifications, Markup,
	etc. This paper identifies a taxonomy and an organizing principle
	of these Tactics, Tools and Techniques that are so immensely useful
	for (Enterprise/Systems) Architects to do there job of building Architectures
	that are strategically maneuverable, i.e., Architectures that can
	handle changes in requirements and are inherently flexible, constantly
	adaptable and ever extensible and completely agile. Agile Architectures
	also referred to, as “Organic Architectures” by many is fundamentally
	an “Architecture” that embraces principles such as “Modifiability”,
	“Portability”, “Integrate-ability”, “Reusability”, “Replace-ability”,
	“Implement-ability” and “Extensibility”. More complex Architectural
	Qualities than the traditional Qualities such as “Security”, “Availability”,
	“Scalability”, etc. This effort is geared towards harnessing methodologies,
	tools and techniques that can leveraged effectively for building
	“Agile” Architectures.},
  file = {:./literature/smart2.pdf:PDF},
  keywords = {architecture methodologies, MDA, RUP, TOGAF, ITIL, Prince 2},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://whitepapers.silicon.com/0,39024759,60167014p,00.htm}
}

@ARTICLE{Rafla2007,
  author = {Tamer Rafla and Pierre N. Robillard and Michel Desmarais},
  title = {A method to elicit architecturally sensitive usability requirements:
	its integration into a software development process},
  journal = {Software Quality Journal},
  year = {2007},
  volume = {15},
  pages = {117-133},
  number = {2},
  month = {Jan},
  abstract = {In the Human-Computer Interaction (HCI) community, software usability
	has primarily been concerned with the presentation of information,
	more precisely with the user interface. However, some usability problems
	can prove costly to fix if the changes require modifications that
	reach beyond the presentation layer, namely those that cannot be
	easily accommodated by the software architecture. Taking into account
	some usability requirements earlier in the software development cycle,
	specifically prior to the architectural design phase, can reduce
	the cost of these modifications. There is a scarcity of methods and
	guidelines with the scope to direct users in eliciting the usability
	requirements that can impact the software architecture.
	
	This paper proposes a usability-driven adaptation of the quality attribute
	workshop (QAW) to assist software development organizations in discovering
	and documenting usability requirements. It shows how this method
	can be integrated into a software development process, by discussing
	how the existing software framework workflows can be adjusted to
	take this new activity into consideration. A preliminary exercise
	was conducted to help discern the utility and the limits of the proposed
	method. Participants with different levels of knowledge of usability
	and comprehension of the system being developed found the method
	constructive, as it guided them in identifying the architecturally
	relevant usability requirements. It also helped determine the usability
	aspects that would not necessarily have been defined if this technique
	had not been employed.},
  address = {Hingham, MA, USA},
  doi = {http://dx.doi.org/10.1007/s11219-006-9009-9},
  file = {:./literature/rafla2007.pdf:PDF},
  issn = {0963-9314},
  keywords = {Usability requirements, Software architecture, Software process, QAW},
  owner = {Stephan},
  publisher = {Kluwer Academic Publishers},
  review = {discussion about how to integrate usability aspects into the software
	development lifecycle
	
	
	introduces UQAW an adaptation of the qualtiy attribute workshop (QAW)
	of the SEI
	
	
	focussed on dealing with usability in requirements engineering phase
	
	
	only little about architecture design through connecting usabilty
	scenarios and properties with patterns (see Folmer)},
  timestamp = {2008.04.02}
}

@ARTICLE{Rajlich2000a,
  author = {Václav Rajlich},
  title = {Modeling software evolution by evolving interoperation graphs},
  journal = {Annals of Software Engineering},
  year = {2000},
  volume = {9},
  pages = {235-248},
  number = {1-4},
  abstract = {Software evolution is the process of software change, most often change
	in software requirements. This paper presents a theoretical model
	for the evolution of component&dash;based software, based on evolving
	interoperation graphs. The model assumes that each change consists
	of smaller granularity steps of change propagation, each of them
	being a visit to one specific component. If the component is modified,
	it may no longer fit with the other components because it may no
	longer properly interact with them. In that case secondary changes
	must be made in neighboring components, which may trigger additional
	changes, etc. The paper contains an example of evolution of a calendar
	program, represented in UML.},
  address = {Red Bank, NJ, USA},
  doi = {10.1023/A:1018933026438},
  file = {:./literature/RajlichASE2000Modeling.pdf:PDF},
  issn = {1022-7091},
  keywords = {modeling, software evolution, evolving interoperation graphs},
  owner = {Stephan},
  publisher = {J. C. Baltzer AG, Science Publishers},
  timestamp = {2008.06.16},
  url = {http://wwwedit.cs.wayne.edu/~vip/publications/Rajlich.ASE.2000.Modeling.pdf}
}

@INPROCEEDINGS{Rajlich1997,
  author = {Rajlich, V\'{a}clav},
  title = {A Model for Change Propagation Based on Graph Rewriting},
  booktitle = {Proceedings of the 13th International Conference on Software Maintenance
	(ICSM '97)},
  year = {1997},
  pages = {84-91},
  address = {Bari, Italy},
  month = {October},
  file = {:./literature/Paper_90.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- change propagation is one of the key parts in maintenance / evolution
	
	- ripple effect caused by "effect-chains"
	
	
	Research Questions:
	
	- gain a formal model of change propagation to achieve solid understanding
	
	
	Contribution:
	
	- model for change propagation in software maintenance / evolution
	
	- 2 processes of change propagation
	
	* change-and-fix
	
	* top-down propagation (MSE = methodology for software evolution)
	
	- prototype tool implementing the model
	
	
	Solution:
	
	- use dependency graph for IA
	
	- evolution of dependency graph modeled as sequence of snapshots
	
	- graph rewriting: replacement of one entity (node) in the graph
	
	- "change-and-fix"-process:
	
	* change the given entity
	
	* use dependency graph to propagate change
	
	* fix all affected entities (repeat this procedure until all nodes
	are valid and visited by the algorithm)
	
	- "top-down-propagation":
	
	* identify "top-entities" (entities which do not support other entites)
	
	* identify "bottom-entites"
	
	* start with top-entities and proceed across related entities
	
	- both approaches implemented in "Ripples 2"-tool:
	
	* parser scans project files and generates dependencies
	
	* tool marks affected classes and reports them to user
	
	-> granularity of entities: class
	
	-> granularity of changes: add, remove, change class
	
	-> granularity of results: class
	
	
	Open Issues:},
  timestamp = {2011.02.23}
}

@ARTICLE{Rajlich2000,
  author = {Rajlich, V.T. and Bennett, K.H.},
  title = {A staged model for the software life cycle},
  journal = {Computer},
  year = {2000},
  volume = {33},
  pages = {66-71},
  number = {7},
  month = {Jul},
  abstract = {Software engineers have traditionally considered any work after initial
	delivery as simply software maintenance. Some researchers have divided
	this work into various tasks, including making changes to functionality
	(perfective), changing the environment (adaptive), correcting errors
	(corrective), and making improvements to avoid future problems (preventive).
	However, many have considered maintenance basically uniform over
	time. Because software development has changed considerably since
	its early days, the authors believe this approach no longer suffices.
	They describe a new view of the software life cycle in which maintenance
	is actually a series of distinct stages, each with different activities,
	tools, and business consequences. While the industry still considers
	postdelivery work as simply software maintenance, the authors claim
	that the process actually falls into stages. They think both business
	and engineering can benefit from understanding these stages and their
	transitions.},
  doi = {10.1109/2.869374},
  file = {:./literature/00869374.pdf:PDF},
  issn = {0018-9162},
  keywords = {software development management, software maintenancebusiness consequences,
	postdelivery work, software development, software engineers, software
	life cycle, software maintenance, staged model},
  owner = {Stephan},
  timestamp = {2008.04.23}
}

@ARTICLE{Rajlich2004,
  author = {Rajlich, V\'{a}clav and Gosavi, Prashant},
  title = {Incremental change in object-oriented programming},
  journal = {IEEE Software},
  year = {2004},
  volume = {21},
  pages = {62-69},
  number = {4},
  file = {:./literature/Paper_171.pdf:PDF},
  owner = {Steffen},
  review = {- paper explains interplay of impact analysis and change propagation
	with incremental change
	
	- explains by example how the analysis procedures interact and are
	applied in software evolution / maintenance
	
	
	-> good to reinforce role of impact analysis for software evolution},
  timestamp = {2011.07.26}
}

@ARTICLE{Ramesh1998,
  author = {Ramesh, Balasubramaniam},
  title = {Factors influencing requirements traceability practice},
  journal = {Communications of the ACM},
  year = {1998},
  volume = {Volume 41 Issue 12},
  pages = {37 - 44},
  file = {:./literature/10.1.1.24.6749.pdf:PDF},
  owner = {Elke},
  timestamp = {2011.05.26},
  url = {http://portal.acm.org/citation.cfm?id=290133.290147}
}

@INPROCEEDINGS{Ramesh1993,
  author = {Ramesh, B. and Edwards, M.},
  title = {Issues in the development of a requirements traceability model},
  booktitle = {Proceedings of IEEE International Symposium on Requirements Engineering,
	1993},
  year = {1993},
  pages = {256-259},
  month = {Jan},
  abstract = {In the development of large-scale, real-time, complex computer intensive
	systems, it is essential to maintain traceability of requirements
	to various outputs to ensure that the system meets the current set
	of requirements. Based on an empirical study in a simulated systems
	development environment, several major issues that need to be considered
	in the development of a model of requirements traceability are addressed},
  doi = {10.1109/ISRE.1993.324849},
  file = {:./literature/Ramesh1993.pdf:PDF},
  keywords = { computer intensive systems; formal specification; requirements traceability
	model; simulated systems development environment; formal specification;},
  owner = {Stephan},
  review = {Elke},
  timestamp = {2010.12.08}
}

@ARTICLE{Ramesh2001,
  author = {Balasubramaniam Ramesh and Matthias Jarke},
  title = {Toward Reference Models for Requirements Traceability},
  journal = {{IEEE} Trans. Softw. Eng.},
  year = {2001},
  volume = {27},
  pages = {58-93},
  number = {1},
  __markedentry = {[Steffen:]},
  abstract = {Requirements traceability is intended to ensure continued alignment
	between stakeholder requirements and various outputs of the system
	development process. To be useful, traces must be organized according
	to some modeling framework. Indeed, several such frameworks have
	been proposed, mostly based on theoretical considerations or analysis
	of other literature. This paper, in contrast, follows an empirical
	approach. Focus groups and interviews conducted in 26 major software
	development organizations demonstrate a wide range of traceability
	practices with distinct low-end and high-end users of traceability.
	From these observations, reference models comprising the most important
	kinds of traceability links for various development tasks have been
	synthesized. The resulting models have been validated in case studies
	and are incorporated in a number of traceability tools. A detailed
	case study on the use of the models is presented. Four kinds of traceability
	link types are identified and critical issues that must be resolved
	for implementing each type and potential solutions are discussed.
	Implications for the design of next-generation traceability methods
	and tools are discussed and illustrated.},
  doi = {http://dx.doi.org/10.1109/32.895989},
  file = {:./literature/TowardReferenceModelsForRequirementsTraceability.pdf:PDF;:./literature/00895989.pdf:PDF},
  issn = {0098-5589},
  keywords = {reference models, requirements engineering, requirements traceability,
	traceability, traceability framework, traceability models, traceability
	practice, software engineering, systems analysiscase study, reference
	models, requirements engineering, requirements traceability, software
	development organizations, stakeholder requirements, system development
	process, traceability link types},
  lccn = {0460},
  owner = {Annie},
  publisher = {IEEE Press},
  review = {Elke},
  timestamp = {2010.03.02},
  url = {http://portal.acm.org/citation.cfm?id=359578}
}

@INPROCEEDINGS{Ramesh1995,
  author = {Ramesh, B. and Powers, T. and Stubbs, C. and Edwards, M.},
  title = {Implementing requirements traceability: a case study},
  booktitle = {Requirements Engineering, 1995., Proceedings of the Second IEEE International
	Symposium on},
  year = {1995},
  pages = {89--95},
  organization = {IEEE},
  file = {Ramesh1995.pdf:literature/Ramesh1995.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.11.15}
}

@ARTICLE{Ramesh1997,
  author = {Ramesh, Balasubramaniam and Stubbs, Curtis and Powers, Timothy and
	Edwards, Michael},
  title = {Requirements traceability: Theory and practice},
  journal = {Annals of Software Engineering},
  year = {1997},
  volume = {3},
  pages = {397-415},
  affiliation = {Georgia State University Department of Computer Information Systems
	Atlanta GA 30303 USA},
  file = {:./literature/ramesh_fulltext.pdf:PDF},
  issn = {1022-7091},
  issue = {1},
  keyword = {Computer Science},
  owner = {Elke},
  publisher = {Springer Netherlands},
  timestamp = {2011.05.31},
  url = {http://dx.doi.org/10.1023/A:1018969401055}
}

@INPROCEEDINGS{Ramollari2007,
  author = {Ervin Ramollari and Dimitris Dranidis and Anthony J. H. Simons},
  title = {A Survey of Service Oriented Development Methodologies},
  booktitle = {Proceedings of The 2nd European Young Researchers Workshop on Service
	Oriented Computing},
  year = {2007},
  pages = {75-80},
  month = {June},
  abstract = {Service orientation is a new software engineering paradigm that introduces
	opportunities as well as challenges. Although existing processes
	and practices can be reused for service oriented development, novel
	techniques are required to address unique SOA requirements. Work
	in this area is quite active and only recently is producing some
	initial results. The aim of this paper is to present a state-of-the-art
	survey on current service oriented development approaches. The characteristics
	that distinguish between these approaches are discussed and a number
	of actual methodologies that have emerged or are still emerging are
	described and compared.},
  file = {:./literature/soasurvey.pdf:PDF},
  keywords = {SOA, service oriented software engineering, methodologies, survey},
  owner = {Stephan},
  timestamp = {2008.05.06},
  url = {http://www.dcs.shef.ac.uk/~ajhs/research/papers/soasurvey.pdf}
}

@INPROCEEDINGS{Rashid2008,
  author = {Rashid, Awais and Chitchyan, Ruzanna},
  title = {Aspect-oriented requirements engineering: a roadmap},
  booktitle = {Proceedings of the 13th international workshop on Software architectures
	and mobility (EA'08)},
  year = {2008},
  pages = {35-41},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {It has been five years since a Vision Paper at the Requirements Engineering
	Conference in 2002 laid out an initial vision for As-pect-Oriented
	Requirements Engineering (AORE). This vision included objectives
	such as offering better means to identify and manage conflicts arising
	due to tangled representations and identifying the mapping and influence
	of crosscutting requirements on architecture, design and implementation
	artefacts. Since then a number of AORE techniques have been proposed
	in literature. In this paper, we review these techniques and discuss
	whether and how effectively the original AORE vision from RE 2002
	has been realised so far. We also discuss how the original vision
	needs to be extended given our improved understanding of AORE challenges
	and present a roadmap for the next five years as a chal-lenge to
	both existing AORE researchers and those planning to pursue work
	in this area.},
  doi = {http://doi.acm.org/10.1145/1370828.1370836},
  file = {:./literature/ea04b-rashid.pdf:PDF},
  isbn = {978-1-60558-032-6},
  keywords = {aspect-oriented requirements engineering},
  location = {Leipzig, Germany},
  owner = {Stephan},
  timestamp = {2009.03.17}
}

@PHDTHESIS{Rausch2001,
  author = {Andreas Rausch},
  title = {Componentware - Methodik des evolutionären Architekturentwurfs},
  school = {TU München},
  year = {2001},
  abstract = {Heutige Softwaresysteme sind äußerst komplex. Erfahrungsgemäß können
	sie von einzelnen
	
	Softwareingenieuren kaum mehr vollständig erfasst werden. Die Entwicklung
	eines Systems
	
	findet meist in einem hochgradig dynamischen Umfeld statt. Der iterative,
	evolutionäre Entwurf
	
	einer Softwarearchitektur und frühes Prototyping können helfen, Risiken
	der Softwareentwicklung
	
	entscheidend zu minimieren. Die Softwarearchitektur beschreibt dabei
	eine geeignete
	
	Zerlegung des Systems in Komponenten und die Abhängigkeiten zwischen
	diesen
	
	Komponenten.
	
	In dieser Arbeit wird eine Methodik des evolutionären Architekturentwurfs
	komponentenbasierter
	
	Systeme entwickelt. Sowohl textbasierte als auch UML-basierte, grafische
	Spezifikationstechniken
	
	für Komponenten, deren Abhängigkeiten und komponentenbasierte Systeme
	
	werden erarbeitet. Mit diesen Spezifikationstechniken kann die Softwarearchitektur
	eines
	
	komponentenbasierten Systems vollständig und präzise beschrieben werden.
	Nach der Veränderung
	
	einzelner Komponentenspezifikationen in Rahmen eines evolutionären
	Entwicklungsschrittes
	
	können die Abhängigkeiten zwischen den Komponenten erneut auf ihre
	Gültigkeit
	
	hin überprüft werden. Die Integration der einzelnen Komponentenspezifikationen
	zu einem
	
	konsistenten Architekturmodell erfolgt so bereits auf der Spezifikationsebene.
	
	Grundlage der erarbeiteten Methodik ist ein Systemmodell, das die
	Menge aller komponentenbasierter
	
	Systeme charakterisiert. Die Komponenten eines solchen Systems werden
	nebenläufig
	
	und verteilt ausgeführt. Sie kommunizieren über asynchrone Nachrichten,
	greifen lesend
	
	und schreibend auf Attribute von Komponenten zu und verändern die
	Struktur des komponentenbasierten
	
	Systems.
	
	Das Systemmodell ist die Basis für die formale Fundierung der erarbeiteten
	Spezifikationstechniken.
	
	Über eine prädikatenbasierte formale Semantik wird einer Spezifikation
	eine Menge
	
	von Eigenschaften zugewiesen. Ein komponentenbasiertes System ist
	genau dann eine korrekte
	
	Implementierung der Spezifikation, wenn es diese Eigenschaften besitzt.
	
	Die Konzeption und prototypische Realisierung einer durchgängigen
	und weitreichenden
	
	Werkzeugunterstützung garantieren die effektive und praxisorientierte
	Umsetzung der erarbeiteten
	
	Methodik. Die vorgestellten Konzepte reichen von der Architekturspezifikation
	über
	
	die Konsistenz- und Integrationsüberprüfung bis zu Prototypengenerierung
	und Testverfahren.},
  file = {:./literature/rausch2001.pdf:PDF},
  keywords = {evolutionäre Softwareentwicklung, komponentenbasierte Softwareentwicklung,
	Spezifikation, Werkzeugunterstützung, Architekturentwurf},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://agrausch.informatik.uni-kl.de/publikationen/repository/books/book001/componentware.pdf}
}

@INPROCEEDINGS{Rautiainen2003,
  author = {Rautiainen, K. and Vuornos, L. and Lassenius, C.},
  title = {An experience in combining flexibility and control in a small company's
	software product development process},
  booktitle = {Empirical Software Engineering, 2003. ISESE 2003. Proceedings. 2003
	International Symposium on},
  year = {2003},
  pages = {28--37},
  file = {Rautiainen2003.pdf:literature/Rautiainen2003.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@MASTERSTHESIS{Reckling2011,
  author = {Stefan Reckling},
  title = {Transformation von Usability-Pattern
	
	unter Verwendung der
	
	Musterbeschreibungssprache USE2PAC
	
	in Softwaremuster},
  school = {TU Ilmenau},
  year = {2011},
  type = {Bachelor Thesis},
  abstract = {Innerhalb dieser Arbeit wurde eine flexible Architektur zur Konstruktion
	von unterschiedlichen,
	
	dynamisch veränderbaren Benutzeroberflächen prototypisch umgesetzt.
	
	Neben hohen Softwarequalitätsansprüchen durchzieht der Aspekt der
	vollständigen
	
	Separierung von Anwendungslogik und grafischer Repräsentation die
	
	Entwicklungsarbeit, angefangen von der Anforderungsanalyse über die
	Entwurfsphase
	
	bis hin zur Implementierung. Gegensätzlich zu den heutigen Werkzeugumgebungen
	
	für die Visualisierung von Benutzeroberfläche unterstützt die entwickelte
	
	Architektur die Kombinierbarkeit von fest deklarierten und selbst
	definierten
	
	Objekten der Nutzerschnittstelle zu neuen Objekten und sorgt nicht
	nur für wiederverwendbare
	
	Strukturen innerhalb der Darstellung, sondern auch in Bezug auf
	
	die Behandlung von Benutzerinteraktionen. Die bereits in der Einleitung
	genannte
	
	Problematik der Wechselwirkung von Einfachheit und Universalität wurde
	dabei
	
	auf den Kontext der Erzeugung von Benutzeroberflächen konkretisiert
	und stellt
	
	damit einen möglichen Architekturansatz dar, die bisher übliche Praxis
	der Erzeugung
	
	kundenindividueller und statischer Webanwendungen abzulösen.},
  file = {UsabilityPatterns-BAReckling2011.pdf:literature/UsabilityPatterns-BAReckling2011.pdf:PDF},
  owner = {matthias},
  timestamp = {2012.12.21}
}

@INPROCEEDINGS{Reder2012,
  author = {Alexander Reder and Alexander Egyed},
  title = {Incremental Consistency Checking for Complex Design Rules and Larger
	Model Changes},
  booktitle = {Model Driven Engineering Languages and Systems MODELS 2012},
  year = {2012},
  number = {7590},
  series = {LNCS},
  pages = {202-218},
  publisher = {Springer},
  abstract = {Advances in consistency checking in model-based software development
	made it possible to detect errors in real-time. However, existing
	approaches assume that changes come in small quantities and design
	rules are generally small in scope. Yet activities such as model
	transformation, re-factoring, model merging, or repairs may cause
	larger model changes and hence cause performance problems during
	consistency checking. The goal of this work is to increase the performance
	of re-validating design rules. This work proposes an automated and
	tool supported approach that re-validates the affected parts of a
	design rule only. It was empirical evaluated on 19 design rules and
	30 small to large design models and the evaluation shows that the
	approach improves the computational cost of consistency checking
	with the gains increasing with the size and complexity of design
	rules.},
  file = {:./literature/Reder2012.pdf:PDF},
  owner = {matthias},
  timestamp = {2013.10.16},
  url = {http://www.alexander-egyed.com/publications/Incremental_Consistency_Checking_for_Complex_Design_Rules_and_Larger_Model_Changes.pdf}
}

@ARTICLE{Reimann2004,
  author = {Wilfried Reimann},
  title = {Building Enterprise Applications with an Integrated Application {P}latform},
  year = {2004},
  volume = {Erfurt, Germany, September.NET.ObjectDays Conference},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.16}
}

@INPROCEEDINGS{Reiter2005,
  author = {Reiter, T. and Kapsammer, E. and Retschitzegger, W. and Schwinger,
	W.},
  title = {Model Integration through Mega Operations},
  booktitle = {Proceedings of the Workshop on Model-driven Web Engineering},
  year = {2005},
  pages = {20-29},
  address = {Sydney, Australia},
  month = {July},
  file = {:./literature/Paper_235.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.05.16}
}

@INPROCEEDINGS{Reitz2006,
  author = {Reitz, Markus},
  title = {Software Evolvability by Component-Orientation},
  booktitle = {Second International IEEE Workshop on Software Evolvability, 2006.
	SE '06},
  year = {2006},
  pages = {66-73},
  month = {Sept. },
  publisher = {IEEE Computer Society},
  abstract = {Software is often in a state of flux because of inaccurate or incomplete
	requirements at development time or due to changing needs during
	the life cycle. Component-orientation structures software systems
	in compartments which localise the impact of requirement changes,
	simplifying replacement of subsystems if the need arises. Unfortunately,
	current technologies focus on the initial construction phase, disregarding
	software evolvability aspects. Although the number of compartments
	affected by requirement changes is usually small, rather tight coupling
	between components complicates and in certain circumstances even
	prevents evolvability. This paper introduces a loosely coupled component
	model whose communication scheme is based on arbitrarily interleavable
	message propagation scopes which define and constrain the "connectedness"
	of software components. Inspired by biological concepts, namely principles
	of signal transmission at cell level and communication mechanisms
	of higher order organisms, analogies between biological components
	and software components which help to increase adaptability and flexibility
	are drawn. Finally, the model's benefits within the context of COMDECO
	are sketched to give an impression of its practical applicability.},
  doi = {10.1109/SOFTWARE-EVOLVABILITY.2006.13},
  file = {:./literature/04032450.pdf:PDF},
  keywords = {object-oriented programming, software prototypingCOMDECO, arbitrarily
	interleavable message propagation, biological inspiration, component-orientation,
	loosely coupled component model, software components, software evolvability,
	software systems},
  owner = {Stephan},
  timestamp = {2008.06.25}
}

@ARTICLE{Rempel2012,
  author = {Rempel, Patrick and Lehnert, Steffen and Kuschke, Tobias and Farooq,
	Qu},
  title = {A Framework for Traceability Tool Comparison},
  journal = {Softwaretechnik Trends},
  year = {2012},
  volume = {32},
  pages = {6-11},
  number = {3},
  month = {August},
  file = {:./literature/Paper_251.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.10.09}
}

@PHDTHESIS{Ren2007,
  author = {Ren, Xiaoxia},
  title = {Change Impact Analysis for {Java} programs and applications},
  school = {New Brunswick Graduate School, Rutgers University},
  year = {2007},
  address = {New Brunswick, New Jersey, USA},
  month = {October},
  file = {:./literature/PhD_6.pdf:PDF},
  owner = {Steffen},
  review = {- proposed methodology requires original and edited version of source
	code and regression tests
	
	- methodology determines test cases which are affected by a change
	to assist programmer with changing software
	
	- thesis implements Chianti prototyp, as proposed in {Ren2003,Ren2004,Ren2005}
	
	- goal of research is to provide programmer with understanding why
	a certain test fails and isolating the changes which are responsible
	for the failure
	
	- thesis invistages dependencies between atomic changes and implements
	heuristic to rank atomic changes according to their likelyhood of
	affecting test case failure
	
	* 3 types of dependencies: structural dependencies (sequence when
	elements are +/-), declaration dependencies (java element declarations)
	and mapping dependencies (map changes to method-level changes)
	
	* also compute syntactic dependencies between atomic changes to exlude
	changes which do not affect certain tests (changes are dependent
	if one is prerequisite for other change)
	
	- Chianti performs IA as follows:
	
	* analyze code edits to obtain set of interdependent atomic changes
	
	* construct a call graph for each test case, either static or dynamic
	
	* determine whether test is affected by correlating changes against
	call graph of orginial version of program
	
	* determine changes that affected a test by constructing call graph
	of edited version and correlating it against call graph of orginial
	version
	
	
	- scope of analysis: code
	
	- tool: Chianti
	
	- language: Java
	
	- scalability:
	
	- granularity
	
	* changes: +/- class, +/-/sig. method, +/- variable
	
	* artifacts: class, method, variable
	
	* results: test case
	
	- technique: CG, ET
	
	- analysis style:
	
	- evaluation
	
	* size: 123 KLOC, 700 class, 7k method
	
	* precision:
	
	* recall:
	
	* time:},
  timestamp = {2011.04.01}
}

@INPROCEEDINGS{Ren2005,
  author = {Ren, Xiaoxia and Ryder, Barbara G. and Stoerzer, Maximilian and Tip,
	Frank},
  title = {Chianti: A Change Impact Analysis Tool for {Java} Programs},
  booktitle = {Proceedings of the 27th international conference on Software Engineering
	(ICSE '05)},
  year = {2005},
  pages = {664-665},
  address = {New York, NY, USA},
  publisher = {ACM},
  file = {:./literature/Paper_161.PDF:PDF},
  owner = {Steffen},
  review = {see other Chianti-paper},
  timestamp = {2011.07.01}
}

@INPROCEEDINGS{Ren2004,
  author = {Ren, X. and Shah, F. and Tip, B.G.R. and Chesley, O.},
  title = {Chianti: A Tool for Change Impact Analysis of {Java} Programs},
  booktitle = {Proceedings of the 19th annual ACM SIG-PLAN Conference on Object-oriented
	programming, systems, languages, and applications (OOPSLA '04)},
  year = {2004},
  pages = {432-448},
  address = {Vancouver, BC, Canada},
  file = {:./literature/Paper_6.pdf:PDF},
  owner = {Steffen},
  review = {[based on Ryder2001, kinda implements the presented approach]
	
	
	Problem:
	
	- changes in OOP programs can have multiple effects on tests
	
	- tests must be adopted to changes
	
	
	Research Questions:
	
	- provide understanding of test behavior after code edit (i.e. change
	implementation)
	
	- isolating a subset of changes effecting a certain test
	
	
	Contribution:
	
	- Chianti tool analyzes two code versions to determine atomic changes,
	reports impact on related tests
	
	- experimental validation of tool / approach
	
	- combination of static analysis to find atomic changes + dynamic
	analysis of call graphs
	
	- tool works on CVS data (the changes)
	
	
	Solution:
	
	- gain list of atomic changes from source code edits
	
	- construct a call graph or dynamic traces for each test by external
	tools
	
	- use call graph to estimate impact of change on tests
	
	- use a new naming strategy for classes (esp. local classes) to ensure
	proper categorization: 
	
	* enclosingClassName + enclosingElementName + selfSuperclassInterfacesName
	+ sequenceNumber
	
	-> granularity of entities: regression tests
	
	-> granularity of changes: atomic changes
	
	-> granularity of results: regression tests
	
	
	Open Issues:
	
	- still no consideration of semantic dependencies
	
	- cost/precision tradeoff between static/dynamic call graphs},
  timestamp = {2011.01.01}
}

@TECHREPORT{Ren2003,
  author = {Ren, Xiaoxia and Shah, Fenil and Tip, Frank and Ryder, Barbara G.
	and Chesley, Ophelia and Dolby, Julian},
  title = {Chianti: A Prototype Change Impact Analysis Tool for {Java}},
  institution = {Rutgers University, Department of Computer Science},
  year = {2003},
  number = {DCS-TR-533},
  month = {September},
  file = {:./literature/Paper_160.PDF:PDF},
  owner = {Steffen},
  review = {see other Chianti-paper},
  timestamp = {2011.07.01}
}

@INCOLLECTION{Riaz2009,
  author = {Riaz, Mehwish and Sulayman, Muhammad and Naqvi, Husnain},
  title = {Architectural Decay during Continuous Software Evolution and Impact
	of `Design for Change' on Software Architectures},
  booktitle = {Advances in Software Engineering},
  publisher = {Springer},
  year = {2009},
  editor = {Slezak, Dominik and Kim, Tai-hoon and Kiumi, Akingbehin and Jiang,
	Tao and Verner, June and Abrahao, Silvia},
  volume = {59},
  series = {Communications in Computer and Information Science},
  pages = {119-126},
  abstract = {Software architecture is the blue print of software and guides the
	development and evolution of the software. A good design produces
	quality software and careful evolution of software leads to a longer
	life of the software whereas a bad design and careless evolution
	leads to decay of the software. This paper discusses the phenomenon
	of architectural decay and gives an account of the practices suggested
	in the literature for identification, resolution and prevention of
	architectural decay. The observations from a controlled experiment
	to study the impact of the prevention practice ‘design for change’
	are also discussed. The results from the studied metrics suggest
	that software created without following a proper design has a greater
	tendency to decay.},
  affiliation = {International Islamic University Department of Computer Science Islamabad
	Pakistan},
  file = {:./literature/Riaz2009.pdf:PDF},
  isbn = {978-3-642-10619-4},
  keyword = {Computer Science},
  keywords = {architectural decay, architectural erosion, architectural drift},
  owner = {Stephan},
  review = {Definition Architectural Decay
	
	"Architectural decay is the phenomenon when concrete (as-built) architecture
	of a software system deviates from its conceptual (as-planned) architecture
	where it no longer satisfies the key quality attributes that led
	to its construction OR when architecture of a software system allows
	no more changes to it due to changes introduced in the system over
	time and reders it un-maintainable."},
  timestamp = {2010.11.08},
  url = {http://dx.doi.org/10.1007/978-3-642-10619-4_15}
}

@ARTICLE{Richardson2006,
  author = {Richardson, I.},
  title = {SPI models: what characteristics are required for small software
	development companies?},
  journal = {Software Quality—ECSQ 2002},
  year = {2006},
  pages = {100--113},
  file = {Richardson2006.pdf:literature/Richardson2006.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@INPROCEEDINGS{Riebisch2003a,
  author = {Matthias Riebisch},
  title = {Towards a More Precise Definition of Feature Models},
  booktitle = {Modeling Variability for Object-oriented Product Lines. (Proceedings
	Workshop at the European Concference on Object-oriented Programming
	(ECOOP))},
  year = {2003},
  editor = {M. Riebisch and J. O. Coplien and D. Streitferdt},
  month = {July},
  publisher = {BookOnDemand Publ. Co.},
  abstract = {Feature models are a well accepted means for expressing requirements
	in a domain on an abstract level. They are applied to describe variable
	and common properties of products in a product line, and to derive
	and validate configurations of software systems. Their industrial
	importance is increasing rapidly. However, methodical usage and tool
	support demands for a more precise definition of features, their
	properties and their relations within a feature model. This position
	paper summarizes the state of the discussion and proposes issues
	for future development. Categories of features and types of their
	attributes and relations are presented. The represented information
	is limited to a customer point of view onto the feature models without
	excluding technically detailed features. Connections of features
	to other models i.e. design, and to implementation elements are given
	by traceability links. Approaches for graphical representations and
	data models for feature models are shown. Proposals of attaching
	additional information for related tasks like product line evolution,
	scoping, effort estimation, definition of product configurations
	and documenting are discussed.},
  citeseerurl = {http://citeseer.ist.psu.edu/626155.html},
  file = {:./literature/06-Matthias.pdf:PDF},
  institution = {Technical University of Ilmenau, Germany},
  keywords = {feature models},
  owner = {Robert},
  timestamp = {2006.09.23},
  url = {http://www.theoinf.tu-ilmenau.de/~Matthias/publ/06-Matthias.pdf}
}

@MISC{Riebisch2004,
  author = {Riebisch, Matthias},
  title = {Evolution und Komposition von Softwaresystemen},
  howpublished = {Digitale Bibliothek Thüringen},
  month = {Juni},
  year = {2004},
  note = {Habilitationsschrift},
  abstract = {Software systems are today bigger, more complex and of higher importance
	for products and services than a decade before. At the same time
	changes are required many more frequently and of a larger size. Furthermore,
	they have to be implemented faster. Additionally, the software must
	achieve a higher life span, particularly because of the cost of its
	development. In the past, Object-Oriented Programming and Reuse techniques
	did not provide the expected success. The introduction of software
	product lines respectively system families makes possible it to reach
	a degree of prefabrication similar to the one of serial production.
	At the same time they facilitate the delivery of product variants
	with a short time to market. In this work methods of the methods
	of domain analysis are integrated with Reuse approaches and techniques
	of Generative Programming, and a methodology for product line development
	is presented. Feature models are used as means expressing variability
	and product configurations, so that the prefabrication be planned
	and the production of customer-specific products can be controlled.
	By enforcing the formalization in terms of syntax and semantics,
	feature models are made accessible to tools and automation. Object-oriented
	design models and architecture are separated into fine-granular components
	in such a way that new products can easily be developed as combinations
	of those components. The implementation of such products is automated
	by the composition of source code components. The composition of
	object models separated similarly enables a uninterrupted automation
	for the product development, which is controlled by a customer by
	means of a feature selection. To facilitate such a composition, the
	Hyperspace approach is applied to UML to Hyper/UML, which makes possible
	a feature-driven separation and composition of object models. In
	this way slim products can be developed, containing only the actually
	needed functionality. For the evolution of product lines and for
	the integration of existing solutions and components into the evolution,
	Reverse Engineering and Refactoring techniques are integrated. Requirements,
	models and implementation are connected by Traceability links to
	perform changes consistently. As a consequence, the loss of architectural
	quality - so-called Architectural Decay - can be avoided during the
	iterative development process. Measures for the improvement of the
	project and quality management are regarded briefly, as far as they
	are of importance for the effectiveness of the developed methods.
	The applicability and suitability of the results of the work were
	examined in several industrial projects.
	
	
	Zusammenfassung:
	
	Softwaresysteme sind heute umfangreicher, komplexer und von entscheidenderer
	Bedeutung für Produkte und Dienstleistungen als eine Dekade zuvor.
	Gleichzeitig sind Änderungen viel häufiger und in größerem Umfang
	erforderlich. Sie müssen auch schneller realisierbar sein. Zudem
	muss die Software eine höhere Lebensdauer erreichen, vor allem wegen
	des Aufwandes zu ihrer Entwicklung. Objektorientierte Programmierung
	und Wiederverwendungstechniken haben dabei nicht den erwarteten Erfolg
	gebracht. Die Einführung von Software-Produktlinien beziehungsweise
	Systemfamilien ermöglichen es, einen der Serienfertigung ähnlichen
	Vorfertigungsgrad zu erreichen und erlauben es gleichzeitig, kurzfristig
	Produktvarianten zu erstellen. In dieser Arbeit werden Methoden der
	Domänenanalyse mit Wiederverwendungsansätzen und Generativen Programmiertechniken
	verknüpft und eine Methodik zur Produktlinien-Entwicklung vorgestellt.
	Featuremodelle werden als Ausdrucksmittel für Variabilität und Produktkonfigurationen
	eingesetzt, damit die Vorfertigung geplant und die Erstellung von
	kundenspezifischen Produkten gesteuert werden kann. Durch Präzisierung
	ihrer Syntax und Erweiterung ihrer Semantik werden Featuremodelle
	einer Nutzung in Werkzeugen zugänglich gemacht. Objektorientierte
	Entwurfsmodelle und Architektur werden so in feingranulare Komponenten
	zerlegt, dass Varianten als neue Produkte mit geringem Aufwand erstellbar
	sind. Die Erstellung der Implementierung solcher Produkte wird durch
	die Komposition von Quelltext-Komponenten automatisiert. Die Komposition
	von ebenfalls zerlegten Objektmodellen ermöglicht eine durchgehende
	Automatisierung der Produkterstellung, die durch einen Kunden mittels
	der Feature-Auswahl gesteuert wird. Dafür wird mit Hyper/UML eine
	Umsetzung des Hyperspace-Ansatzes auf die Modellierungssprache UML
	entwickelt, die eine Feature-gesteuerte Zerlegung und Komposition
	von Objektmodellen ermöglicht. Damit lassen sich schlanke Produkte
	entwickeln, die nur die tatsächlich benötigte Funktionalität enthalten.
	Zur Evolution von Produktlinien und zur Einbindung existierender
	Lösungen und Komponenten in die Evolution werden Reverse-Engineering-
	und Refactoring-Techniken integriert. Anforderungen, Modelle und
	Implementierung werden durch Traceability-Links verbunden, damit
	Änderungen konsistent durchgeführt werden können. Diese Mittel tragen
	dazu bei, dass während einer iterativen Entwicklung der Verlust an
	Architektur-Qualität, das sogenannte Architectural Decay, vermieden
	werden kann. Maßnahmen zur Verbesserung des Projekt- und Qualitätsmanagements
	werden kurz betrachtet, soweit sie wichtige Randbedingungen für die
	Wirksamkeit der Methoden schaffen müssen. Die Anwendbarkeit und Eignung
	der Ergebnisse der Arbeiten wurde in mehreren industriellen Projekten
	überprüft.},
  file = {:./literature/Habilitation_Riebisch_2004.pdf:PDF},
  keywords = {software product line; feature model; evolution, traceability, architecture,
	domain engineering, generative programming, variability, UML, Hyperspace},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://www.db-thueringen.de/servlets/DocumentServlet?id=8410}
}

@INPROCEEDINGS{Riebisch2004a,
  author = {Matthias Riebisch},
  title = {Supporting Evolutionary Development by Feature Models and Traceability
	Links},
  booktitle = {Proceedings 11th IEEE International Conference and Workshop on the
	Engineering of Computer-Based Systems, ECBS},
  year = {2004},
  pages = {370-377},
  address = {Los Alamitos, CA, USA},
  month = {May},
  publisher = {IEEE Computer Society},
  abstract = {During their usage, software systems have to be changed constantly.
	If such changes are implemented in an incomplete or inconsistent
	way a loss of architectural quality will occur, i.e. in terms of
	maintainability and understandability. The lack of traceability of
	the impact of changed requirements in the software enhances this
	effect. Traceability links have been proposed as a link between the
	requirements and the different parts of a solution. In practical
	use, these links are difficult to establish and maintain. Currently,
	tools cannot effectively support these links due to human-required
	decisions. This paper introduces feature models as an intermediate
	element for linking requirements to design models. They enable a
	more appropriate bridging of the different levels of abstraction.
	Feature models group sets of requirements to a feature and enable
	a modeling of the variability of requirements. The feature models
	structure traceability links between requirements, design elements
	and implementation parts. This leads to lower efforts of establishing
	and maintaining the links. Furthermore, descriptions of design decisions
	can be attached to the links. Industrial experience with this approach
	shows its support for the evolutionary development of large software
	systems, especially in the improved comprehension of the changes
	by the developers.},
  doi = {http://doi.ieeecomputersociety.org/10.1109/ECBS.2004.1316721},
  file = {:./literature/01316721.pdf:PDF},
  isbn = {0-7695-2125-8},
  keywords = {formal specification, software architecture, software development
	management, software maintenance, software prototyping, software
	reusability, software tools feature models, formal specification,
	software design elements, software evolutionary development, software
	maintenance, traceability links},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://www.theoinf.tu-ilmenau.de/~Matthias/home/publ/RiebischM_Traceability.pdf}
}

@ARTICLE{Riebisch2010,
  author = {Matthias Riebisch and Stephan Bode},
  title = {Design Decision Support for Evolvability and Variability},
  journal = {Softwaretechnik-Trends},
  year = {2010},
  volume = {30},
  pages = {52-53},
  number = {2},
  note = {Proceedings 2nd Workshop Design for Future (DFF2010)},
  file = {:./literature/riebisch_DFF2010.pdf:PDF},
  owner = {Stephan},
  timestamp = {2011.02.10}
}

@ARTICLE{Riebisch2009,
  author = {Matthias Riebisch and Stephan Bode},
  title = {Software-Evolvability},
  journal = {Informatik-Spektrum},
  year = {2009},
  volume = {32},
  pages = {339-343},
  number = {4},
  month = {Aug},
  doi = {10.1007/s00287-009-0349-2},
  file = {:./literature/software-evolvability.pdf:PDF},
  keywords = {software evolvability, software evolution, software maintenance, software
	maintainability, subcharacteristics},
  owner = {Stephan},
  timestamp = {2009.04.29}
}

@INPROCEEDINGS{Riebisch2011,
  author = {Riebisch, Matthias and Bode, Stephan and Farooq, Qurat-Ul-Ann and
	Lehnert, Steffens},
  title = {Towards Comprehensive Modelling by Inter-Model Links Using an Integrating
	Repository},
  booktitle = {8th IEEE Workshop on Model-Based Development for Computer-Based Systems},
  year = {2011},
  pages = {284-291},
  file = {:./literature/Paper_246.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.02.13}
}

@INPROCEEDINGS{Riebisch2008,
  author = {Matthias Riebisch and Robert Brcina},
  title = {Optimizing Design for Variability Using Traceability Links},
  booktitle = {Proceedings 15th Annual IEEE International Conference and Workshop
	on the Engineering of Computer Based Systems, ECBS},
  year = {2008},
  pages = {235-244},
  publisher = {IEEE Computer Society},
  abstract = {Software systems have to provide flexibility by implementing variability.
	Existing design methodologies do not support means for optimizing
	the design for variability and for measuring the overhead effort.
	Therefore, the solutions cannot be optimized regarding a minimal
	overhead for variability. Other methods are lacking of a traceability
	for variability mechanisms, or do not provide means for measuring
	and optimizing solutions. The paper introduces traceability links
	for variability with a special emphasis on support for implementation,
	build and deployment, and presents guidelines for optimizing the
	design with indicators for evaluating the results. The feasibility
	of the approach is shown by a case study from an industrial setting.},
  doi = {http://doi.ieeecomputersociety.org/10.1109/ECBS.2008.37},
  file = {:./literature/brcina_riebisch_OptimizationDesign_final.pdf:PDF},
  isbn = {978-0-7695-3141-0},
  keywords = {Optimisation of Design, Traceability, Variability, Characteristic},
  owner = {Robert},
  timestamp = {2008.06.04},
  url = {http://www.theoinf.tu-ilmenau.de/~Matthias/home/publ/brcina_riebisch_OptimizationDesign_final.pdf}
}

@INPROCEEDINGS{Riebisch2011a,
  author = {Matthias Riebisch and Alexander Pacholik and Stephan Bode},
  title = {Towards Optimization of Design Decisions for Embedded Systems by
	Exploiting Dependency Relationships},
  booktitle = {Proceedings Workshop Modellbasierte Entwicklung eingebetteter Systeme
	(MBEES2011)},
  year = {2011},
  month = {February},
  organization = {Dagstuhl},
  file = {:./literature/OptimizationOfDesignDecisions-110131.pdf:PDF},
  keywords = {Goal Solution Scheme, embedded system, decision procedure, dependencies},
  owner = {Stephan},
  timestamp = {2011.02.10}
}

@INPROCEEDINGS{Riebisch2003,
  author = {Matthias Riebisch and Detlef Streitferdt and Ilian Pashov},
  title = {Modeling Variability for Object-Oriented Product Lines},
  booktitle = {ECOOP Workshops},
  year = {2003},
  editor = {Buschmann, Frank and Buchmann, Alejandro P. and Cilia, Mariano},
  pages = {165-178},
  publisher = {Springer},
  abstract = {The concept of a software product line is a promising approach for
	increasing planned reusability in industry. For planning future requirements,
	the integration of domain analysis activities with software development
	for reusability turned out to be necessary, both from a process and
	from an economic point of view. In this context, variability of requirements
	in a domain is expressed by feature models. Feature models enable
	planning and strategic decisions both for architectural and for component
	development. By expressing feature dependencies, feature models are
	used to partition the architecture and the implementation. For industrial
	use, appropriate methods for modeling variability in requirements,
	design and implementation as well as tools for supporting feature
	models and for integrating them with other models are needed. The
	ECOOP workshop explored the possibilities and limitations of feature
	models and supporting methods. Its fully reviewed contributions aim
	at improving the feature model usage as well as the integration into
	the software development process. Improving industrial applicability
	of feature modeling and methods is an important goal. This paper
	provides a summary of the discussion and presents the major results
	as well as important questions and issues identified for future research.},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  doi = {10.1007/b98806},
  ee = {http://springerlink.metapress.com/openurl.asp?genre=article{\&}issn=0302-9743{\&}volume=3013{\&}spage=165},
  file = {:./literature/ModelingVariability-WSReaderPaper.pdf:PDF},
  keywords = {software product lines, software variability},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://www.theoinf.tu-ilmenau.de/~streitdf/TheHome/own/data/ModelingVariability-WSReaderPaper.pdf}
}

@INPROCEEDINGS{Riebisch2007,
  author = {Matthias Riebisch and Sven Wohlfarth},
  title = {Introducing Impact Analysis for Architectural Decisions},
  booktitle = {Proceedings 14th Annual IEEE International Conference and Workshop
	on the Engineering of Computer Based Systems (ECBS2007)},
  year = {2007},
  pages = {381-390},
  publisher = {IEEE},
  file = {:./literature/Riebisch2007-ImpactAnalysis.pdf:PDF},
  owner = {Stephan},
  timestamp = {2011.04.29}
}

@TECHREPORT{Ritze2008,
  author = {Ritze, M.},
  title = {{Comparing the traceability features of {CASE} tools (in German:
	Vergleich von CASE-Tools bez\"{u}glich Traceability-F\"{a}higkeiten)}},
  institution = {Ilmenau University of Technology},
  year = {2008},
  file = {:./literature/SA2.pdf:PDF},
  owner = {Elke},
  review = {hab das Papier nicht gefunden, es wird in Patrick MÃ¤ders Dissertation
	beschrieben},
  timestamp = {2011.06.10}
}

@PHDTHESIS{Robbes2008a,
  author = {Robbes, Romain},
  title = {Of Change and Software},
  school = {Faculty of Informatics of the University of Lugano},
  year = {2008},
  month = {December},
  file = {:./literature/PhD_4.pdf:PDF},
  owner = {Steffen},
  review = {- scope of analysis:
	
	- tool:
	
	- language:
	
	- scalability:
	
	- granularity
	
	* changes:
	
	* artifacts:
	
	* results:
	
	- technique:
	
	- analysis style:
	
	- evaluation
	
	* size:
	
	* precision:
	
	* recall:
	
	* time:},
  timestamp = {2011.02.10}
}

@INPROCEEDINGS{Robbes2008c,
  author = {Robbes, Romain and Lanza, Michele},
  title = {{SpyWare}: A Change-Aware Development Toolset},
  booktitle = {Proceedings of the 30th international conference on Software engineering
	(ICSE '08)},
  year = {2008},
  pages = {847-850},
  address = {Leipzig, Germany},
  month = {May},
  file = {:./literature/Paper_94.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- changes must be considered as a central aspect of software evolution,
	if one wants to understand software evolution
	
	- most software development tools only consider source code, but not
	history of code / software
	
	
	Research Questions:
	
	- how to capture changes as they happen and not extract change information
	from version control systems and repositories
	
	- capture changes on the level of program entities, not on level of
	files or lines of code
	
	
	Contribution:
	
	- tool called Spyware which gathers change information in repository
	to assist developer (therefore integrated into IDE)
	
	- work in paper is based on {Robbes2007a}
	
	
	Solution:
	
	- automatically record changes as they happen in the IDE on the level
	of software entities
	
	* enables modeling of change history as a sequence of first-class
	change operations and not versions or revisions
	
	- create SpyWare platform that intgrates various aspects to aid developer
	
	* provide any-time access to changes
	
	* visualize changes of software entities
	
	- store changes in a repository
	
	- model evolution as a sequence of changes, related by transformations
	from one state to the other
	
	-> granularity of artifacts: class/method-level, not file or statement
	level
	
	-> granularity of changes: atomic changes (add/delete) and composite
	changes; changes for packages, classes, methods, variables and statements
	are considered
	
	-> granularity of results: no details
	
	
	Open Issues:
	
	- tool not useful for already existing projects where no incremental
	data could be gather (in contrast to other history based approaches
	which have problems with new projects)
	
	- tool is for single-user only, not multi-user},
  timestamp = {2011.02.24}
}

@ARTICLE{Robbes2007a,
  author = {Robbes, Romain and Lanza, Michele},
  title = {A Change-based Approach to Software Evolution},
  journal = {Electronic Notes in Theoretical Computer Science},
  year = {2007},
  volume = {166},
  pages = {93-109},
  month = {January},
  file = {:./literature/Paper_96.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- current version control systems do not store all available information,
	only those that were commited; intermediate information gets lost
	
	- software analyis tools not integrated into actual development tools
	
	- analysis spent on version control systems expensive due to vast
	amount of data
	
	- hard to track software entities which are spread across several
	different files in current version control systems
	
	
	Research Questions:
	
	- how to achieve incremental change information by listening to changes
	done in the IDE
	
	- how to overcome limitations of current version control systems where
	it is possible to merge different changes in a single commit and
	therefore loosing too much (change-) information
	
	
	Contribution:
	
	- model development information as change operations, retrieved from
	the development environment
	
	- integrate analysis features into development environment to assit
	developer
	
	- alternative data source for history-based approaches for impact
	analysis
	
	
	Solution:
	
	- approach based on two concepts:
	
	* integration of analysis into IDE
	
	* a model based on first-class change operations (modeling the history
	in an incremental way)
	
	- hook into IDEs notification system when software entities are changed,
	recompiled etc.
	
	- for granularity of approach, see {Robbes2008c}
	
	
	Open Issues:
	
	- approch not suitable when trying to use with already developed project
	where no incremental data is available
	
	- approach is language specific
	
	- see {Robbes2008c}},
  timestamp = {2011.02.24}
}

@INCOLLECTION{Robbes2007b,
  author = {Robbes, Romain and Lanza, Michele and Lungu, Mircea},
  title = {An Approach to Software Evolution Based on Semantic Change},
  booktitle = {Fundamental Approaches to Software Engineering},
  publisher = {Springer Berlin / Heidelberg},
  year = {2007},
  volume = {4422},
  series = {Lecture Notes in Computer Science},
  pages = {27-41},
  file = {:./literature/Paper_95.pdf:PDF},
  journal = {Fundamental Approaches to Software Engineering},
  owner = {Steffen},
  review = {same as {Robbes2007a} and {Robbes2008c}},
  timestamp = {2011.02.24}
}

@TECHREPORT{Robbes2008b,
  author = {Robbes, Romain and Lanza, Michele and Pollet, Damien},
  title = {A Benchmark for Change Prediction},
  institution = {Faculty of Informatics, Università della Svizzerra Italiana},
  year = {2008},
  number = {06},
  address = {Lugano, Switzerland},
  month = {October},
  booktitle = {Faculty of Informatics, Università della Svizzerra Italiana, Lugano,
	Switzerland},
  file = {:./literature/Paper_63.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- current IA approaches evaluated by using data from versioning systsms
	
	- however, this does not provide valid basis for objective evaluation
	(since data is not very accurate)
	
	- no chronology of changes within one set of changes
	
	- change sets can become too big (bulk updates)
	
	- lots of unnecessary information in changes which do not express
	real code changes
	
	
	Research Questions:
	
	- decide which IA approach (for forward and and re-engineering) is
	best suited for change prediction / change discovery
	
	
	Contribution:
	
	- benchmark for objective evaluation of IA approaches based on fine-grained
	data from IDE usage
	
	- new approach that records sequence of change and exact content (change-based
	software evolution [CBSE])
	
	
	Solution:
	
	- benchmarking procedure:
	
	* run algorithm to compute his prediction set
	
	* compare to actual change and implement change
	
	* perform this with all algorithms (IA approaches) and gather rate
	of false-positives and missed changes
	
	* measure accuracy for fain- (method-level) and coarse-grained prediction
	(class-level)
	
	- following approaches were evaluated:
	
	* association rules mining
	
	* degree of interest (Mylyn)
	
	* coupling-based
	
	* association rules with time coupling
	
	* HITS (similar to PageRank)
	
	* merged approaches
	
	-> HITS performed best
	
	-> as did the combination of change coupling + association rules (proposed
	by Kagdi)
	
	
	Open Issues:
	
	- not all approaches could be measure with all test data
	
	- test data too small},
  timestamp = {2011.02.10}
}

@BOOK{Robertson2006,
  title = {Mastering the requirements process},
  publisher = {Addison-Wesley Professional},
  year = {2006},
  author = {Robertson, S. and Robertson, J.},
  owner = {patrickr},
  timestamp = {2012.03.08}
}

@BOOK{Robertson1999,
  title = {Mastering the Requirements Process},
  publisher = {Addison-Wesley},
  year = {1999},
  author = {Robertson, Suzanne and Robertson, James},
  owner = {Stephan},
  timestamp = {2010.11.10}
}

@ARTICLE{Robinson2003,
  author = {Robinson, William N. and Pawlowski, Suzanne D. and Volkov, Vecheslav},
  title = {Requirements Interaction Management},
  journal = {ACM Computing Surveys},
  year = {2003},
  volume = {35},
  pages = {132-190},
  number = {2},
  month = {June},
  abstract = {Requirements interaction management (RIM) is the set of activities
	directed toward the discovery, management, and disposition of critical
	relationships among sets of requirements, which has become a critical
	area of requirements engineering. This survey looks at the evolution
	of supporting concepts and their related literature, presents an
	issues-based framework for reviewing processes and products, and
	applies the framework in a review of RIM state-of-the-art. Finally,
	it presents seven research projects that exemplify this emerging
	discipline.},
  acmid = {857079},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/857076.857079},
  file = {:./literature/Robinson2003.pdf:PDF},
  issn = {0360-0300},
  issue = {2},
  keywords = {KAOS, KATE, Oz, Requirements engineering, Telos, WinWin, analysis
	and design, composite system, deficiency driven design, dependency
	analysis, distributed intentionality, interaction analysis, software
	cost reduction (SCR)., system architecture, system specification,
	viewpoints},
  numpages = {59},
  owner = {Stephan},
  publisher = {ACM},
  timestamp = {2011.01.16}
}

@INPROCEEDINGS{Rochimah2007,
  author = {Rochimah, S. and Wan Kadir, W.M.N. and Abdullah, A. H.},
  title = {An Evaluation of Traceability Approaches to Support Software Evolution},
  booktitle = {Proceedings of the 2nd International Conference on Advances in Software
	Engineering},
  year = {2007},
  file = {:./literature/Paper_217.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.30}
}

@ARTICLE{Rodriguez2007,
  author = {Rodr{\'\i}guez, A. and Fern{\'a}ndez-Medina, E. and Piattini, M.},
  title = {A bpmn extension for the modeling of security requirements in business
	processes},
  journal = {IEICE transactions on information and systems},
  year = {2007},
  volume = {90},
  pages = {745--752},
  number = {4},
  file = {Rodriguez2007.pdf:literature/Rodriguez2007.pdf:PDF},
  owner = {patrickr},
  publisher = {The Institute of Electronics, Information and Communication Engineers},
  timestamp = {2012.11.30}
}

@INPROCEEDINGS{Rolland1998,
  author = {Rolland, C.},
  title = {A comprehensive view of process engineering},
  booktitle = {Advanced Information Systems Engineering},
  year = {1998},
  pages = {1--24},
  organization = {Springer},
  file = {Rolland1998.pdf:literature/Rolland1998.pdf:PDF},
  owner = {patrickr},
  review = {Contribution:
	
	* Application of Four-Worlds process modeling framework (subject world,
	usage world, system world, development world) to "Software development
	process engineering"},
  timestamp = {2012.08.06}
}

@INPROCEEDINGS{Rolland1997,
  author = {Rolland, C.},
  title = {A primer for method engineering},
  booktitle = {Proceedings of the conference INFORSID (INFormatique des ORganisations
	et Systèmes d'Information et de Décision)},
  year = {1997},
  file = {Rolland1997.pdf:literature/Rolland1997.pdf:PDF},
  journal = {Proceedings of the Infor},
  owner = {patrickr},
  review = {Contribution:
	
	* Application of Four-Worlds process modeling framework (subject world,
	usage world, system world, development world) to "method engineering"},
  timestamp = {2012.08.15}
}

@ARTICLE{Rolland2010,
  author = {Rolland, C. and Kirsch-Pinheiro, M. and Souveyet, C.},
  title = {An intentional approach to service engineering},
  journal = {Services Computing, IEEE Transactions on},
  year = {2010},
  volume = {3},
  pages = {292--305},
  number = {4},
  file = {Rolland2010.pdf:literature/Rolland2010.pdf:PDF},
  owner = {patrickr},
  publisher = {IEEE},
  timestamp = {2012.12.19}
}

@ARTICLE{Rolland1999,
  author = {Rolland, C. and Prakash, N. and Benjamen, A.},
  title = {A multi-model view of process modelling},
  journal = {Requirements Engineering},
  year = {1999},
  volume = {4},
  pages = {169--187},
  number = {4},
  file = {Rolland1999.pdf:literature/Rolland1999.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.12.11}
}

@ARTICLE{Rolland1998a,
  author = {Rolland, C. and Souveyet, C. and Achour, C.B.},
  title = {Guiding goal modeling using scenarios},
  journal = {Software Engineering, IEEE Transactions on},
  year = {1998},
  volume = {24},
  pages = {1055--1071},
  number = {12},
  file = {Rolland1998a.pdf:literature/Rolland1998a.pdf:PDF},
  owner = {patrickr},
  publisher = {IEEE},
  timestamp = {2012.12.18}
}

@ARTICLE{841112,
  author = {Ropponen, J. and Lyytinen, K.},
  title = {Components of software development risk: how to address them? A project
	manager survey},
  journal = {Software Engineering, IEEE Transactions on},
  year = {2000},
  volume = {26},
  pages = {98 -112},
  number = {2},
  month = {feb},
  abstract = {Software risk management can be defined as an attempt to formalize
	risk oriented correlates of development success into a readily applicable
	set of principles and practices. By using a survey instrument we
	investigate this claim further. The investigation addresses the following
	questions: 1) What are the components of software development risk?
	2) how does risk management mitigate risk components, and 3) what
	environmental factors if any influence them? Using principal component
	analysis we identify six software risk components: 1) scheduling
	and timing risks, 2) functionality risks, 3) subcontracting risks,
	4) requirements management, 5) resource usage and performance risks,
	and 6) personnel management risks. By using one-way ANOVA with multiple
	comparisons we examine how risk management (or the lack of it) and
	environmental factors (such as development methods, manager's experience)
	influence each risk component. The analysis shows that awareness
	of the importance of risk management and systematic practices to
	manage risks have an effect on scheduling risks, requirements management
	risks, and personnel management risks. Environmental contingencies
	were observed to affect all risk components. This suggests that software
	risks can be best managed by combining specific risk management considerations
	with a detailed understanding of the environmental context and with
	sound managerial practices, such as relying on experienced and well-educated
	project managers and launching correctly sized projects},
  doi = {10.1109/32.841112},
  issn = {0098-5589},
  keywords = {environmental contingencies;environmental factors;functionality risks;multiple
	comparisons;one-way ANOVA;performance risks;personnel management
	risks;principal component analysis;project manager survey;requirements
	management;resource usage;scheduling risks;software development risk
	management;subcontracting risks;timing risks;principal component
	analysis;risk management;software development management;},
  owner = {elkeb},
  review = {zeigt eine konkrete Studie zu Risikomanagement in der Praxis},
  timestamp = {2011.07.01}
}

@INPROCEEDINGS{Rosa2001,
  author = {Rosa, Nelson S. and Justo, George R. R. and Cunha, Paulo R. F.},
  title = {A framework for building non-functional software architectures},
  booktitle = {Proceedings of the 2001 ACM symposium on Applied computing, SAC '01},
  year = {2001},
  pages = {141-147},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Non-functional requirements ( NFRs ) are rarely taken in account in
	most software development processes. There exist reasons that can
	help us to understand why these requirements are not explicitly dealt
	with: their complexity, their usually informal statement, their high
	abstraction level, as well as the rare support of languages, methodologies
	and tools for them. In this paper, we introduce a framework for explicitly
	dealing with NFRs in the software development process. This framework
	addresses the description, integration with functional requirements,
	reﬁnement and mapping of NFRs into actual implementation elements.},
  doi = {http://doi.acm.org/10.1145/372202.372299},
  file = {:./literature/CM20.pdf:PDF},
  isbn = {1-58113-287-5},
  keywords = {non-functional requirements, quality, architecture},
  location = {Las Vegas, Nevada, United States},
  owner = {Stephan},
  review = {Parmenides framework
	
	
	formal description of NFR-Attributes, NFR-Requirements and NFR-Realisations
	in process-oriented language and a product-oriented language
	
	
	process approach:
	
	- first description of functional requirements
	
	- description of software architecture
	
	- description of non-functional requirements
	
	- process-NFL specification
	
	- combination to abstracht non-functional software architecture
	
	--> mapping of NFR to existing architectural components with decomposition
	rules
	
	--> concrete non-functional software architecture},
  timestamp = {2009.07.24}
}

@INPROCEEDINGS{Rosenblum1997,
  author = {David Rosenblum and Gregg Rothermel},
  title = {A Comparative Study of Regression Test Selection Techniques},
  booktitle = {In Proc. of the 2nd Int'l. Workshop on Empir. Studies of Softw. Maint},
  year = {1997},
  pages = {89--94},
  __markedentry = {[qurat:]},
  file = {:/literature/RegressionTesting/a comparitive study of regression test selection teshniques.pdf:PDF},
  keywords = {COMPARITIVE, Read, Relevant},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@ARTICLE{Rosenblum1996,
  author = {Rosenblum, David S. and Weyuker, Elaine J.},
  title = {Predicting the cost-effectiveness of regression testing strategies},
  journal = {SIGSOFT Softw. Eng. Notes},
  year = {1996},
  volume = {21},
  pages = {118--126},
  month = {October},
  __markedentry = {[qurat:]},
  acmid = {239118},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/250707.239118},
  file = {:/literature/RegressionTesting/Predicting the Cost-Effectiveness of Regression Testing Strategies.pdf:PDF},
  issn = {0163-5948},
  issue = {6},
  keywords = {cost estimation, regression testing, software analysis, test coverage
	comparative analysiss},
  numpages = {9},
  owner = {Annie},
  publisher = {ACM},
  timestamp = {2011.10.20},
  url = {http://doi.acm.org/10.1145/250707.239118}
}

@ARTICLE{Rothermel1996,
  author = {Rothermel, G. and Harrold, M.J.},
  title = {Analyzing regression test selection techniques},
  journal = {Software Engineering, IEEE Transactions on},
  year = {1996},
  volume = {22},
  pages = {529 -551},
  number = {8},
  month = {aug},
  __markedentry = {[qurat:]},
  doi = {10.1109/32.536955},
  file = {:/literature/RegressionTesting/analyzing regression test selection techniques.pdf:PDF},
  issn = {0098-5589},
  keywords = {comparative analysis, framework;program test reuse;regression test
	selection techniques;selective retest;software maintenance;test suite;program
	debugging;program testing;software maintenance;software reusability;statistical
	analysis;},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@ARTICLE{Rothermel1997,
  author = {Rothermel, Gregg and Harrold, Mary Jean},
  title = {A safe, efficient regression test selection technique},
  journal = {ACM Trans. Softw. Eng. Methodol.},
  year = {1997},
  volume = {6},
  pages = {173--210},
  month = {April},
  __markedentry = {[qurat:]},
  acmid = {248262},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/248233.248262},
  file = {:/literature/RegressionTesting/a safe efficient regression test selection technique.pdf:PDF},
  issn = {1049-331X},
  issue = {2},
  keywords = {regression test selection, regression testing, selective retest, code
	baseds},
  numpages = {38},
  owner = {Annie},
  publisher = {ACM},
  timestamp = {2011.10.20},
  url = {http://doi.acm.org/10.1145/248233.248262}
}

@ARTICLE{Rothermel1997a,
  author = {Rothermel, Gregg and Harrold, Mary Jean},
  title = {Experience With Regression Test Selection},
  journal = {Empirical Softw. Engg.},
  year = {1997},
  volume = {2},
  pages = {178--188},
  month = {February},
  __markedentry = {[qurat:]},
  acmid = {594398},
  address = {Hingham, MA, USA},
  doi = {10.1023/A:1009765704299},
  file = {:/literature/RegressionTesting/experience with regression test selection.pdf:PDF},
  issn = {1382-3256},
  issue = {2},
  keywords = {comparative analysis},
  numpages = {11},
  owner = {Annie},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=594372.594398}
}

@INPROCEEDINGS{Rothermel1994,
  author = {Rothermel, Gregg and Harrold, Mary Jean},
  title = {Selecting Regression Tests for Object-Oriented Software},
  booktitle = {Proceedings of the International Conference on Software Maintenance},
  year = {1994},
  series = {ICSM '94},
  pages = {14--25},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[qurat:]},
  acmid = {655717},
  file = {:/literature/RegressionTesting/selecting regression test for object oriented software.pdf:PDF},
  isbn = {0-8186-6330-8},
  keywords = {Read, Relevant, code baseds},
  numpages = {12},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=645543.655717}
}

@INPROCEEDINGS{Rothermel1993,
  author = {Rothermel, Gregg and Harrold, Mary Jean},
  title = {A Safe, Efficient Algorithm for Regression Test Selection},
  booktitle = {Proceedings of the Conference on Software Maintenance},
  year = {1993},
  series = {ICSM '93},
  pages = {358--367},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[qurat:]},
  acmid = {658172},
  file = {:/literature/RegressionTesting/a safe efficient algoritham for regression test selection.pdf:PDF},
  isbn = {0-8186-4600-4},
  keywords = {code based},
  numpages = {10},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=645542.658172}
}

@INPROCEEDINGS{Roettger2003,
  author = {Simone Röttger and Steffen Zschaler},
  title = {CQML+: Enhancements to CQML},
  booktitle = {Proc. 1st Int'l Workshop on Quality of Service in Component-Based
	Software Engineering, Toulouse, France},
  year = {2003},
  editor = {J.-M. Bruel},
  pages = {43-56},
  month = jun,
  publisher = {Cépaduès-Éditions},
  file = {:./literature/qoscbse03-language.pdf:PDF},
  keywords = {CQML, modeling non-functional requirements},
  owner = {Stephan},
  timestamp = {2008.06.13},
  url = {http://www-st.inf.tu-dresden.de/comquad/qoscbse03-language.pdf}
}

@ARTICLE{Roettger2007,
  author = {Simone Röttger and Steffen Zschaler},
  title = {Tool Support for Refinement of Non-functional Specifications},
  journal = {Software and Systems Modeling (SoSyM)},
  year = {2007},
  volume = {6},
  pages = {185-204},
  number = {2},
  month = {June},
  abstract = {Model driven architecture (MDA) views application development as a
	continuous transformation of models of the target system. We propose
	a methodology which extends this view to non-functional properties.
	In previous publications we have shown how we can use so-called context
	models to make the specification of non-functional measurements independent
	of their application in concrete system specifications. We have also
	shown how this allows us to distinguish two roles in the development
	process: the measurement designer and the application designer.
	
	In this paper we use the notion of context models to allow the measurement
	designer to provide measurement definitions at different levels of
	abstraction. A measurement in our terminology is a non-functional
	dimension that can be constrained to describe a non-functional property.
	Requiring the measurement designer to define transformations between
	context models, and applying them to measurement definitions, enables
	us to provide tool support for refinement of non-functional constraints
	to the application designer. The paper presents the concepts for
	such tool support as well as a prototype implementation.},
  comment = {Special Issue Paper},
  doi = {10.1007/s10270-006-0024-x},
  file = {:./literature/roettger_zschaler_sosym_06.pdf:PDF},
  keywords = {Non-functional Properties, Model Transformation, Refinement, CASE
	tool support},
  owner = {Stephan},
  review = {description of an approach that uses context models to specify non-functional
	measurements at different levels of abstraction
	
	- tool support for approach provided
	
	
	basics
	
	---------
	
	measurement:
	
	- non-functional dimension that can be constrained to describe a NF
	property
	
	- mapping from states, objects, or events of a physical system (e.g.
	an implemented and running application) to a formal system (e.g.
	the set of real numbers)
	
	- examples: response time (mapping from operation call to real number),
	or confidentiality (mapping from information channel to value indicating
	level of confidentiality)
	
	- once a measurement has been modeled ->resuse it for different applications
	
	-> use of context models:
	
	- models of the relevant aspects of target applications
	
	- applied to system models specific for application
	
	- representation of different levels of abstraction for a measurement
	
	
	2 roles in development process: measurement designer, application
	designer
	
	- application designer: thinks about and creates functional model
	at different levels of abstraction
	
	- measurement designer: creation of library of measurements -> non-functional
	model - context models and transformations
	
	
	development process for non-functional properties
	
	---------------------------------------------------------------------
	
	- application designer switches between modelling and refining NF
	properties of components
	
	- separation of measurement definition and usage
	
	- measurement usage: specification of NF properties of applications
	using these measurements
	
	
	process:
	
	1) definition of measurements at different levels of abstraction by
	measurements designer
	
	2) use of measurements by application designer
	
	3) tool-supported refinement of measurements by application designer
	
	4) modelling and refinement of connectors between components during
	assembly process
	
	
	3rd role: component developer:
	
	- provide implementations
	
	- test NF properties of components
	
	- translate test results into NF specification for each component
	implementation
	
	
	languages:
	
	- UML 2.0 for functional model: added representation for streaming
	ports
	
	- CQML+ for non-functional specifications
	
	
	NF refinement
	
	- 2 kinds: structural refinement and measurement refinement (here
	focus on latter)
	
	-> transformations (in CQML+) between contexts models of different
	levels of abstraction
	
	
	2 kinds of transformations:
	
	- classifier transformations: type replacements
	
	- feature transformations: replacement of features (attributes, navigations,
	operation calls) from more abstract to finer model
	
	
	toolkit
	
	--------
	
	measurement workbench: definition of measurements, classification
	-> measurement repository
	
	measurement transformation engine: refinement of measurements -> meta-model
	for CQML+ used
	
	component test container: for component developer
	
	CASE tool integration for application development: usage of measurements
	
	
	open issues
	
	-----------------
	
	- management of large number of context models on different levels
	of abstraction
	
	-> complexity must be reduced for easier refinement by application
	designer
	
	- no case study until now
	
	
	critics
	
	--------
	
	- all depends on measurement designer and his responsibility to specify
	measurements, context models, and transformations
	
	-> what if measurement definition for NF aspect not possible?
	
	
	- in contrast to NFR framework [Chung et al.] focussed on modelling
	NF properties at design time and on realisation
	
	- framework leaves open how requirements can be achieved by application
	
	
	interesting references
	
	------------------------------
	
	- Malan & Bredemeyer: Defining non-functional requirements
	
	- Röttger & Zschaler: CQML+
	
	- Zschaler: Towards semantic framework for non-functional specification
	of component-based systems},
  timestamp = {2008.04.02},
  url = {http://www.steffen-zschaler.de/publications/roettger_zschaler_sosym_06.pdf}
}

@INPROCEEDINGS{Rowe1997,
  author = {Rowe, D. and Leaney, J.},
  title = {Evaluating evolvability of computer based systems architectures-an
	ontological approach},
  booktitle = {Engineering of Computer-Based Systems, 1997. Proceedings., International
	Conference and Workshop on},
  year = {1997},
  pages = {360-367},
  month = {Mar},
  publisher = {IEEE},
  abstract = {System evolvability is a system's ability to withstand changes in
	its requirements, environment and implementation technologies. The
	need for greater systems evolvability is becoming recognised, especially
	in the engineering of computer based systems, where the development,
	commissioning and replacement of large systems is highly resource
	intensive. Despite this need, there are no formal means for evaluating
	the evolvability of a system and thus no means of proving that one
	system is more evolvable than another. Recognising this, we review
	the nature of change and evolution with respect to computer based
	systems. We contend that a systems architecture is the best level
	of abstraction at which to evaluate its evolvability. An ontological
	basis which allows for the formal definition of a system and its
	change at the architectural level is presented and applied to the
	domain of computer based systems engineering. Utilising this definition
	of change we draw on the deeper ontological theories in order to
	establish a model of systems architecture evolution. This model is
	then applied to a small CBS for concept validation.},
  doi = {10.1109/ECBS.1997.581903},
  file = {:./literature/Rowe_EvaluatingEvolvability.pdf:PDF},
  keywords = {formal specification, systems engineeringcomputer based system, computer
	based systems architectures, concept validation, evolvability, ontological
	approach, systems architecture},
  owner = {Stephan},
  timestamp = {2009.02.17}
}

@INPROCEEDINGS{Rowe1998,
  author = {David Rowe and John Leaney and David Lowe},
  title = {Defining systems architecture evolvability - a taxonomy of change},
  booktitle = {Proceedings of the 11th International Conference on the Engineering
	of Computer Based Systems (ECBS'98)},
  year = {1998},
  pages = {45-52},
  address = {Jerusalem, Israel},
  publisher = {IEEE},
  abstract = {Evolvability is part of the alchemy of systems engineering. Designing
	a system that is evolvable is considered best practice in many industry
	domains. However, what does ‘evolvable’ mean? And in what context
	does a system evolve? Reviewing the many factors of system change
	and their associated definitions, we conclude that a single definition
	for ‘evolvability’ is not adequate. We assert that evolvability is
	a composite quality which allows a system’s architecture to accommodate
	change in a cost effective manner while maintaining the integrity
	of the architecture.
	
	In order to define evolvability as a composite, we propose a taxonomy
	which classifies the different aspects of evolvability. Using this
	taxonomy to select relevant systems architecting and design approaches,
	a systems architect can be confident in including those aspects of
	evolution most suitable to a particular application.
	
	The concepts introduced in this paper are applied to the Ericsson
	AXE telecommunications switching systemfor illustration and justification.},
  file = {:./literature/1998-Row98a.pdf:PDF},
  keywords = {system architecture evolvability, taxonomy, software change},
  owner = {Stephan},
  review = {definitions for terms of change:
	
	- adaptability
	
	- changeability
	
	- flexibility
	
	- extensibility
	
	- enhanceability
	
	
	states existing definitions for evolveability
	
	
	important attributes of system change: scalability, generality, evolvability
	
	
	qualities that contribute to evolveability:
	
	- generality
	
	- adaptability
	
	- scalability
	
	- extensibility
	
	
	-> refined definition for evolveability:
	
	"An attribute that bears on the ability of a system to accommodate
	change in its requirements throughout the system’s lifespan with
	the least possible cost while maintaining architectural integrity."
	
	
	- further examination of sub-qualities on Ericson AXE telecommunication
	switching system},
  timestamp = {2008.07.08},
  url = {http://services.eng.uts.edu.au/~dbl/archive/1998-Row98a.pdf}
}

@INPROCEEDINGS{Roy2006,
  author = {Jean-Francois Roy and Jason Kealey and Daniel Amyot},
  title = {Towards Integrated Tool Support for the User Requirements Notation},
  booktitle = {SAM 2006: Language Profiles - Fifth Workshop on System Analysis and
	Modelling},
  year = {2006},
  volume = {4320},
  series = {LNCS},
  pages = {198-215},
  publisher = {Springer},
  abstract = {The User Requirements Notation (URN) combines the Goal-oriented Requirement
	Language (GRL) with the Use Case Map (UCM) scenario notation. Although
	tools exist in isolation for both views, they are currently not meant
	to work together, hence preventing one to exploit URN to its fullest
	extent. This paper presents jUCMNav, a new Eclipse-based tool that
	supports both UCM and GRL in an integrated way. jUCMNav supports
	links between the two languages that can be exploited during analysis.
	An overview of the current editing and analysis capabilities is given,
	with a particular emphasis on the new concept of GRL strategies,
	which simplify the evaluation of GRL models. The extensibility of
	the tool is also discussed.},
  doi = {10.1007/11951148_13},
  file = {:./literature/Roy2006.pdf:PDF},
  keywords = {URN, tool support, goal-oriented modelling, jUCMNav, use case maps,
	goal-oriented requirement language},
  owner = {Stephan},
  timestamp = {2009.01.26}
}

@BOOK{Rozanski2005,
  title = {Software Systems Architecture: Working With Stakeholders Using Viewpoints
	and Perspectives},
  publisher = {Addison-Wesley Professional},
  year = {2005},
  author = {Rozanski, Nick and Woods, E\'{o}in},
  isbn = {0321112296},
  keywords = {software architecture},
  owner = {Stephan},
  timestamp = {2011.01.05}
}

@MISC{Rugaber1995,
  author = {S. Rugaber},
  title = {Program Comprehension},
  howpublished = {Encyclopedia of Computer Science and Technology},
  year = {1995},
  citeseerurl = {http://citeseer.ist.psu.edu/rugaber95program.html},
  file = {:./literature/encyc.pdf:PDF},
  keywords = {program comprehension},
  owner = {Robert},
  text = {Rugaber, S. Program Comprehension, in Encyclopedia of Computer Science
	and Technology, 35(20), Marcel Dekker, Inc:New York, 341-368,1995.},
  timestamp = {2008.07.16},
  url = {http://www-static.cc.gatech.edu/reverse/repository/encyc.ps}
}

@BOOK{Rumbaugh2004,
  title = {The Unified Modeling Language Reference Manual},
  publisher = {Addison-Wesley Professional},
  year = {2004},
  author = {Rumbaugh, James and Jacobson, Ivar and Booch, Grady},
  series = {Addison-Wesley Object Technology Series},
  edition = {2nd},
  abstract = {{Written by the three pioneers behind the Unified Modeling Language
	(UML) standard, <I>The Unified Modeling Language Reference Manual</I>
	provides an excellent real-world guide to working with UML. This
	title provides expert knowledge on all facets of today's UML standard,
	helping developers who are encountering UML on the job for the first
	time to be more productive.<p> The book begins with a history of
	UML, from structured design methods of the '60s and '70s to the competing
	object-oriented design standards that were unified in 1997 to create
	UML. For the novice, the authors illustrate key diagram types such
	as <I>class</I>, <I>use case</I>, <I>state machine</I>, <I>activity</I>,
	and <I>implementation</I>. (Of course, learning these basic diagram
	types is what UML is all about. The authors use an easy-to-understand
	ticket-booking system for many of their examples.)<p> After a tour
	of basic document types, <I>The Unified Modeling Language Reference
	Manual</I> provides an alphabetical listing of more than 350 UML
	terms. Entries range from a sentence or two to several pages in length.
	(<I>Class</I>, <I>operation</I>, and <I>use case</I> are just a few
	of the important terms that are covered.) Though you will certainly
	need to be acquainted with software engineering principles, this
	reference will serve the working software developer well. As the
	authors note, this isn't <I>UML for Dummies</I>, but neither is it
	an arcane academic treatise. The authors succeed in delivering a
	readable reference that will answer any UML question, no matter how
	common or obscure. <I>--Richard Dragan</I>} {The authors have done
	an outstanding job with this UML book. The definitions of the terms
	are the best I have seen. The organization and material in the encyclopedia
	are fantastic!<BR> -Perry Cole, MCIWorldCom <p>The Unified Modeling
	Language (UML) has rapidly become the standard notation for modeling
	software-intensive systems. This book provides the definitive description
	of UML from its original developers--James Rumbaugh, Ivar Jacobson,
	and Grady Booch. Whether you are capturing requirements, developing
	a software architecture, designing the implementation, or trying
	to understand an existing system, this is the book for you. <BR>
	<br> The majority of the book is a unique alphabetical list of articles
	covering every aspect of UML in a form convenient for quick reference
	and detailed study. This format permits full coverage of UML details
	as well as high-level articles without confusing the reader by constant
	shifts in level. The first part of the book--a complete summary of
	UML concepts organized by subject area--provides an introduction
	to UML for the newcomer as well as entry points into the detailed
	articles. <BR> <br>Highlights of the book include: <BR> Two-color
	diagrams, extensively annotated <BR> Thorough coverage of both semantics
	and notation, separated in each article for easy reference <BR> Further
	explanations of concepts whose meaning or purpose is obscure in the
	original specifications <BR> Discussion sections offering usage advice
	and additional insight into tricky concepts <BR> A hyperlinked version
	of the book in Adobe Reader format on CD-ROM, an excellent resource
	for browsing or searching the text for specific information <BR>
	Full text of the UML specification documents on CD-ROM, courtesy
	of the Object Management Group <BR> Notation summary, with hyperlinks
	to individual articles on CD-ROM}},
  citeulike-article-id = {500637},
  howpublished = {Hardcover},
  isbn = {0321245628},
  keywords = {UML},
  owner = {Robert},
  posted-at = {2006-02-10 16:16:50},
  priority = {2},
  timestamp = {2008.05.05},
  url = {http://www.amazon.com/Modeling-Language-Reference-Addison-Wesley-Technology/dp/0321245628}
}

@MASTERSTHESIS{Rumpf2009,
  author = {Matthias Rumpf},
  title = {{Evolution\"are Softwarearchitekturentwicklung mit der Methode Attribute
	Driven Design (ADD)}},
  school = {Ilmenau University of Technology},
  year = {2009},
  type = {Diploma thesis},
  month = {Oct},
  file = {:./literature/DA_ADD_Rumpf_091020.pdf:PDF},
  keywords = {ADD, Attribute Driven Design, evolvability},
  owner = {Stephan},
  timestamp = {2010.11.17}
}

@ARTICLE{Runeson2009,
  author = {Runeson, Per and H\"{o}st, Martin},
  title = {Guidelines for conducting and reporting case study research in software
	engineering},
  journal = {Journal of Empirical Software Engineering},
  year = {2009},
  volume = {14},
  pages = {131-164},
  file = {:./literature/Paper_188.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.11.14}
}

@INPROCEEDINGS{Rungta2012,
  author = {Rungta, Neha and Person, Suzette and Branchaud, Joshua},
  title = {A Change-Impact Analysis to Characterize Evolving Program Behaviors},
  booktitle = {Proceedings of the 28th IEEE International Conference on Software
	Maintenance},
  year = {2012},
  address = {Riva del Garda, Trento, Italy},
  month = {September},
  file = {:./literature/Paper_256.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.08.08}
}

@BOOK{Rupp2004,
  title = {Requirements- Engineering und -Management},
  publisher = {SOPHIST GROUP, Carl Hanser Verlag München Wien},
  year = {2004},
  author = {Chris Rupp},
  address = {Nürnberg},
  edition = {3},
  keywords = {requirements engineering, requirements management},
  language = {german},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://www.hanser.de/buch.asp?isbn=3-446-40509-7}
}

@TECHREPORT{Russel2006,
  author = {Russel, N. and van der Aalst, WMP and ter Hofstede, A.},
  title = {Exception handling patterns in process-aware information systems},
  institution = {BPM Center Report BPM-06-04},
  year = {2006},
  file = {Russel2006.pdf:literature/Russel2006.pdf:PDF},
  owner = {patrickr},
  pages = {06--04},
  timestamp = {2012.11.26}
}

@INPROCEEDINGS{Russell2006a,
  author = {Russell, N. and van der Aalst, W. and ter Hofstede, A.},
  title = {Workflow exception patterns},
  booktitle = {Advanced Information Systems Engineering},
  year = {2006},
  pages = {288--302},
  organization = {Springer},
  file = {Russell2006a.pdf:literature/Russell2006a.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.11.26}
}

@INPROCEEDINGS{Russell2005a,
  author = {Russell, N. and van der Aalst, W. and Ter Hofstede, A. and Edmond,
	D.},
  title = {Workflow resource patterns: Identification, representation and tool
	support},
  booktitle = {Advanced Information Systems Engineering},
  year = {2005},
  pages = {11--42},
  organization = {Springer},
  file = {Russell2005a.pdf:literature/Russell2005a.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.11.26}
}

@ARTICLE{Russell2005,
  author = {Russell, N. and ter Hofstede, A. and Edmond, D. and van der Aalst,
	W.},
  title = {Workflow data patterns: Identification, representation and tool support},
  journal = {Conceptual Modeling--ER 2005},
  year = {2005},
  pages = {353--368},
  file = {Russell2005.pdf:literature/Russell2005.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.11.26}
}

@TECHREPORT{Russell2004,
  author = {Nick Russell and Arthur H. M. Ter Hofstede and David Edmond},
  title = {Workflow data patterns},
  institution = {Eindhoven University of Technology},
  year = {2004},
  file = {Russell2004.pdf:literature/Russell2004.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.11.26}
}

@TECHREPORT{Russell2004a,
  author = {Russell, N. and Ter Hofstede, A.H.M. and Edmond, D. and van der Aalst,
	W.M.P.},
  title = {Workflow resource patterns},
  institution = {Eindhoven University of Technology},
  year = {2004},
  file = {Russell2004a.pdf:literature/Russell2004a.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.11.26}
}

@TECHREPORT{Russell2006,
  author = {Russell, N. and Ter Hofstede, A.H.M. and Mulyar, N.},
  title = {Workflow controlflow patterns: A revised view},
  institution = {Eindhoven University of Technology},
  year = {2006},
  file = {Russell2006.pdf:literature/Russell2006.pdf:PDF},
  owner = {patrickr},
  publisher = {Citeseer},
  timestamp = {2012.11.26}
}

@INPROCEEDINGS{Ruth2007,
  author = {Ruth, M. and Sehun Oh and Loup, A. and Horton, B. and Gallet, O.
	and Mata, M. and Shengru Tu},
  title = {Towards Automatic Regression Test Selection for Web Services},
  booktitle = {Computer Software and Applications Conference, 2007. COMPSAC 2007.
	31st Annual International},
  year = {2007},
  volume = {2},
  pages = {729 -736},
  month = {july},
  doi = {10.1109/COMPSAC.2007.219},
  file = {:/literature/RegressionTesting/Towards Automatic Regression Test Selection for Web Services.pdf:PDF},
  issn = {0730-3157},
  keywords = {WSRT, Web service;automatic regression test selection;program verification;system
	monitoring;Web services;program testing;program verification;system
	monitoring;},
  owner = {Steffen},
  review = {+ a CFG is generated for each operation of a service
	
	
	+ the CFG's of composite services have call nodes. 
	
	+ All call nodes are replaced with the CFG's of appropriate services
	to construct a global CFG
	
	
	+no service discovery and lookup is considered.
	
	+Each CFG node contains the hashcode of the corresponding program
	construct.
	
	+ A dual travesal is carried out to find the parts of graph which
	are different. 
	
	 +structual differences in the graph
	
	 +content differences identified by hash code.
	
	Synchrounous and sequentail changes are considered to identify the
	location of faults.
	
	
	Pseudo codes are provided
	
	
	a case study of bank loan system with three major services is provided
	
	the selectivity of composite service was less then simple services.},
  timestamp = {2012.03.01}
}

@INPROCEEDINGS{Ruth2007a,
  author = {Ruth, Michael and Tu, Shengru},
  title = {A Safe Regression Test Selection Technique for Web Services},
  booktitle = {Proceedings of the Second International Conference on Internet and
	Web Applications and Services},
  year = {2007},
  pages = {47--},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid = {1260609},
  doi = {10.1109/ICIW.2007.8},
  file = {:/literature/RegressionTesting/A Safe Regression Test Selection Technique for Web Services.pdf:PDF},
  isbn = {0-7695-2844-9},
  keywords = {WSRT,},
  owner = {Steffen},
  timestamp = {2012.03.01},
  url = {http://dl.acm.org/citation.cfm?id=1260202.1260609}
}

@INPROCEEDINGS{Ryder2001,
  author = {Ryder, B.G. and Tip, F.},
  title = {Change Impact Analysis for Object-Oriented Programs},
  booktitle = {Proceedings of the 2001 ACM SIGPLAN-SIGSOFT workshop on Program analysis
	for software tools and engineering (PASTE '01)},
  year = {2001},
  pages = {46-53},
  address = {Snowbird, Utah, USA},
  month = {June},
  file = {:./literature/Paper_3.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- changes in OOP programs can have multiple effects + effects on tests
	
	- changes more difficult to implement than in imperative programming
	languages
	
	
	Research Questions:
	
	- mapping of code changes to a set of atomic changes in a partial
	order
	
	
	Contribution:
	
	- classification of atomic changes into certain categories
	
	- provide a look-up map for method calls to determine where a method
	should be changed (in the class hierarchy)
	
	
	Solution:
	
	- use call graphs for IA analysis
	
	- use a look-up map for method calls to detect appropriate places
	to implement changes
	
	- extract dependencies through partial ordering of atomic changes
	(e.g. first rename, than add parameter)
	
	-> granularity of entities: regression tests
	
	-> granularity of changes: atomic changes
	
	-> granularity of results: regression tests
	
	
	Open Issues:
	
	- not all code changes considered (only add/remove method, add/remove
	data, change method body)
	
	- only syntactic dependencies considered (e.g. no inheritance from
	non-existing class)
	
	- semantic dependencies not considered (e.g. new method requires changed
	existing method on call)
	
	
	fav. quote from paper: "While we do not expect this to be difficult..."
	;-)
	
	
	"Well, what you plan and what takes place ain't ever exactly been
	similar"
	
	- Jayne Cobb},
  timestamp = {2011.01.01}
}

@ARTICLE{S2011,
  author = {Vipin Kumar K S and Sheena Mathew},
  title = {A Model Based Approach For Regression Testing Utilizing Distributed
	Architecture},
  journal = {International Journal of Computer Applications},
  year = {2011},
  volume = {16},
  pages = {26--31},
  number = {2},
  month = {February},
  note = {Published by Foundation of Computer Science},
  __markedentry = {[qurat:]},
  file = {:/literature/RegressionTesting/A Model Based Approach For Regression Testing Utilizing Distributed Architecture.pdf:PDF},
  keywords = {Read, Relevant, code based, class dependence graphs},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@ARTICLE{Soderlund2005,
  author = {S{\"o}derlund, J.},
  title = {Developing project competence: empirical regularities in competitive
	project operations},
  journal = {International Journal of Innovation Management},
  year = {2005},
  volume = {9},
  pages = {451--480},
  number = {04},
  file = {Soderlund2005.pdf:literature/Soderlund2005.pdf:PDF},
  owner = {patrickr},
  publisher = {World Scientific},
  timestamp = {2012.10.22}
}

@ARTICLE{Sajeev2003a,
  author = {A.S.M. Sajeev and Bugi Wibowo},
  title = {UML Modeling for Regression Testing of Component Based Systems},
  journal = {Electronic Notes in Theoretical Computer Science},
  year = {2003},
  volume = {82},
  pages = {190--198},
  number = {6},
  month = sep,
  abstract = {Selection of test cases for regression testing of {Component-Based}
	Software Systems is a difficult problem since source code of commercial-off-the-shelf
	{(COTS)} components are not often available. This paper demonstrates
	a {UML} model of regression testing of components. We use {UML} and
	{Object-Constraint} Language to specify selection of regression test
	cases based on version information.},
  doi = {10.1016/S1571-0661(04)81037-5},
  file = {:/literature/RegressionTesting/UML Modeling for Regression Testing of Component Based Systems 2.pdf:PDF},
  issn = {1571-0661},
  owner = {Annie},
  timestamp = {2011.01.04},
  url = {http://www.sciencedirect.com/science/article/B75H1-4DDWKDK-K4/2/9e76045356988eb0b5f1303bfd4bbd54}
}

@INPROCEEDINGS{Sajeev2003,
  author = {A. S. M. Sajeev and Bugi Wibowo},
  title = {Regression Test Selection Based on Version Changes of Components},
  booktitle = {Proceedings of the Tenth Asia-Pacific Software Engineering Conference
	Software Engineering Conference},
  year = {2003},
  pages = {78},
  publisher = {{IEEE} Computer Society},
  abstract = {In component-based systems, regression test selectionis a challenge
	since vendors of {commercial-off-the-shelf(COTS)} components do not
	release source {code.In} thispaper we model the regression test selection
	ofcomponent based software systems using {UML} {andObject-Constraint}
	{Language.Our} model selects test casesbased on version information
	that can be made availablewith components without the need for accessing
	sourcecode.},
  file = {:/literature/RegressionTesting/regression test selection based on version changes of components.pdf:PDF},
  isbn = {0-7695-2011-1},
  owner = {Annie},
  timestamp = {2011.01.04},
  url = {http://portal.acm.org/citation.cfm?id=956416.956536&coll=GUIDE&dl=GUIDE&CFID=54491404&CFTOKEN=93053143}
}

@INPROCEEDINGS{Sametinger2002,
  author = {J. Sametinger and M. Riebisch},
  title = {Evolution Support by Homogeneously Documenting Patterns, Aspects
	and Traces},
  booktitle = {Proceedings 6th European Conference on Software Maintenance and Reengineering,
	Budapest, Hungary},
  year = {2002},
  pages = {134-140},
  month = {Mar},
  publisher = {IEEE Computer Society Press},
  abstract = {The evolution of complex software systems is promoted by software
	engineering principles and techniques like separation of concerns,
	encapsulation, stepwise refinement, and reusability of design solutions.
	Design patterns capture the expertise for reusable design solutions.
	Aspect-oriented programming is a methodology that enables the modularization
	of cross-cutting concerns. Traceability links designate dependencies
	between requirements, design, and source code. In order to support
	maintenance, documentation has to enable understandability by describing
	these issues. Descriptions have to facilitate tool support for automating
	documentation activities. In this paper, we use the notion of patterns,
	aspects and traces for a homogeneous documentation approach. We integrate
	various types of documentation, keep track of traces from requirements
	to the source code, keep design information in the source code, and
	generate additional design views on software systems. We have implemented
	these ideas as an extension to javadoc, the documentation approach
	used by Java. This extension can be used to automatically generate
	views on the design and on aspects as well as on traceability links
	as part of the standard javadoc system documentation.},
  doi = {10.1109/CSMR.2002.995798},
  file = {:./literature/00995798.pdf:PDF},
  keywords = {evolution, maintanence, documentation, design pattern, traceability,
	object-oriented design, javadoc},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://www.theoinf.tu-ilmenau.de/~Matthias/home/publ/CSMR02-paper.pdf}
}

@INPROCEEDINGS{Santelices2008,
  author = {Santelices, R. and Chittimalli, P. K. and Apiwattanapong, T. and
	Orso, A. and Harrold, M. J.},
  title = {Test-Suite Augmentation for Evolving Software},
  booktitle = {Proceedings of the 2008 23rd IEEE/ACM International Conference on
	Automated Software Engineering},
  year = {2008},
  series = {ASE '08},
  pages = {218--227},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid = {1642959},
  doi = {http://dx.doi.org/10.1109/ASE.2008.32},
  file = {:/literature/RegressionTesting/Test-suite Augmentation for Evolving Software.pdf:PDF},
  isbn = {978-1-4244-2187-9},
  keywords = {Read, Relevant, CodeBased},
  numpages = {10},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dx.doi.org/10.1109/ASE.2008.32}
}

@TECHREPORT{Santelices2010,
  author = {Santelices, Raul and Harrold, Mary Jean},
  title = {Probabilistic Slicing for Predictive Impact Analysis},
  institution = {Georgia Tech Center for Experimental Research in Computer Systems
	(CERCS)},
  year = {2010},
  file = {:./literature/Paper_57.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- static program slicing is too imprecise (computed impact sets too
	large)
	
	- dynamic slicing and thin slicing not better as they miss relevant
	statements
	
	
	Research Questions:
	
	- how can static slicing or slicing in general be enhanced to reduce
	the set of proposed impacts utilizing probalistics
	
	
	Contribution:
	
	- new slicing technique: probalistic slicing
	
	- augument a static forward slice with relevance score for each statement
	
	
	Solution:
	
	- obseravtion 1: not all statements have a similar probability of
	being impacted by a certain change
	
	- observation 2: some data dependencies less likely to be covered
	(apply interprocedural slicing to estimate if a definition is used)
	
	- observation 3: data dependencies propage with higher probability
	than control dependencies
	
	- probability that A is affected by B computed by statically analyzing:
	
	* execution reaches A after executing B
	
	* sequences of data / control dependencies executed between B and
	A
	
	* modification of program state propagates through B to A
	
	* if all three things occur, A is impacted by B
	
	- use standard static slices to generate dependence graph that covers
	all possible executions
	
	- interprocedural dependence graph annotated with the probability
	that the dependency will be covered by changes and propagete changes
	
	* each path in the graph has a probability to propagate a change from
	source to target, composed of all single probabilities on the path
	
	- final probabilities in the PDG are computed as:
	
	* compute coverage and propagation probalities to form the impact
	probability of a depedency
	
	* run data-flow analysis on PDG to combine all dependencies between
	a source and a target
	
	-> granularity of entities: statements
	
	-> granularity of changes: any changes to statements
	
	-> granularity of results: statements
	
	
	Open Issues:
	
	- no comparison to other slicing techniques in terms of false-positives
	and missed impacts},
  timestamp = {2011.02.10}
}

@ARTICLE{Saunders2006,
  author = {Saunders, C.S. and Ahuja, M.K.},
  title = {Are all distributed teams the same? Differentiating between temporary
	and ongoing distributed teams},
  journal = {Small Group Research},
  year = {2006},
  volume = {37},
  pages = {662--700},
  number = {6},
  file = {Saunders2006.pdf:literature/Saunders2006.pdf:PDF},
  owner = {patrickr},
  publisher = {Sage Publications},
  timestamp = {2012.10.19}
}

@ARTICLE{Scarbrough2004,
  author = {Scarbrough, H. and Bresnen, M. and Edelman, L.F. and Laurent, S.
	and Newell, S. and Swan, J.},
  title = {The Processes of Project-based Learning An Exploratory Study},
  journal = {Management Learning},
  year = {2004},
  volume = {35},
  pages = {491--506},
  number = {4},
  file = {Scarbrough2004.pdf:literature/Scarbrough2004.pdf:PDF},
  owner = {patrickr},
  publisher = {Sage Publications},
  timestamp = {2012.10.22}
}

@ARTICLE{Scarbrough2004a,
  author = {Scarbrough, H. and Swan, J. and Laurent, S. and Bresnen, M. and Edelman,
	L. and Newell, S.},
  title = {Project-based learning and the role of learning boundaries},
  journal = {Organization Studies},
  year = {2004},
  volume = {25},
  pages = {1579--1600},
  number = {9},
  file = {Scarbrough2004a.pdf:literature/Scarbrough2004a.pdf:PDF},
  owner = {patrickr},
  publisher = {Sage Publications},
  timestamp = {2012.10.22}
}

@BOOK{Schaefer1994,
  title = {Objektorientierte Entwurfsmethoden: Verfahren zum objektorientierten
	Software-Verfahren zum objektorientierten Softwareentwurf im Überblick},
  publisher = {Addison-Wesley},
  year = {1994},
  author = {Steffen Schäfer},
  pages = {187},
  keywords = {object oriented software design, software engineering, design methods},
  language = {german},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://www.amazon.de/Objektorientierte-Entwurfsmethoden-Verfahren-objektorientierten-Softwareentwurf/dp/3893196927/ref=sr_1_1?ie=UTF8&s=books&qid=1216212739&sr=1-1}
}

@BOOK{Schaefer1994a,
  title = {Objektorientierte Entwurfsmethoden: Verfahren zum objektorientierten
	Software-Verfahren zum objektorientierten Softwareentwurf im Überblick},
  publisher = {Addison-Wesley},
  year = {1994},
  author = {Steffen Schäfer},
  pages = {187},
  keywords = {object oriented software design, software engineering, design methods},
  language = {german},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://www.amazon.de/Objektorientierte-Entwurfsmethoden-Verfahren-objektorientierten-Softwareentwurf/dp/3893196927/ref=sr_1_1?ie=UTF8&s=books&qid=1216212739&sr=1-1}
}

@INPROCEEDINGS{Scharf2011,
  author = {Scharf, Andreas and Z\"{u}ndorf, Albert},
  title = {{Difference Visualization for Models (DVM)} - Visualizing model changes
	directly within diagrams},
  year = {2011},
  abstract = {Today's software development and maintenance is time consuming, cost-intensive
	and particularly an iterative process. Since models and diagrams
	are the main artifact in the development process of numerous research
	institutes and software companies, it is necessary to show and merge
	differences as the model evolves. While there are plenty of difference
	tools available for textual artifacts (like source code) this does
	not hold for diagrams. This paper presents an approach to show and
	merge deltas of different model versions directly within the corresponding
	diagram editor. This is done by integrating the Difference Visualization
	for Models (DVM) framework into existing editors with as little effort
	as possible.},
  added-at = {2011-05-09T14:37:01.000+0200},
  biburl = {http://www.bibsonomy.org/bibtex/28a396c96cdd17cbb848745cf3da6e273/zenobios},
  file = {:/literature/changeIdentification/FujabaDays2011_DVM.pdf:PDF},
  interhash = {ed17946f77d5bc7dde0ec37c22c9b17a},
  intrahash = {8a396c96cdd17cbb848745cf3da6e273},
  keywords = {Read, sys:relevantfor:se delta diagram diff editor gef myown se uml},
  owner = {Steffen},
  review = {Changes
	
	
	+add
	
	+delete
	
	+modify
	
	+move},
  timestamp = {2011-05-09T14:37:01.000+0200},
  url = {http://seblog.cs.uni-kassel.de/wp-content/uploads/2011/05/FujabaDays2011_DVM.pdf}
}

@PHDTHESIS{Schleipen2012,
  author = {Miriam Schleipen},
  title = {Adaptivität und semantische Interoperabilität von Manufacturing Execution
	Systemen (MES)},
  school = {Institut für Anthropomatik (IFA), Fakultät für Informatik, Uni Karlsruhe},
  year = {2012},
  file = {:./literature/Schleipen2012.pdf:PDF},
  owner = {matthias},
  timestamp = {2013.02.18},
  url = {http://digbib.ubka.uni-karlsruhe.de/volltexte/1000031246}
}

@MISC{Schmitz2005,
  author = {Oliver Schmitz},
  title = {Der Hyper/J Ansatz},
  howpublished = {Seminar "Post-Objekt-Orientierte Software-Entwicklungsansätze" -
	Präsentationsfolien},
  month = {Aug.},
  year = {2005},
  note = {Universität Koblenz-Landau},
  file = {:./literature/FolienSchmitz.pdf:PDF},
  keywords = {Hyper/J, multidimensional development},
  owner = {Stephan},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Schnieders2006,
  author = {Schnieders, A.},
  title = {Variability mechanism centric process family architectures},
  booktitle = {Engineering of Computer Based Systems, 2006. ECBS 2006. 13th Annual
	IEEE International Symposium and Workshop on},
  year = {2006},
  pages = {10--pp},
  organization = {IEEE},
  file = {Schnieders2006.pdf:literature/Schnieders2006.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.23}
}

@INPROCEEDINGS{Schrettner2012,
  author = {Schrettner, Lajos and J\'{a}sz, Judit and Gergely, Tam\'{a}s and
	Besz\'{e}des, \'{A}rp\'{a}d and Gyim\'{o}thy, Tibor},
  title = {Impact Analysis in the Presence of Dependence Clusters Using Static
	Execute After in WebKit},
  booktitle = {Proceedings of the 12th IEEE International Working Conference on
	Source Code Analysis and Manipulation},
  year = {2012},
  address = {Riva del Garda, Trento, Italy},
  month = {September},
  file = {:./literature/Paper_257.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.08.08}
}

@BOOK{Schwaber2001,
  title = {Agile Software Development with Scrum},
  publisher = {Prentice Hall},
  year = {2001},
  author = {Schwaber, Ken and Beedle, Mike},
  address = {Upper Saddle River, NJ, USA},
  edition = {1st},
  isbn = {0130676349},
  keywords = {Scrum},
  owner = {Stephan},
  timestamp = {2010.12.22}
}

@ARTICLE{Schwarz2009,
  author = {Hannes Schwarz and J\"urgen Ebert and Andreas Winter},
  title = {Graph-based traceability: a comprehensive approach},
  journal = {Software and Systems Modeling},
  year = {2009},
  volume = {9},
  pages = {473-492},
  number = {4},
  abstract = {In recent years, traceability has been globally accepted as being
	a key success factor of software development projects. However, the
	multitude of different, poorly integrated taxonomies, approaches
	and technologies impedes the application of traceability techniques
	in practice. This paper presents a comprehensive view on traceability,
	pertaining to the whole software development process. Based on the
	state of the art, the field is structured according to six specific
	activities related to traceability as follows: definition, recording,
	identification, maintenance, retrieval, and utilization. Using graph
	technology, a comprehensive and seamless approach for supporting
	these activities is derived, combining them in one single conceptual
	framework. This approach supports the definition of metamodels for
	traceability information, recording of traceability information in
	graph-based repositories, identification and maintenance of traceability
	relationships using transformations, as well as retrieval and utilization
	of traceability information using a graph query language. The approach
	presented here is applied in the context of the ReDSeeDS project
	(Requirements Driven Software Development System) that aims at requirements-based
	software reuse. ReDSeeDS makes use of traceability information to
	determine potentially reusable architectures, design, or code artifacts
	based on a given set of reusable requirements. The project provides
	case studies from different domains for the validation of the approach.},
  doi = {10.1007/s10270-009-0141-4},
  file = {:./literature/schwarz+2009.pdf:PDF},
  keywords = {traceability, graph technology, model transformation, software engineering,
	TGraph, JGraLab},
  owner = {Stephan},
  review = {good state-of-the-art analysis according to traceability activities
	
	- definition
	
	- recording
	
	- identification
	
	- maintenance
	
	- retrieval
	
	- utilization
	
	
	own approach uses TGraphs as datastructure for traceability 
	
	- GReQL as query language
	
	- link establishment only based on model transformation
	
	- considered artefacts: requirements (in an own representation form),
	architecture and design models in UML, and Java code
	
	
	common traceability link retrieval patterns
	
	- existence
	
	- reachable entities
	
	- slice
	
	
	
	----------------------
	
	Elke},
  timestamp = {2010.07.30}
}

@PHDTHESIS{Schwefer2007,
  author = {Gabriel Schwefer},
  title = {Pattern-Oriented Transformations between Analysis and Design Models
	(POTAD)},
  school = {TU Ilmenau},
  year = {2007},
  month = {Oct.},
  abstract = {Eine Antwort auf viele aktuelle Anforderungen im Elektrik/Elektronik-Bereich
	der Fahrzeugentwicklung ist ein durchgängig modellbasierter Entwicklungsprozess,
	der Modelle der System- und Softwareentwicklung integriert. Ein Systemmodell
	beschreibt mit der logischen Systemarchitektur die Funktionen eines
	Fahrzeugs und mit der technischen Systemarchitektur die realisierende
	Elektrik/Elektronik, wie z. B. Steuergeräte, Sensoren/Aktoren und
	Bussysteme. Im Rahmen der Softwareentwicklung muss für einzelne Funktionen
	aus der logischen Systemarchitektur unter Berücksichtigung der technischen
	Systemarchitektur und weiterer Anforderungen ein Softwaredesignmodell
	erstellt werden. Aktuelle modellbasierte Entwicklungsansätze versprechen
	mit Hilfe des Konzepts der Modelltransformation den Übergang zwischen
	Modellen unterschiedlicher Entwicklungsphasen automatisieren zu können.
	Dieses Konzept bietet sich dazu an, aus einem Systemarchitekturmodell
	ein Grundgerüst eines Softwaredesignmodells zu erzeugen und damit
	einen Teil der Softwareentwicklungsaktivitäten zu automatisieren.
	
	Die Analyse dieser Arbeit zeigt, dass die erarbeiteten domänenspezifischen
	Anforderungen, die für solch ein Szenario an einen Modelltransformationsmechanismus
	gestellt werden müssen, durch aktuelle Ansätze nicht vollständig
	erfüllt werden. Der eigene Ansatz Pattern-Oriented Transformations
	between Analysis and Designmodels (POTAD) verwendet die logische
	Systemarchitektur im Rahmen der Softwareentwicklung als Analysemodell
	und systematisiert dessen Zusammenhang mit dem Designmodell auf der
	Basis von Analyse- und Designmustern. Für ein im Analysemodell gefundenes
	Analysemuster instanziiert eine POTAD-Transformationsregel mit Hilfe
	dieser Systematik in Abhängigkeit nichtfunktionaler Anforderungen
	und der technischen Systemarchitektur unterschiedliche Designmuster
	im Designmodell. Gleichzeitig werden Verknüpfungen zwischen den Analyse-
	und Designmustern angelegt, die zur späteren Verfolgung von Designentscheidungen
	genutzt werden. Anhand eines dem POTAD-Entwicklungsprozess folgenden
	Prototyps, der die in der POTAD-Transformationssprache formulierten
	Regeln ausführen kann und die Verfolgbarkeit werkzeugseitig unterstützt,
	wird die Realisierbarkeit des Lösungsansatzes gezeigt.
	
	POTAD wurde durch studentische Arbeiten anhand einer Fallstudie überprüft,
	die typische Eigenschaften der betrachteten Domäne abdeckt. Die Ergebnisse
	dieser Arbeiten haben die Tauglichkeit von POTAD gezeigt, die Methodik
	und die Transformationssprache verbessert und Grenzen aufgezeigt.},
  file = {:./literature/DissSchwefer2007.pdf:PDF},
  keywords = {design pattern, analysis pattern, model driven design, model transformation,
	software engineering, system engineering, ROPES method, POTAD},
  owner = {Stephan},
  review = {interesting part: pattern description with UML using templates (and
	collaborations), instantiation of patterns templates},
  timestamp = {2010.02.10},
  url = {http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:de:gbv:ilm1-2008000021}
}

@INPROCEEDINGS{Scott2002a,
  author = {Scott, L. and Carvalho, L. and Jeffery, R.},
  title = {A process-centred experience repository for a small software organisation},
  booktitle = {Software Engineering Conference, 2002. Ninth Asia-Pacific},
  year = {2002},
  pages = {603--609},
  file = {Scott2002a.pdf:literature/Scott2002a.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@ARTICLE{Scott2002,
  author = {Scott, L. and Carvalho, L. and Jeffery, R. and D'Ambra, J. and Becker-Kornstaedt,
	U.},
  title = {Understanding the use of an electronic process guide},
  journal = {Information and Software Technology},
  year = {2002},
  volume = {44},
  pages = {601--616},
  number = {10},
  file = {Scott2002.pdf:literature/Scott2002.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@INPROCEEDINGS{Scott2001,
  author = {Scott, L. and Jeffery, R. and Carvalho, L. and D'Ambra, J. and Rutherford,
	P.},
  title = {Practical software process improvement-the IMPACT project},
  booktitle = {Software Engineering Conference, 2001. Proceedings. 2001 Australian},
  year = {2001},
  pages = {182--189},
  organization = {IEEE},
  file = {Scott2001.pdf:literature/Scott2001.pdf:PDF}
}

@ARTICLE{Sechser2009,
  author = {Sechser, B.},
  title = {The marriage of two process worlds},
  journal = {Software Process: Improvement and Practice},
  year = {2009},
  volume = {14},
  pages = {349--354},
  number = {6},
  file = {Sechser2009.pdf:literature/Sechser2009.pdf:PDF},
  owner = {patrickr},
  publisher = {Wiley Online Library},
  timestamp = {2012.07.20}
}

@ARTICLE{team2011standard,
  author = {SEI},
  title = {Standard CMMI Appraisal Method for Process Improvement (SCAMPI) A,
	Version 1.3: Method Definition Document},
  year = {2011},
  file = {team2011standard.pdf:literature/team2011standard.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.19}
}

@TECHREPORT{team2010cmmi,
  author = {SEI},
  title = {CMMI for Development (CMMI-DEV)},
  institution = {Version 1.3, Technical Report, CMU/SEI-2010-TR-033, Software Engineering
	Institute},
  year = {2010},
  file = {team2010cmmi.pdf:literature/team2010cmmi.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.19}
}

@ARTICLE{CMMI2002Continuous,
  author = {SEI},
  title = {Capability Maturity Model{\textregistered} Integration (CMMI), Version
	1.1--Continuous Representation},
  year = {2002},
  file = {CMMI2002Continuous.pdf:literature/CMMI2002Continuous.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.19}
}

@TECHREPORT{SEI2002stagedCMMI,
  author = {SEI},
  title = {Capability Maturity Model Integration (CMMI), Version 1.1--Staged
	Representation},
  year = {2002},
  file = {SEI2002stagedCMMI.pdf:literature/SEI2002stagedCMMI.pdf:PDF}
}

@ARTICLE{Seibel2010,
  author = {Seibel, Andreas and Neumann, Stefan and Giese, Holger},
  title = {Dynamic hierarchical mega models: comprehensive traceability and
	its efficient maintenance},
  journal = {Software and Systems Modeling},
  year = {2010},
  volume = {9},
  pages = {493-528},
  number = {4},
  __markedentry = {[Steffen:]},
  file = {:./literature/Paper_222.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.30}
}

@INPROCEEDINGS{Seifert2003,
  author = {Tilman Seifert and Markus Pizka},
  title = {{Supporting Software-Evolution at the Process Level}},
  booktitle = {Workshop on Migration and Evolvability of Long-life Software Systems
	(MELLS), Erfurt, Germany},
  year = {2003},
  editor = {Ilian Pashov and Matthias Riebisch and Michael Zettler},
  abstract = {The ability to be changeable is inherent to software — in fact, this
	is what defines it as being “soft”. The long-term management of large
	software sys- tems depends on the ability of a system to be “easy”
	to maintain and evolve. In contrast to commonly presented views,
	we define three ways to look at evolvabil- ity. First, it can be
	considered to be a quality property, and must therefore be sub- ject
	to quality control. Second, it can be handled as a non-functional
	requirement and must therefore be part of the requirements management
	and change manage- ment process. Third, one could claim that it is
	not the system’s ability but the ability of the development and maintenance
	team that allows for cost-effective maintenance cycles. This in turn
	requires a sound understanding of the system and its environment.
	This paper argues that the combination of these three differ- ent
	views allows for a coherent understanding of maintenance and evolution
	of software systems. We suggest a couple of principles how to deal
	with long-lived systems in a systematic fashion, and derive a development
	process model built on these principles.},
  file = {:./literature/2003_pspm_evolution.pdf:PDF},
  keywords = {software evolution, software evolvability, process model, staged models},
  owner = {Stephan},
  review = {software evolution and architectural design is not only based on experience
	but on a systematic approach
	
	
	evolvability discussed as
	
	- quality property
	
	- non-functional requirement
	
	- an ability of the team
	
	
	critique on Staged Model
	
	- helpful for discussion about state of system
	
	- no hints on how to stay in the evolution stage as long as possible
	
	- architectural integrity not defined although most important for
	evolvability
	
	- no return back from servicing to evolution
	
	- initial development should not be separated from other stages
	
	
	introduction of the Pizka-Seifert-Process-Model
	
	- extension of the Staged Software Life Cycle Model
	
	- evolution and consolidation phases
	
	- regular consolidation with minor effort helps as a preventive measur
	to avoid significant quality deterioration},
  timestamp = {2009.12.16},
  url = {http://www4.informatik.tu-muenchen.de/publ/papers/2003_pspm_evolution.pdf}
}

@ARTICLE{Selic2003,
  author = {Selic, B.},
  title = {The pragmatics of model-driven development},
  journal = {IEEE Software},
  year = {2003},
  volume = {20},
  pages = {19-25},
  number = {5},
  month = {Sept.-Oct.},
  abstract = {The potential benefits of using models are significantly greater in
	software than in other engineering disciplines because of the potential
	for a seamless link between models and the systems they represent.
	Unfortunately, models have rarely produced anticipated benefits.
	The key lies in resolving pragmatic issues related to the artifacts
	and culture of the previous generation of software technologies.},
  doi = {10.1109/MS.2003.1231146},
  file = {:./literature/01231146.pdf:PDF},
  issn = {0740-7459},
  keywords = { modelling, software engineering, software standards artifacts, culture,
	industrial experience, model-driven development methods, pragmatic
	issues, software development, software engineering},
  owner = {Stephan},
  timestamp = {2008.04.17}
}

@INPROCEEDINGS{Seo2000,
  author = {Seo, J. and Choi, B.},
  title = {Tailoring test process by using the component-based development paradigm
	and the XML technology},
  booktitle = {Software Engineering Conference, 2000. APSEC 2000. Proceedings. Seventh
	Asia-Pacific},
  year = {2000},
  pages = {356--363},
  organization = {IEEE},
  file = {Seo2000.pdf:literature/Seo2000.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.23}
}

@INPROCEEDINGS{Serrano2003,
  author = {Serrano, M.A. and de Oca, C.M. and Cedillo, K.},
  title = {An experience on using the team software process for implementing
	the Capability Maturity Model for software in a small organization},
  booktitle = {Quality Software, 2003. Proceedings. Third International Conference
	on},
  year = {2003},
  pages = {327--334},
  file = {Serrano2003.pdf:literature/Serrano2003.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@TECHREPORT{Sessions2007,
  author = {Roger Sessions},
  title = {Comparison of the Top Four Enterprise Architecture Methodologies},
  institution = {ObjectWatch},
  year = {2007},
  month = {May},
  file = {:./literature/4EAComparison.pdf:PDF},
  keywords = {Architecture methodology, Zachman, Gartner, FEA, TOGAF},
  owner = {Stephan},
  review = {four enterprise architectural methodologies
	
	- Zachman framework -- kind of taxonomy
	
	- The Open Group Architectural Framework (TOGAF) -- process
	
	- The Federal Enterprise Architecture (FEA) -- viewed as implemented
	enterprise architecture or procriptive methodology
	
	- The Gartner Methodology -- enterprise architectural practice
	
	
	approaches discussed, application for case study, comparison
	
	
	very generic approaches for whole enterprise (!) architectures},
  timestamp = {2008.04.02},
  url = {http://www.objectwatch.com/whitepapers/4EAComparison.pdf}
}

@TECHREPORT{Sessions2007a,
  author = {Sessions, Roger},
  title = {Controlling Complexity in Enterprise Architectures: Executive Overview
	Part I of III},
  institution = {ObjectWatch},
  year = {2007},
  month = {June},
  file = {:./literature/ControllingComplexity-1.pdf:PDF},
  keywords = {Enterprise Architecture, complexitiy},
  owner = {Stephan},
  review = {introduces a process called "simple iteratetive partitions" (SIP)
	for enterprise architectures to handle complexity
	
	
	mathematical model used to handle complexity based on probability
	theory and set theory
	
	
	- partitioning to reduce overall complexity
	
	- simplification algorithms using mappings between business requirements
	and IT functionality
	
	
	SIP as meta-methodology on top of other enterprise architecture methodologies
	
	
	SIP process - 5 phases
	
	- SIP Preparation
	
	- Partition Identification
	
	- Partition Simplification
	
	- Partition Priorization
	
	- Partition Iteration},
  timestamp = {2008.04.02},
  url = {http://www.objectwatch.com/whitepapers/ControllingComplexity-1.pdf}
}

@TECHREPORT{Sessions2007b,
  author = {Sessions, Roger},
  title = {Controlling Complexity in Enterprise Architectures: Mathematical
	Foundations Part II of III},
  institution = {ObjectWatch},
  year = {2007},
  month = {June},
  file = {:./literature/ControllingComplexity-2.pdf:PDF},
  keywords = {Enterprise Architecture, complexitiy},
  owner = {Stephan},
  review = {reducing complexity by partitioning attributes
	
	
	partitioning based on equivalence relation
	
	
	SIP partitionates functionalities --> results in partitioned attributes
	
	
	find synergistic and autonomous functionalities (opposites)
	
	
	synergy more than mere equivalence relation -> defines a unique and
	beyond an optimal partition
	
	synergy equivalence relation leeds to best possible partition
	
	
	further steps to partitioning in SIP process: consolidation, elimination,
	outsourcing},
  timestamp = {2008.04.02},
  url = {http://www.objectwatch.com/whitepapers/ControllingComplexity-2.pdf}
}

@TECHREPORT{Sessions2007c,
  author = {Sessions, Roger},
  title = {Controlling Complexity in Enterprise Architectures: The SIP Methodology
	Part III of III},
  institution = {ObjectWatch},
  year = {2007},
  month = {June},
  file = {:./literature/ControllingComplexity-3.pdf:PDF},
  keywords = {Enterprise Architecture, complexitiy},
  owner = {Stephan},
  review = {goals of the SIP process:
	
	- complexity control
	
	- logic-based decisions
	
	- value driven deliverables
	
	- reproducable result
	
	- verifyable architectures
	
	- flexible methodology
	
	
	6 primary phases divided into three categories
	
	- preliminary with EA evaluation
	
	- preparatory with SIP preparation, partition identification, partition
	simplification, and partition prioritization
	
	- iteration: partition iteration (choose partition, architect, implement,
	evalutate)
	
	
	basic partitioning unit: Autonomous Business Capability (ABC)
	
	ABC contains business process and technology elements},
  timestamp = {2008.04.02},
  url = {http://www.objectwatch.com/whitepapers/ControllingComplexity-3.pdf}
}

@TECHREPORT{Sessions2006,
  author = {Sessions, Roger},
  title = {A Better Path to Enterprise Architectures},
  institution = {ObjectWatch},
  year = {2006},
  month = {March},
  file = {:./literature/ABetterPath-Final.pdf:PDF},
  keywords = {enterprise architectures, complexitiy},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://www.objectwatch.com/whitepapers/ABetterPath-Final.pdf}
}

@ARTICLE{Sharafat2008,
  author = {Sharafat, Ali R. and Tahvildari, Ladan},
  title = {Change Prediction in Object-Oriented Software Systems: A Probabilistic
	Approach},
  journal = {Journal of Software},
  year = {2008},
  volume = {3},
  pages = {26-39},
  number = {5},
  month = {May},
  file = {:./literature/Paper_87.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- estimation of change-proness useful for many tasks in maintenance
	/ evolutionary development:
	
	* change prediction
	
	* effort reduction
	
	
	Research Questions:
	
	- assessing probability that a class will change in future
	
	
	Contribution:
	
	- new approach for automated predicting changes in OO software, combining
	the following to predict class changes:
	
	* dependencies from UML diagrams
	
	* source code metrics
	
	* change log
	
	* expected time of next release
	
	- methods to estimate propagation between sets of classes based on
	number and types of dependencies between them
	
	
	Solution:
	
	- consider internal and external changes to classes
	
	* internal: changes within the class
	
	* external: changes carried from other classes
	
	- probability of change for class X is the probability of the union
	of internal/external changes
	
	* internal probability: % of past release which contained changes
	of this class
	
	 - computed by source code metrics and data from history-log
	
	 - metrics operate on method and data members
	
	* external probability: probability of change from external classes
	to the questioned class
	
	 - extract dependencies between classes from UML diagrams to compute
	probability that a change to class "A" propagates to class "B"
	
	 - if there is more than 1 dependency between two classes, 3 possible
	solutions:
	
	 * normalize dependencies
	
	 * element-wise calculation:
	
	 - move focus on elements of classes (i.e. methods/data) to compute
	probability
	
	 - solves the problem but expensive due to non-linear system
	
	 * merging dependencies
	
	 - cyclic dependencies require special treatment, 3 possible techniques:
	
	 * non-linear system of equations; basic assumption: changes in different
	classes are independent events
	
	 * linear system of equations; basic assumption: changes in a class
	due to different sources is mutually exclusive
	
	 * depth first search graph
	
	 -> DFS more suitable (correctness)
	
	- computation of probability that class will change in future version:
	
	* compute prob. for current change (composed of internal/external
	prob., see above)
	
	* now take into account the time between each version (TimeBetweenReleases
	- TBR) and the expected time to release of new verion (TTR) ....[more
	weird math]
	
	* use it to compute a "daily probability to change"
	
	-> granularity of entities: class
	
	-> granularity of changes: changes to classes
	
	-> granularity of results: class
	
	
	Open Issues:
	
	- changes from history can be viewed as dependent, therefore Markov
	model could take them into account
	
	- determine parameters for calculations from source code or related
	data, instead through empirical studies (manually)},
  timestamp = {2011.02.23}
}

@INPROCEEDINGS{Sharafat2007,
  author = {Sharafat, Ali R. and Tahvildari, Ladan},
  title = {A Probabilistic Approach to Predict Changes in Object-Oriented Software
	Systems},
  booktitle = {Proceedings of the 11th European Conference on Software Maintenance
	and Reengineering (CSMR '07)},
  year = {2007},
  pages = {27-38},
  address = {Amsterdam, Netherlands},
  month = {March},
  file = {:./literature/Paper_115.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- change prediction has become major concern in software maintenance
	
	- good prediction reduces costs and provides understanding of architectural
	stability
	
	
	Research Questions:
	
	- how to quantify architectural stability by predicting changes
	
	
	Contribution:
	
	- novel approach to predict changes in object oriented software
	
	- probalistic approach working on source code and change history
	
	
	Solution:
	
	- approach consists of 3 steps:
	
	 * estimate likelyhood of change, due to changes from class itself
	
	 - measured with metrics
	
	 * extract dependencies between classes from UML diagrams
	
	 - approximate probability that change will propagate from one class
	to another class
	
	 * find total value of probability through bayes' theorem
	
	- distinguish between raw-probability and time-normalized-probability:
	
	* RP: percentage of past releases in which class was changed
	
	* TNP: takes RP and time between releases and expected time of next
	release
	
	-> granularity of entities: method, variable
	
	-> granularity of changes: method, variable
	
	-> granularity of results: class
	
	
	==> same as [Sharafat2008]
	
	
	Open Issues:},
  timestamp = {2011.03.14}
}

@INPROCEEDINGS{Sharif2007,
  author = {Sharif, Bonita and Maletic, Jonathan I.},
  title = {Using Fine-Grained Differencing to Evolve Traceability Links},
  booktitle = {Proceedings of the 4th ACM International Workshop on Traceability
	in Emerging Forms of Software Engineering},
  year = {2007},
  pages = {76-81},
  address = {Lexington, Kentucky},
  month = {March},
  file = {:./literature/Paper_230.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.05.10}
}

@ARTICLE{Shenhar2001,
  author = {Shenhar, A.J.},
  title = {Contingent management in temporary, dynamic organizations: The comparative
	analysis of projects},
  journal = {The Journal of High Technology Management Research},
  year = {2001},
  volume = {12},
  pages = {239--271},
  number = {2},
  file = {Shenhar2001.pdf:literature/Shenhar2001.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.22}
}

@INPROCEEDINGS{Sherba2003a,
  author = {Sherba, Susanne A. and Anderson, Kenneth M.},
  title = {A Framework for Managing Traceability Relationships between Requirements
	and Architectures},
  booktitle = {Proceedings of the International Conference on Software Engineering},
  year = {2003},
  pages = {150-156},
  address = {Portland, Oregon},
  month = {May},
  __markedentry = {[Steffen:]},
  file = {:./literature/Paper_216.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.25}
}

@CONFERENCE{Sherba2003,
  author = {Sherba, Susanne and Anderson, KennethM. and Faisal Maha},
  title = {A Framework for Mapping Traceability Relationships},
  booktitle = {2nd International Workshop on Traceability in Emerging Formas of
	SE},
  year = {2003},
  __markedentry = {[Steffen:]},
  file = {:./literature/paper5.pdf:PDF},
  owner = {Elke},
  timestamp = {2011.05.12}
}

@TECHREPORT{Sherriff2007,
  author = {Sherriff, Mark and Williams, Laurie},
  title = {Empirical Software Change Impact Analysis using Singular Value Decomposition},
  institution = {IBM, North Carolina State University},
  year = {2007},
  file = {:./literature/Paper_18.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- current IA through call-graphs or static code analysis do not consider
	non-source files
	
	
	Research Questions:
	
	- how to gain IA from change records and how to extend on non-source
	files
	
	
	Contribution:
	
	- methodology for IA on change records
	
	- IA not just on source files, also on other files like documentation
	
	- provide likelihood of impact from changes
	
	
	Solution:
	
	- change records compiled into matrix
	
	- compute association clusters from matrix through singular value
	decomposition
	
	- each file weighted in cluster as to its degree of participation
	
	- possible issues are marked by high singular values
	
	-> granularity of entities: file
	
	-> granularity of changes: change records from version control
	
	-> granularity of results: file
	
	
	Open Issues:
	
	- IA only on the level of files
	
	- only accurate on single changes (not on a mixed set of changes)
	
	- only 60% precision
	
	- doesn't work for projects in early stage, since very few change
	logs are available},
  timestamp = {2011.01.07}
}

@TECHREPORT{Shin2012,
  author = {Shin, Yonghee and Hayes, Jane Huffman and Cleland-Huang, Jane},
  title = {A Framework for Evaluating Traceability Benchmark Metrics},
  institution = {DePaul University, College of Computing and Digital Media},
  year = {2012},
  number = {21},
  file = {:./literature/Paper_242.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.06.11}
}

@INPROCEEDINGS{Shiri2007,
  author = {Shiri, Maryam and Hassine, Jameleddine and Rilling, Juergen},
  title = {Modification analysis support at the requirements level},
  booktitle = {Ninth international workshop on Principles of software evolution:
	in conjunction with the 6th ESEC/FSE joint meeting},
  year = {2007},
  series = {IWPSE '07},
  pages = {43--50},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[qurat:]},
  acmid = {1294961},
  doi = {http://doi.acm.org/10.1145/1294948.1294961},
  file = {:/literature/RegressionTesting/Modification Analysis Support at the Requirements Level.pdf:PDF},
  isbn = {978-1-59593-722-3},
  keywords = {change impact analysis, formal concept analysis, regression testing,
	use case maps, modification support for specifications, interesting},
  location = {Dubrovnik, Croatia},
  numpages = {8},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://doi.acm.org/10.1145/1294948.1294961}
}

@BOOK{Shneiderman1992,
  title = {Designing the user interface: strategies for effective human-computer
	interaction},
  publisher = {Addison-Wesley},
  year = {1992},
  author = {Ben Shneiderman},
  pages = {573},
  address = {Boston, MA, USA},
  edition = {2nd},
  abstract = {The much-anticipated fourth edition of Designing the User Interface
	provides a comprehensive, authoritative introduction to the dynamic
	field of human-computer interaction (HCI). Students and professionals
	learn practical principles and guidelines needed to develop high
	quality interface designs-ones that users can understand, predict,
	and control. It covers theoretical foundations, and design processes
	such as expert reviews and usability testing. Numerous examples of
	direct manipulation, menu selection, and form fill-in give readers
	an understanding of excellence in design. Recent innovations in collaborative
	interfaces, online help, and information visualization receive special
	attention. A major change in this edition is the integration of the
	World Wide Web and mobile devices throughout the book. Chapters have
	examples from cell phones, consumer electronics, desktop displays,
	and Web interfaces.},
  keywords = {user interface design, usability engineering},
  owner = {Stephan},
  timestamp = {2008.08.01},
  url = {http://www.amazon.de/Designing-User-Interface-Human-Computer-Human-computer/dp/0321197860}
}

@ARTICLE{Siedersleben2007,
  author = {Johannes Siedersleben},
  title = {SOA revisited: Komponentenorientierung bei Systemlandschaften},
  journal = {Wirtschaftsinformatik},
  year = {2007},
  volume = {49},
  pages = {110-117},
  number = {1},
  file = {:./literature/SOARevisited-Siedersleben_wi2007_s_110_117-1.pdf:PDF},
  keywords = {service oriented, software component},
  owner = {Stephan},
  review = {charakteristische Eigenschaften für Systemlandschaften
	
	-----------------------------------------------------------------
	
	- entstehen im Laufe der Zeit
	
	- dramatische Änderungen technischer sowie fachlicher Anforderungen
	
	
	- Redundanz von Daten und Funktionen (unvermeidbar) -> eliminieren
	oder zumindest kontrollieren
	
	
	- heterogen
	
	- fachliche Redundanz und Inkosistenzen sind charakteristisch, keine
	behebbaren Mängel
	
	
	SOA
	
	------
	
	Methode zum Entwurf von Systemlandschaften
	
	
	- Komponentenorientierung
	
	- Lose Kopplung - asynchrone Kommunikation
	
	- Workflow für Ablaufsteuerung
	
	
	"SOA ist Komponentenorientierung in Verbindung mit loser Kopplung
	und ausgelagerter Ablaufsteuerung."
	
	
	SOA ist Verallgemeinerung der Komponentenorientierung von Systemen
	auf Systemlandschaften
	
	
	3 Modelle:
	
	Prozessmodell
	
	 - welche Geschäftsprozesse gibt es
	
	Servicemodell
	
	 - Geschäftsdaten und Geschäftsfunktionen
	
	 - Unterscheidung zwischen abstrakten Geschäftsobjekte und ihrer Implementierung
	in verschiedenen Systemen 
	
	Technikmodell
	
	 - Ausnahmebehandlung, Monitoring
	
	 - wie werden nichtfunktionale Eigenschaften umgesetzt
	
	
	Governance: Projektleitung des Großprojektes SOA, das schon in Teilprojekte
	zerlegt ist
	
	
	ESB
	
	-----
	
	- Routing (wie durch Broker bei Corba)
	
	- Persistenz (keine Nachricht geht verloren)
	
	- Fachliche Transformation (isolierte Begriffswelten der beteiligten
	Systeme)
	
	- Technische Transformation
	
	- Workflow (BPEL als Standard für Ablaufsteuerung)
	
	- Fehlerbehandlung (jeder Aufruf eines Service kann fehlschlagen)
	
	- Monitoring, Protokollierung (Überprüfung von SLAs)
	
	- Lastverteilung, Ausfallsicherheit und Skalierbarkeit
	
	
	Ablaufsteuerung
	
	--------------------
	
	2 Varianten
	
	a) ESB verwaltet alle Workflow-Ebenen, eine Workflow-Komponente kennt
	alle Workflow-Definitionen
	
	b) ein Baum von ESBs entsprechend der Struktur des Workflow-Baums,
	jeder ESB verwaltet einen Workflow-Knoten (hier optimale Trennung
	der Zuständigkeiten)
	
	
	Kriterien für Services
	
	-------------------------
	
	- mächtige Operationen (besser als viele kleine - Performance, Reduzierung
	von Inkonsistenzen durch Asynchronität)
	
	- Idempotenz (mehrmalige Aufrufe von Operationen mit denselben Parametern
	haben nicht dieselbe Wirkung - z.B. nur einmal stornieren)
	
	- One-Shot-Methoden (laufen in einem System in einer einzelnen Transaktion
	ganz oder gar nicht ab -> mehrere unabhängige Transaktionenen ->
	keine Rollback-Möglichkeit -> kompensierende Methoden)
	
	- Kontextfreiheit (keine Benutzer, keine Sitzungen)
	
	- richtige Abstraktionsebene (nicht zu konkret -> prüfen mit Änderungsszenarien)
	
	
	Systemkategorien für Systemlandschaften
	
	-------------------------------------------------
	
	Portale
	
	- Zugang zu ein oder mehreren Anwendungen
	
	- Single-Sign-On
	
	- oft nur ein Portal pro Systemlandschaft, möglicherweise verschiedene
	je Benutzergruppe
	
	- technischer Rahmen, wenig fachliche Logik
	
	
	Prozesse
	
	- jedes Prozesssystem unterstützt einen oder mehrere Geschäftsprozesse
	
	- kann im ESB implementiert sein
	
	- Steuerung des Workflows, Abbildung der Geschäftsprozesse
	
	- fachlicher Rahmen
	
	
	Funktionen
	
	- Implementierung der Services
	
	- Verknüpfung zu Workflows
	
	
	Daten
	
	- Einhaltung der Konsistenzbedingungen
	
	- Standard-Geschäftsobjektfunkionen
	
	
	Analyse
	
	- Verdichtung und Analyse der Geschäftsdaten},
  timestamp = {2008.05.29},
  url = {http://www.wirtschaftsinformatik.de/index.php;do=show/site=wi/sid=36fd063fe31c248580575d6811ad7574/alloc=12/id=2012}
}

@BOOK{Siedersleben2004,
  title = {Moderne Software-Architektur: Umsichtig planen, robust bauen mit
	Quasar},
  publisher = {dpunkt.verlag},
  year = {2004},
  author = {Johannes Siedersleben},
  pages = {281},
  address = {Heidelberg, Germany},
  keywords = {Quasar, software architecture},
  language = {german},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://www.dpunkt.de/buecher/2142.html}
}

@ARTICLE{Siedersleben2000,
  author = {Johannes Siedersleben and Ernst Denert},
  title = {Wie baut man Informationssysteme? {\"U}berlegungen zur Standardarchitektur},
  journal = {Informatik Spektrum},
  year = {2000},
  volume = {23},
  pages = {247-257},
  number = {4},
  ee = {http://dx.doi.org/10.1007/s002870000110},
  file = {Informationssysteme-Siedersleben2000.pdf:literature/Informationssysteme-Siedersleben2000.pdf:PDF},
  keywords = {Quasar, Software Architecture, Quality},
  owner = {matthias},
  timestamp = {2012.12.21}
}

@TECHREPORT{Siedersleben2003,
  author = {Siedersleben (ed.), Johannes},
  title = {{Quasar: Die sd\&m Standardarchitektur. Parts 1 and 2}},
  institution = {sd\&m Research},
  year = {2003},
  abstract = {Dieses Papier beschreibt die Standardarchitektur betrieblicher Informationssysteme
	bei sd&m. Der vorliegende Teil 1 behandelt folgende Themen: 
	
	●Grundsätze und Begriffe (Kapitel 1 und 2) 
	
	●Quasar-Windmühle (Kapitel 3) 
	
	●Standardarchitektur des Anwendungskerns (Kapitel4) 
	
	Teil 1 ist Ergebnis der Arbeitsgruppe Software-Architektur im Rahmen
	des Projekts „Themenarbeit“. Mitglieder dieser Gruppe waren Andreas
	Hess, Bernhard Humm, Stefan Scheidle und Johannes Siedersleben. 
	
	Teil 2 behandelt die Standardarchitekturen für Transaktionen, Persistenz,
	GUI und Verteilung. 
	
	Von den zahllosen Reviewern seien namentlich genannt: Gerd Beneken,
	Manfred Broy, Olaf Deterding-Meyer, Roland Feindor, Olaf Fricke,
	Alex Hofmann, Christian Kamm, Oliver Juwig, Hanno Ridder, Rupert
	Stützle, Markus Uhlendahl und Boris Zech. Ihnen allen wird herzlich
	gedankt.},
  comment = {http://www.fbi.h-da.de/fileadmin/personal/b.humm/Publikationen/Siedersleben_-_Quasar_2__sd_m_Brosch_re_.pdf},
  file = {:./literature/sdm_quasar_teil-1.pdf:PDF;:./literature/sdm_quasar_teil-2.pdf:PDF},
  keywords = {software architecture, Quasar},
  owner = {Stephan},
  timestamp = {2008.08.01},
  url = {http://www.fbi.h-da.de/fileadmin/personal/b.humm/Publikationen/Siedersleben_-_Quasar_1__sd_m_Brosch_re_.pdf}
}

@PHDTHESIS{Sigdel2011,
  author = {Kamana Sigdel},
  title = {System-Level Design Space Exploration of Reconfigurable Architectures},
  school = {Technische Universiteit Delft},
  year = {2011},
  abstract = {Reconfigurable architectures are becoming increasingly popular as
	
	they bear a promise of combining the flexibility of software with
	
	the performance of hardware. Nevertheless, such architectures are
	
	subject to numerous constraints, such as performance, memory requirements,
	
	chip area, and power consumption. To create an efficient design, performing
	
	Design Space Exploration (DSE) at various stages is essential in order
	to
	
	effectively appraise several design alternatives. DSE at early design
	stages
	
	facilitates designers in rapid performance evaluation of different
	parameters,
	
	such as architectural characteristics, application-to-architecture
	mappings,
	
	scheduling policies, and hardware-software partitionings. DSE methodologies
	
	help traversing (typically) huge design spaces efficiently, thus performing
	
	DSE at a high level of abstraction facilitates design decisions to
	be made at
	
	very early design stages, which can significantly reduce the overall
	design
	
	time of a system.
	
	Towards this goal, in this dissertation, we develop a generic system-level
	
	framework, called rSesame, in order to perform modeling and simulation
	
	of dynamically reconfigurable architectures at early design stages.
	The
	
	framework can be deployed as a standard modeling and simulation framework
	
	for performing system-level DSE to explore several design parameters,
	while
	
	designing dynamically reconfigurable architectures. Performing runtime
	
	evaluations together with static explorations, enables reconfigurable
	architectures
	
	to be more efficient in terms of several design constraints. As a
	
	result, the rSesame framework combines both static and runtime explorations
	
	in order to facilitate system-level DSE of reconfigurable architectures
	with
	
	respect to architectural exploration, hardware-software partitioning
	and task
	
	mapping/scheduling.
	
	We deployed the rSesame framework to evaluate the Molen reconfigurable
	
	architecture by assessing and evaluating a wide range of applicationto-
	
	architecture-mappings. These mappings are evaluated based on different
	
	system attributes, such as execution time, number of reconfigurations,
	timeweighted
	
	area usage, percentage of hardware/software execution, percentage
	
	of reconfiguration, and hardware reusability efficiency, under different
	resource
	
	conditions. The case study shows that the rSesame framework can be
	
	efficiently deployed to facilitate system-level DSE of reconfigurable
	architectures
	
	by effectively appraising several alternatives, both statically and
	at runtime.
	
	The study also shows that the framework can be deployed, not only
	to
	
	evaluate and compare different architecture-to-application-mappings,
	but also
	
	to efficiently evaluate different architectural conditions at runtime.},
  file = {:literature/Sigdel-PhD-2011.pdf:PDF},
  owner = {matthias},
  timestamp = {2013.04.15}
}

@INPROCEEDINGS{Sillito2006,
  author = {Sillito, Jonathan and Murphy, Gail C and {De Volder}, Kris},
  title = {{Questions programmers ask during software evolution tasks}},
  booktitle = {14th ACM SIGSOFT international symposium on Foundations of software
	engineering - SIGSOFT '06/FSE-14},
  year = {2006},
  pages = {23-33},
  doi = {10.1145/1181775.1181779},
  file = {:./literature/Sillito2006.pdf:PDF},
  isbn = {1595934685},
  keywords = {Information needs,Software Evolution,change tasks,development tools,empirical
	study,grounded theory,program comprehension,soft-,ware evolution},
  mendeley-groups = {Empirical study,ICSE2015,ECSA2014},
  mendeley-tags = {Information needs,Software Evolution},
  owner = {Sebastian},
  timestamp = {2014.03.07},
  url = {http://portal.acm.org/citation.cfm?doid=1181775.1181779}
}

@INCOLLECTION{Simao2003,
  author = {Régis P. S. Simão and Arnaldo D. Belchior},
  title = {Quality Characteristics for Software Components: Hierarchy and Quality
	Guides},
  booktitle = {Component-Based Software Quality},
  publisher = {Springer},
  year = {2003},
  volume = {2693/2003},
  series = {LNCS},
  chapter = {10},
  pages = {184-206},
  abstract = {The success of software component applications dependsupon a number
	of factors, one of the most important being the quality of components.
	According to the ISO/IEC 9126 standard, quality characteristics can
	be used both as goals to be attained in the processes of developing,
	selecting or acquiring components and as criteria for predicting
	the properties of final applications. This chapter identifies the
	quality characteristics and sub-characteristics most relevant for
	software components and organizes them in dimensions that are critical
	to their assessment. A quality guide is presented, which was elaborated
	through a field research carried out with developers of components
	and component-based applications. A software quality evaluation model
	was used to treat collected data.},
  doi = {10.1007/b11721},
  file = {:./literature/Simao2003.pdf:PDF},
  keywords = {quality attributes, quality characteristics, software components,
	principles},
  owner = {Stephan},
  timestamp = {2009.11.11}
}

@ARTICLE{Simidchieva2007,
  author = {Simidchieva, B. and Clarke, L. and Osterweil, L.},
  title = {Representing process variation with a process family},
  journal = {Software Process Dynamics and Agility},
  year = {2007},
  pages = {109--120},
  file = {Simidchieva2007.pdf:literature/Simidchieva2007.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.07.20}
}

@INCOLLECTION{Singer2008,
  author = {Singer, Janice and Sim, Susan E. and Lethbridge, Timothy C.},
  title = {Software Engineering Data Collection for Field Studies},
  booktitle = {Guide to Advanced Empirical Software Engineering},
  publisher = {Springer London},
  year = {2008},
  editor = {Shull, Forrest and Singer, Janice and SjÃ¸berg, Dag I. K.},
  pages = {9-34},
  note = {10.1007/978-1-84800-044-5_1},
  abstract = {Software engineering is an intensely people-oriented activity, yet
	little is known about how software engineers perform their work.
	In order to improve software engineering tools and practice, it is
	therefore essential to conduct field studies, i.e., to study real
	practitioners as they solve real problems. To aid this goal, we describe
	a series of data collection techniques for such studies, organized
	around a taxonomy based on the degree to which interaction with software
	engineers is necessary. For each technique, we provide examples from
	the literature, an analysis of some of its advantages and disadvantages,
	and a discussion of special reporting requirements. We also talk
	briefly about recording options and data analysis.},
  affiliation = {National Research Council Canada Institute for Information Technology
	K1A 0R6 Ottawa Ontario Canada},
  file = {:./literature/Singer2008.pdf:PDF},
  isbn = {978-1-84800-044-5},
  keyword = {Computer Science},
  owner = {elkeb},
  timestamp = {2011.06.27},
  url = {http://dx.doi.org/10.1007/978-1-84800-044-5_1}
}

@MISC{Singh1995,
  author = {Raghu Singh},
  title = {INTERNATIONAL STANDARD, ISO/IEC 12207, SOFTWARE LIFE CYCLE PROCESSES},
  howpublished = {Federal Aviation Administration
	
	Washington, DC, USA},
  year = {1995},
  owner = {Elke},
  timestamp = {2011.06.08}
}

@ARTICLE{Sipper2012,
  author = {Sipper, Moshe},
  title = {Ubiquity symposium: Evolutionary computation and the processes of
	life: Darwinian software engineering: the short term, the middle
	ground, and the long haul},
  journal = {Ubiquity},
  year = {2012},
  volume = {2012},
  pages = {2:1--2:6},
  number = {December},
  month = dec,
  abstract = {In this article, Moshe Sipper discusses a foreseeable future in which
	an entirely new paradigm of producing software will emerge. Sipper
	calls this software engineering revolution, “Darwinian Software Engineering”—a
	time when it will be possible to program computers by means of 
	
	evolution.},
  address = {New York, NY, USA},
  articleno = {2},
  doi = {10.1145/2406356.2406358},
  file = {:./literature/sipper2012.pdf:PDF},
  issn = {1530-2180},
  issue_date = {December 2012},
  keywords = {evolution},
  numpages = {6},
  owner = {matthias},
  publisher = {ACM},
  timestamp = {2013.01.09},
  url = {http://doi.acm.org/10.1145/2406356.2406358}
}

@INPROCEEDINGS{Skoglund2005,
  author = {Skoglund, M. and Runeson, P.},
  title = {A case study of the class firewall regression test selection technique
	on a large scale distributed software system},
  booktitle = {Empirical Software Engineering, 2005. 2005 International Symposium
	on},
  year = {2005},
  pages = { 10 pp.},
  month = {nov.},
  __markedentry = {[qurat:]},
  doi = {10.1109/ISESE.2005.1541816},
  file = {:/literature/RegressionTesting/ACaseStudyofTheClassFirewallRegressionTestSelectionTechniqueona LargeScaleDistributedSoftwareSystem.pdf:PDF},
  keywords = {Read, Relevant, CaseStudy, Java byte code analysis; class firewall
	regression test selection technique; empirical evaluation; large
	scale distributed software system; large scale industrial software
	system; organization software development budget; scenario testing;
	test execution; Java; authorisation; distributed processing; program
	testing; regression analysis;},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@INPROCEEDINGS{Sneed2006b,
  author = {Sneed, H.M.},
  title = {Integrating legacy software into a service oriented architecture},
  booktitle = {Proceedings of the 10th European Conference on Software Maintenance
	and Reengineering, 2006. CSMR 2006.},
  year = {2006},
  volume = {00},
  pages = {11 pp.},
  month = {March},
  publisher = {IEEE Computer Society},
  abstract = {Legacy programs, i. e. programs which have been developed with an
	outdated technology make-up for the vast majority of programs in
	many user application environments. It is these programs which actually
	run the information systems of the business world. Moving to a new
	technology such as service oriented architecture is impossible without
	taking these programs along. This contribution presents a tool supported
	method for achieving that goal. Legacy code is wrapped behind an
	XML shell which allows individual functions within the programs,
	to be offered as Web services to any external user. By means of this
	wrapping technology, a significant part of the company software assets
	can be preserved within the framework of a service oriented architecture.},
  doi = {10.1109/CSMR.2006.28},
  file = {:./literature/01602353.pdf:PDF},
  issn = {1052-8725 },
  keywords = {Internet, XML, integrated software, software architecture, software
	maintenance, software tools Web service, Web services description
	language, XML, company software assets, legacy code, legacy program,
	legacy software, service oriented architecture, system integration,
	tool supported method, wrapping technology},
  owner = {Stephan},
  timestamp = {2008.06.16}
}

@INPROCEEDINGS{Sneed2006a,
  author = {Sneed, Harry M.},
  title = {Selective Regression Testing of a Host to DotNet Migration},
  booktitle = {Proceedings of the 22nd IEEE International Conference on Software
	Maintenance},
  year = {2006},
  pages = {104--112},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[qurat:]},
  acmid = {1172985},
  doi = {10.1109/ICSM.2006.57},
  file = {:/literature/RegressionTesting/Selective Regression Testing of a host dotnet migration.pdf:PDF},
  isbn = {0-7695-2354-4},
  keywords = {CaseStudy, .net classes},
  numpages = {9},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=1172962.1172985}
}

@INPROCEEDINGS{Sneed2004,
  author = {Sneed, Harry M.},
  title = {Reverse Engineering of Test Cases for Selective Regression Testing},
  booktitle = {Proceedings of the Eighth Euromicro Working Conference on Software
	Maintenance and Reengineering (CSMR'04)},
  year = {2004},
  pages = {69--},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[qurat:]},
  acmid = {977751},
  file = {:/literature/RegressionTesting/Reverse Engineering of Test Cases for Selective Regression Testing.pdf:PDF},
  isbn = {0-7695-2107-X},
  keywords = {Read, Relevant, Reverse engineering to link code with specification,
	selective regression testing, test caserecovery, static code analysis,
	dynamic test analysis,system repositories},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=977397.977751}
}

@BOOK{Snehota1995,
  title = {Developing relationships in business networks},
  publisher = {Routledge, London},
  year = {1995},
  author = {Snehota, I. and Hakansson, H.},
  file = {Snehota1995.pdf:literature/Snehota1995.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.10.30}
}

@PHDTHESIS{Sochos2006a,
  author = {Periklis Sochos},
  title = {The Feature-Architecture Mapping Method for Feature-Oriented Development
	of Software Product Lines},
  school = {Technical University of Ilmenau, Germany},
  year = {2006},
  keywords = {feature model, feature-oriented design},
  owner = {Robert},
  timestamp = {2008.07.16}
}

@INPROCEEDINGS{Sochos2006,
  author = {Periklis Sochos and Matthias Riebisch and Ilka Philippow},
  title = {The Feature-Architecture Mapping (FArM) Method for Feature-Oriented
	Development of Software Product Lines},
  booktitle = {Proceedings 13th Annual IEEE International Symposium and Workshop
	on Engineering of Computer Based Systems, ECBS},
  year = {2006},
  pages = {308-318},
  month = {March},
  publisher = {IEEE Computer Society},
  abstract = {Software product lines (PLs) are large, complex systems, demanding
	high maintainability and enhanced flexibility. Nonetheless, in the
	state of the art PL methods, features are scattered and tangled throughout
	the system components, leading to poor maintainability. Additionally,
	the majority of PL methods support manual product composition, while
	the implementation of feature-level variability in PL products influences
	the system's conceptual integrity. Generative programming techniques
	do enhance flexibility, but on the cost of maintainability. The feature-architecture
	mapping (FArM) method provides a stronger mapping between features
	and the architecture. It is based on a series of transformations
	on the initial PL feature model. During these transformations, architectural
	components are derived, encapsulating the business logic of each
	transformed feature and having interfaces reflecting the feature
	interactions. The flexibility of FArM architectures is supported
	through the explicit integration of plug-in mechanisms. The methodology
	is evaluated in the context of a wireless handheld device PL.},
  doi = {http://doi.ieeecomputersociety.org/10.1109/ECBS.2006.69},
  file = {:./literature/01607380.pdf:PDF},
  isbn = {0-7695-2546-6},
  keywords = {object-oriented programming, software architecture, software maintenance
	FArM architecture, PL feature model, architectural component, business
	logic, complex system, feature-architecture mapping, feature-oriented
	development, plug-in mechanism, software product line, wireless handheld
	device PL},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://www.theoinf.tu-ilmenau.de/~Matthias/home/publ/ecbs06-FArMfinal.pdf}
}

@INPROCEEDINGS{Some2008,
  author = {Som\'{e}, St\'{e}phane S. and Anthonysamy, Pauline},
  title = {An approach for aspect-oriented use case modeling},
  booktitle = {Proceedings of the 13th international workshop on Software architectures
	and mobility (EA'08)},
  year = {2008},
  pages = {27-34},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {A use case model is a speciﬁcation of a system’s requirements consisting
	in use cases, actors and relationships. A use case captures stakeholders
	concerns as required interactions between a system and its actors.
	Use case models may however include concerns that crosscut across
	several use cases. We propose an <<aspect >> relation for the modularization
	and composition of these crosscutting concerns. The composition approach
	is formally established by mappings to Petri nets, and is implemented
	as an extension to an existing use case modeling tool.},
  doi = {http://doi.acm.org/10.1145/1370828.1370835},
  file = {:./literature/ea05d-some.pdf:PDF},
  isbn = {978-1-60558-032-6},
  keywords = {aspect-oriented use case modelling},
  location = {Leipzig, Germany},
  owner = {Stephan},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Soto2008,
  author = {Soto, Martin and Munch, J\"{u}rgen},
  title = {Using model comparison to maintain model-to-standard compliance},
  booktitle = {Proceedings of the 2008 international workshop on Comparison and
	versioning of software models},
  year = {2008},
  series = {CVSM '08},
  pages = {35-40},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1370162},
  doi = {http://doi.acm.org/10.1145/1370152.1370162},
  file = {:/literature/changeIdentification/p35-soto.pdf:PDF},
  isbn = {978-1-60558-045-6},
  keywords = {Read, compliance, compliance maintenance, deltaprocess, evolyzer,
	model comparison, software processes},
  location = {Leipzig, Germany},
  numpages = {6},
  owner = {Steffen},
  timestamp = {2012.03.01},
  url = {http://doi.acm.org/10.1145/1370152.1370162}
}

@INPROCEEDINGS{Sousa2003,
  author = {Ge\'orgia Maria C. de Sousa and Ism\^{e}nia G. L. da Silva and Jaelson
	Brelaz de Castro},
  title = {Adapting the {NFR} Framework to Aspect-Oriented Requirements Engineering},
  booktitle = {XVII Brazilian Symposium on Software Engineering},
  year = {2003},
  address = {Manaus, Brazil},
  month = {October},
  abstract = {One of the most important principles in Software Engineering is separation
	of concerns. At first, the research towards applying that principle
	throughout the software development process has provided structured
	and object-oriented methods. However, when using those methods it
	is difficult to achieve separation of concerns such as security,
	performance, reliability, persistence, distribution, etc., the so-called
	crosscutting concerns. Hence, Aspect-Oriented Paradigm has emerged
	to address those issues. Similar to what happened with structured
	and object-oriented paradigms, in the last years, the Software Engineering
	community has been interested in propagating the Aspect-Oriented
	Paradigm to early stages of the software life cycle. The purpose
	of this paper is to give a contribution to Aspect-Oriented Requirements
	Engineering, adapting the NFR-Framework in order to improve the mapping
	of crosscutting non-functional requirements onto artifacts at later
	development stages and to make better the composition of those requirements
	with non-crosscutting ones.},
  file = {:./literature/SBES03_AdaptingTheNFRFrameworkToAspect.pdf:PDF},
  keywords = {aspect-oriented requirements engineering, AORE, NFR framework, non-functional
	requirements, crosscutting requirements},
  owner = {Stephan},
  timestamp = {2008.07.31},
  url = {http://www.imira.im.ufba.br/pub/Aside/ProjetoPibicAliceReferencias/SBES03_AdaptingTheNFRFrameworkToAspect.pdf}
}

@INPROCEEDINGS{Spanoudakis2003,
  author = {G. Spanoudakis and A. d'Avila-Garces and A. Zisman},
  title = {Revising Rules to Capture Requirements Traceability Relations: A
	Machine Learning Approach},
  booktitle = {Proceedings of the 15th International Conference in Software Engineering
	and Knowledge Engineering (SEKE 2003)},
  year = {2003},
  pages = {570-577},
  organization = {Knowledge Systems Institute, Skokie},
  file = {:./literature/Spanoudakis2003.pdf:PDF},
  keywords = {rule-based traceability},
  owner = {Stephan},
  timestamp = {2010.12.11}
}

@INCOLLECTION{Spanoudakis2005,
  author = {George Spanoudakis and Andrea Zisman},
  title = {Software Traceability: A Roadmap},
  booktitle = {Handbook of Software Engineering and Knowledge Engineering},
  publisher = {World Scientific Publishing Co.},
  year = {2005},
  editor = {Chang S. K.},
  volume = {III},
  pages = {395-428},
  address = {River Edge, NJ},
  __markedentry = {[Steffen:]},
  abstract = {Traceability of software artefacts has been recognised as an important
	factor for supporting various activities in the software system development
	process. In general, the objective of traceability is to improve
	the quality of software systems. More specifically, traceability
	information can be used to support the analysis of implications and
	integration of changes that occur software systems; the maintenance
	and evolution of software systems; the reuse of software system components
	by identifying and comparing requirements of new and existing systems;
	the testing of software system components; and system inspection,
	by indicating alternatives and compromises made during development.
	Traceability enables system acceptance by allowing users to better
	understand the system and contributes to clear and consistent system
	documentation. Over the last few years, the software and system engineering
	communities have developed a large number of approaches and techniques
	to address various aspects of traceability. Research into software
	traceability has been mainly concerned with the study and definition
	of different types of traceability relations; support for the generation
	of traceability relations; development of architectures, tools, and
	environments for the representation and maintenance of traceability
	relations; and empirical investigations into organisational practices
	regarding the establishment and deployment of traceability relations
	in the software development life cycle. However, despite its importance
	and the work resulted from numerous years of research, empirical
	studies of traceability needs and practices in industrial organisations
	have indicated that traceability support is not always satisfactory.
	As a result, traceability is rarely established in existing industrial
	settings. In this article, we present a roadmap of research and practices
	related to software traceability and identify issues that are still
	open for further research. Our roadmap is organised according to
	the main topics that have been the focus of software traceability
	research.},
  citeseerurl = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.154.2734},
  file = {:./literature/SoftwareTraceabilityRoadmap.pdf:PDF},
  keywords = {software traceability, traceability relations, representation and
	maintenance of traceability, deployment of traceability, software
	development process},
  owner = {Stephan},
  review = {exhausting state-of-the-art analysis of existing traceability approaches
	
	- vertical/horizontal
	
	- pre-traceability/post-traceability
	
	- manual, semi-automatic, automatic
	
	
	good analysis of link types
	
	- dependency
	
	- generalisation/refinement
	
	- evolution
	
	- satisfaction
	
	- overlap
	
	- conflicting
	
	- rationalisation
	
	- contribution
	
	
	approach types for representation, recording, and maintenance
	
	- single centralised database
	
	- software repository
	
	- hypermedia
	
	- mark-up (XML with XLink)
	
	- event-based
	
	
	purposes
	
	- change impact analysis
	
	- verification, validation, testing, standards compliance analysis
	
	- reuse of software artefacts
	
	- software artefact understanding
	
	
	good explanation of what is still missing or insufficient
	
	- clear and precise semantics (for example through standardized link
	types), deep and richer sematics
	
	- only few approaches considering conflict and rationalisation relations
	
	- CASE tools lack support for satisfiability relations and dependency
	relations
	
	- abstraction mechanisms necessary to support different granularity
	for utilization of links
	
	- reliable automated approaches
	
	- (automated) rule-based approaches good (in precision and recall)
	but not perfect - trust of users needed
	
	- cost-effectiveness, correctness, completeness
	
	- use of ontologies, machine learning techniques
	
	- tool support for all link types and artefact types along the development
	process
	
	- yet no automatic generation technique/tool for heterogeneous development
	settings (with different CASE tools)},
  timestamp = {2010.07.30}
}

@ARTICLE{Spanoudakis2004,
  author = {Spanoudakis, G. and Zisman, A. and Perez-Minana, E. and Krause, P.},
  title = {Rule-Based Generation of Requirements Traceability Relations},
  journal = {Journal of Systems and Software},
  year = {2004},
  volume = {72},
  pages = {105-127},
  number = {2},
  __markedentry = {[Steffen:]},
  abstract = {The support for traceability between requirement specifications has
	been recognised as an important task in the development life cycle
	of software systems. In this paper, we present a rule-based approach
	to support the automatic generation of traceability relations between
	documents which specify requirement statements and use cases (expressed
	in structured forms of natural language), and analysis object models
	for software systems. The generation of such relations is based on
	traceability rules of two different types. More specifically, we
	use requirement-to-object-model rules to trace the requirements and
	use case specification documents to an analysis object model, and
	inter-requirements traceability rules to trace requirement and use
	case specification documents to each other. By deploying such rules,
	our approach can generate four different types of traceability relations.
	To implement and demonstrate our approach, we have implemented a
	traceability prototype system. This system assumes requirement and
	use case specification documents and analysis object models represented
	in XML. It also uses traceability rules which are represented in
	an XML-based rule mark-up language that we have developed for this
	purpose. This XML-based representation framework makes it easier
	to deploy our prototype in settings characterised by the use of heterogeneous
	software engineering and requirements management tools. The developed
	prototype has been used in a series of experiments that we have conducted
	to evaluate our approach. The results of these experiments have provided
	encouraging initial evidence about the plausibility of our approach
	and are discussed in the paper.},
  doi = {http://dx.doi.org/10.1016/S0164-1212(03)00242-5},
  file = {:./literature/jss04.pdf:PDF},
  keywords = {Requirement traceability; Natural language processing; Rule-based
	traceability reasoning},
  owner = {Stephan},
  timestamp = {2009.03.31},
  url = {http://www.soi.city.ac.uk/~gespan/jss04.pdf}
}

@MASTERSTHESIS{Spijkerman2010,
  author = {Spijkerman, Wietze},
  title = {Tool Support for Change Impact Analysis in Requirement Models - Exploiting
	semantics of requirement relations as traceability relations},
  school = {Faculty of Electrical Engineering, Mathematics and Computer Science,
	University of Twente},
  year = {2010},
  month = {October},
  file = {:./literature/Master_4.pdf:PDF},
  owner = {Steffen},
  review = {useful stuff: change impact rules for requirements
	
	
	- requirements are first artifacts available in software development
	and therefore subject of change right from the beginning
	
	- one must use semantics of traceability links to limit "impact explosion"
	
	- exploit semantics of requirements relations to conduct impact analysis;
	by identifying a classification for requirements changes
	
	- contribution is also refinement of requirements relations for impact
	analysis
	
	- establish rules to facilitate impact propagation across requirements
	based on their interconnections (traces)
	
	
	- scope of analysis: requirements
	
	- tool: TRIC-CIA
	
	- language: -
	
	- scalability: -
	
	- granularity
	
	* changes: +/- requirement, +/-/chg. req. property, +/-/chg. req.
	constraint, +/-chg. req. relation
	
	* artifacts: requirement
	
	* results: requirement
	
	- technique: traceability, rules
	
	- analysis style:
	
	- evaluation
	
	* size: -
	
	* precision: -
	
	* recall: -
	
	* time: -},
  timestamp = {2011.02.23}
}

@INPROCEEDINGS{Sridharan2007,
  author = {Sridharan, Manu and Fink, Stephen J. and Bod\'{i}k, Rastislav},
  title = {Thin Slicing},
  booktitle = {Proceedings of the 2007 ACM SIGPLAN conference on Programming language
	design and implementation (PLDI '07)},
  year = {2007},
  pages = {112-122},
  month = {June},
  file = {:./literature/Paper_64.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- slices of modern programs produced by standard slicing grow too
	large for human perception and understanding
	
	- common definition of relevance to widespread
	
	- not all statements of a slice are of an equivalent value to developers
	
	
	Research Questions:
	
	- what statements do really affect a certain variable etc. and what
	statements can be excluded (although dependent) from/on the slice
	
	
	Contribution:
	
	- new slicing approach called "Thin Slicing"
	
	- slice consists of only those statements that produce and copy values
	to it
	
	
	Solution:
	
	- only include statements that are useful for understanding / developing
	(i.e. don't include statements of well-tested/understood libraries
	if they affect a traced statement)
	
	- technically, only direct uses of memory locations
	
	* they are called producer statements
	
	* i.e. statements that connect other statements with their producers
	(producer flow dependency)
	
	- exclude statements that say why something affects a trace item are
	excluded (only those that compute items are allowed)
	
	* they are called explainer statements
	
	- thin slices can be expanded to show explainer statements, e.g. for
	explaining aliasing
	
	* compute additional thin slices for the pointers in question
	
	- thin slices computed as follows:
	
	* compute a statement's transitive flow dependencies
	
	* compute a call graph to track interprocedural dependencies (difference
	to existing slicing: add edges to statements instead, not just to
	other procedures)
	
	* apply transitive closure on this graph to obtain thin slice 
	
	
	Open Issues:},
  timestamp = {2011.02.16}
}

@INPROCEEDINGS{Stoerzer2006,
  author = {St\"{o}rzer, Maximilian and Ryder, Barbara G. and Ren, Xiaoxia and
	Tip, Frank},
  title = {Finding Failure-Inducing Changes in {Java} programs using Change
	Classification},
  booktitle = {Proceedings of the 14th ACM SIGSOFT international symposium on Foundations
	of software engineering},
  year = {2006},
  pages = {57-68},
  address = {Portland, Oregon, USA},
  file = {:./literature/Paper_184.PDF:PDF},
  owner = {Steffen},
  timestamp = {2011.10.17}
}

@ARTICLE{Staab2001,
  author = {Staab, S. and Studer, R. and Schnurr, H.-P. and Sure, Y.},
  title = {Knowledge processes and ontologies},
  journal = {IEEE Intelligent Systems},
  year = {2001},
  volume = {16},
  pages = {26-34},
  number = {1},
  month = {Jan/Feb},
  abstract = { In this article, we present an approach for ontology-based knowledge
	management (KM) that includes a tool suite and a methodology for
	developing ontology-based KM systems. It builds on the distinction
	between knowledge processes and knowledge metaprocesses, and is illustrated
	by CHAR (Corporate History AnalyzeR), a KM system for corporate history
	analysis.},
  doi = {10.1109/5254.912382},
  file = {:./literature/Staab2001.pdf:PDF},
  issn = {1541-1672},
  keywords = {CHAR; corporate history analysis; knowledge metaprocesses; knowledge
	processes; ontology-based knowledge management; software tool suite;
	business data processing; knowledge based systems; management; Ontology
	Engineering, On-To-Knowledge},
  owner = {Stephan},
  timestamp = {2011.03.15}
}

@INPROCEEDINGS{Stallbaum2008,
  author = {Heiko Stallbaum and Andreas Metzger and Klaus Pohl},
  title = {An automated technique for risk-based test case generation and prioritization},
  booktitle = {Proceedings of the 3rd international workshop on Automation of software
	test},
  year = {2008},
  pages = {67--70},
  address = {Leipzig, Germany},
  publisher = {{ACM}},
  abstract = {In practice, available testing budgets limit the number of test cases
	that can be executed. Thus, a representative subset of all possible
	test cases must be chosen to guarantee adequate coverage of a test
	object. In risk-based testing, the probability of a fault and the
	damage that this fault can cause when leading to a failure is considered
	for test case prioritization. Existing approaches for risk-based
	testing provide guidelines for deriving test cases. However, those
	guidelines lack the level of detail and precision needed for automation.
	In this contribution, we introduce the risk-based testing technique
	{RiteDAP,} which automatically generates system test cases from activity
	diagrams and prioritizes those test cases based on risk. The results
	of applying the technique to a practical example are presented and
	the ability of different prioritization strategies to uncover faults
	is evaluated.},
  doi = {10.1145/1370042.1370057},
  file = {:/literature/RegressionTesting/An Automated Technique for Risk-based Test Case Generation and Prioritization.pdf:PDF},
  isbn = {978-1-60558-030-2},
  keywords = {model-based testing, risk-based testing, test case generation},
  owner = {Annie},
  timestamp = {2011.01.04},
  url = {http://portal.acm.org/citation.cfm?id=1370042.1370057&coll=GUIDE&dl=GUIDE&CFID=54491404&CFTOKEN=93053143}
}

@BOOK{Stamatis2003,
  title = {Failure Mode and Effect Analysis: FMEA from Theory to Execution},
  publisher = {ASQ Quality Press},
  year = {2003},
  author = {D. H. Stamatis},
  edition = {2nd},
  keywords = {Failure Mode and Effect Analyis, FMEA},
  owner = {Stephan},
  timestamp = {2008.10.28},
  url = {http://books.google.de/books?id=T9TxNHWJZmIC}
}

@INPROCEEDINGS{Stanek2006,
  author = {J. Stanek and S. Kothari and T.N. Nguyen and C. Cruz-Neira},
  title = {Online Software Maintenance for Mission-Critical Systems},
  booktitle = {Software Maintenance, 2006. ICSM '06. 22nd IEEE International Conference
	on},
  year = {2006},
  pages = {93--103},
  abstract = {Online software maintenance {(OSM)} is performed while an application
	is running. It requires transforming the runtime state of the application
	to go along with updates of its software. The goal is to perform
	maintenance of mission-critical systems while they continue to run.
	This research presents dynamically evolvable C++ classes as a way
	to enable {OSM.} The associated implementation mechanism is called
	the {OSM} framework. We provide a high-level view of the {OSM} framework
	and then describe different types of object-oriented design transformations
	that are supported. The accompanying state transformations are described
	to evolve the live objects along with the software. We have implemented
	a prototype of the {OSM} framework; it works with the g++ and the
	Microsoft C++ compilers. Performance results are presented to assess
	the memory and processing overheads of the {OSM} framework. The proposed
	approach advances the state of the art in two ways: (a) it extends
	the notion of dynamic evolvability by including fission and fusion
	and other object-oriented design transformations, and (b) it provides
	a novel {OSM} framework that takes advantage of C++ templates},
  doi = {10.1109/ICSM.2006.44},
  file = {:/literature/RegressionTesting/Online Software Maintenance for Mission-Critical Systems.pdf:PDF},
  isbn = {1063-6773},
  keywords = {C++ language, dynamically evolvable C++ classes, mission-critical
	systems, object-oriented design transformation, object-oriented programming,
	online software maintenance, safety-critical software, software maintenance,
	software updates, state transformation},
  owner = {Annie},
  timestamp = {2011.01.04}
}

@ARTICLE{Stevens1974,
  author = {Wayne P. Stevens and Glenford J. Myers and Larry L. Constantine},
  title = {Structured Design},
  journal = {IBM Systems Journal},
  year = {1974},
  volume = {13},
  pages = {115-139},
  number = {2},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  file = {:./literature/ibmsj1302C.pdf:PDF},
  keywords = {software design, software engineering},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://domino.research.ibm.com/tchjr/journalindex.nsf/e90fc5d047e64ebf85256bc80066919c/751ad3c1867f587a85256bfa00685aaa?OpenDocument}
}

@MASTERSTHESIS{Stollberg2010,
  author = {Ralf Stollberg},
  title = {{Klassifikation von Architekturstilen und -mustern hinsichtlich qualitativer
	Ziele f\"ur den Softwarearchitekturentwurf}},
  school = {Ilmenau University of Technology},
  year = {2010},
  type = {Bachelor thesis},
  address = {Ilmenau, Germany},
  owner = {Stephan},
  timestamp = {2010.12.31}
}

@PHDTHESIS{Streitferdt2003a,
  author = {Detlef Streitferdt},
  title = {Family-Oriented Requirements Engineering},
  school = {Technische Universität Ilmenau},
  year = {2003},
  abstract = {Zusammenfassung:
	
	Heutige Softwareprodukte sollen in kurzer Zeit bei gleichzeitig hoher
	Qualität entwickelt werden, wobei die Software-Technik dieser Forderung
	durch die Vorfertigung einzelner Komponenten gerecht wird. Die geplante
	und umfassende Wiederverwendung von Komponenten innerhalb einer Anwendungsdomäne
	wird durch das Konzept der Systemfamilienentwicklung unterstützt.
	Eine Systemfamilie basiert auf einer Referenzarchitektur, die aus
	Anteilen besteht, die allen Familienmitgliedern gemein sind und Anteilen,
	die optional sind. In allen Phasen der Systemfamilienentwicklung
	müssen gemeinsame und optionale Anteile berücksichtigt und korrekt
	verarbeitet werden, wobei Fehler in der Requirements-Engineering-Phase,
	dem Beginn der Entwicklung, den größten wirtschaftlichen Schaden
	nach sich ziehen. In dieser Arbeit zeigt die Analyse der Requirements-Engineering-Phase
	der Systemfamilienentwicklung, dass die Systemfamilienmodelle der
	meisten, existierenden Ansätze auf der Merkmalmodellierung basieren,
	die jedoch inkonsistent und nicht automatisiert verarbeitbar ist.
	Der hier beschriebene Lösungsansatz - Family-Oriented Requirements
	Engineering (FORE) - erweitert Merkmalmodelle und integriert sie
	in ein neues Datenmodell, das alle im Verlauf der Requirements-Engineering-Phase
	erarbeiteten Informationen enthält. Zur Modellierung aller Abhängigkeiten
	innerhalb von Merkmalmodellen und von Merkmalen zu weiteren Modellelementen
	bietet FORE die neue Feature Constraint Language (FCL) mit 30 vordefinierten
	Beziehungen an, wodurch Systemfamilienmodelle überprüfbar sind. Durch
	die kundenspezifische Auswahl von Merkmalen wird ein Familienmitglied
	basierend auf der Systemfamilie abgeleitet. Die erweiterten Merkmalmodelle
	von FORE ermöglichen die automatisierte Überprüfung einer Merkmalauswahl,
	sodass nur gültige Familienmitglieder abgeleitet werden können. Sowohl
	die Entwicklung eines Systemfamilienmodells als auch die Ableitung
	von Familienmitgliedern werden durch den FORE-Entwicklungsprozess
	unterstützt, der existierende Ansätze und die erweiterte Merkmalmodellierung
	in einem Requirements-Engineering-Prozess für Systemfamilien integriert.
	Anhand eines Prototyps wird die Realisierbarkeit des Lösungsansatzes
	gezeigt, indem das FORE-Datenmodell in eine XML-Struktur umgesetzt
	und die Benutzung des Prototyps dem FORE-Entwicklungsprozess folgt.
	FORE wurde im Rahmen eines universitären Projektes, wie auch durch
	diverse studentische Arbeiten mit Industriepartnern überprüft. Die
	Ergebnisse dieser Arbeiten haben die Praxistauglichkeit von FORE
	gezeigt, den Prozess und das Datenmodell verbessert und dessen Grenzen
	aufgezeigt.
	
	
	Abstract:
	
	Modern software products shall be developed within a short time and
	at the same time they should be of a high quality. Software engineering
	is able to fulfill these requirements by prefabricating components.
	Within a domain, planned and comprehensive reuse of components is
	supported by the concept of system family development. A system family
	is based on a reference architecture made of assets, which are common
	to all family members and assets, which are variable. Commonalities
	and variabilities have to be considered in all phases of the system
	family development and they have to be elaborated correctly. Mistakes
	made in the requirements engineering phase, as the beginning of a
	development, will cause the most damage to the overall development.
	
	The analysis of the requirements engineering phase of system family
	development in this paper shows, that most of the current scientific
	solutions in this field are based on feature modeling, although it
	is inconsistent and cannot be automatically processed. The proposed
	solution of this paper - Family-Oriented Requirements Engineering
	(FORE) - extends feature modeling and integrates it into a new data
	model, capable of holding all the information acquired within the
	requirements engineering phase. Dependencies within feature models
	and between features and further model elements can be modeled with
	the new FORE Feature Constraint Language (FCL). FCL offers 30 predefined
	dependencies for verifiable system family models. Extended feature
	models of FORE allow the automated verification of a subset of features.
	Thus, only valid family members can be derived of the system family.
	The development of a system family model as well as the derivation
	of family members are supported by the FORE development process.
	The FORE-process integrates current processes and the extended feature
	modeling of FORE into a requirements engineering process for system
	families. The proposed solution was prototypically realized by implementing
	the FORE-Data Model as XML-Schema. The usage of the prototype is
	aimed at the FORE-Development Process. FORE was tested within a University
	project as well as in several student works with industry partners.
	The results of this paper have shown the applicability of FORE, improved
	its process and data model and revealed its limits.},
  file = {:./literature/ilm1-2004000032.pdf:PDF},
  keywords = {requirements engineering},
  owner = {Robert},
  timestamp = {2007.03.20},
  url = {http://www.db-thueringen.de/servlets/DocumentServlet?id=1744}
}

@INPROCEEDINGS{Streitferdt2003,
  author = {Detlef Streitferdt and Matthias Riebisch and Ilka Philippow},
  title = {Details of Formalized Relations in Feature Models Using {OCL}},
  booktitle = {Proceedings 10th IEEE International Conference and Workshop on the
	Engineering of Computer-Based Systems, ECBS},
  year = {2003},
  pages = {297-304},
  month = {April},
  publisher = {IEEE Computer Society},
  abstract = {System families are a form of high level reuse of development assets
	in a specific problem domain, by making use of commonalities and
	variabilities. To represent assets belonging to the core of the family
	and assets belonging to variable parts, feature modeling is a widely
	used concept. Consistency checking in feature models is not yet addressed
	appropriately by current methods. The paper gives a brief overview
	of feature modeling and elaborates the problems of current approaches.
	Based on the applications of these approaches within an ongoing research
	project, the paper proposes a formalized definition for feature modeling
	using the Object Constraint Language (OCL) and a set of associations
	and constraints to be used in the feature model. The relations between
	features in the feature model and features to external assets are
	examined and a way to formally handle these relations is presented
	as a result of a research project.},
  doi = {http://doi.ieeecomputersociety.org/10.1109/ECBS.2003.1194811},
  file = {:./literature/01194811.pdf:PDF},
  isbn = {0-7695-1917-2},
  keywords = {constraint handling, formal specification, object-oriented languages,
	software reusability, specification languages Object Constraint Language,
	consistency checking, external assets, feature constraints, feature
	modeling, feature models, formalized definition, formalized relations,
	high level development asset reuse, system families},
  owner = {Robert},
  timestamp = {2008.07.16}
}

@ARTICLE{Strens1994,
  author = {Strens, R. and Dobson, J.},
  title = {Responsibility modelling as a technique for organisational requirements
	definition},
  journal = {Intelligent Systems Engineering},
  year = {1994},
  volume = {3},
  pages = {20-26},
  number = {1},
  month = {Spring},
  abstract = {The paper proposes that the concept of responsibility provides a means
	of identifying and specifying, in a way that is meaningful both to
	users and systems designers, the organisational requirements that
	arise when a technical system is placed in a social context. The
	paper shows how organisational structure may be represented as a
	network of responsibility relationships, how requirements arise from
	the discharge of obligations associated with responsibilities, and
	how these concepts have been applied to the particular example of
	specifying user requirements for clinical workstations in acute hospitals},
  file = {:./literature/ResponsibilityModelling.pdf:PDF},
  keywords = {health care, management scienceclinical workstations, cute hospitals,
	modelling, organisational requirements, organisational structure,
	responsibility, user requirements},
  owner = {Stephan},
  review = {interesting part: section 2 concept of responsibilities with relation
	between responsiblities, obligations and activities},
  timestamp = {2010.02.10}
}

@INPROCEEDINGS{Subramanian2003,
  author = {Nary Subramanian and Chung, Lawrence},
  title = {Process-oriented metrics for software architecture evolvability},
  booktitle = {Proceedings Sixth International Workshop on Principles of Software
	Evolution},
  year = {2003},
  pages = { 65-70},
  month = {Sept.},
  abstract = {Evolution of software systems is almost a natural process. Evolution
	can occur at different levels of abstraction of software. Evolution
	at the architectural level, being the highest level of solution,
	can often times be the most critical to the success and survival
	of the pertaining software system. Metrics for software architectural
	evolvability will help determine the extent to which the architectural
	evolution can take place. We propose a framework called the POMSAE,
	process-oriented metrics for software architecture evolvability,
	that will help not only to intuitively develop architectural evolvability
	metrics but also to trace the metrics back to the evolvability requirements.
	This will then help analyze the reasons for the strengths/weaknesses
	in the metrics. POMSAE is partially validated by demonstrating its
	application to two practical telecom systems.},
  doi = {10.1109/IWPSE.2003.1231212},
  file = {:./literature/01231212.pdf:PDF},
  keywords = { formal specification, formal verification, software architecture,
	software metrics, software prototyping formal specification, formal
	verification, process-oriented metrics, software abstraction, software
	architecture evolvability, software metrics, software systems evolution},
  owner = {Stephan},
  review = {presents metrics for evolvability based on requirements
	
	
	software evolution: dynamic behaviour of programming systems as they
	are maintained and enhanced over their life times [Belady and Lehman]
	
	
	the NFR evolvability should be stated as part of the requirements
	
	
	description of POMSAE framework (based on NFR framework [Chung et
	al.]:
	
	- set of softgoals
	
	- set of contribution types
	
	- set of methods for refining softgoals
	
	- set of correlation rules
	
	- labeling procedure
	
	- metrification schemes
	
	
	decomposition of evolvability:
	
	- first by topic: component, connection, pattern, style, constraint
	
	- second by type: creatability, enhanceability, changeability, addability
	
	
	further applicaiton of POMSAE framework (the metrics) shown},
  timestamp = {2008.07.08}
}

@INPROCEEDINGS{Sun2010,
  author = {Sun, Xiaobing and Li, Bixin and Tao, Chuanqi and Wen, Wanzhi and
	Zhang, Sai},
  title = {Change Impact Analysis Based on a Taxonomy of Change Types},
  booktitle = {Proceedings of the IEEE 34th Annual Computer Software and Applications
	Conference},
  year = {2010},
  pages = {373-382},
  address = {Seoul, Korea (South)},
  month = {July},
  file = {:./literature/Paper_141.pdf:PDF},
  issn = {0730-3157},
  journal = {Computer Software and Applications Conference, Annual International},
  owner = {Steffen},
  review = {important stuff: IA based on change types and relation types
	
	
	Problem:
	
	- IA critical in software maintenance
	
	- different change types have different impact
	
	
	Research Questions:
	
	- how to improve static IA to keep it usable for real-life practice
	
	- how does a certain kind of change impact other entities
	
	- how does quality of SIS affect quality of EIS
	
	
	Contribution:
	
	- static IA approach which considers different change types and impact
	mechanism
	
	- taxonomy of different change types
	
	
	Solution:
	
	- proposed approach consists of following:
	
	* classification of change types at class and class member level
	
	* construct intermediate representation of OO programs (Java)
	
	* analyze impact mechanisms and rules of different change types
	
	* perform IA based on these rules
	
	- provide distinct change types for classes, methods and variables
	
	- provide distinct dependency types between classes, methods and variables,
	t ypes:
	
	* use
	
	* member
	
	* inheritance
	
	* call
	
	- intermediate representation of OO code is called "Object Oriented
	Class and Member Dependence Graph" (OOCMDG)
	
	- change propagation considers change type and dependencies between
	entities
	
	- SIS obtained by forward and backward walks on OOCMDG of change entity
	
	- EIS obtained by:
	
	* classify changes according to change types
	
	* compute union of change types for each entity
	
	* calculate SIS for each entity based on their change types
	
	* calculate EIS based on impact rules of change types
	
	-> granularity of entities: class, method, variable
	
	-> granularity of changes: fine-grained, atomic changes
	
	-> granularity of results: class, method, variable
	
	
	Open Issues:
	
	- impact of change types on statement level
	
	- large scale case studies required},
  timestamp = {2011.03.14}
}

@ARTICLE{Sun2011,
  author = {Sun, Xiaobing and Li, Bixin and Tao, Chuanqi and Zhang, Sai},
  title = {{HSM}-based Change Impact Analysis of Object-Oriented {Java} Programs},
  journal = {Chinese Journal of Electronics},
  year = {2011},
  volume = {20},
  pages = {247-251},
  number = {2},
  month = {April},
  file = {:./literature/Paper_170.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- small changes can potentially affect large parts of the system
	
	- most IA approaches focus on method level
	
	
	Research Questions:
	
	- enhance IA with fine-grained analysis
	
	
	Contribution:
	
	- new static IA technique "HSMImpact" based on hierarchical slicing
	models
	
	
	Solution:
	
	- apply a stepwise slicing algorithm on hierarchical dependence graphs
	
	- distinguish between 4 types of dependency graphs:
	
	* package level DG, class-level DG, method-level DG, statement-level
	DG
	
	- HSM comprised of 3 steps:
	
	* define hierarchical change sets at different granularity
	
	* apply CIA process
	
	* compute hierarchical impact sets from package to statement level
	
	-> granularity of entities: package, class, method, statement, variable
	
	-> granularity of changes: +/- package, +/-/r. class, +/-/sig./r.
	method, +/- /r./t. variable
	
	-> granularity of results: package, class, method, statement, variable
	
	
	Open Issues:
	
	- conduct further and larger case studies to evaluate HSM
	
	- how to apply HSM in software maintenance},
  timestamp = {2011.07.26}
}

@INPROCEEDINGS{Sunetnanta2001,
  author = {Sunetnanta, Thanwadee and Finkelstein, Anthony},
  title = {Automated Consistency Checking for Multiperspective Software Specifications},
  booktitle = {Proceedings of the Workshop on Advanced Separation of Concerns (ICSE2001)},
  year = {2001},
  address = {Toronto, Ontario, Canada},
  month = {May},
  file = {:./literature/Paper_201.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.03.15}
}

@ARTICLE{Sunye2001,
  author = {Suny\'{e}, Gerson and Pollet, Damien and Le Traon, Yves and J\'{e}z\'{e}quel,
	Jean-Marc},
  title = {Refactoring {UML} Models},
  journal = {Lecture Notes in Computer Science},
  year = {2001},
  volume = {2185},
  pages = {134-148},
  file = {:./literature/Paper_186.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.11.01}
}

@INPROCEEDINGS{Sutcliffe1998,
  author = {Alistair G. Sutcliffe and Shailey Minocha},
  title = {Scenario-based Analysis of Non-Functional Requirements},
  booktitle = {REFSQ'98},
  year = {1998},
  pages = {219-234},
  publisher = {Presses universitaeires de Namur},
  file = {:./literature/Sutcliffe1998.pdf:PDF},
  keywords = {scenario description, requirements analysis},
  owner = {Stephan},
  timestamp = {2010.11.15}
}

@INPROCEEDINGS{SuttonJr1996,
  author = {Sutton Jr, S.M. and Osterweil, L.J.},
  title = {PDP: Programming a programmable design process},
  booktitle = {Software Specification and Design, 1996., Proceedings of the 8th
	International Workshop on},
  year = {1996},
  pages = {186--190},
  organization = {IEEE},
  file = {SuttonJr1996.pdf:literature/SuttonJr1996.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.23}
}

@ARTICLE{Svahnberg2005,
  author = {Mikael Svahnberg and Jilles van Gurp and Jan Bosch},
  title = {A Taxonomy of Variability Realization Techniques},
  journal = {Software: Practice and Experience},
  year = {2005},
  volume = {35},
  pages = {705-754},
  number = {8},
  abstract = {evelopment of software product families relies heavily on the use
	of variability to manage the differences between products by delaying
	design decisions to later stages of the development and usage of
	the constructed software systems. Implementation of variability is
	not a trivial task, and is governed by a number of factors. In this
	paper, we describe the factors that are relevant in determining how
	to implement variability, and present a taxonomy of variability realization
	techniques.},
  doi = {http://dx.doi.org/10.1002/spe.v35:8},
  file = {:./literature/Svahnberg2005.pdf:PDF},
  keywords = {variability, software product lines, development process, software
	architecture, variability realization techniques},
  owner = {Stephan},
  publisher = {John Wiley \& Sons, Inc.},
  review = {provides definition of variability},
  timestamp = {2010.03.04}
}

@INPROCEEDINGS{Swartout1997,
  author = {Swartout, Bill and Patil, Ramesh and Knight, Kevin and Russ, Tom},
  title = {Toward Distributed Use of Large-Scale Ontologies},
  booktitle = {AAAI Symposium on Ontological Engineering},
  year = {1997},
  address = {Stanford},
  keywords = {Ontology Engineering, SENSUS},
  owner = {Stephan},
  timestamp = {2011.03.15}
}

@ARTICLE{Sydow2004,
  author = {Sydow, J. and Lindkvist, L. and DeFillippi, R.},
  title = {Project-based organizations, embeddedness and repositories of knowledge:
	Editorial},
  journal = {Organization Studies},
  year = {2004},
  volume = {25},
  pages = {1475--1489},
  number = {9},
  file = {Sydow2004.pdf:literature/Sydow2004.pdf:PDF},
  owner = {patrickr},
  publisher = {Sage Publications},
  timestamp = {2012.10.22}
}

@MISC{INCOSE,
  author = {International Council on Systems Engineering (INCOSE)},
  howpublished = {http://www.incose.org/ProductsPubs/products/rmsurvey.aspx},
  owner = {Elke},
  timestamp = {2011.06.09},
  url = {http://www.incose.org/ProductsPubs/products/rmsurvey.aspx}
}

@BOOK{Szyperski2002,
  title = {Component Software - Beyond Object-Oriented Programming},
  publisher = {Addison-Wesley/ ACM Press},
  year = {2002},
  author = {Szyperski, Clemens and Gruntz, Dominik and Murer, Stephan},
  pages = {624},
  address = {USA},
  edition = {2nd},
  keywords = {component based development, object-oriented programming},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://www.amazon.com/Component-Software-Beyond-Object-Oriented-Programming/dp/0201745720}
}

@INPROCEEDINGS{Toth2010a,
  author = {T\'{o}th, Gabriella and Heged\H{u}s, P\'{e}ter and Besz\'{e}des,
	\'{A}rp\'{a}d and Gyim\'{o}thy, Tibor and J\'{a}sz, Judit},
  title = {Comparison of different impact analysis methods and programmer's
	opinion: an empirical study},
  booktitle = {Proceedings of the 8th International Conference on the Principles
	and Practice of Programming in Java (PPPJ '10)},
  year = {2010},
  address = {New York, USA},
  file = {:./literature/Paper_71.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- notion of impact set / dependency set of a change very imprecise
	
	- very different approaches to solve the IA problem
	
	
	Research Questions:
	
	- which alogrithm / approach most suitable to detect dependencies
	
	- comparison of different approaches of what developers think are
	dependencies
	
	
	Contribution:
	
	- case study of several approaches based on experimental Java system
	
	- show which one is closest to developers expectations
	
	
	Solution:
	
	- case study based on 5 questions:
	
	* do programmers and algorithms identify same dependencies
	
	* relationships between different kinds of dependency sets
	
	* how is the algorithm ranked (precision/recall)
	
	* do programmers identify dependencies with same level of confidence
	
	* how did IA algorithms change programmers opinion
	
	- algorithms to be evaluated implemented with JRipples framework,
	following algorithms were used:
	
	* callgraph
	
	* static slice
	
	* static execution after sequences
	
	* co-changed files
	
	- "ownSync" was program to be analyzed by developers and by the algorithms
	
	- dependencies found by algorithms and programmers were merged together
	
	- programmers were asked about their confidence on the dependencies
	
	
	Open Issues:},
  timestamp = {2011.02.17}
}

@INPROCEEDINGS{Toth2010b,
  author = {T\'{o}th, Gabriella and Nagy, C. and J\'{a}sz, Judit and Besz\'{e}des,
	\'{A}rp\'{a}d and F\"{u}l\"{o}p, Lajos Jen\H{o}},
  title = {{CIASYS} - Change Impact Analysis at System Level},
  booktitle = {Proceedings of the 14th European Conference on Software Maintenance
	and Reengineering (CSMR '10)},
  year = {2010},
  file = {:./literature/Paper_173.pdf:PDF},
  owner = {Steffen},
  review = {project, spanning:
	
	[Jasz2008], [Beszedes2007a], [Beszedes2007b]},
  timestamp = {2011.07.26}
}

@INPROCEEDINGS{Tahvildari2002,
  author = {Tahvildari, L. and Kontogiannis, K.},
  title = {On the role of design patterns in quality-driven re-engineering},
  booktitle = {Proceedings Sixth European Conference on Software Maintenance and
	Reengineering},
  year = {2002},
  pages = {230-240},
  month = {March},
  abstract = {Design patterns have been widely adopted and well investigated by
	the software engineering community over the past decade. However,
	their primary use is still associated with forward engineering and
	the design phase of the software life-cycle. In this paper, we examine
	design patterns from a different perspective namely, their classification
	and usage for software re-engineering and restructuring. Specifically,
	twenty three design patterns originally presented in the "Gang of
	Four" book are reclassified for re-engineering purposes into two
	major categories, primitive and complex. Moreover, their relationships
	and impacts to specific re-engineering objectives are presented in
	terms of a layered model that is denoted by six different relations
	namely: uses, refines, conflicts, is-similar-to, combines-with, and
	requires. The paper also discusses how the classification scheme
	can be applied for the re-engineering and restructuring of object-oriented
	systems.},
  doi = {10.1109/CSMR.2002.995810},
  file = {:./literature/C7-2002.pdf:PDF},
  keywords = {classification, object-oriented programming, reverse engineering,
	software engineering, software maintenanceclassification, design
	patterns, formalization, object-oriented systems, software life-cycle,
	software reengineering, software restructuring},
  owner = {Stephan},
  timestamp = {2008.06.03},
  url = {http://www.swen.uwaterloo.ca/~kostas/publications/conferences/C7-2002.pdf}
}

@ARTICLE{Tahvildari2003,
  author = {Ladan Tahvildari and Kostas Kontogiannis and John Mylopoulos},
  title = {Quality-driven software re-engineering},
  journal = {Journal of Systems and Software},
  year = {2003},
  volume = {66},
  pages = {225-239},
  number = {3},
  month = {June},
  abstract = {Software re-engineering consists of a set of activities intended to
	restructure a legacy system to a new target system that conforms
	with hard and soft quality constraints (or non-functional requirements,
	NFR). This paper presents a framework that allows specific NFR such
	as performance and maintainability to guide the re-engineering process.
	Such requirements for the migrant system are modeled using soft-goal
	interdependency graphs and are associated with specific software
	transformations. Finally, an evaluation procedure at each transformation
	step determines whether specific qualities for the new migrant system
	can be achieved.},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1016/S0164-1212(02)00082-1},
  file = {:./literature/j3.pdf:PDF},
  issn = {0164-1212},
  keywords = {Software re-engineering; Soft-goal interdependency graphs; Software
	architecture; Software quality; Non-functional requirements; Software
	metrics; Design patterns},
  owner = {Stephan},
  publisher = {Elsevier Science Inc.},
  review = {description of framework for NFR guiding the re-engineering process
	using SIG
	
	
	re-engineering lifecycle
	
	----------------------------
	
	
	requirements analysis phase (identification of concrete re-engineering
	goals)
	
	model analysis phase (documenting and understanding the functionality
	of the legacy system)
	
	source code analysis phase (understanding of a system's implementation)
	
	remediation phase (selection of a target software structure that aims
	to repair a design or a sorce code defect with respect to a target
	quality requirement)
	
	transformation phase( phyiscally transforming software structures
	according to remediation strategies)
	
	evaluation phase (assessing the new system)
	
	
	design pattern catalog
	
	--------------------------
	
	3 primary relationships between patterns: use, refine, conflicts
	
	3 secondary relationships: similar, combine, require
	
	
	maintainability
	
	-----------------
	
	perfective maintenance (add new functionality)
	
	adaptive maintenance (port to another platform)
	
	corrective maintenance (fix errors)
	
	
	2 major areas: source code quality and documentation quality
	
	
	interesting references:
	
	Boehm et al.: Characteristics of Software Quality
	
	[Tahvildari2002] classification of design patterns for re-engineering
	purposes},
  timestamp = {2008.05.29},
  url = {http://www.swen.uwaterloo.ca/~kostas/publications/journals/j3.pdf}
}

@INPROCEEDINGS{Tambe2008,
  author = {Sumant Tambe and Akshay Dabholkar and Aniruddha Gokhale},
  title = {CQML: Aspect-oriented Modeling for Modularizing and Weaving QoS Concerns
	in Component-based Systems},
  booktitle = {AOSD08: 7th Annual Aspect-Oriented Software Development Conference},
  year = {2008},
  abstract = {Designing large, component-based systems with multiple quality of
	service (QoS) concerns is a hard problem because these concerns crosscut
	the system functional composition concerns and get tangled with other
	para-functional concerns, such as deployment. Current model-driven
	engineering (MDE) system design tools tend to focus predominantly
	on system functional composition, and tightly couple QoS modeling
	concerns with structural concerns. Moreover, the tools are often
	component technology-specific although the notion of composition
	and QoS are inherently platform-independent resulting in multiple
	MDE tools that reinvent solutions to the same problems. 
	
	This paper describes the Component QoS Modeling Language (CQML), which
	is a reusable, platform-independent, aspect-oriented modeling approach
	for separation of crosscutting concerns for QoS properties. CQML
	is applicable to all those functional composition modeling languages
	which conform to a small set of invariant properties. The join point
	model of CQML enables declarative QoS aspect modeling and automated
	weaving of QoS concerns into the base modeling language. We evaluate
	the capabilities of CQML for a variety of base modeling languages
	and provide quantitative results indicating the modeling effort saved
	in automating the weaving of QoS concerns.},
  file = {:./literature/AOSD08_CQML.pdf:PDF},
  keywords = {AOM, MDE, DSML, QoS, Aspects},
  owner = {Stephan},
  timestamp = {2008.05.15},
  url = {http://www.dre.vanderbilt.edu/~gokhale/WWW/papers/AOSD08_CQML.pdf}
}

@INPROCEEDINGS{Tamimi:2011:AMB:1989676.1989689,
  author = {Tamimi, Sabah and Zahoor, Muhammad},
  title = {{Analysis of model based regression testing approaches}},
  booktitle = {Proceedings of the 10th WSEAS international conference on communications,
	electrical \& computer engineering, and 9th WSEAS international conference
	on Applied electromagnetics, wireless and optical communications},
  year = {2011},
  series = {ACELAE'11},
  pages = {65--70},
  address = {Stevens Point, Wisconsin, USA},
  publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
  abstract = {{One of the important phases in the life cycle of software development
	process is the designing phase. There are different models used in
	this particular phase including class diagrams, state diagrams and
	use cases etc. To test the conformance of the software it is very
	essential that test cases should be derived from these specific models.
	Similarly regressions testing through these models are very significant
	for testing of modified software. There are several regression testing
	approaches based on these model in literature. This survey report
	is the analysis of the model based regression testing techniques
	according to the parameter identified during this study. The summary
	as well as the analysis of the approaches is discussed in this survey
	report. In the end we concluded the survey by identifying the areas
	of further research in the field of model based regression testing.}},
  citeulike-article-id = {9681970},
  citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1989676.1989689},
  file = {:/literature/RegressionTesting/analysis of model based regression testing approaches.pdf:PDF},
  keywords = {based, evaluation, model, parameters, regression, testing, uml},
  location = {Canary Islands, Spain},
  owner = {Steffen},
  posted-at = {2011-08-19 10:02:36},
  priority = {2},
  timestamp = {2012.03.01},
  url = {http://portal.acm.org/citation.cfm?id=1989676.1989689}
}

@INPROCEEDINGS{Tan2007,
  author = {Tan, Xiangchen and Feng, Tie and Zhang, Jiachen},
  title = {Mapping Software Design Changes to Source Code Changes},
  booktitle = {Proceedings of the 8th ACSIS International Conference on Software
	Engineering, Artificial Intelligence, Networking, and Parallel/Distributed
	Computing},
  year = {2007},
  pages = {650-655},
  address = {Qingdao},
  month = {August},
  file = {:./literature/Paper_196.PDF:PDF},
  owner = {Steffen},
  timestamp = {2012.03.01}
}

@ARTICLE{Tang2010,
  author = {Tang, Antony and Avgeriou, Paris and Jansen, Anton and Capilla, Rafael
	and Ali Babar, Muhammad},
  title = {A comparative study of architecture knowledge management tools},
  journal = {Journal of Systems and Software},
  year = {2010},
  volume = {83},
  pages = {352-370},
  number = {3},
  abstract = {Recent research suggests that architectural knowledge, such as design
	decisions, is important and should be recorded alongside the architecture
	description. Different approaches have emerged to support such architectural
	knowledge (AK) management activities. However, there are different
	notions of and emphasis on what and how architectural activities
	should be supported. This is reflected in the design and implementation
	of existing AK tools. To understand the current status of software
	architecture knowledge engineering and future research trends, this
	paper compares five architectural knowledge management tools and
	the support they provide in the architecture life-cycle. The comparison
	is based on an evaluation framework defined by a set of 10 criteria.
	The results of the comparison provide insights into the current focus
	of architectural knowledge management support, their advantages,
	deficiencies, and conformance to the current architectural description
	standard. Based on the outcome of this comparison a research agenda
	is proposed for future work on AK tools.},
  doi = {DOI: 10.1016/j.jss.2009.08.032},
  file = {:./literature/Tang2010.pdf:PDF},
  issn = {0164-1212},
  keywords = {Architectural knowledge management tool},
  owner = {Stephan},
  timestamp = {2010.12.31},
  url = {http://www.sciencedirect.com/science/article/B6V0N-4X4GHP5-1/2/84a45c0d6dda12f7f563273ff85be120}
}

@ARTICLE{Tang2006,
  author = {Tang, Antony and Babar, Muhammad Ali and Gorton, Ian and Han, Jun},
  title = {{A survey of architecture design rationale}},
  journal = {Journal of Systems and Software},
  year = {2006},
  volume = {79},
  pages = {1792--1804},
  number = {12},
  month = dec,
  doi = {10.1016/j.jss.2006.04.029},
  file = {:literature/Tang2006.pdf:PDF},
  issn = {01641212},
  keywords = {design rationale,software architecture,survey},
  owner = {Sebastian},
  timestamp = {2014.03.19},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0164121206001415}
}

@ARTICLE{Tang2007a,
  author = {Tang, Antony and Jin, Yan and Han, Jun},
  title = {A rationale-based architecture model for design traceability and
	reasoning},
  journal = {Journal of Systems and Software},
  year = {2007},
  volume = {80},
  pages = {918--934},
  number = {6},
  month = jun,
  annote = {- design rationale representation - argumentation based - template-based
	- viewpoints of the architecture design elements (a) data viewpoint
	(b) application viewpoint (c) technology viewpoint – Design is a
	process of synthesising through alternative solutions in the design
	space (Simon, 1981). },
  doi = {10.1016/j.jss.2006.08.040},
  file = {:./literature/tang2007.pdf:PDF},
  isbn = {0164-1212},
  issn = {01641212},
  mendeley-groups = {Reading list,Finished with notes},
  mendeley-tags = {Architecture Knowledge,Traceability,design reasoning},
  owner = {Sebastian},
  timestamp = {2013.11.28},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0164121206002287}
}

@INBOOK{Tang2011,
  pages = {35-60},
  title = {Supporting Co-evolving Architectural Requirements and Design through
	Traceability and Reasoning},
  publisher = {Springer},
  year = {2011},
  editor = {Avgeriou, P. and Grundy, J. and Lago, P. and Mistrik, I.},
  author = {Tang, Antony and Liang, Peng and Clerc, Viktor and van Vliet, Hans},
  file = {:./literature/Paper_231.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.05.10}
}

@INBOOK{Tang2011a,
  chapter = {Supporting Co-evolving Architectural Requirements and Design through
	Traceability and Reasoning},
  pages = {35-60},
  title = {Relating Software Requiremens and Software Architecture},
  publisher = {Springer},
  year = {2011},
  editor = {Lago, P. and Grundy, P. and Mistrik, J.},
  author = {Tang, Antony and Liang, Peng and Clerc, Viktor and van Vliet, Hans},
  __markedentry = {[Steffen:]},
  file = {:./literature/Paper_224.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.30}
}

@INPROCEEDINGS{Tang2011b,
  author = {Tang, Antony and Liang, Peng and van Vliet, Hans},
  title = {Software Architecture Documentation: The Road Ahead},
  booktitle = {Proceedings of the 2011 Ninth Working IEEE/IFIP Conference on Software
	Architecture},
  year = {2011},
  pages = {252-255},
  month = {June},
  __markedentry = {[Steffen:]},
  file = {:./literature/Paper_226.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.30}
}

@ARTICLE{Tang2007,
  author = {Tang, Antony and Nicholson, Ann and Jin, Yan and Han, Jun},
  title = {Using Bayesian belief networks for change impact analysis in architecture
	design},
  journal = {The Journal of Systems and Software},
  year = {2007},
  volume = {80},
  pages = {127-148},
  file = {:./literature/Paper_14.PDF:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- design rationales useful for verification & tracing but often not
	documented
	
	- knowledge of design rationales erodes / gets lost
	
	
	Research Questions:
	
	- record architecture decisions in a structured way to enable tracing
	
	
	Contribution:
	
	- employ causal relationships between architecture elements
	
	- perform "what-if"-reasoning on element/relation-graphs modeled as
	bayesian belief networks
	
	
	Solution:
	
	- use ARM (architecture rationalisation method) together with bayesion
	belief networks to perform IA
	
	- use BBN to quantify relationships between decisions and architecture
	elements
	
	- represent architecture elements and relations in a BBN (mapping
	from ARM elements to BBN nodes, mapping from ARM relations to BBN
	edges)
	
	- employ 3 probability-based IA methods on architecture elements
	
	- architect assigns probabilities to elements through estimation (by
	experience and assessment)
	
	-> granularity of entities: entire UML
	
	-> granularity of changes: no details
	
	-> granularity of results: entire UML
	
	
	Open Issues:
	
	- semi-objective (actually pure-objective) probability estimations
	by architect & others
	
	- small systems will not benefit from approach},
  timestamp = {2011.01.05}
}

@INPROCEEDINGS{Tang2009,
  author = {Tang, A. and Van Vliet, H.},
  title = {Modeling constraints improves software architecture design reasoning},
  booktitle = {Software Architecture, 2009 European Conference on Software Architecture.
	WICSA/ECSA 2009. Joint Working IEEE/IFIP Conference on},
  year = {2009},
  pages = {253-256},
  doi = {10.1109/WICSA.2009.5290813},
  file = {:./literature/tang2009.pdf:PDF},
  keywords = {formal specification;software architecture;alloy tool;constraint verification;design
	constraints specification;fundamental mechanisms;software architecture
	design reasoning;Australia;Coherence;Decision making;Humans;Logic
	design;Process design;Psychology;Shape memory alloys;Software architecture;Software
	design},
  owner = {Sebastian},
  timestamp = {2013.07.25}
}

@INPROCEEDINGS{Tarhini2006,
  author = {Tarhini, A. and Fouchal, H. and Mansour, N.},
  title = {Regression Testing Web Services-based Applications},
  booktitle = {Computer Systems and Applications, 2006. IEEE International Conference
	on.},
  year = {2006},
  pages = { 163 - 170},
  month = {8,},
  doi = {10.1109/AICCSA.2006.205085},
  file = {:/literature/RegressionTesting/Regression Testing Web Services-based Applications.pdf:PDF},
  issn = { },
  keywords = {WSRT},
  owner = {Steffen},
  review = {+ a web application is modelled as a time labelled transition system.
	
	
	+each component is modelled as tlts as 
	
	
	+ a log file is maintained for each component containing the services
	for the component and corresponding test sequences + priority ranking
	of the services
	
	+modification types
	
	 +connecting to a new web service
	
	 +modification of a component
	
	 +modification of a web application specifications},
  timestamp = {2012.03.01}
}

@TECHREPORT{Team2011,
  author = {CMMI Product Team},
  title = {CMMI® für Entwicklung, Version 1.3},
  institution = {SEI},
  year = {2011},
  address = {http://www.sei.cmu.edu},
  month = {November},
  file = {:./literature/10tr033de_v11.pdf:PDF},
  owner = {elkeb},
  review = {Traceability ab S. 355},
  timestamp = {2012.03.20},
  url = {http://www.sei.cmu.edu/library/assets/whitepapers/10tr033de_v11.pdf}
}

@TECHREPORT{Team2010,
  author = {CMMI Product Team},
  title = {CMMI® for Development, Version 1.3},
  institution = {SEI},
  year = {2010},
  file = {:./literature/10tr033.pdf:PDF},
  owner = {elkeb},
  review = {Traceability ab S.345},
  timestamp = {2012.03.20},
  url = {http://www.sei.cmu.edu/reports/10tr033.pdf}
}

@INPROCEEDINGS{Tekinerdogan2004,
  author = {Tekinerdogan, B.},
  title = {ASAAM: aspectual software architecture analysis method},
  booktitle = {Proceedings. Fourth Working IEEE/IFIP Conference on Software Architecture,
	2004. WICSA 2004.},
  year = {2004},
  pages = {5-14},
  month = {June},
  publisher = {IEEE Computer Society},
  abstract = {Software architecture analysis methods aim to predict the quality
	of a system before it has been developed. In general, the quality
	of the architecture is validated by analyzing the impact of predefined
	scenarios on architectural components. Hereby, it is implicitly assumed
	that an appropriate refactoring of the architecture design can help
	in coping with critical scenarios and mending the architecture. This
	paper shows that there are also concerns at the architecture design
	level which inherently crosscut multiple architectural components,
	which cannot be localized in one architectural component and which,
	as such, can not be easily managed by using conventional abstraction
	mechanisms. We propose the aspectual software architecture analysis
	method (ASAAM) to explicitly identify and specify these architectural
	aspects and make them transparent early in the software development
	life cycle. ASAAM introduces a set of heuristic rules that help to
	derive architectural aspects and the corresponding tangled architectural
	components from scenarios. The approach is illustrated for architectural
	aspect identification in the architecture design of a window management
	system.},
  adress = {Oslo, Norway},
  citeseerurl = {http://citeseer.ist.psu.edu/tekinerdogan03asaam.html},
  doi = {10.1109/WICSA.2004.1310685},
  file = {:./literature/01310685.pdf:PDF},
  keywords = { object-oriented programming, software architecture, software quality
	abstraction mechanism, architectural aspect identification, architecture
	design refactoring, aspect-oriented software architecture design,
	conventional abstraction mechanisms, heuristic rules, multiple architectural
	components, scenario-based architectural evaluation, scenario-based
	aspect-identification, software architecture analysis, software development
	life cycle, system quality, window management system},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://www3.cs.utwente.nl/~bedir/papers/pdf/2004/ASAAM-Aspectual%20Software%20Architecture%20Analysis%20Method.pdf}
}

@ARTICLE{Terrion2002,
  author = {Terrion, J.L. and Ashforth, B.E.},
  title = {From ‘I’to ‘we’: The role of putdown humor and identity in the development
	of a temporary group},
  journal = {Human Relations},
  year = {2002},
  volume = {55},
  pages = {55--88},
  number = {1},
  file = {Terrion2002.pdf:literature/Terrion2002.pdf:PDF},
  owner = {patrickr},
  publisher = {Sage Publications},
  timestamp = {2012.10.19}
}

@INCOLLECTION{Thalheim2011,
  author = {Thalheim, Bernhard},
  title = {The Theory of Conceptual Models, the Theory of Conceptual Modelling
	and Foundations of Conceptual Modelling},
  booktitle = {Handbook of Conceptual Modeling: Theory, Practice and Research Challenges},
  publisher = {Springer},
  year = {2011},
  editor = {Embley, David W. and Thalheim, Bernhard},
  pages = {543--577},
  address = {Berlin, Heidelberg},
  file = {Chapter17EpilogueThalheim2011.pdf:literature/Chapter17EpilogueThalheim2011.pdf:PDF},
  owner = {matthias},
  timestamp = {2012.12.20}
}

@INCOLLECTION{Thalheim2012,
  author = {Thalheim, Bernhard},
  title = {The science and art of conceptual modelling},
  booktitle = {Transactions on Large-Scale Data- and Knowledge-Centered Systems
	VI},
  publisher = {Springer-Verlag},
  year = {2012},
  editor = {Hameurlain, Abdelkader and K\"{u}ng, Josef and Wagner, Roland and
	Liddle, Stephen W. and Schewe, Klaus-Dieter},
  pages = {76--105},
  address = {Berlin, Heidelberg},
  abstract = {Conceptual modelling is one of the central activities in Computer
	Science. Conceptual models are mainly used as intermediate artifact
	for system construction. They are schematic descriptions of a system,
	a theory, or a phenomenon of an origin thus forming a model. A conceptual
	model is a model enhanced by concepts. The process of conceptual
	modelling is ruled by the purpose of modelling and the models. It
	is based on a number of modelling acts, on a number of correctness
	conditions, on modelling principles and postulates, and on paradigms
	of the background or substance theories. Purposes determine the (surplus)
	value of a model. Conceptual modelling is performed by a modeller
	that directs the process based on his/her experience, education,
	understanding, intention and attitude. Conceptual models are products
	that are used by other stakeholders such as programmers, learners,
	business users, and evaluators. Conceptual models use a language
	as a carrier for the modelling artifact and are restricted by the
	expressiveness of this carrier.
	
	
	This paper aims at a discussion of a general theory of modelling as
	a culture and an art. A general theory of modelling also considers
	modelling as an apprenticeship and as a technology. It is thus an
	art. Modelling is on of the main elements of Computer Science culture
	that consists of commonly accepted behaviour patterns, arts, consensus,
	institutions, and all other supporting means and thoughts.},
  file = {ConceptualModellingScienceArtDexaTLDKS2012.pdf:literature/ConceptualModellingScienceArtDexaTLDKS2012.pdf:PDF},
  isbn = {978-3-642-34178-6},
  keywords = {conceptual modelling, foundations of modelling, modelling workflow},
  numpages = {30},
  owner = {matthias},
  timestamp = {2012.12.20},
  url = {http://dl.acm.org/citation.cfm?id=2407076.2407079}
}

@INPROCEEDINGS{Thalheim2013,
  author = {Bernhard Thalheim},
  title = {The Definition of the (Conceptual) Model},
  booktitle = {Proc. 23rd European Japanese Conference on Information Modelling
	and Knowledge Bases (EJC2013)},
  year = {2013},
  note = {Draft Version ? from Author directly},
  file = {:./literature/ConceptualModelDefintionEJC2013FullOfShort.pdf:PDF},
  owner = {matthias},
  timestamp = {2013.05.28}
}

@INPROCEEDINGS{Thalheim2009,
  author = {Thalheim, Bernhard},
  title = {Towards a Theory of Conceptual Modelling},
  booktitle = {Proceedings of the ER 2009 Workshops (CoMoL, ETheCoM, FP-UML, MOST-ONISW,
	QoIS, RIGiM, SeCoGIS) on Advances in Conceptual Modeling - Challenging
	Perspectives},
  year = {2009},
  series = {ER '09},
  pages = {45--54},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  abstract = {Conceptual modelling is a widely applied practice and has led to a
	large body of knowledge on constructs that might be used for modelling
	and on methods that might be useful for modelling. It is commonly
	accepted that database application development is based on conceptual
	modelling. It is however surprising that only very few publications
	have been published on a <em>theory of conceptual modelling</em>
	.
	
	
	<em>Modelling</em> is typically supported by languages that are well-founded
	and easy to apply for the description of the application domain,
	the requirements and the system solution. It is thus based on a <em>theory
	of modelling constructs</em> . At the same time, modelling incorporates
	a description of the application domain and a prescription of requirements
	for supporting systems. It is thus based on methods of <em>application
	domain gathering</em> . Modelling is also an engineering activity
	with engineering steps and engineering results. It is thus <em>engineering</em>
	. The first facet of modelling has led to a huge body of knowledge.
	The second facet is considered from time to time in the scientific
	literature. The third facet is underexposed in the scientific literature.
	
	
	This paper aims in developing principles of conceptual modelling.
	They cover modelling constructs as well as modelling activities as
	well as modelling properties and as well as management of models.
	We first clarify the notion of conceptual modelling. Principles of
	modelling may be applied and accepted or not by the modeler. Based
	on these principles we can derive a theory of conceptual modelling
	that combines foundations of modelling constructs, application capture
	and engineering.
	
	
	A general theory of conceptual modelling is far too comprehensive
	and far too complex. It is not yet visible how such a theory can
	be developed. This paper therefore aims in introducing a framework
	and an approach to a general theory of conceptual modelling. We are
	however in urgent need of such a theory. We are sure that this theory
	can be developed and use this paper for the introduction of the main
	ingredients of this theory.},
  doi = {10.1007/978-3-642-04947-7_7},
  file = {ConceptualModellingTheoryJUCS2010.pdf:literature/ConceptualModellingTheoryJUCS2010.pdf:PDF},
  isbn = {978-3-642-04946-0},
  location = {Gramado, Brazil},
  numpages = {10},
  owner = {matthias},
  timestamp = {2012.12.20},
  url = {http://dx.doi.org/10.1007/978-3-642-04947-7_7}
}

@UNPUBLISHED{Thoma2006,
  author = {Matthias Thoma},
  title = {Modellgetriebene Software-Entwicklung: Architekturen, Muster und
	Eclipse-basierte MDA},
  note = {Seminararbeit},
  month = {Aug.},
  year = {2006},
  abstract = {Architekturevaluationsverfahren sollen Software-Architekten erlauben,
	in einer frühen Phase der Software-Entwicklung ihre Entwürfe auf
	Qualitätsmerkmale hin zu prüfen und Risiken aufzudecken. Diese Arbeit
	gibt einen Überblick über die szenariobasierten Architekturevaluationsverfahren
	”Software Architecture Analysis Method“ (SAAM), ”Architecture Tradeoff
	Analysis Method“ (ATAM) und ”Architecture-level modiﬁability analysis“
	(ALMA). Über ein Klassiﬁkationsschema werden die wichtigsten Unterschiede
	der jeweiligen Methoden herausgearbeitet. Zusätzlich wurden Ansätze
	für die Einbindung von Architekturevaluationsverfahren in den Software-Entwicklunsprozess
	entwickelt. Im besonderen wird eine mögliche Einbindung der Verfahren
	in den Extreme Programming (XP) Prozess betrachtet.},
  file = {:./literature/SeminararbeitATAM_SAAM_ALMA.pdf:PDF},
  keywords = {Architekturbewertung, SAAM, ATAM, ALMA},
  owner = {Stephan},
  review = {Vorstellung der Schritte der szenariobasierten Verfahren SAAM, ATAM
	und ALMA
	
	
	grobe Herausstellung von Unterschieden
	
	
	Vorschlag für Integration der Methoden in Wasserfallmodell oder eXtreme
	Programming
	
	
	3 Kategorien von Szenarien:
	
	- Anwendungsfall (Use Case): spiegelt gewöhnlichen Gebrauch des Systems
	wider
	
	- Wachstumsszenario (growth scenario): beschreibt erwartete und wahrscheinliche
	Modifizierung des Systems
	
	- Erkundungsszenario (exploratory scenario): beinhaltet weitgehende
	Modifizierungen, Randfälle und Stresstests, Verwendung zum Austesten
	der Grenzen der Architektur
	
	
	Szenarien nicht für alle Qualitätsmerkmale gleichermaßen geeignet
	--> schwierig: Zuverlässigkeit, Performance, Security},
  timestamp = {2009.02.10}
}

@INPROCEEDINGS{Thomas2008,
  author = {Hendrik Thomas and Rike Brecht and Bernd Markscheffel and Stephan
	Bode and Karsten Spekowius},
  title = {{TMchartis -- a Tool Set for Designing Multiple Problem-Oriented
	Visualizations for Topic Maps}},
  booktitle = {Proceedings 3rd International Conference on Topic Maps Research and
	Applications -- Scaling Topic Maps (TMRA'07), 2007},
  year = {2008},
  editor = {Maicher, Lutz and Garshol, Lars Marius},
  volume = {4999},
  series = {LNCS (LNAI)},
  pages = {36-40},
  month = {Aug},
  publisher = {Springer},
  abstract = {J. L. Borges once wrote about a Chinese emperor, who commanded the
	creation of an accurate map of China [1]. The resulting map was as
	detailed as possible but therefore it had to match the size of China.
	What use would make such a map, especially if you have a narrow navigation
	question, e.g. where the forbidden city is located?},
  doi = {10.1007/978-3-540-70874-2_4},
  file = {:./literature/tmchartis_080820.pdf:PDF},
  keywords = {topic maps, problem-oriented visualization},
  owner = {Stephan},
  timestamp = {2008.08.20}
}

@INPROCEEDINGS{Tichelaar2000,
  author = {Tichelaar, S. and Ducasse, S. and Demeyer, S. and Nierstrasz, O.},
  title = {A meta-model for language-independent refactoring},
  booktitle = {Proceedings of the International Symposium on Principles of Software
	Evolution, 2000},
  year = {2000},
  pages = {154-164},
  abstract = {Refactoring-transforming code while preserving behaviour-is considered
	a key approach for improving object-oriented software systems. Unfortunately,
	all of the current refactoring tools depend on language-dependent
	refactoring engines, which prevents a smooth integration with mainstream
	development environments. We investigate the similarities between
	refactorings for Smalltalk and Java, derive a language-independent
	meta-model and show that it is feasible to build a language-independent
	refactoring engine on top of this meta-model. Our feasibility study
	is validated by means of a tool prototype which uses the same engine
	to refactor both Smalltalk and Java code. Using our approach we minimize
	the language-dependent part of refactoring tools, providing a standard
	way for programmers and tools to perform refactorings no matter what
	language they work in.},
  doi = {10.1109/ISPSE.2000.913233},
  file = {:./literature/Tich00b_ipse2000.pdf:PDF},
  keywords = {Java, Smalltalk, object-oriented programming, software tools, Java,
	Smalltalk, code transformation, language-independent refactoring,
	meta-model, object-oriented software, software maintenance, software
	tools},
  owner = {Stephan},
  timestamp = {2008.04.23},
  url = {http://www.engr.uconn.edu/~steve/Cse298300/Tich00b_ipse2000.pdf}
}

@ARTICLE{Tip1994,
  author = {Tip, Frank},
  title = {A Survey of Program Slicing Techniques},
  journal = {Journal of Programming Languages},
  year = {1994},
  volume = {3},
  pages = {121-189},
  booktitle = {Journal of Programming Languages},
  file = {:./literature/Paper_67.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.02.17}
}

@INPROCEEDINGS{Toma2007,
  author = {Ioan Toma and Dumitru Roman and Dieter Fensel},
  title = {On Describing and Ranking Services based on Non-Functional Properties},
  booktitle = {Proceedings of the Third International Conference on Next Generation
	Web Services Practices, 2007. NWeSP '07},
  year = {2007},
  pages = {61-66},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {Service-oriented architectures are rapidly becoming the dominant computing
	paradigm. However, current SOA solutions are still restricted in
	their application context to being in-house solutions of companies.
	While service orientation is widely acknowledged for its potential
	to revolutionize the world of computing, its success depends on resolving
	a number of fundamental challenges, such as discovery, ranking and
	selection of services. Robust and automatic solutions for these challenges
	requires various services and user requests aspects, including functional
	and non-functional, to be semantically described. Non-functional
	properties especially are highly relevant especially during ranking
	and selection tasks. This paper introduces a semanticallyenables
	approach for describing non-functional properties of services and
	further discusses how such descriptions can be used during in one
	service related task, namely ranking.},
  doi = {10.1109/NWESP.2007.18},
  file = {:./literature/04392683.pdf:PDF},
  isbn = {0-7695-3022-2},
  keywords = {service, non-functional properties, ranking},
  owner = {Stephan},
  review = {introduces approach for semantically described non-functional properties
	used for service ranking
	
	
	utilizes Web Service Modeling Ontology (WSMO) and Web Service Modeling
	Language (WSML) following design principles from the Web Service
	Modeling Framework (WSMF)
	
	
	two categories of non-functional aspects:
	
	- annotations (metadata)
	
	- non-functional properties/quality of service
	
	
	very specific to (Semantic) Web Services},
  timestamp = {2008.04.11},
  url = {http://www.ieeexplore.ieee.org/iel5/4392665/4392666/04392683.pdf?tp=&isnumber=4392666&arnumber=4392683}
}

@ARTICLE{Tonella2003,
  author = {Tonella, Paolo},
  title = {Using a Concept Lattice of Decomposition Slices for Program Understanding
	and Impact Analysis},
  journal = {IEEE Transactions on Software Engineering},
  year = {2003},
  volume = {29},
  pages = {495-509},
  number = {6},
  month = {June},
  file = {:./literature/Paper_10.PDF:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- slicing focuses on sub-computations whereas lattices focuses on
	cohesive groupings
	
	- both are required for IA but not yet coupled
	
	
	Research Questions:
	
	- possibilities of coupling decomposition slice graph (from program
	slicing) with concept lattices (groups elements which share common
	attributes etc.)
	
	- increase IA and maintenance through new analysis on concept lattices
	of slicing graphs
	
	
	Contribution:
	
	- extend decomposition slice graphs to lattices ("lattice of decomposition
	slices")
	
	
	Solution:
	
	- combine nodes from both approaches via and/or-relations (and-lattice,
	or-lattice) to gain a lattice of decomposition slices
	
	- two decomposition slices interfere, when they've got a non-empty
	intersection
	
	- decomposition slices provide strong-intersections, lattices provide
	weak and strong-intersections -> better results through coupling
	
	- identify nodes which are directly affected by a change with the
	help of concept lattices
	
	- traverse lattice upwards to find more possible impacts
	
	-> granularity of entities: variables
	
	-> granularity of changes: statements
	
	-> granularity of results: variables
	
	
	Open Issues:
	
	- scaling to huge projects problematic
	
	- displaying huge lattice-graphs not possible},
  timestamp = {2011.01.05}
}

@ARTICLE{Toulme2006,
  author = {Toulm\'{e}, Antoine},
  title = {Presentation of EMF Compare Utility},
  journal = {Eclipse Modeling Symposium 2006},
  year = {2006},
  pages = {1-8},
  file = {:/literature/changeIdentification/ESE2006-EclipseModelingSymposium10_EMFCompareUtility.pdf:PDF},
  keywords = {read,},
  owner = {Steffen},
  review = {Difference types
	
	
	Element’s differences:
	
	- Creation: an element was added
	
	- Deletion: an element was deleted
	
	- Order: the order of this element has
	
	changed
	
	Attributes’ differences
	
	- Set: the value of this attribute has
	
	changed
	
	- Add: the attribute has been added
	
	- Remove: the attribute has been removed},
  timestamp = {2012.03.01},
  url = {http://www.eclipsecon.org/summiteurope2006/index.php?page=detail/&id=6}
}

@ARTICLE{Traon2000,
  author = {Y. Le Traon and T. Jeron and J.-M. Jezequel and P. Morel},
  title = {Efficient object-oriented integration and regression testing},
  journal = {IEEE Transactions on Reliability},
  year = {2000},
  volume = {49},
  pages = {12--25},
  number = {1},
  abstract = {This paper presents a model, a strategy and a methodology for planning
	integration and regression testing from an object-oriented model.
	It shows how to produce a model of structural system test dependencies
	which evolves with the refinement process of the object-oriented
	design. The model (test dependency graph) serves as a basis for ordering
	classes and methods to be tested for regression and integration purposes
	(minimization of test stubs). The mapping from unified modeling language
	to the defined model is detailed as well as the test methodology.
	While the complexity of optimal stub minimization is exponential
	with the size of the model, an algorithm is given that: computes
	a strategy for integration testing with a quadratic complexity in
	the worst case; and provides an efficient testing order for minimizing
	the number of stubs. Various integration strategies are compared
	with the optimized algorithm (a real-world case study illustrates
	this comparison). The results of the experiment seem to give nearly
	optimal stubs with a low cost despite the exponential complexity
	of getting optimal stubs. As being a part of a design-for-testability
	approach, the presented methodology also leads to the early repartition
	of testing resources during system integration for reducing integration
	duration},
  doi = {10.1109/24.855533},
  file = {:/literature/RegressionTesting/efficient object oriented integration and regression testing.pdf:PDF},
  issn = {0018-9529},
  keywords = {design-for-testability approach, integration strategies, object-oriented
	design, object-oriented integration, object-oriented methods, optimal
	stub minimization, program testing, quadratic complexity, regression
	testing, software reliability, test dependency graph, Unified Modeling
	Language},
  owner = {Annie},
  review = {This technique is although relevent but they do not perform any experimrnts
	with regression test selection.},
  timestamp = {2011.01.04}
}

@ARTICLE{Tratt_2008,
  author = {Tratt, Laurence},
  title = {A Change Propagating Model Transformation Language},
  journal = {Journal of Object Technology},
  year = {2008},
  volume = {7},
  pages = {107–126},
  number = {3},
  file = {:/literature/changeIdentification/10.1.1.78.5938.pdf:PDF},
  keywords = {Read},
  owner = {Steffen},
  publisher = {ETH Zurich},
  timestamp = {2012.03.01},
  url = {http://www.jot.fm/issues/issue_2008_03/article3/index.html}
}

@INPROCEEDINGS{Trendowicz2003,
  author = {Adam Trendowicz and Teade Punter},
  title = {Quality Modeling for Software Product Lines},
  booktitle = {Proceedings 7th ECOOP Workshop on Quantitative Approaches in Object-Oriented
	Software Engineering (QAOOSE'2003)},
  year = {2003},
  month = {July},
  abstract = {In today's embedded software systems development, non-functional requirements
	(e.g., dependability, maintainability) are becoming more and more
	important. Simultaneously the increasing pressure to develop software
	in less time and at lower costs pushes software industry towards
	product line’s solutions. To support product lines for high quality
	embedded software, quality models are needed. In this paper, we investigate
	to which extent existing quality modeling approaches facilitate high
	quality software product lines. First, we define several requirements
	for an appropriate quality model. Then, we use those requirements
	to review the existing quality modeling approaches. We conclude from
	the review that no single quality model fulfills all of our requirements.
	However, several approaches contain valuable characteristics. Based
	upon those characteristics, we propose the Prometheus approach. Prometheus
	is a goal-oriented method that integrates quantitative and qualitative
	approaches to quality control. The method starts quality modeling
	early in the software lifecycle and is reusable across product lines.},
  file = {:./literature/QAOOSE_2003_Trendowicz_Punter__Quality_Modeling_for_Software_Product_Lines.pdf:PDF},
  keywords = {Quality modeling, Software Product Lines, Non-functional requirements,
	Bayesian Belief Networks, Goal-Question-Metric, Prometheus},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://www-ctp.di.fct.unl.pt/QUASAR/QAOOSE2003/papers/QAOOSE_2003_Trendowicz_Punter__Quality_Modeling_for_Software_Product_Lines.pdf}
}

@ARTICLE{Tsantalis2005,
  author = {Tsantalis, Nikolaos and Chatzigeorgiou, Alexander and Stephanides,
	George},
  title = {Predicting the Probability of Change in Object-Oriented Systems},
  journal = {IEEE Transactions on Software Engineering},
  year = {2005},
  volume = {31},
  pages = {601-614},
  number = {7},
  month = {July},
  file = {:./literature/Paper_93.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- OO software offers better support for changing software systems
	due to OO principles
	
	- however, hard to measure how OO software will be affected by changes
	
	
	Research Questions:
	
	- how can one quantify flexibility and change proness of OO software
	
	- if a change occurs in one class, how is the probability that another
	class changes as well (better: has to change)
	
	
	Contribution:
	
	- probalistic approach to measure change proness of OO software (code
	level)
	
	- evaluate how each class will be affected by a change
	
	
	Solution:
	
	- distinguish between 3 ways how a class can be affected externaly
	("external axis")
	
	* inheritance: interface, class inheritance
	
	* references: direct instance, reference
	
	* dependencies
	
	- also consider the "inner axis", i.e. changes within the class itself
	
	- compute the probability of change for each of these axis
	
	- approach allows specification of seperate thresholds for each of
	the different probabilities
	
	- tool scans history database of software to calculate probabilities
	(however, user has to classify changes as "internal" or "ripple effect")
	
	* converts database to XML files, containing information about the
	different axis
	
	- if two classes are mutally dependent:
	
	* remove relation temporarily
	
	* calculate probabilities
	
	* restore relation
	
	* adjust probabilities
	
	- probability calculation
	
	* 1. detect cycles by constructing a relationship tree
	
	* 2. calc. prob. for classes without cycles
	
	* 3. calc. prob. for classes which are directly part of a cycle
	
	* 4. calc. prob. for classes without cycles but have an axis to a
	class which is part of a cycle
	
	* 5. calc. prob. for classes without cycles but have an axis to a
	class from step 4.
	
	-> granularity of entities: class
	
	-> granularity of changes: atomic changes (e.g. inheritance change)
	
	-> granularity of results: class
	
	
	Open Issues:
	
	- dependencies on libraries not considered
	
	- all changes are seen as independent, which might not hold in reality
	
	- user has to distinguish between changes manually
	
	- not useful in early development stages},
  timestamp = {2011.02.23}
}

@ARTICLE{Tun2009,
  author = {Tun, Thein Than and Trew, Tim and Jackson, Michael and Laney, Robin
	and Nuseibeh, Bashar},
  title = {Specifying features of an evolving software system},
  journal = {Softw. Pract. Exper.},
  year = {2009},
  volume = {39},
  pages = {973--1002},
  month = {August},
  acmid = {1568516},
  address = {New York, NY, USA},
  doi = {10.1002/spe.v39:11},
  file = {:/literature/changeIdentification/10.1.1.158.6311.pdf:PDF},
  issn = {0038-0644},
  issue = {11},
  keywords = {evolution, feature composition, problem frames, software features,
	specifications},
  numpages = {30},
  owner = {Steffen},
  publisher = {John Wiley \& Sons, Inc.},
  timestamp = {2012.03.01},
  url = {http://dl.acm.org/citation.cfm?id=1568514.1568516}
}

@ARTICLE{Turner2004,
  author = {Turner, J.},
  title = {Five necessary conditions for project success},
  journal = {International Journal of Project Management},
  year = {2004},
  volume = {22},
  pages = {349--350},
  number = {5},
  owner = {patrickr},
  timestamp = {2012.10.18}
}

@ARTICLE{Turner1993,
  author = {Turner, J.R. and Cochrane, R.A.},
  title = {Goals-and-methods matrix: coping with projects with ill defined goals
	and/or methods of achieving them},
  journal = {International Journal of Project Management},
  year = {1993},
  volume = {11},
  pages = {93--102},
  number = {2},
  file = {Turner1993.pdf:literature/Turner1993.pdf:PDF},
  keywords = {Project complexity},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.17}
}

@ARTICLE{Tyree2005,
  author = {Tyree, J. and Akerman, A.},
  title = {{Architecture Decisions: Demystifying Architecture}},
  journal = {IEEE Software},
  year = {2005},
  volume = {22},
  pages = {19-27},
  number = {2},
  abstract = { We believe that a key to demystifying architecture products lies
	in the architecture decisions concept. We can make the architecture
	more transparent and clarify its rationale for all stakeholders by
	explicitly documenting major architecture decisions.},
  doi = {10.1109/MS.2005.27},
  file = {:./literature/Tyree2005.pdf:PDF},
  issn = {0740-7459},
  keywords = {architecture decisions; system documentation; decision making; software
	architecture; system documentation;},
  owner = {Stephan},
  timestamp = {2011.01.11}
}

@MASTERSTHESIS{Ulbts2008,
  author = {Ulbts, Jürgen},
  title = {Ein Repository zur Unterstützung der Auswahl von Architekturstilen
	im Rahmen der MidArch-Methode},
  school = {University of Oldenburg},
  year = {2008},
  file = {:./literature/diplomarbeit_juergen_ulbts.pdf:PDF},
  owner = {Sebastian},
  timestamp = {2013.07.26}
}

@INPROCEEDINGS{Uschold1995,
  author = {Uschold, M. and King, M.},
  title = {Towards a Methodology for Building Ontologies},
  booktitle = {Proceedings Workshop on Basic Ontological Issues in Knowledge Sharing
	(IJCAI95)},
  year = {1995},
  address = {Montreal},
  file = {:./literature/Uschold1995.pdf:PDF},
  keywords = {Ontology Engineering},
  owner = {Stephan},
  timestamp = {2011.03.15}
}

@INPROCEEDINGS{Vanciu2010,
  author = {Vanciu, Radu and Rajlich, V\'{a}clav},
  title = {Hidden dependencies in software systems},
  booktitle = {Proceedings of the IEEE International Conference on Software Maintenance
	(ICSM '10)},
  year = {2010},
  pages = {1-10},
  address = {Timisoara},
  month = {September},
  file = {:./literature/Paper_174.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- hidden dependencies play important role in software evolution and
	maintenance
	
	- however , they are hard to detect
	
	
	Research Questions:
	
	- do well hidden dependencies exist in even well structure software
	
	
	Contribution:
	
	- new IA technique "execute completey after"-relation to reveal hidden
	dependencies
	
	- dynamically filters generated pre- and postconditions
	
	
	Solution:
	
	- dynamic data flow analysis is basis of hidden dependency analysis
	
	- this is based on execution traces
	
	- IECA is different from SEA relation and EA relation
	
	* methods calling others must be terminated before other is executed
	
	* methods must be containded by different class (not the same)
	
	- IECA consists of pre- and postconditions
	
	- potential hidden dependencies between f and g are revealed by:
	
	* post-cond(f) is implied by at least one pre-cond(g)
	
	* called significant precondition conjunction SPC(f,g)
	
	- a potential hidden dependency is a true hidden dependency if both
	methods share same domain or programming concept
	
	- Reveal tool extends "Daikon" tool and "Simplify theorem prover"
	
	-> granularity of entities: method
	
	-> granularity of changes:
	
	-> granularity of results: method
	
	
	Open Issues:
	
	- more and larger case studies
	
	- use hidden dependencies in firewalls and other regression test strategies},
  timestamp = {2011.07.26}
}

@BOOK{VanDerAalst2004,
  title = {Workflow management: models, methods, and systems},
  publisher = {MIT press},
  year = {2004},
  author = {Van Der Aalst, W. and Van Hee, K.},
  owner = {patrickr},
  timestamp = {2012.11.26}
}

@INCOLLECTION{VanDerStraeten2003,
  author = {Van Der Straeten, Ragnhild and Mens, Tom and Simmonds, Jocelyn and
	Jonckers, Viviane},
  title = {Using Description Logic to Maintain Consistency between UML Models},
  booktitle = {{UML} 2003 - The Unified Modeling Language. Modeling Languages and
	Applications},
  publisher = {Springer Berlin / Heidelberg},
  year = {2003},
  editor = {Stevens, Perdita and Whittle, Jon and Booch, Grady},
  volume = {2863},
  series = {Lecture Notes in Computer Science},
  pages = {326-340},
  affiliation = {Systems and Software Engineering Lab, Department of Computer Science,
	Vrije Universiteit Brussel, Pleinlaan 2, 1050 Brussel, Belgium},
  file = {:./literature/Paper_204.pdf:PDF},
  isbn = {978-3-540-20243-1},
  keyword = {Computer Science},
  owner = {Steffen},
  timestamp = {2012.03.15}
}

@ARTICLE{Gorp2003,
  author = {Van Gorp, Pieter and Stenten, Hans and Mens, Tom and Demeyer, Serge},
  title = {Towards Automating Source-Consistent UML Refactorings},
  journal = {Lecture Notes in Computer Science},
  year = {2003},
  volume = {2863},
  pages = {144-158},
  file = {:./literature/Paper_185.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.11.01}
}

@ARTICLE{VanGrembergen2004,
  author = {Van Grembergen, W. and De Haes, S. and Guldentops, E.},
  title = {Structures, processes and relational mechanisms for IT governance},
  journal = {Strategies for information technology governance},
  year = {2004},
  volume = {2004},
  pages = {1--36},
  owner = {patrickr},
  publisher = {Idea Group Publishing Hershey, PA},
  timestamp = {2012.11.19}
}

@INPROCEEDINGS{Vaucher2008,
  author = {Vaucher, Stephane and Sahraoui, Houari and Vaucher, Jean},
  title = {Discovering New Change Patterns in Object-Oriented Systems},
  booktitle = {Proceedings of the 2008 15th Working Conference on Reverse Engineering
	(WCRE '08)},
  year = {2008},
  pages = {37-41},
  address = {Washington, DC, USA},
  file = {:./literature/Paper_126.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- software has to evolve to meet needs of stakeholders
	
	- effort of maintaining and evolving software surpasses development
	costs
	
	- keep track of class changes not easy (e.g. move, rename etc.) ->
	"Origin Analysis"
	
	
	Research Questions:
	
	- how to identify evolution patterns from software
	
	
	Contribution:
	
	- new approach to discover evolution-patterns in software
	
	- evaluation with 2 case studies
	
	
	Solution:
	
	- keep track of changes in classes by applying IR techniques
	
	- calculate "level of change" for each class evolution:
	
	* relative implementation change
	
	 - count changes to methods by counting number of added, removed,
	modified instructions
	
	 - total change to class is measured as sum of changes to methods
	
	* relative functional change
	
	 - changes in public interface of class
	
	 - number of add/removed public methods divided by toal number of
	public methods
	
	* include all changes to a class in a vector
	
	- cluster classes which change together
	
	- use dynamic time warping to find similar groups of class-clusters
	(patterns)
	
	- usefulness of groups evaluated by checking release notes and architecture
	
	- 4 groups of class-cluster:
	
	* usual suspects: classes which frequently change together
	
	* code stabilisations: new classes that require a few versions before
	becoming stable
	
	* punctual changes: classes grouped due to change in specific version
	
	* common concern: classes implementing same concern
	
	-> granularity of entities: classes
	
	-> granularity of changes: add, remove, modified methods / statements
	
	-> granularity of results: classes
	
	
	Open Issues:
	
	- changes between pairs of versions considered independent (not true
	in practice)
	
	- noisy data (short lived classes)},
  timestamp = {2011.04.01}
}

@ARTICLE{Vendler1957,
  author = {Vendler, Z.},
  title = {Verbs and times},
  journal = {The philosophical review},
  year = {1957},
  pages = {143--160},
  file = {Vendler1957.pdf:literature/Vendler1957.pdf:PDF},
  owner = {patrickr},
  publisher = {JSTOR},
  timestamp = {2012.12.19}
}

@MISC{VDI5600,
  author = {{Verein Deutscher Ingenieure}},
  title = {Fertigungsmanagementsysteme - {M}anufacturing {E}xecution {S}ystems
	({MES})},
  howpublished = {VDI 5600},
  month = {Dec.},
  year = {2007},
  file = {:./literature/VDI-RichtlinieMES.pdf:PDF},
  keywords = {MES, manufacturing execution system},
  owner = {Stephan},
  timestamp = {2009.02.10}
}

@INPROCEEDINGS{Vidacs2007,
  author = {Vid\'{a}cs, L\'{a}szl\'{o} and Besz\'{e}des, \'{A}rp\'{a}d and Ferenc,
	Rudolf},
  title = {Macro Impact Analysis Using Macro Slicing},
  booktitle = {Proceedings of the Second International Conference on Software and
	Data Technologies (ICSOFT '07)},
  year = {2007},
  pages = {230-235},
  file = {:./literature/Paper_131.PDF:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- macros useful concept in programming languages
	
	- however macros result in incomprehensible, unmaintainable code due
	to their nature
	
	- no IA approaches for the level of macros available
	
	
	Research Questions:
	
	- which parts of code are affected by a certain macro change
	
	
	Contribution:
	
	- new IA approach for slicing macros
	
	
	Solution:
	
	- build macro dependency graph used to compute forward dynamic macro
	slices
	
	* based on macro definitions and macro calls
	
	* use coloring and multiple edges to add support for later defined
	and re-defined macros
	
	- dynamic forward macro slices are used to conduct IA
	
	-> granularity of entities: macros
	
	-> granularity of changes: changes in macro definition
	
	-> granularity of results: macro, variable, method, class
	
	- experimental tool, based on Columbus C/C++ framework developed
	
	
	Open Issues:
	
	- add backward macro slices
	
	- implement efficient algorithm to compute global macro slices},
  timestamp = {2011.04.04}
}

@BOOK{Vliet2007,
  title = {Software Engineering: Principles and Practice},
  publisher = {John Wiley \& Sons},
  year = {2007},
  author = {Vliet, HV},
  number = {c},
  file = {Vliet2007 - Software Engineering - Principles and Practice.pdf:literature/Vliet2007 - Software Engineering - Principles and Practice.pdf:PDF},
  journal = {Requirements Engineering},
  owner = {Stephan},
  timestamp = {2010.12.31}
}

@ARTICLE{Voas2004,
  author = {Voas, J.},
  title = {Software's secret sauce: the "-ilities" [software quality]},
  journal = {IEEE Software},
  year = {2004},
  volume = {21},
  pages = {14-15},
  number = {6},
  month = {Nov.-Dec.},
  abstract = {If beauty is in the eye of the beholder, then quality must be as well.
	We live in a world where beauty to one is a complete turnoff to another.
	Software quality is no different. We have the developer's perspective,
	the end users perspective, the testers perspective, and so forth.
	As you can see, meeting the requirements might be different from
	being fit for a purpose, which can also be different from complying
	with rules and regulations on how to develop and deploy the software.
	Yet we can think of all three perspectives as ways to determine how
	to judge and assess software quality. These three perspectives tie
	directly to the persistent software attributes focus section in this
	issue and, consequently, to the concept of software "-ilities". The
	-ilities (or software attributes) are a collection of closely related
	behaviors that by themselves have little or no value to the end users
	but that can greatly increase a software application or system's
	value when added.},
  doi = {10.1109/MS.2004.54},
  file = {:./literature/01353217.pdf:PDF},
  issn = {0740-7459},
  keywords = { formal specification, formal verification, software metrics, software
	quality end users perspective, software attributes, software measurement,
	software quality, software requirements},
  owner = {Stephan},
  review = {- some common argumentation for the importance of "ilities"
	
	- stresses the analogy with the need for the right ingredients and
	flavouring when cooking},
  timestamp = {2008.04.02}
}

@ARTICLE{Voas1998,
  author = {Voas, Jeffrey},
  title = {{COTS software: the economical choice?}},
  journal = {IEEE Software},
  year = {1998},
  volume = {15},
  pages = {16--19},
  number = {2},
  doi = {10.1109/52.663777},
  file = {:./literature/Voas1998.pdf:PDF},
  issn = {07407459},
  owner = {Sebastian},
  timestamp = {2014.03.19},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=663777}
}

@BOOK{Voelter2013,
  title = {DSL Engineering: Designing, Implementing and Using Domain-Specific
	Languages},
  publisher = {CreateSpace Independent Publishing Platform},
  year = {2013},
  author = {Markus Voelter},
  file = {:./literature/markusvoelter-dslengineering-1.0.pdf:PDF},
  owner = {matthias},
  timestamp = {2013.01.31}
}

@ARTICLE{VonKrogh2001,
  author = {Von Krogh, G. and Nonaka, I. and Aben, M.},
  title = {Making the most of your company's knowledge: a strategic framework},
  journal = {Long range planning},
  year = {2001},
  volume = {34},
  pages = {421--439},
  number = {4},
  file = {VonKrogh2001.pdf:literature/VonKrogh2001.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.11.19}
}

@INPROCEEDINGS{Vora2010,
  author = {Vora, Urjaswala},
  title = {Change Impact Analysis and Software Evolution Specification for Continually
	Evolving Systems},
  booktitle = {Proceedings of the Fifth International Conference on Software Engineering
	Advances},
  year = {2010},
  pages = {238-243},
  address = {Nice, France},
  month = {August},
  file = {:./literature/Paper_148.pdf:PDF},
  owner = {Steffen},
  review = {[very confusing paper]
	
	
	Problem:
	
	- lot of IA techniques work on too fine-grained level of entities
	
	- IA needs to be applied on higher levels of change management
	
	- IA must first be conducted on architectural design level to capture
	module dependencies
	
	- current architecture models do not capture dependencies between
	models explicitly
	
	
	Research Questions:
	
	- how to take into account that control flow changes faster than data
	flow
	
	- how to improve IA on architectural level
	
	
	Contribution:
	
	- new modeling language to capture dependencies between modules:
	
	"temporal control flow rule-based architecture" (TeCFRA)
	
	- new ADL which supports TeCFRA
	
	
	Solution:
	
	- TeCFRA models dependencies as control flow rules which serve as
	connectors
	
	- TeCFRA consists of 2 frameworks:
	
	* execution framework
	
	 - external control flow adds flexibility to analysis
	
	 - focus on method invocation
	
	 - model control flow classes and their methods as control flow rules
	
	 - consists of metadata repository and rule engine
	
	 - divide applications into "activities"; divide "activities" into
	"tasks" (method/method-calls)
	
	 - user then invokes activities
	
	* evolution management framework
	
	 - captures dependencies between architectural components
	
	 - consists of 3 repositories (ADL spec., Evolution spe., metadata)
	and "Evolution spec. to ADL spec."-mapper
	
	- defined TeCFRADL (new ADL)
	
	* model design and evolution of architecture
	
	* supports nun-functional properties at component and connector level
	
	- rule-based IA with control call graphs on TeCFRADL architectures
	
	-> granularity of entities: class, method
	
	-> granularity of changes: no details given
	
	-> granularity of results: architectural components
	
	
	Open Issues:
	
	- empirical validation},
  timestamp = {2011.04.04}
}

@MISC{W3C-OWL2009,
  author = {{W3C OWL Working Group}},
  title = {{OWL 2 Web Ontology Language Document Overview}},
  howpublished = {{W3C Recommendation}},
  month = {October 27},
  year = {2009},
  abstract = {The OWL 2 Web Ontology Language, informally OWL 2, is an ontology
	language for the Semantic Web with formally defined meaning. OWL
	2 ontologies provide classes, properties, individuals, and data values
	and are stored as Semantic Web documents. OWL 2 ontologies can be
	used along with information written in RDF, and OWL 2 ontologies
	themselves are primarily exchanged as RDF documents.
	
	
	This document serves as an introduction to OWL 2 and the various other
	OWL 2 documents. It describes the syntaxes for OWL 2, the different
	kinds of semantics, the available profiles (sub-languages), and the
	relationship between OWL 1 and OWL 2.},
  keywords = {OWL},
  owner = {Stephan},
  timestamp = {2010.12.27},
  url = {http://www.w3.org/TR/owl2-overview/}
}

@ARTICLE{Wada2008,
  author = {H. Wada and J. Suzuki and K. Oba},
  title = {A Model-Driven Development Framework for Non-Functional Aspects in
	Service Oriented Architecture},
  journal = {Journal of Web Services Research},
  year = {2008},
  volume = {5},
  number = {4},
  abstract = {Service Oriented Architecture (SOA) is an emerging style of software
	architectures to reuse and integrate existing systems for designing
	new applications. Each application is designed in an implementation
	independent manner using two major abstract concepts: services and
	connections between services. In SOA, non-functional aspects (e.g.,
	security and fault tolerance) of services and connections should
	be described separately from their functional aspects (i.e., business
	logic) because different applications use services and connections
	in different non-functional contexts. This paper proposes a model-driven
	development (MDD) framework for non-functional aspects in SOA. The
	proposed MDD framework consists of (1) a Unified Modeling Language
	(UML) profile to graphically model non-functional aspects in SOA,
	and (2) an MDD tool that accepts a UML model defined with the proposed
	profile and transforms it to application code. This paper also demonstrates
	how the proposed framework is used in model-driven development of
	serviceoriented applications. Empirical evaluation results show that
	the proposed MDD framework improves the reusability and maintainability
	of service-oriented applications by hiding low-level implementation
	technologies in UML models.},
  file = {:./literature/jwsr.pdf:PDF},
  keywords = {Service Oriented Architecture, Visual Non-functional Modeling, UML,
	Metamodeling, Model Driven Development},
  owner = {Stephan},
  review = {introduction of an MDD framework with:
	
	(1) a UML profile for non-functional aspects
	
	(2) an MDD tool for transforming a UML modell to application code
	
	
	adressed non-functional aspects:
	
	service deployment semantics, message transmission semantics, message
	processing semantics, security semantics
	
	
	modelling support for regulatory compliance
	
	
	MDD support for service-oriented architectures separating function
	from non-functional aspects through models
	
	
	designer defines UML model using the UML profile
	
	Ark Transformer transforms it (XMI input) to source code (skeletons)
	and deployment descriptors for a specific ESB (e.g. MuleESB)
	
	developer implements the application code using the transformation
	result
	
	
	good related work section with lots of references to works on funcitonal
	and non-functional modelling for SOA
	
	- mainly addressed non-funcitonal aspects: message transmission, message
	processing, security},
  timestamp = {2008.04.10},
  url = {http://www.cs.umb.edu/~jxs/pub/jwsr.pdf}
}

@MASTERSTHESIS{Wagner2010,
  author = {Philipp Wagner},
  title = {{Tool Support for the Analysis during Software Architectural Design
	(in German: Werkzeugunterst{\"u}tzung f{\"u}r die Analyse beim Softwarearchitekturentwurf)}},
  school = {Ilmenau University of Technology},
  year = {2010},
  type = {Bachelor thesis},
  address = {Ilmenau, Germany},
  month = {December},
  file = {:./literature/Master_7.pdf:PDF},
  keywords = {architectural analysis, Global Analysis, influence factors, factor
	table, issue card, EMFfit, EMFTrace},
  owner = {Stephan},
  timestamp = {2010.12.17}
}

@INPROCEEDINGS{Wagner2008,
  author = {Stefan Wagner and Florian Deissenboeck and Sebastian Winter},
  title = {Managing Quality Requirements Using Activity-Based Quality Models},
  booktitle = {Proceedings of the 6th international workshop on Software quality
	(WoSQ'08)},
  year = {2008},
  pages = {29-34},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Managing requirements on quality aspects is an important issue in
	the development of software systems. Difficulties arise from expressing
	them appropriately what in turn results from the difficulty of the
	concept of quality itself. Building and using quality models is an
	approach to handle the complexity of software quality. A novel kind
	of quality models uses the activities performed on and with the software
	as an explicit dimension. These quality models are a well-suited
	basis for managing quality requirements from elicitation over refinement
	to assurance. The paper proposes such an approach and shows its applicability
	in an automotive case study.},
  doi = {http://doi.acm.org/10.1145/1370099.1370107},
  file = {:./literature/wosq08.pdf:PDF},
  isbn = {978-1-60558-023-4},
  keywords = {quality requirements, quality models, activities, stakeholders, activity-based
	quality model, non-functional requirements},
  location = {Leipzig, Germany},
  owner = {Stephan},
  timestamp = {2009.04.28},
  url = {http://www4.informatik.tu-muenchen.de/~deissenb/publications/2008_wagnerst_quality_requirements.pdf}
}

@INPROCEEDINGS{Walderhaug2006,
  author = {Walderhaug, St\r{a}le and Johansen, Ulrik and Stav, Erlend and Aagedal,
	Jan},
  title = {Towards a generic solution for traceability in {MDD}},
  booktitle = {Proceedings of the ECMDA Traceability Workshop},
  year = {2006},
  pages = {41-50},
  address = {Sintef, Trondheim},
  __markedentry = {[Steffen:]},
  file = {:./literature/Paper_211.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.25}
}

@INPROCEEDINGS{WalidS.AbdEl-hamid2010,
  author = {Walid S. Abd El-hamid, Sherif S. El-etriby, and Mohiy M. Hadhoud},
  title = {A General Regression Test Selection Technique},
  year = {2010},
  editor = {World Academy of Science, Engineering and Technology},
  file = {:/literature/RegressionTesting/A General Regression Test Selection Technique.pdf:PDF},
  keywords = {code based},
  owner = {Annie},
  review = {class diagram and sequence diagram},
  timestamp = {2011.01.04}
}

@INPROCEEDINGS{Walker2006,
  author = {Walker, Robert J. and Holmes, Reid and Hedgeland, Ian and Kapur,
	Puneet and Smith, Andrew},
  title = {A lightweight approach to technical risk estimation via probabilistic
	impact analysis},
  booktitle = {Proceedings of the 2006 international workshop on Mining software
	repositories (MSR '06)},
  year = {2006},
  pages = {98-104},
  address = {Shanghai, China},
  file = {:./literature/Paper_129.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- evolutionary development approach common practice in industry
	
	- developers have little influence on descisions to be made
	
	- management has little understanding of technical details
	
	
	Research Questions:
	
	- how to assess the impact of a change at an early stage without having
	implementation (e.g. code)
	
	
	Contribution:
	
	- new technique to assess and communicate technical risks, based on
	weakly change estimation, historical change behavior and current
	structure of software
	
	
	Solution:
	
	- approach relies on probabilistic IA and requires following input:
	
	* structural dependency graph
	
	* historical change datat (CVS)
	
	* estimation of analyst where change is likely to take place
	
	- use structural dependency to calculate probabilities of change propagation
	
	- process consists of following steps:
	
	* extract dependency structure from project source
	
	* extract change date from CVS
	
	 - inferred by analyzing log data
	
	 - compare 2 change records to identify atomic change sets
	
	* create conditional probability graph model
	
	 - like a normal dependency graph
	
	 - annotate edges with probabilities
	
	 * count how often source and target changed together in CVS records
	
	 - use modified Dijkstra-algorithm to compute graph
	
	* user interaction with tool, i.e. mark changed entities etc.
	
	-> granularity of entities: java types (classes?)
	
	-> granularity of changes: atomic CVS change sets
	
	-> granularity of results: java types (classes?)
	
	- implemented in Eclipse based tool "TRE" (tech. risk estimation)
	
	- scalability:
	
	* time: O(n log n)
	
	
	Open Issues:
	
	- tool doesn't work if no history data is available
	
	- bulk updates are problematic
	
	- add variability to granularity of input (e.g. packages)
	
	- treat different types of changes differently},
  timestamp = {2011.04.04}
}

@BOOK{Wallmueller1990,
  title = {Software-Qualitätssicherung in der Praxis},
  publisher = {Hanser},
  year = {1990},
  author = {Ernest Wallmüller},
  address = {München, Wien},
  owner = {Stephan},
  timestamp = {2009.04.28}
}

@INPROCEEDINGS{Wang2008,
  author = {Wang, Di and Li, Bixin and Cai, Ju},
  title = {Regression Testing of Composite Service: An XBFG-Based Approach},
  booktitle = {Proceedings of the 2008 IEEE Congress on Services Part II},
  year = {2008},
  pages = {112--119},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid = {1476225},
  doi = {10.1109/SERVICES-2.2008.28},
  file = {:/literature/RegressionTesting/04700507.pdf:PDF},
  isbn = {978-0-7695-3313-1},
  keywords = {Regression testing, Test path, Test case, Service composition, BPEL,
	WSRT},
  numpages = {8},
  owner = {Steffen},
  review = {+Evolution in composite services
	
	
	 +process alteration -> design stage
	
	 +static binding alteration -> deployment stage
	
	 +dynamic binding alteration -> running stage
	
	
	process alteration and static binding alternation are manual changes
	
	
	
	The original and delta BPEL is transformed in to extensible bpel flow
	graph (XBFG) 
	
	
	All the simple paths are extracted from the baseline and delta XBFG
	
	
	paths affected by process and static binding alteration are selected.
	
	
	Seect test cases based on selected paths
	
	
	Every element in XBFG has a hash codeconsisting of , id, source, target
	and
	
	category. 
	
	
	The two changed elements can be detected by comparing the hashcode
	of the element.
	
	Every node is distinguised by an id because same activities can exist
	in the BPEL document and their hashcodes can be same.
	
	
	two edges can have same ids if they have same source and target node.
	
	
	if binding of a partner changed all the activities corresponding to
	this partner need to be retested.
	
	
	In case of dinamic binding a binding change tabke is maintained during
	each execution and compared. If a change in the table is detected,
	the activities corresponding to this changed partner links are considered
	to be retested.
	
	
	
	Analysis
	
	
	Attention is paid to only binding scenarios, process alteration is
	not focused
	
	
	For larger processes, construction of XBFG can be computation intensive
	
	
	No dependencies are considered during regression testing},
  timestamp = {2012.03.01},
  url = {http://dl.acm.org/citation.cfm?id=1475697.1476225}
}

@ARTICLE{Wangenheim2006,
  author = {von Wangenheim, C.G. and Anacleto, A. and Salviano, C.F.},
  title = {Helping small companies assess software processes},
  journal = {Software, IEEE},
  year = {2006},
  volume = {23},
  pages = {91--98},
  number = {1},
  file = {Wangenheim2006.pdf:literature/Wangenheim2006.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@ARTICLE{Ward2007,
  author = {Ward, S. and Chapman, C.},
  title = {Making Risk Management More Effective},
  journal = {The Wiley Guide to Managing Projects},
  year = {2007},
  pages = {852--875},
  owner = {patrickr},
  publisher = {Wiley Online Library},
  timestamp = {2012.10.18}
}

@ARTICLE{Wateridge1998,
  author = {Wateridge, J.},
  title = {How can IS/IT projects be measured for success?},
  journal = {International Journal of Project Management},
  year = {1998},
  volume = {16},
  pages = {59--63},
  number = {1},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.18}
}

@ARTICLE{Watkins1994,
  author = {R. Watkins and M. Neal},
  title = {Why and How of {R}equirements {T}racing},
  journal = {IEEE Software},
  year = {1994},
  volume = {11},
  pages = {104-106},
  number = {4},
  month = {Jul},
  abstract = {While requirements traceability is explicitly required in US Department
	of Defense software contracts, it is often hard to sell in other
	situations. This article explains how Abbott Laboratories Diagnostics
	Division approaches traceability. To illustrate our program, we describe
	how we applied it to an R&D project to develop an embedded, real-time
	in vitro diagnostic instrument. The software is part of a system
	to test human body fluids for conditions such as cancer or hepatitis.
	We learned a great deal from this application and continue to experiment
	with and evolve the traceability-analysis process. In particular,
	we found that we must establish documentation rules and formats much
	earlier in the life cycle. Another lesson we learned is that traceability
	does cost. You need staff to support formal inspections or reviews.
	For most projects, you need some type of tool to assist in managing
	the trace matrices. We developed a relatively low-cost tool to handle
	our needs. Whatever the cost, it is important to include it as well
	as the costs for developing and maintaining procedures for documentation
	formats and generation, traceability analysis, and formal inspections.
	Our biggest lesson is that traceability is critical to project success.
	We believe it was one of the key factors in releasing our diagnostic
	instrument on time. Finally, we determined the conditions under which
	some type of traceability program is necessary.},
  doi = {10.1109/52.300100},
  file = {:./literature/00300100.pdf:PDF},
  keywords = {computerised instrumentation, medical diagnostic computing, real-time
	systems, software engineering, software quality, systems analysisR&,D
	project, cancer, costs, documentation formats, documentation rules,
	embedded, real-time in vitro diagnostic instrument, formal inspections,
	hepatitis, human body fluids, project success, requirements traceability,
	software productivity, software quality, trace matrices, traceability
	analysis},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.16}
}

@ARTICLE{Weick1993,
  author = {Weick, K.E.},
  title = {The collapse of sensemaking in organizations: The Mann Gulch disaster},
  journal = {Administrative science quarterly},
  year = {1993},
  pages = {628--652},
  file = {Weick1993.pdf:literature/Weick1993.pdf:PDF},
  owner = {patrickr},
  publisher = {JSTOR},
  timestamp = {2012.10.19}
}

@MISC{Weide,
  author = {Bruce W. Weide},
  title = {"Modular Regression Testing": Connections to Component-Based Software},
  __markedentry = {[qurat:]},
  file = {:/literature/RegressionTesting/Modular regression testing, connectons to component based software.pdf:PDF},
  keywords = {code based, component based, s},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@TECHREPORT{Weiderman1997,
  author = {Nelson Weiderman and Dennis Smith and Scott Tilley},
  title = {Approaches to Legacy System Evolution},
  institution = {CMU/SEI},
  year = {1997},
  number = {CMU/SEI-97-TR-014},
  month = {December},
  abstract = {The approach that one chooses to evolve software-intensive systems
	depends on the organization, the system, and the technology. We believe
	that significant progress in system architecture, system understanding,
	object technology, and net-centric computing make it possible to
	economically evolve software systems to a state in which they exhibit
	greater functionality and maintainability. In particular, interface
	technology, wrapping technology, and network technology are opening
	many opportunities to leverage existing software assets instead of
	scrapping them and starting over. But these promising technologies
	cannot be applied in a vacuum or without management understanding
	and control. There must be a framework in which to motivate the organization
	to understand its business opportunities, its application systems,
	and its road to an improved target system. This report outlines a
	comprehensive system evolution approach that incorporates an enterprise
	framework for the application of the promising technologies in the
	context of legacy systems.},
  file = {:./literature/97tr014.pdf:PDF},
  keywords = {legacy systems, evolution},
  owner = {Stephan},
  timestamp = {2008.06.16},
  url = {http://www.sei.cmu.edu/pub/documents/97.reports/pdf/97tr014.pdf}
}

@ARTICLE{Weigand2002,
  author = {Weigand, H. and van den Heuvel, W.J.},
  title = {Cross-organizational workflow integration using contracts},
  journal = {Decision Support Systems},
  year = {2002},
  volume = {33},
  pages = {247--265},
  number = {3},
  file = {Weigand2002.pdf:literature/Weigand2002.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.10}
}

@ARTICLE{Weinreich2012,
  author = {Weinreich, Rainer and Buchgeher, Georg},
  title = {{Towards supporting the software architecture life cycle}},
  journal = {Journal of Systems and Software},
  year = {2012},
  volume = {85},
  pages = {546--561},
  number = {3},
  month = mar,
  doi = {10.1016/j.jss.2011.05.036},
  file = {:./literature/weinreich2012.pdf:PDF},
  issn = {01641212},
  keywords = {software architecture,software architecture life cycle,software architecture
	model},
  owner = {Sebastian},
  publisher = {Elsevier Inc.},
  timestamp = {2013.12.03},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0164121211001361}
}

@INPROCEEDINGS{Weiss2004,
  author = {Weiss, M. and Esfandiari, B.},
  title = {On Feature Interactions among Web Services},
  booktitle = {Proceedings. IEEE International Conference on Web Services (ICWS'04)},
  year = {2004},
  pages = { 88-95},
  month = {July},
  publisher = {IEEE},
  abstract = {Web services promise to allow businesses to adapt rapidly to changes
	in the business environment, and the needs of different customers.
	However, the rapid introduction of new services paired with the dynamicity
	of the business environment also leads to undesirable interactions
	that negatively impact service quality and user satisfaction. In
	this paper, we propose an approach for modeling such undesirable
	interactions as feature interactions. Our approach for detecting
	interactions is based on goal-oriented analysis and scenario modeling.
	It allows us to reason about feature interactions in terms of goal
	conflicts, and feature deployment. Two case studies illustrate the
	approach. The paper concludes with a discussion, and an outlook on
	future research.},
  doi = {10.1109/ICWS.2004.1314727},
  file = {:./literature/1314727.pdf:PDF},
  keywords = { Internet, electronic commerce, management of change, quality of service
	Web services, business adaptation, business environment changes,
	customer needs, feature deployment, feature interactions, goal-oriented
	analysis, scenario modeling, service quality, user satisfaction},
  owner = {Stephan},
  review = {feature interactions between web services are modeled with goal-oriented
	approach using GRL
	
	
	3 types of interactions identified:
	
	- goal conflicts
	
	- deployment and ownership
	
	- information hiding
	
	
	however:
	
	- no discussion of design decisions
	
	- only very high-level consideration of architecture in form of services
	and their features},
  timestamp = {2009.01.16}
}

@INPROCEEDINGS{Welzel1995,
  author = {Welzel, D. and Hausen, H.L. and Schmidt, W.},
  title = {Tailoring and conformance testing of software processes: the ProcePT
	approach},
  booktitle = {Software Engineering Standards Symposium, 1995.(ISESS'95)'Experience
	and Practice', Proceedings., Second IEEE International},
  year = {1995},
  pages = {41--49},
  file = {Welzel1995.pdf:literature/Welzel1995.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@MASTERSTHESIS{Wendler2007,
  author = {Stefan Wendler},
  title = {{Entwurfsentscheidungen bei der Entwicklung von Software-Architekturen}},
  school = {Technical University of Ilmenau},
  year = {2007},
  type = {Diploma Thesis},
  address = {Ilmenau, Germany},
  abstract = {Zusammenfassung:
	
	Die Architekturentwicklung ist ein herausforderndes Thema in der Softwareentwicklung.
	Bei der Architekturentwicklung sind vielfältige Entwurfsentscheidungen
	zu treffen. Diese Entscheidungen müssen eine hohe Qualität der Softwarearchitektur
	sicherstellen, damit die Änderbarkeit und arbeitsteilige Entwicklung
	des Softwaresystems ermöglicht wird. Ohne eine hohe Qualität der
	Softwarearchitektur sind Softwaresysteme in Zukunft nur schlecht
	oder gar nicht zu warten. Eine kostspielige Neuentwicklung würde
	unausweichlich werden. 
	
	Das Softwarearchitekturkonzept Quasar stellt Ansätze und Richtlinien
	für den Entwurf einer Softwarearchitektur von hoher Qualität bereit.
	Mit den Konzepten von Quasar, die das Architekturwissen über betriebliche
	Informationssysteme aus zahlreichen von der sd&m AG realisierten
	Projekten verkörpert, wird ein komponentenbasierter Entwicklungsansatz
	beschrieben. Neben diesem Erfahrungsschatz von sd&m fließen viele
	grundlegende Kriterien und Prinzipien, die im Laufe der Zeit bei
	der Erstellung von Softwarearchitekturen entwickelt worden, wesentlich
	mit ein. 
	
	In dieser Arbeit wird das Quasar-Architekturkonzept hinsichtlich seiner
	praktischen Anwendbarkeit untersucht. Dabei werden die zu treffenden
	Entwurfsentscheidungen und entstehenden Artefakte Entwurfsaktivitäten
	zugeordnet. Auf Basis realer Anforderungen werden mit einem Beispielprojekt
	die Entwicklungsaktivitäten aufgestellt und durchgeführt. Um die
	vielfältigen Verbindungen der dabei erstellen Artefakt nachvollziehbar
	zu gestalten und die Übersicht zu gewährleisten, werden Traceability-Links
	eingesetzt.
	
	
	Abstract:
	
	Developing software architectures is quite a challenging issue in
	current software engineering. Varied design decisions have to be
	reached when developing software architectures. In order to enable
	changeability and development based on division of labour, these
	design decisions need to guarantee a high quality in the resulting
	software architecture. With lack of quality software systems can
	poorly or even not be maintained in future. Therefore a costly redevelopment
	would be inevitable.
	
	Approaches and principles for designing high quality software architectures
	are provided by Quasar. Concepts of Quasar, which represent the architecture
	knowledge of the sd&m AG about administrative information systems,
	specify a component-driven development approach. Besides the experience
	of sd&m many fundamental criteria and principles, which have emerged
	from creating software architectures over time, were incorporated
	in Quasar. 
	
	The Quasar architecture concept will be analysed concerning its practical
	application in this diploma thesis. Thereby design decisions to be
	reached and resulting artefacts will be assigned to design activities.
	Based on real requirements the design activities will be issued and
	realized by means of an example project. To keep varied relationships
	between created artefacts traceable and for the sake of clarity traceability
	links will be established.},
  file = {:./literature/Diplomarbeit_Wendler_2007.pdf:PDF},
  keywords = {design decisions, traceability, software architecture, Quasar},
  owner = {Stephan},
  timestamp = {2008.08.01}
}

@INPROCEEDINGS{Westerheim2005,
  author = {Westerheim, H. and Hanssen, G.K.},
  title = {The introduction and use of a tailored unified process-a case study},
  booktitle = {Software Engineering and Advanced Applications, 2005. 31st EUROMICRO
	Conference on},
  year = {2005},
  pages = {196--203},
  file = {Westerheim2005.pdf:literature/Westerheim2005.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@INPROCEEDINGS{Westhuizen2002,
  author = {van der Westhuizen, Christian and van der Hoek, Andr\'{e}},
  title = {Understanding and Propagating Architectural Changes},
  booktitle = {Third Working IEEE/IFIP Conference on Software Architecture},
  year = {2002},
  pages = {95-109},
  file = {:./literature/Paper_193.pdf:PDF},
  owner = {Steffen},
  timestamp = {2011.12.29}
}

@INPROCEEDINGS{Wettel2007,
  author = {Wettel, Richard and Lanza, Michele},
  title = {Program Comprehension through Software Habitability},
  booktitle = {Proceedings of the 15th IEEE International Conference on Program
	Comprehension (ICPC '07)},
  year = {2007},
  pages = {231–240},
  address = {Banff, Alberta, BC},
  month = {June},
  file = {:./literature/Paper_39.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	
	Research Questions:
	
	
	Contribution:
	
	
	Solution:
	
	
	Open Issues:},
  timestamp = {2011.02.04}
}

@INPROCEEDINGS{Wettel2007a,
  author = {Wettel, Richard and Lanza, Michele},
  title = {Visualizing Software Systems as Cities},
  booktitle = {4th IEEE International Workshop on Visualizing Software for Understanding
	and Analysis (VISSOFT 2007)},
  year = {2007},
  pages = {92-99},
  month = {June},
  file = {:./literature/Paper_253.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.11.05}
}

@INPROCEEDINGS{White1996,
  author = {White, Lee J.},
  title = {Regression Testing of GUI Event Interactions},
  booktitle = {Proceedings of the 1996 International Conference on Software Maintenance},
  year = {1996},
  series = {ICSM '96},
  pages = {350--358},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[qurat:]},
  acmid = {655863},
  file = {:/literature/RegressionTesting/Regression Testing of GUI Event Interactions.pdf:PDF},
  isbn = {0-8186-7677-9},
  keywords = {Not Much Relevant, GUI Testing, Pairwise Event Interaction, GUI Function
	Testing, Regression Testing, not model baseds},
  numpages = {9},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=645544.655863}
}

@INPROCEEDINGS{White1993,
  author = {White, Lee J. and Narayanswamy, Venkatasubramaniam and Friedman,
	Ted and Kirschenbaum, Marc and Piwowarski, Paul and Oha, Mitsuru},
  title = {Test Manager: A Regression Testing Tool},
  booktitle = {Proceedings of the Conference on Software Maintenance},
  year = {1993},
  series = {ICSM '93},
  pages = {338--347},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid = {658156},
  file = {:/literature/RegressionTesting/Test Manager A Regression Testing Tool.PDF:PDF},
  isbn = {0-8186-4600-4},
  keywords = {Read, ToolReport, code baseds},
  numpages = {10},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=645542.658156}
}

@ARTICLE{Whitley2006,
  author = {Whitley, R.},
  title = {Project-based firms: new organizational form or variations on a theme?},
  journal = {Industrial and Corporate Change},
  year = {2006},
  volume = {15},
  pages = {77--99},
  number = {1},
  file = {Whitley2006.pdf:literature/Whitley2006.pdf:PDF},
  owner = {patrickr},
  publisher = {Oxford Univ Press},
  timestamp = {2012.10.22}
}

@ARTICLE{Wiegers1999,
  author = {Wiegers, K.E.},
  title = {Software process improvement in Web time},
  journal = {Software, IEEE},
  year = {1999},
  volume = {16},
  pages = {78--86},
  number = {4},
  file = {Wiegers1999.pdf:literature/Wiegers1999.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.27}
}

@TECHREPORT{Wieringa1995,
  author = {R.J. Wieringa},
  title = {An introduction to requirements traceability},
  institution = {Faculty of Mathematics and Computer Science, Vrije Universiteit,
	Nederlands},
  year = {1995},
  month = {November},
  file = {:./literature/95-traceability.pdf:PDF},
  keywords = {requirements traceability},
  language = {english},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://www.cs.vu.nl/pub/roelw/95-traceability.ps.Z}
}

@ARTICLE{Wilde1992,
  author = {Wilde, Norman and Huitt, Ross},
  title = {Maintenance Support for Object-Oriented Programs},
  journal = {IEEE Trans. Softw. Eng.},
  year = {1992},
  volume = {18},
  pages = {1038--1044},
  month = {December},
  __markedentry = {[qurat:]},
  acmid = {147667},
  address = {Piscataway, NJ, USA},
  doi = {10.1109/TSE.1992.1263033},
  file = {:/literature/RegressionTesting/maintinance support for object oriented programs.pdf:PDF},
  issn = {0098-5589},
  issue = {12},
  keywords = {dependencies in OO programs, interesting for RT.},
  numpages = {7},
  owner = {Annie},
  publisher = {IEEE Press},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=147665.147667}
}

@ARTICLE{Wilde1993,
  author = {Wilde, N. and Matthews, P. and Huitt, R.},
  title = {Maintaining object-oriented software},
  journal = {Software, IEEE},
  year = {1993},
  volume = {10},
  pages = {75 -80},
  number = {1},
  month = {jan},
  __markedentry = {[qurat:]},
  doi = {10.1109/52.207232},
  file = {:/literature/RegressionTesting/maintaining object oriented software.pdf:PDF},
  issn = {0740-7459},
  keywords = {code based, cooperating object classes;dynamic binding;object-oriented
	software maintenance;polymorphism;object-oriented programming;software
	maintenance;},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@INPROCEEDINGS{Wilkerson2012,
  author = {Wilkerson, Jerod W.},
  title = {A Software Change Impact Analysis Taxonomy},
  booktitle = {Proceedings of the 28th IEEE International Conference on Software
	Maintenance},
  year = {2012},
  address = {Riva del Garda, Trento, Italy},
  month = {September},
  file = {:./literature/Paper_250.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.08.15}
}

@ARTICLE{Williams2009,
  author = {Williams, Byron J. and Carver, Jeffrey C.},
  title = {Characterizing Software Architecture Changes: A Systematic Review},
  journal = {Information and Software Technology},
  year = {2009},
  volume = {52},
  pages = {31-51},
  number = {1},
  month = {July},
  booktitle = {Information and Software Technology},
  file = {:./literature/Paper_55.pdf:PDF},
  owner = {Steffen},
  publisher = {Elsevier B.V.},
  review = {Problem:
	
	
	Research Questions:
	
	
	Contribution:
	
	
	Solution:
	
	
	Open Issues:},
  timestamp = {2011.02.10}
}

@ARTICLE{Williams1999,
  author = {Williams, T.M.},
  title = {The need for new paradigms for complex projects},
  journal = {International Journal of Project Management},
  year = {1999},
  volume = {17},
  pages = {269--273},
  number = {5},
  file = {Williams1999.pdf:literature/Williams1999.pdf:PDF},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.17}
}

@INCOLLECTION{springerlink:10.1007/978-3-540-73031-6_17,
  author = {Winkler, Stefan},
  title = {Information Flow Between Requirement Artifacts. Results of an Empirical
	Study},
  booktitle = {Requirements Engineering: Foundation for Software Quality},
  publisher = {Springer Berlin / Heidelberg},
  year = {2007},
  editor = {Sawyer, Pete and Paech, Barbara and Heymans, Patrick},
  volume = {4542},
  series = {Lecture Notes in Computer Science},
  pages = {232-246},
  note = {10.1007/978-3-540-73031-6_17},
  abstract = {Requirements engineering is still an area of software engineering
	in which theory and practice greatly differ. This work presents the
	results of an empirical study of artifacts created and used in the
	requirements engineering process. We discover that meeting notes
	and lists of requirements are most commonly used, that they usually
	play the role of information sources, and that specification documents
	are information sinks. Furthermore we show that most projects create
	several different artifacts. Finally we find out that despite the
	quality risks, inconsistencies between artifacts are often accepted.},
  affiliation = {FernUniversität in Hagen, 58084 Hagen Germany Germany},
  file = {:./literature/InfFlow.pdf:PDF},
  isbn = {978-3-540-73030-9},
  keyword = {Computer Science},
  owner = {elkeb},
  timestamp = {2012.01.31},
  url = {http://dx.doi.org/10.1007/978-3-540-73031-6_17}
}

@ARTICLE{Winkler2010,
  author = {Stefan Winkler and Jens von Pilgrim},
  title = {A survey of traceability in requirements engineering and model-driven
	development},
  journal = {Software and Systems Modeling},
  year = {2010},
  volume = {9},
  pages = {529-565},
  number = {4},
  __markedentry = {[Steffen:]},
  abstract = {Traceability---the ability to follow the life of software artifacts---is
	a topic of great interest to software developers in general, and
	to requirements engineers and model-driven developers in particular.
	This article aims to bring those stakeholders together by providing
	an overview of the current state of traceability research and practice
	in both areas. As part of an extensive literature survey, we identify
	commonalities and differences in these areas and uncover several
	unresolved challenges which affect both domains. A good common foundation
	for further advances regarding these challenges appears to be a combination
	of the formal basis and the automated recording opportunities of
	MDD on the one hand, and the more holistic view of traceability in
	the requirements engineering domain on the other hand.},
  affiliation = {FernUniversität in Hagen, 58084 Hagen, Germany},
  doi = {10.1007/s10270-009-0145-0},
  file = {:./literature/Winkler2009.pdf:PDF},
  keywords = {traceability, survey, requirements engineering, model-driven development,
	model-driven engineering},
  owner = {Stephan},
  publisher = {Springer Berlin / Heidelberg},
  review = {recent comprehensive survey of existing traceability approaches
	
	
	also states some challenges
	
	
	Elke},
  timestamp = {2010.08.05}
}

@INPROCEEDINGS{Winter1998,
  author = {Mario Winter},
  title = {Managing Object-Oriented Integration and Regression Testing
	
	(without becoming drowned)},
  year = {1998},
  editor = {Eurostar},
  file = {:/literature/RegressionTesting/managing object oriented integration and regression testing.pdf:PDF},
  keywords = {model based},
  owner = {Annie},
  timestamp = {2011.01.04}
}

@ARTICLE{Winter2006,
  author = {Winter, M. and Smith, C. and Morris, P. and Cicmil, S.},
  title = {Directions for future research in project management: the main findings
	of a UK government-funded research network},
  journal = {International journal of project management},
  year = {2006},
  volume = {24},
  pages = {638--649},
  number = {8},
  owner = {patrickr},
  publisher = {Elsevier},
  timestamp = {2012.10.24}
}

@INPROCEEDINGS{Winter2007,
  author = {Sebastian Winter and Stefan Wagner and Florian Deissenboeck},
  title = {A Comprehensive Model of Usability},
  booktitle = {Proceedings of Engineering Interactive Systems},
  year = {2007},
  series = {LNCS},
  publisher = {Springer},
  abstract = {Usability is a key quality attribute of successful software systems.
	Unfortunately, there is no common understanding of the factors influencing
	usability and their interrelations. Hence, the lack of a comprehensive
	basis for designing, analyzing, and improving user interfaces. This
	paper proposes a 2-dimensional model of usability that associates
	system properties with the activities carried out by the user. By
	separating activities and properties, sound quality criteria can
	be identified, thus facilitating statements concerning their interdependencies.
	This model is based on a tested quality meta-model that fosters preciseness
	and completeness. A case study demonstrates the manner by which such
	a model aids in revealing contradictions and omissions in existing
	usability standards. Furthermore, the model serves as a central and
	structured knowledge base for the entire quality assurance process,
	e.g. the automatic generation of guideline documents.},
  file = {:./literature/2007_winters_usability.pdf:PDF},
  keywords = {usability, quality models, quality assessment},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://www4.in.tum.de/~winterse/publikationen/2007_winters_usability.pdf}
}

@INPROCEEDINGS{Wissink2006,
  author = {Wissink, T. and Amaro, C.},
  title = {Successful Test Automation for Software Maintenance},
  booktitle = {Software Maintenance, 2006. ICSM '06. 22nd IEEE International Conference
	on},
  year = {2006},
  pages = {265 -266},
  month = {sept.},
  doi = {10.1109/ICSM.2006.63},
  file = {:/literature/RegressionTesting/Successful Test Automation for Software Maintenance.pdf:PDF},
  issn = {1063-6773},
  keywords = {Not Relevant},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@INPROCEEDINGS{Wloka2009,
  author = {J. Wloka and B.G. Ryder and F. Tip},
  title = {JUnitMX - A change-aware unit testing tool},
  booktitle = {Software Engineering, 2009. ICSE 2009. IEEE 31st International Conference
	on},
  year = {2009},
  pages = {567--570},
  abstract = {Developers use unit testing to improve the quality of software systems.
	Current development tools for unit testing help with automating test
	execution, with reporting results, and with generating test stubs.
	However, they offer no aid for designing tests aimed specifically
	at exercising the effects of changes to a program. This paper describes
	a unit testing tool that leverages a change model to assist developers
	in the creation of new unit tests. The tool provides developers with
	quantitative feedback and detailed information about change effects,
	which not only facilitate the writing of more effective tests, but
	also motivate developers with an achievable coverage goal.},
  doi = {10.1109/ICSE.2009.5070557},
  file = {:/literature/RegressionTesting/JUnitMXâ€” A Change-aware Unit Testing Tool.pdf:PDF},
  isbn = {0270-5257},
  keywords = {{JUnitMX-change-aware} unit testing tool, program change, program
	testing, software maintenance, software quality, software system
	quality improvement, software tools, test execution automation, test
	stub generation},
  owner = {Annie},
  timestamp = {2011.01.04}
}

@PHDTHESIS{Wohlfarth2008,
  author = {Sven Wohlfarth},
  title = {A Process of Rational Decision-Making for Architectural Decisions
	(in German: Entwicklung eines rationalen Entscheidungsprozesses f\"{u}r
	Architekturentscheidungen)},
  school = {TU Ilmenau},
  year = {2008},
  abstract = {In Softwareentwicklungsprozessen müssen permanent die richtigen Design-
	und Architekturentscheidungen getroffen werden, damit die mit dem
	Entwicklungs- oder Reengineeringprojekt verbundenen Ziele in vollem
	Umfang erfüllt werden können. Diese Entscheidungen können dabei von
	unterschiedlicher Natur sein. So werden einerseits Entscheidungen
	getroffen, die nur geringe Auswirkungen auf das Softwaresystem haben.
	Auf der anderen Seite existieren Entscheidungen mit strategischem
	Charakter, die sich auf große Teile der Architektur und auf zentrale
	Systemeigenschaften auswirken. Gerade die strategischen Architekturentscheidungen
	sind in Großprojekten mit 50 oder mehr Entwicklern von hoher kombinatorischer
	Komplexität und beinhalten große Unsicherheiten über versteckte Abhängigkeiten.
	Der Entscheidungsträger, meist der Architekt oder der Projektleiter,
	ist mit einer Vielzahl unterschiedlicher Faktoren und Bedingungen
	konfrontiert. Hierzu zählen konkurrierende Ziele oder alternative
	Lösungsansätze, für die meist nur unvollständige Informationen vorliegen.
	Unter diesen Voraussetzungen führen unsystematische Entscheidungen
	zu unkalkulierbaren Risiken mit gravierenden Folgen für das Softwaresystem
	und das Entwicklungsprojekt, wie z. B. eine deutliche Erhöhung der
	Entwicklungskosten oder zeitliche Verzögerungen. Die bereits existierenden
	Methoden zur Entscheidungsunterstützung berücksichtigen die spezifischen
	Eigenschaften von Softwarearchitekturen zu wenig. Sie sind zu feingranular,
	codeorientiert und benötigen Informationen in einer formalen Genauigkeit
	und Vollständigkeit, die bei Architekturentscheidungen in Großprojekten
	aus Aufwandsgründen nicht erhoben werden können. Somit fehlt eine
	Unterstützung des Entscheidungsträgers, um die Vielzahl an Einzelinformationen
	und subjektiven Einschätzungen zu strukturieren sowie die Entscheidungsfindung
	systematisch und fokussiert durchzuführen. Mit der vorliegenden Dissertation
	wird das Ziel verfolgt, die Komplexität, Unsicherheiten und Risiken
	bei Architekturentscheidungen zu reduzieren, um aufwandsintensive
	Korrekturen zu vermeiden und die Architekturziele in vollem Umfang
	zu erfüllen. Auf der Grundlage des in der Entscheidungstheorie beschriebenen
	generischen Vorgehens zur Entscheidungsfindung wird ein Vier-Phasen-Entscheidungsprozess
	entwickelt. Dieser Prozess beinhaltet Methoden und Konzepte, um ausgehend
	von den Zielen, Rahmenbedingungen und der existierenden Architektur
	systematisch alternative Lösungsansätze zu entwickeln. Im Anschluss
	werden die Lösungsansätze nach rationalen Gesichtspunkten im Hinblick
	auf die Zielerreichung bewertet, um eine ausgewogene Entscheidung
	zu treffen. Der entwickelte Entscheidungsprozess berücksichtigt dabei
	die speziellen Eigenschaften von Softwarearchitekturen: Trotz unvollständiger
	Informationen und Unsicherheiten können versteckte Abhängigkeiten
	mit einem szenariobasierten Analyse- und Bewertungsansatz, auf der
	Grundlage der Architecture-Level-Modifiability-Analysis (ALMA), sichtbar
	gemacht werden. Die systematische Aufteilung komplexer Entscheidungen
	in handhabbare Einzelentscheidungen wird durch die Anwendung eines
	gestuften Verfahrens mit Grob- und Feinplanung erreicht.Um ein ökonomisch
	sinnvolles Verhältnis zwischen dem Aufwand zur Entscheidungsfindung
	und dem Nutzen in Form von reduzierten Risiken, Unsicherheiten und
	einer geringeren Komplexität zu ermöglichen, kann die Detailtiefe
	der Analysen anhand eindeutiger Kriterien flexibel angepasst werden.Zwei
	praktische prototypische Anwendungen des Entscheidungsprozesses zeigen
	auf, wie eine Architekturentscheidung systematisch und nach rationalen
	Gesichtspunkten durchgeführt werden kann. Die während der Entscheidungsfindung
	getroffenen Annahmen und Erwartungen werden im Anschluss mit den
	Ergebnissen der realen Implementierung verglichen. Anhand des Vergleichs
	wird klar erkennbar, welche versteckten Abhängigkeiten durch den
	Einsatz des Entscheidungsprozesses bereits frühzeitig erkannt wurden
	sowie welche Vorteile die richtige Entscheidungsfindung für das Softwaresystem
	und das Entwicklungsprojekt hat.},
  file = {:./literature/Wohlfarth2008.pdf:PDF},
  owner = {Stephan},
  timestamp = {2010.04.08},
  url = {http://www.db-thueringen.de/servlets/DerivateServlet/Derivate-16664/ilm1-2008000177.pdf}
}

@ARTICLE{Wohlin2003,
  author = {Wohlin, C. and H{\"o}st, M. and Henningsson, K.},
  title = {Empirical research methods in software engineering},
  journal = {Empirical Methods and Studies in Software Engineering},
  year = {2003},
  pages = {7--23},
  file = {:./literature/wohlin_fulltext.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.11.14}
}

@BOOK{Wohlin2000,
  title = {Experimentation in software engineering: an introduction},
  publisher = {Kluver Academic},
  year = {2000},
  author = {Wohlin, C. and Runeson, P. and Host, M. and Ohlsson, C. and Regnell,
	B. and Wessl{\'e}n, A.},
  owner = {patrickr},
  timestamp = {2012.11.14}
}

@TECHREPORT{Wojcik2006,
  author = {Rob Wojcik and Felix Bachmann and Len Bass and Paul Clements and
	Paulo Merson and Robert Nord and Bill Wood},
  title = {{Attribute-Driven Design (ADD), Version 2.0}},
  institution = {CMU/SEI},
  year = {2006},
  number = {CMU/SEI-2006-TR-023},
  month = {Nov},
  abstract = {This report revises the Attribute-Driven Design (ADD) method that
	was developed by the Carnegie Mellon Software Engineering Institute.
	The motivation for revising ADD came from practitioners who use the
	method and want ADD to be easier to learn, understand, and apply.
	
	The ADD method is an approach to defining a software architecture
	in which the design process is based on the software quality attribute
	requirements. ADD follows a recursive process that decomposes a system
	or system element by applying architectural tactics and patterns
	that satisfy its driving quality attribute requirements.
	
	This technical report revises the steps of ADD and offers practical
	guidelines for carrying out each step. In addition, important design
	decisions that should be considered at each step are provided.},
  file = {:./literature/Wojcik2006.pdf:PDF},
  keywords = {attribute-driven design, ADD},
  owner = {Stephan},
  timestamp = {2010.11.17},
  url = {http://www.sei.cmu.edu/reports/06tr023.pdf}
}

@ARTICLE{Wolff2006,
  author = {Wolff, Manfred and Albrecht, Michael and Gutsche, Fabian},
  title = {Test {D}riven {D}evelopment},
  journal = {JavaSpektrum},
  year = {2006},
  volume = {06},
  pages = {36-39},
  file = {:./literature/TDD.pdf:PDF},
  keywords = {test driven development},
  language = {german},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://www.manfred-wolff.de/data/TDD.pdf}
}

@ARTICLE{Wolter2007,
  author = {Wolter, C. and Schaad, A.},
  title = {Modeling of task-based authorization constraints in BPMN},
  journal = {Business Process Management},
  year = {2007},
  pages = {64--79},
  file = {Wolter2007.pdf:literature/Wolter2007.pdf:PDF},
  owner = {patrickr},
  publisher = {Springer},
  timestamp = {2012.11.30}
}

@INPROCEEDINGS{Wong2009,
  author = {Wong, Sunny and Cai, Yuanfang},
  title = {Predicting Change Impact from Logical Models},
  booktitle = {Proceedings of the IEEE International Conference on Software Maintenance
	(ICSM '09)},
  year = {2009},
  pages = {467-470},
  address = {Edmonton, AB, Canada},
  month = {September},
  file = {:./literature/Paper_19.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- frequent changes tend to introduce new bugs and side effect
	
	- understand scope of change impact to prevent this
	
	- approaches trying to solve this with historical data cannot cope
	with lack of information or inconsitencies between them
	
	
	Research Questions:
	
	- improve prediction of the impact scope of changes
	
	
	Contribution:
	
	- extract logical model from UML models and combine it with (if available)
	historical information (i.e. version data)
	
	
	Solution:
	
	- approaches based on augmented constraint network (ACN) [ACN models
	design decisions and their relations; variables model decisions;
	logical constraints model relations]
	
	- derive assumed relations from UML models to perform IA in combination
	with version history
	
	- supports classes, interfaces and relations between them
	
	- enhance each ACN with a dominace relation, e.g. stating that a class
	implementation cannot change the interface the class implements
	
	- ranking of impacted classes by assigned weights (the more sub-ACNs,
	the higher the rank; distance between source/target influence the
	weight, the closer, the higher the rank)
	
	- report 10 highest ranked elements to the user [why 10?]
	
	- combine with mining the version history: multiply weight with ration
	gained from version mining:
	
	* probalistic + history mining
	
	-> granularity of entities: UML class
	
	-> granularity of changes: no details
	
	-> granularity of results: UML class
	
	
	Open Issues:
	
	- convert heterogenous artifacts into ACN (not just classes)
	
	- max. precision of 29% revealed by evaluation and max. 56% recall},
  timestamp = {2011.01.07}
}

@TECHREPORT{Wong2011,
  author = {Wong, Sunny and Cai, Yuanfang and Dalton, Michael},
  title = {Change Impact Analysis with Stochastic Dependencies},
  institution = {Drexel University Philadelphia, PA, USA},
  year = {2011},
  booktitle = {33rd International Conference on Software Engineering (ICSE), to
	appear},
  file = {:./literature/Paper_22.pdf:PDF},
  journal = {33rd International Conference on Software Engineering
	
	(ICSE)},
  owner = {Steffen},
  review = {Problem:
	
	- current approaches that perform IA on logical couplings stored in
	version history, do not consider temporal dimension of the history
	
	
	Research Questions:
	
	- what timespan of a history must be taken into account to perform
	solid IA
	
	
	Contribution:
	
	- formalization of logical couplings as stochastic processes using
	Markov chains
	
	- define families of stochastical dependencies on perform IA on them
	(each family weights history datas differently)
	
	
	Solution:
	
	- compute probability that two components are dependent through Markow
	chains
	
	- reason about stochastic dependencies whether an element will be
	impacted or not
	
	- use thresholds to filter related elements to get the "most related
	ones" etc.
	
	* history based + probabilities
	
	-> granularity of entities: no details
	
	-> granularity of changes: change sets from version control systems
	
	-> granularity of results: no details
	
	
	Open Issues:
	
	- bad results when applied on projects with "stable" history (i.e.
	history that remains valid for a long time)
	
	- cannot cope with bulk-updates (i.e. no history/SVN update for each
	little fix, instead collect changes and submit them together)
	
	- bad performance in contrast to other IA},
  timestamp = {2011.01.10}
}

@INPROCEEDINGS{Wong1997,
  author = {Wong, W. Eric and Horgan, Joseph R. and London, Saul and Bellcore,
	Hira Agrawal},
  title = {A Study of Effective Regression Testing in Practice},
  booktitle = {Proceedings of the Eighth International Symposium on Software Reliability
	Engineering},
  year = {1997},
  series = {ISSRE '97},
  pages = {264--},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[qurat:]},
  acmid = {856115},
  file = {:/literature/RegressionTesting/Study of Effective Regression Testing in Practice.pdf:PDF},
  isbn = {0-8186-8120-9},
  keywords = {code based, Regression Testing, Modification-Based Test Selection,
	Test Set Minimization, Test Set Prioritization},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=851010.856115}
}

@TECHREPORT{Wood2007,
  author = {William G. Wood},
  title = {{A Practical Example of Applying Attribute-Driven Design (ADD), Version
	2.0}},
  institution = {CMU/SEI},
  year = {2007},
  number = {CMU/SEI-2007-TR-005},
  month = {Feb.},
  abstract = {This report describes an example application of the Attribute-Driven
	Design (ADD) method developed by the Carnegie Mellon® Software Engineering
	Institute. The ADD method is an approach to defining a software architecture
	in which the design process is based on the quality attribute requirements
	the software must fulfill. ADD follows a recursive process that decomposes
	a system or system element by applying architectural tactics and
	patterns that satisfy its driving quality attribute requirements.
	
	The example in this report shows a practical application of the ADD
	method to a client-server system. In particular, this example focuses
	on selecting patterns to satisfy typical availability requirements
	for fault tolerance. The design concerns and patterns presented in
	this report---as well as the models used to determine whether the
	architecture satisfies the architectural drivers---can be applied
	in general to include fault tolerance in a system. Most of the reasoning
	used throughout the design process is pragmatic and models how an
	experienced architect works.},
  file = {:./literature/Wood2007.pdf:PDF},
  keywords = {ADD, example, software architectur design method},
  owner = {Stephan},
  timestamp = {2011.01.11}
}

@INPROCEEDINGS{Wu1999a,
  author = {Ye Wu and Mei-Hwa Chen and Kao, H.M.},
  title = {Regression testing on object-oriented programs},
  booktitle = {Software Reliability Engineering, 1999. Proceedings. 10th International
	Symposium on},
  year = {1999},
  pages = {270 -279},
  __markedentry = {[qurat:]},
  doi = {10.1109/ISSRE.1999.809332},
  file = {:/literature/RegressionTesting/Regression testing on OO Programs.pdf:PDF},
  keywords = {code based, empirical study;function-calling sequences;modified software;object-oriented
	programs;program structure;regression testing;software quality;specifications;static
	information;test cases;object-oriented programming;program testing;program
	verification; Read; Rel},
  owner = {Annie},
  timestamp = {2011.10.20}
}

@INPROCEEDINGS{Wu1999,
  author = {Wu, Ye and Chen, Mei-Hwa and Kao, Howard M.},
  title = {Regression Testing on Object-Oriented Programs},
  booktitle = {Proceedings of the 10th International Symposium on Software Reliability
	Engineering},
  year = {1999},
  series = {ISSRE '99},
  pages = {270--},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[qurat:]},
  acmid = {856186},
  file = {:/literature/RegressionTesting/Regression Testing on Object-Oriented Programs.pdf:PDF},
  isbn = {0-7695-0443-4},
  keywords = {Read, Relevant, code baseds},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=851020.856186}
}

@INPROCEEDINGS{Wu2003,
  author = {Ye Wu and Jeff Offutt},
  title = {Maintaining Evolving Component-Based Software with UML},
  booktitle = {Proceedings of the Seventh European Conference on Software Maintenance
	and Reengineering},
  year = {2003},
  pages = {133},
  publisher = {{IEEE} Computer Society},
  abstract = {Component-based software engineering is increasingly being adopted
	for software {development.This} approach relies on using reusable
	components as the building blocks for contructing {software.On} the
	one hand, this helps improve software quality and productivity; on
	the other hand, it necessitates frequent maintenance activities.the
	cost of maintenance for conventional software can account for as
	much as two-thirds of the toal cost, and it is likely to be more
	for component-based {software.This} paper presents a {UML-based}
	technique that attempts to help resolve difficulties introduced by
	the implementation transparent characteristics of component-based
	software {systems.This} technique can also be useful for other maintenance
	{activities.For} corrective maintenance activities, the technique
	starts with {UML} diagrams that represent changes to a component,
	and uses them to support regression {testing.To} accommodate this
	approach for perfective maintenance activities, more challenges are
	{encountered.We} provide a {UML-based} framework to evaluate the
	similarities of the old andnew components, and corresponding retesting
	strategies are provided.},
  file = {:/literature/RegressionTesting/maintaing evolving component based software with uml.pdf:PDF},
  isbn = {0-7695-1902-4},
  keywords = {component-based software, modeling language (uml), program analysis,
	software maintenance, unified},
  owner = {Annie},
  review = {Case study: small example},
  timestamp = {2011.01.04},
  url = {http://portal.acm.org/citation.cfm?id=872754.873603&coll=GUIDE&dl=GUIDE&CFID=54491404&CFTOKEN=93053143}
}

@INPROCEEDINGS{Xia2004,
  author = {Xia, Franck and Srikanth, Praveen},
  title = {A Change Impact Dependency Measure for Predicting the Maintainability
	of Source Code},
  booktitle = {Proceedings of the 28th Annual International Computer Software and
	Applications Conference (COMPSAC '04)},
  year = {2004},
  volume = {2},
  pages = {22-23},
  month = {September},
  file = {:./literature/Paper_99.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- maintenance much more expensive then development of software
	
	- maintenance relies on skills of involved developers, relies on subjective
	and vague factors which are hard to measure
	
	
	Research Questions:
	
	- how to measure internal software artifacts and relfect on external
	view of maintainability
	
	- when changing a statement, what other statements are affected
	
	
	Contribution:
	
	- new measure defined in paper: change impact dependency
	
	- new measure relying purely on internal and objective attributes
	of source code
	
	- provide a theoretical model for software maintainability
	
	
	Solution:
	
	- investigate source code at granularity of methods
	
	- trace changes through method calls
	
	- take into account that not all traced LOC are really impacted (they
	provided a formula computing this)
	
	- limit the traceing to two levels of ripple-effects
	
	-> granularity of entities: statements
	
	-> granularity of changes: atomic changes to classes and variables
	
	-> granularity of results: statements
	
	
	Open Issues:
	
	- number for limit tracing gained from only 2 open source algorithms
	/ programs, likely different number for larger / other systems},
  timestamp = {2011.02.24}
}

@ARTICLE{Xia2004a,
  author = {Xia, W. and Lee, G.},
  title = {Grasping the complexity of IS development projects},
  journal = {Communications of the ACM},
  year = {2004},
  volume = {47},
  pages = {68--74},
  number = {5},
  file = {Xia2004a.pdf:literature/Xia2004a.pdf:PDF},
  keywords = {Project complexity},
  owner = {patrickr},
  publisher = {ACM},
  timestamp = {2012.10.17}
}

@INPROCEEDINGS{Xiao2007,
  author = {Xiao, Hua and Guo, Jin and Zou, Ying},
  title = {Supporting Change Impact Analysis for Service Oriented Business Applications},
  booktitle = {Proceedings of the International Workshop on Systems Development
	in SOA Environments (SDSOA '07)},
  year = {2007},
  pages = {6-11},
  file = {:./literature/Paper_124.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- business process languages used to model processes
	
	- changes in business processes must be performed on code as well
	
	- assess impact and cost of business process change not trivial
	
	
	Research Questions:
	
	- how to estimate the costs and impacts of an business process change
	to the underlying software
	
	
	Contribution:
	
	- approach for estimating cost of business process change
	
	- approach relies on metric for estimation
	
	- manage can use metric to evaluate change before doing business process
	change
	
	
	Solution:
	
	- generate SIS from business processes
	
	* use data and control dependencies between BPEL elements
	
	- map SIS to corresponding source code entities
	
	- perform dependency-based IA on these code entities (e.g. inheritance,
	call-relations etc.)
	
	* generate propagation graph for each entity
	
	* use inheritance-relations to propagate changes in methods to other
	methods in the inheritance hierarchy
	
	* use call-graph to store method calls
	
	- calculate the overall impact and cost, using a metric
	
	* calculate distance between changed entity and EIS-entity
	
	* if one method appears in several propagation graphs, always use
	the shortest distance
	
	-> granularity of entities: BPEL tasks
	
	-> granularity of changes: add, remove, modify of BPEL tasks
	
	-> granularity of results: methods
	
	
	Open Issues:
	
	- enhance metric to filter out irrelevant methods},
  timestamp = {2011.04.01}
}

@INPROCEEDINGS{Xie02macroand,
  author = {Tao Xie and David Notkin},
  title = {Macro and Micro Perspectives on Strategic Software Quality Assurance
	in Resource Constrained Environments},
  booktitle = {In EDSER-4},
  year = {2002},
  file = {:/literature/RegressionTesting/macro and micro perspective.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.03.01}
}

@INPROCEEDINGS{Xing2006,
  author = {Xing, Zhenchang and Stroulia, Eleni},
  title = {Refactoring Detection based on UMLDiff Change-Facts Queries},
  booktitle = {Proceedings of the 13th Working Conference on Reverse Engineering},
  year = {2006},
  pages = {263--274},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid = {1174736},
  doi = {10.1109/WCRE.2006.48},
  file = {:/literature/changeIdentification/Refactoring Detection based on UMLDiff Change-Facts Queries.pdf:PDF},
  isbn = {0-7695-2719-1},
  keywords = {Re},
  numpages = {12},
  owner = {Steffen},
  review = {Changes
	
	
	+Subsystem & package
	
	• Added, removed, renamed, or moved
	
	+Class & interface
	
	• Added, removed, renamed, or
	
	moved
	
	• Generalization change of class and interface, and no-longer or new
	interface implementation of class
	
	• No-longer or new outgoing and incoming usage dependencies
	
	• Visibility, modifier, deprecationstatus change
	
	+Method & constructor
	
	• Added, removed, renamed, moved, extracted, or inlined
	
	• Parameter added, removed; parameter type changed; parameterorder
	changed
	
	• No-longer or new outgoing field read/write, method call, class instantiation;
	no-longer or new incoming call
	
	• No-longer or new declared, thrown, and caught exception
	
	• Return type change
	
	• Visibility, modifier, deprecationstatus change
	
	+Field 
	
	• Added, removed, renamed, or moved
	
	• No-longer or new read-by and written-by dependencies
	
	• Data type change
	
	• Visibility, modifier, deprecationstatus change},
  timestamp = {2012.03.01},
  url = {http://dl.acm.org/citation.cfm?id=1174510.1174736}
}

@INPROCEEDINGS{Xing2005,
  author = {Xing, Zhenchang and Stroulia, Eleni},
  title = {{UMLDiff}: An Algorithm for Object-Oriented Design Differencing},
  booktitle = {Proceedings of the 20th IEEE/ACM international Conference on Automated
	software engineering (ASE '05)},
  year = {2005},
  pages = {54-65},
  address = {Long Beach, California, USA},
  month = {November},
  file = {:./literature/Paper_76.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- it is crucial to understand evolution of software entities in evolutionary
	development
	
	- current diff-tools focus on "line-diff" and change deltas from CVS,
	not useful for structured models
	
	- they ignore high-level structural data
	
	
	Research Questions:
	
	- help developers to reason about changes on the design level
	
	
	Contribution:
	
	- UMLDiff approach for detecting structural changes between two subsequent
	versions of several UML-models
	
	- changes presented as tree containing add/remove/move/etc. operations
	(structural changes)
	
	
	Solution:
	
	- use a data-metamodel which is similar to UMLs static-structure model
	(a graph; nodes = classes, interfaces etc.; edges = relationships)
	
	- use a fact extractor to extract this information from source code
	and map it to structural models
	
	- UMLDiff traverses the graphs of two compared models by moving from
	one logical level to another in both graphs simultaneously
	
	* starts at root-node and traverses down to method/attribute-level
	
	* entities are considered to be the same when they share the same
	name and / or same relations to other entities
	
	 - name similarity (how similar are the names of two entities)
	
	 - structure similarity (how similar are two sets of entities/relationships)
	
	 - use a user-defined threshold to determine whether two entities
	are the same
	
	* UMLDif uses entities with same name as "landmarks" to further search
	for renamed/moved entities
	
	- it is able to detect moved entities
	
	 * however, moving of abstract methods not detected
	
	- UMLDiff reports changes according to taxonomy of changes in terms
	of type, affected entities etc.
	
	- UMLDiff is able to detect changes in relationships of type inheritance,
	usage and field/method return types
	
	- UMLDiff detects changes in attributes of entities (visibility, e.g.
	public as well as move, rename, add, delete)
	
	-> granularity of entities: UML classes
	
	-> granularity of changes: atomic changes to UML diagrams
	
	-> granularity of results: UML classes
	
	
	Open Issues:
	
	- accuracy of UMLDiff suffers from large/complex set of changes (bulk-update)
	
	- due to the concept of using landmarks (same name, same class): if
	such an entity is removed an a new one with same name/class but different
	"interna" added, they are still considered to be "the same"
	
	- renaming can only be resolved within the context of two general-matched
	entites, i.e. renaming a function inside a class can be detected,
	but not renaming of a class which is a "root"-class
	
	- moving does not work for abstract methods},
  timestamp = {2011.02.19}
}

@INPROCEEDINGS{Xing2004a,
  author = {Xing, Zhenchang and Stroulia, Eleni},
  title = {Data-mining in Support of Detecting Class Co-evolution},
  booktitle = {Proceedings of the 16th International Conference on Software Engineering
	\& Knowledge Engineering (SEKE'04)},
  year = {2004},
  pages = {123-128},
  month = {June},
  file = {:./literature/Paper_65.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- many non-trivial relationships between UML classes in long evolving
	systems, which are not expressed in source code
	
	- co-evolutions of UML classes often not obvious, but "hidden" in
	history data (e.g. from CVS)
	
	
	Research Questions:
	
	- how to recover / detect co-evolutions of UML classes from development
	history (i.e. several revisions of UML classes)
	
	- what is the benefit of recovering co-evolutions and lost dependencies
	between UML classes
	
	
	Contribution:
	
	- reover lost knowledge (co-evolution of UML classes) through data
	mining
	
	- recover design-level changes of UML classes from history data
	
	
	Solution:
	
	- use a database of UML class evolution histories
	
	- use UMLDiff to gather differences between single revisions
	
	- apply Apriori-algorithm on database to gather association rules
	
	- use statistical correlation between occurences of certain items
	
	-> granularity of entities: UML classes
	
	-> granularity of changes: atomic changes to UML diagrams
	
	-> granularity of results: UML classes
	
	
	Open Issues:
	
	- creating a more specific notion of co-evolution in terms of specific
	modifications},
  timestamp = {2011.02.16}
}

@INPROCEEDINGS{Xing2004b,
  author = {Xing, Zhenchang and Stroulia, Eleni},
  title = {Understanding Class Evolution in Object-Oriented Software},
  booktitle = {Proceedings of the 12th IEEE International Workshop on Program Comprehension
	(IWPC'04)},
  year = {2004},
  pages = {34-43},
  month = {June},
  file = {:./literature/Paper_66.pdf:PDF},
  owner = {Steffen},
  review = {--> extended version of Xing2004a
	
	
	Problem:
	
	- understand class evolution is essential for understanding the current
	design of the software
	
	- single snapshots are not sufficient enough in evolutionary development
	
	
	Research Questions:
	
	- how to utilize evolution / change information to provide answers
	to maintainers in order to change / understand / maintain software
	
	- reover lost information from systems design (in UML)
	
	
	Contribution:
	
	- taxonomy of class evolution profiles (8 types)
	
	- method for categorizing a class' evolution profile
	
	- approach relying on data mining to detect co-evolutions among classes
	
	- structural Diff-algorithm for UML classes presented
	
	
	Solution:
	
	- UMLDiff is a domain specific tree-diff-algorithm which is aware
	of UML semantics (expressed in XMI)
	
	* parse the input into 2 labeled trees
	
	* identify after-before changes between trees (like "add", "remove")
	
	* results in change-tree
	
	- apply UMLDiff on all snapshots of a system to generate a sequence
	of change trees ("trail of changes")
	
	- analyze this trail to produce class-evolution profiles
	
	* use these profiles to categorize classes into 1 of 8 class evolution
	profiles
	
	 - use a sliding window (lenght defined by user) to check the classes
	evolution characteristic
	
	 - class types are: active classes, idle classes, rocket class (sharp
	increase in size), shrinking classes, die-hard classes, legacy classes,
	volatile classes, short-lived classes
	
	* detect co-evolutions between classes (that have common change behaviour)
	
	 - apply Apriori association rule mining on classes to gather rules
	with a minimum support & confidence (thresholds set by user)
	
	 * support: number of transactions that contain a item
	
	 * confidence: ratio of support between two groups of entities (=
	support(A) / support(B), if this is > threshold, it indicates that
	A & B change together)
	
	-> granularity of entities: UML classes
	
	-> granularity of changes: atomic changes to UML diagrams
	
	-> granularity of results: UML classes
	
	
	Open Issues:
	
	- conduct a real case study (one with a larger system)},
  timestamp = {2011.02.16}
}

@ARTICLE{Xu2007,
  author = {Xu, G. and Feng, Z. and Wu, H. and Zhao, D.},
  title = {Swift trust in a virtual temporary system: A model based on the Dempster-Shafer
	theory of belief functions},
  journal = {International Journal of Electronic Commerce},
  year = {2007},
  volume = {12},
  pages = {93--126},
  number = {1},
  file = {Xu2007.pdf:literature/Xu2007.pdf:PDF},
  owner = {patrickr},
  publisher = {ME Sharpe},
  timestamp = {2012.10.19}
}

@INPROCEEDINGS{Xu2004,
  author = {Xu, Lihua and Dias, Marcio and Richardson, Debra},
  title = {Generating Regression Tests via Model Checking},
  booktitle = {Proceedings of the 28th Annual International Computer Software and
	Applications Conference - Volume 01},
  year = {2004},
  series = {COMPSAC '04},
  pages = {336--341},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[qurat:]},
  acmid = {1025520},
  file = {:/literature/RegressionTesting/Generating Regression Tests via Model Checking.pdf:PDF},
  isbn = {0-7695-2209-2-1},
  keywords = {Software Testing, Regression Testing, Model Checking, Formal Specification,
	textual specification based, state baseds},
  numpages = {6},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=1025117.1025520}
}

@INPROCEEDINGS{Xu2005,
  author = {Lihua Xu and Hadar Ziv and Debra Richardson and Zhixiong Liu},
  title = {Towards modeling non-functional requirements in software architecture},
  booktitle = {Early Aspects 2005: Aspect-Oriented Requirements Engineering and
	Architecture Design Workshop},
  year = {2005},
  address = {Chicago, IL},
  month = {March},
  abstract = {Functional requirements (FRs) capture the intended behavior of the
	system, in terms of the services or tasks the system is required
	to perform, while non-functional requirements (NFRs) are requirements
	that impose restrictions on the product being developed [3]. Despite
	the obvious importance and relevance of non-functional requirements,
	NFRs specified during requirement engineering are almost always left
	to be verified after the implementation is finished, which means
	NFRs are not mapped directly and explicitly from requirements engineering
	to architectural design. This leaves software development with potential
	exacerbation of the age-old problem of requirements errors that are
	not detected until very late in process. Modeling and analyzing NFRs
	in software architectures at least partially overcomes this deficiency.
	
	This position paper introduces our early research, which proposes
	a grouping mechanism, similar to the separation of concerns achieved
	in Aspect-Oriented Programming (AOP), to model NFRs in software architectures
	directly and explicitly. This eventually directs our ultimate research
	goal, which is to verify software architecture with respect to NFRs
	defined in requirements engineering. An example of how we model NFRs
	in software architecture is provided using the canonical KLAX example
	for the C2 architectural style.},
  file = {:./literature/12_XuZivRichardsonLiu_UCIrvineCSFullerton.pdf:PDF},
  keywords = {non-functional requirements},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://trese.cs.utwente.nl/early-aspects-AOSD2005/Papers/12_XuZivRichardsonLiu_UCIrvineCSFullerton.pdf}
}

@INPROCEEDINGS{Xu2005a,
  author = {Xu, P.},
  title = {Knowledge support in software process tailoring},
  booktitle = {System Sciences, 2005. HICSS'05. Proceedings of the 38th Annual Hawaii
	International Conference on},
  year = {2005},
  pages = {87c--87c},
  file = {Xu2005a.pdf:literature/Xu2005a.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@ARTICLE{Xu2008,
  author = {Xu, P. and Ramesh, B.},
  title = {Using process tailoring to manage software development challenges},
  journal = {IT Professional},
  year = {2008},
  volume = {10},
  pages = {39--45},
  number = {4},
  file = {Xu2008.pdf:literature/Xu2008.pdf:PDF},
  owner = {patrickr},
  publisher = {IEEE},
  timestamp = {2012.07.23}
}

@INPROCEEDINGS{Xu2003,
  author = {Xu, P. and Ramesh, B.},
  title = {A tool for the capture and use of process knowledge in process tailoring},
  booktitle = {System Sciences, 2003. Proceedings of the 36th Annual Hawaii International
	Conference on},
  year = {2003},
  pages = {7--pp},
  file = {Xu2003.pdf:literature/Xu2003.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.25}
}

@INPROCEEDINGS{5462461,
  author = {Bo Yang and Ji Wu and Chao Liu and Luo Xu},
  title = {A Regression Testing Method for Composite Web Service},
  booktitle = {Biomedical Engineering and Computer Science (ICBECS), 2010 International
	Conference on},
  year = {2010},
  pages = {1 -4},
  month = {april},
  doi = {10.1109/ICBECS.2010.5462461},
  file = {:/literature/RegressionTesting/05462461.pdf:PDF},
  keywords = {WSRT, SOA-based software;WS testing;composite Web services testing;regression
	testing method;system under testing;Web services;program testing;regression
	analysis;software architecture;},
  owner = {Steffen},
  review = {+The paper discusses nothing about regression testing.
	
	
	
	Test information is in form of test behaviour and test data
	
	+test behaviour = test cases=test steps
	
	
	+ how the test behaviour and test data are generated is not discussed.
	
	
	+the test process is represented by an FSM.
	
	
	+no test generation details are provided. 
	
	
	
	-the overall language and concept explanation is very poor in the
	paper.
	
	
	+a small example of database services is used as a casestudy.},
  timestamp = {2012.03.01}
}

@INPROCEEDINGS{Yau1978,
  author = {Yau, S. S. and Collofello, J. S. and McGregor, T. M.},
  title = {Ripple effect analysis of software maintenance},
  booktitle = {Proceedings Computer Software and Applications Conference (COMPSAC
	'78)},
  year = {1978},
  pages = {60-65},
  publisher = {IEEE Computer Society Press: Piscataway NJ},
  owner = {Steffen},
  timestamp = {2011.09.13}
}

@INPROCEEDINGS{Yazdanshenas2012,
  author = {Yazdanshenas, Amir Reza and Moonen, Leon},
  title = {Fine-Grained Change Impact Analysis for Component-Based Product Families},
  booktitle = {Proceedings of the 28th IEEE International Conference on Software
	Maintenance},
  year = {2012},
  address = {Riva del Garda, Trento, Italy},
  month = {September},
  file = {:./literature/Paper_259.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.08.08}
}

@INPROCEEDINGS{Yie2009,
  author = {Yie, Andres and Casallas, Rubby and Deridder, Dirk and Wagelaar,
	Dennis},
  title = {A practical approach to multi-modeling views composition},
  booktitle = {Proceedings of the 3rd International Workshop on Multi-Paradigm Modeling},
  year = {2009},
  file = {:./literature/Paper_219.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.04.30}
}

@ARTICLE{Ying2004,
  author = {Ying, Annie T.T. and Murphy, Gail C. and Ng, Raymond and Chu-Carroll,
	Mark C.},
  title = {Predicting Source Code Changes by Mining Change History},
  journal = {IEEE Transactions on Software Engineering},
  year = {2004},
  volume = {30},
  pages = {574-586},
  number = {9},
  month = {September},
  booktitle = {IEEE TRANSACTIONS ON SOFTWARE ENGINEERING},
  file = {:./literature/Paper_45.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- modification tasks performed on source which is spread over huge
	code base
	
	- dependencies between source code of different languages difficult
	to determine using trad. IA
	
	
	Research Questions:
	
	- how can change patterns help to improve IA
	
	- how to detect change patterns through data mining of repository
	histories
	
	
	Contribution:
	
	- approach based on mining change patterns among files
	
	- propose possible impacted files based on change patterns
	
	- interestingness criteria for pattern recommendation
	
	
	Solution:
	
	- approach consists of three steps:
	
	* extract data from repository and preprocess it
	
	 + devide data into set of atomic changes
	
	 + skip non-useful changes (e.g. changing comments)
	
	* apply association rule mining algorithm to form change patterns
	
	 + use frequent pattern mining to find recurring 
	
	 + apply FP-tree algorithm for this purpose
	
	* recommend relevant source files by querying against mined patterns
	
	 + patterns are searched for file under consideration (e.g. file A
	is to be changed, therefore search all proposed patterns for occurrence
	of file A)
	
	 + sort relevant files into 3 groups: surprising, neutral and obvious
	
	-> granularity of entities: files
	
	-> granularity of changes: atomic change sets
	
	-> granularity of results: files
	
	
	Open Issues:
	
	- definition of 3 classes of "interestingness" of possible impacts
	might cause problems (i.e. if a file is marked as "obvious", it is
	not reported, however, the developer could still miss it)
	
	- bulk-updates to repository decrease effectiveness of approach
	
	- less effective if only a few revisions available
	
	- approach works on files, could be changed to methods but this would
	weaken the associations},
  timestamp = {2011.02.08}
}

@INPROCEEDINGS{Yoder1997,
  author = {Joseph W. Yoder and Jeffrey Barcalow},
  title = {Architectural Patterns for Enabling Application Security},
  booktitle = {Proceedings 4th Conf. on Patterns Languages of Programs (PLoP '97)},
  year = {1997},
  owner = {Stephan},
  timestamp = {2010.11.18}
}

@INPROCEEDINGS{Yoo2004,
  author = {Yoo, Namho and Choi, Hyeong-Ah},
  title = {An {XML}-Based Approach for Interface Impact Analysis in Sustained
	System},
  booktitle = {Proceedings of the International Conference on Information and Knowledge
	Engineering (IKE'04)},
  year = {2004},
  pages = {161-167},
  address = {Las Vegas, Nevada, USA},
  month = {June},
  file = {:./literature/Paper_89.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- current systems are connected with other software systems
	
	- each system offers a special interface for other systems
	
	- changes to one system or its interface are likely to affect connected
	systems as well
	
	- difficult to estimate changes carried across system borders
	
	= "Interface Impact Analysis"
	
	
	Research Questions:
	
	- how can one assess the impact to a interface of a system in a network
	of connected systems
	
	
	Contribution:
	
	- XML based approach for building a common information architecture
	between connected systems for impact assessment
	
	- approach works for systems which communicate via messages
	
	
	Solution:
	
	- convert each send message into XML format and save to log
	
	- construct a "message graph" for all connected system, i.e. which
	system sends which message to what other system
	
	- use this graph to trace messages that should be changed (or which
	interface sending them should be changed)
	
	- apply filtering algorithm on the message graph to prune paths created
	by other messages
	
	* algorithm uses data dictionary and dependency graph as input
	
	-> granularity of entities: systems
	
	-> granularity of changes: no details
	
	-> granularity of results: systems
	
	
	Open Issues:
	
	- integrate security and performance IA next to trad. "software IA"},
  timestamp = {2011.02.23}
}

@ARTICLE{Yoo2010,
  author = {Yoo, S. and Harman, M.},
  title = {Regression testing minimization, selection and prioritization: a
	survey},
  journal = {Software Testing, Verification and Reliability},
  year = {2010},
  pages = {n/a--n/a},
  __markedentry = {[qurat:]},
  doi = {10.1002/stvr.430},
  file = {:/literature/RegressionTesting/regression_testing_survey_yoo_harman.pdf:PDF},
  issn = {1099-1689},
  keywords = {regression testing, test suite minimization, regression test selection,
	test case prioritization, comparative study},
  owner = {Annie},
  publisher = {John Wiley \& Sons, Ltd.},
  timestamp = {2011.10.20},
  url = {http://dx.doi.org/10.1002/stvr.430}
}

@INPROCEEDINGS{Yoon2001,
  author = {Yoon, I.C. and Min, S.Y. and Bae, D.H.},
  title = {Tailoring and verifying software process},
  booktitle = {Software Engineering Conference, 2001. APSEC 2001. Eighth Asia-Pacific},
  year = {2001},
  pages = {202--209},
  organization = {IEEE},
  file = {Yoon2001.pdf:literature/Yoon2001.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.07.23}
}

@INPROCEEDINGS{Yu,
  author = {Yu, Bo and Mili, Ali and Abdelmoez, W. and Gunnalan, R. and Shereshevsky,
	M. and Ammar, Hany H.},
  title = {Requirements Change Impact In Software Architecture},
  file = {:./literature/Paper_132.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- architectural attributes differ from code attributes
	
	- architecture focused on level of components and interconnections
	
	
	Research Questions:
	
	- how to estimate probability that a change to one architectural component
	causes changes in other arch. components
	
	
	Contribution:
	
	- new approach for requirement change propagation probabilities to
	estimate impact of change to one component on other components
	
	
	Solution:
	
	- arrange requirements change probabilities in a matrix (NxN)
	
	- use this matrix to reason about architecture
	
	* if a row is filled, a change to this component will affect many
	others etc.
	
	* if a row is filled, the component is likely to change often as well
	etc.
	
	- use 3 metrics to predict change propagation
	
	* backward functional call dependency (BD): # of functions other components
	call from this component
	
	* foward functional call dependency (FD): # of functions this components
	call from other components
	
	* total forward and backward functional call dependency (TD): combine
	both BD and FD
	
	* transfer this into 3 matrices (one for each metric)
	
	- distinguish between 3 "dangerousness"-levels of changes
	
	-> granularity of entities: components
	
	-> granularity of changes: no details given
	
	-> granularity of results: components
	
	- basically it's a call-graph build of methods from architectural
	components
	
	
	Open Issues:
	
	- further case studies
	
	- exploit information how stable components and requirements are to
	improve prediction},
  timestamp = {2011.04.04}
}

@PHDTHESIS{Yu1995,
  author = {Eric Siu-Kwong Yu},
  title = {Modelling Strategic Relationships for Process Reengineering},
  school = {University of Toronto, Ontario, Canada},
  year = {1995},
  address = {Toronto, Ont., Canada, Canada},
  note = {Adviser-John Mylopoulos},
  file = {:./literature/DKBS-TR-94-6.pdf:PDF},
  isbn = {0-612-02887-9},
  order_no = {AAINN02887},
  owner = {Stephan},
  publisher = {University of Toronto},
  timestamp = {2009.01.26},
  url = {http://portal.acm.org/citation.cfm?id=922590}
}

@INPROCEEDINGS{Yu2006,
  author = {Liguo Yu and Ramaswamy, S.},
  title = {Software and Biological Evolvability: A Comparison Using Key Properties},
  booktitle = {Second International IEEE Workshop on Software Evolvability, SE '06.},
  year = {2006},
  pages = {82-88},
  month = {Sept. },
  publisher = {IEEE Computer Society},
  abstract = {Biological and software systems share a common property from evolution:
	they need to change and adapt to either a new environment or a new
	requirement. If the environment or requirement changes, those systems
	that have high evolvability will survive and others will be eliminated.
	The evolvability of a biological system has been widely studied and
	shown to be dependent on several properties: self-organization, modularity,
	gene duplication, gene robustness, and symbiosis. This position paper
	discusses the evolvability of a software system with respect to these
	properties. Our study shows that software systems share similar evolvability
	properties with biological systems. We conclude that studying and
	comparing the internal structures as well as the overall evolution
	process of these biological systems can help us understand software
	systems from a holistic 'product-lifecycle' perspective thereby helping
	us develop software systems with better evolvability traits.},
  doi = {10.1109/SOFTWARE-EVOLVABILITY.2006.11},
  file = {:./literature/04032452.pdf:PDF},
  keywords = {evolution (biological), software prototyping, biological system evolvability,
	product-lifecycle perspective, software system evolvability},
  owner = {Stephan},
  review = {discussion of key evolvability properties of biological systems for
	software systems
	
	- self-organization
	
	- modularity
	
	- gene duplication
	
	- gene robustness
	
	- symbiosis
	
	
	self-organization
	
	- if a system has high capability of self-organization, does it also
	have high evolvability?
	
	- the time and effort a system spent on self-organization could be
	ameasure of evolvability
	
	
	modularity and hierarchy organization
	
	-> in biological (based on genotypes) and software systems
	
	
	gene duplication
	
	- in biological systems essential together with modularity
	
	
	gene robustness
	
	- some features of organisms restistant to change
	
	- software product lines -> core assets more stable than custom assets
	
	
	symbiosis
	
	- cooperation important for evolution
	
	-> effective information sharing},
  timestamp = {2008.07.08}
}

@INPROCEEDINGS{Yu2008,
  author = {Yu, Yanbing and Jones, James A. and Harrold, Mary Jean},
  title = {An empirical study of the effects of test-suite reduction on fault
	localization},
  booktitle = {Proceedings of the 30th international conference on Software engineering},
  year = {2008},
  series = {ICSE '08},
  pages = {201--210},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[qurat:]},
  acmid = {1368116},
  doi = {http://doi.acm.org/10.1145/1368088.1368116},
  file = {:/literature/RegressionTesting/An Empirical Study of the Effects of Test-Suite Reduction.pdf:PDF},
  isbn = {978-1-60558-079-1},
  keywords = {empirical study, fault localization, test-suite reduction, COMPARATIVE},
  location = {Leipzig, Germany},
  numpages = {10},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://doi.acm.org/10.1145/1368088.1368116}
}

@INPROCEEDINGS{Yu2003,
  author = {Yijun Yu and John Mylopoulos and Eric Yu and Julio Cesar Leite and
	Linda Lin Liu and Erik D'Hollander},
  title = {Software refactoring guided by multiple soft-goals},
  booktitle = {In Proc. of The First International Workshop on REFactoring: Achievements,
	Challenges, Effects (REFACE 2003)},
  year = {2003},
  pages = {7-11},
  abstract = {Software refactoring is intended to enhance the quality of a software
	by improving its understandability, performance, as wel l as other
	quality attributes. We adopt the model ling framework of [14] in
	order to analyze software qualities, to determine which software
	refactoring transformations are most appropriate. In addition, we
	use software metrics to evaluate software quality quantitatively.
	Our framework adopts and extends work reported in [15].},
  file = {:./literature/YijunYu_NFR_Refactoring.pdf:PDF},
  keywords = {refactoring, softgoal, goal modeling},
  owner = {Stephan},
  timestamp = {2009.02.10},
  url = {http://www.cs.toronto.edu/~yijun/literature/paper/yu03reface.pdf}
}

@INCOLLECTION{Yu2009,
  author = {Yu, Yijun and Niu, Nan and Gonz\'{a}lez-Baixauli, Bruno and Mylopoulos,
	John and Easterbrook, Steve and do Prado Leite, Julio Cesar Sampaio},
  title = {Requirements Engineering and Aspects},
  booktitle = {{Design Requirements Engineering: A Ten-Year Perspective}},
  publisher = {Springer Berlin/Heidelberg},
  year = {2009},
  editor = {Aalst, Will and Mylopoulos, John and Sadeh, Norman M. and Shaw, Michael
	J. and Szyperski, Clemens and Lyytinen, Kalle and Loucopoulos, Pericles
	and Mylopoulos, John and Robinson, Bill},
  volume = {14},
  series = {Lecture Notes in Business Information Processing},
  pages = {432-452},
  abstract = {A fundamental problem with requirements engineering (RE) is to validate
	that a design does satisfy stakeholder requirements. Some requirements
	can be fulfilled locally by designed modules, where others must be
	accommodated globally by multiple modules together. These global
	requirements often crosscut with other local requirements and as
	such lead to scattered concerns. We explore the possibility of borrowing
	concepts from aspect-oriented programming (AOP) to tackle these problems
	in early requirements. In order to validate the design against such
	early aspects, we propose a framework to trace them into coding and
	testing aspects. We demonstrate the approach using an open-source
	e-commerce platform. In the conclusion of this work, we reflect on
	the lessons learnt from the case study on how to fit RE and AOP research
	together.},
  affiliation = {The Open University Department of Computing UK},
  doi = {10.1007/978-3-540-92966-6_24},
  isbn = {978-3-540-92966-6},
  keyword = {Computer Science},
  keywords = {requirements engineering, aspect-orientation},
  owner = {Stephan},
  review = {includes survey on approaches combining GORE approaches with aspect-orientation},
  timestamp = {2010.11.09},
  url = {http://dx.doi.org/10.1007/978-3-540-92966-6_24}
}

@ARTICLE{Zachman1987,
  author = {Zachman, J. A.},
  title = {A framework for information systems architecture},
  journal = {IBM systems journal},
  year = {1987},
  volume = {26},
  pages = {276-292},
  number = {3},
  abstract = {With increasing size and complexity of the implementations of information
	systems, it is necessary to use some logical construct (ora rchitecture)
	for defining and controlling the interfaces and the integration of
	all of the components of the system. This paper defines information
	systems architecture by creating a descriptive framework from disciplines
	quite independent of information systems, then by analogy specifies
	information systems architecture based upon the neutral, objective
	framework. Also, some preliminary conclusions about the implicationso
	f the resultant descriptive framework are drawn. The discussion is
	limited to architecture and does not include a strategic planning
	methodology.},
  file = {:./literature/ibmsj2603E.pdf:PDF;:./literature/zachman_framework.pdf:PDF},
  keywords = {information system, architecture},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {https://www.research.ibm.com/journal/sj/263/ibmsj2603E.pdf}
}

@INPROCEEDINGS{Zaidman2008,
  author = {Zaidman, Andy and Rompaey, Bart Van and Demeyer, Serge and Deursen,
	Arie van},
  title = {Mining Software Repositories to Study Co-Evolution of Production
	\& Test Code},
  booktitle = {Proceedings of the 2008 International Conference on Software Testing,
	Verification, and Validation},
  year = {2008},
  pages = {220--229},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[qurat:]},
  acmid = {1382085},
  doi = {10.1109/ICST.2008.47},
  file = {:/literature/RegressionTesting/Mining Software Repositories to Study Co-Evolution of Production & Test Code.pdf:PDF},
  isbn = {978-0-7695-3127-4},
  keywords = {software testing, software evolution, software co-evolution, mining
	software repositories, software quality, co-evolution of test and
	development code},
  numpages = {10},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dl.acm.org/citation.cfm?id=1381305.1382085}
}

@ARTICLE{Zaidman2011,
  author = {Andy Zaidman and Bart Van Rompaey and Arie van Deursen and Serge
	Demeyer},
  title = {Studying the co-evolution of production and test code in open source
	and industrial developer test processes through repository mining},
  journal = {EMPIRICAL SOFTWARE ENGINEERING},
  year = {2011},
  volume = {16},
  pages = {325-364},
  number = {3},
  file = {:/literature/RegressionTesting/Comparing the co-evolution of production nad test code.pdf:PDF},
  owner = {Steffen},
  timestamp = {2012.03.01}
}

@INPROCEEDINGS{Zalewski2006,
  author = {Zalewski, Marcin and Schupp, Sibylle},
  title = {Change Impact Analysis for Generic Libraries},
  booktitle = {Proceedings of the 22nd IEEE International Conference on Software
	Maintenance (ICSM'06)},
  year = {2006},
  pages = {35-44},
  address = {Philadelphia, Pennsylvania},
  month = {September},
  file = {:./literature/Paper_121.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- libraries are widespread and used by many developers
	
	- changes in a library have huge impact and interface and software
	using the libraries
	
	- changes to one concept in the library can affect many algorithms
	and types
	
	
	Research Questions:
	
	
	Contribution:
	
	- approach to detect impact of changes to conceptual specification
	of generic libraries
	
	- approach based on principle of pipes & filters and utilizes several
	reachability algorithms 
	
	
	Solution:
	
	- proposed approach: conceptual change impact analysis (CCIA)
	
	- analysis based on pipes & filters:
	
	* 1. find changes a conceptual specification is impacted by
	
	* 2. optional filters refine output to detect specific kinds of impact
	
	- provide 2 filter algorithms:
	
	* one to detect impact of change to degree of genericity
	
	* one to detect compatibility to different versions
	
	- apply changes to program and then compute the difference between
	old and new version
	
	* identify added and removed entities ("Diff")
	
	- use dependency graphs build by syntactic analysis of code to propagate
	changes
	
	* annotate nodes with diff-information, e.g. "added"
	
	* use depth-first-search to propagate impact
	
	* use diff-information to stop propagation, e.g. when reaching a "deleted"
	edge
	
	* detects any impact
	
	- provide 2 algoriths to search for specific impacts:
	
	* constraints change: checks whether requirements for algorithm parameters
	changed
	
	* concept compatibility: checks whether a concept is compatible between
	versions
	
	- case study of changed STL iterator concept
	
	-> granularity of entities: conceptual STL specifications
	
	-> granularity of changes: add / delete
	
	-> granularity of results: compatibility information of STL concept
	specifications
	
	- implemented in CCIA prototype
	
	
	Open Issues:
	
	- fully automate analysis
	
	- identifiy basic queries in order to build new, complex filters based
	on the basic queries},
  timestamp = {2011.04.01}
}

@ARTICLE{Zdun2013,
  author = {Zdun, Uwe and Capilla, Rafael and Tran, Huy and Zimmermann, Olaf},
  title = {{Sustainable Architectural Design Decisions}},
  journal = {IEEE Software},
  year = {2013},
  volume = {30},
  pages = {46--53},
  number = {6},
  month = nov,
  doi = {10.1109/MS.2013.97},
  file = {:./literature/zdun2013.pdf:PDF},
  issn = {0740-7459},
  owner = {Sebastian},
  timestamp = {2013.12.03},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6576117}
}

@ARTICLE{Zdun2007,
  author = {Uwe Zdun and Schahram Dustdar},
  title = {Model-Driven and Pattern-Based Integration of Process-Driven SOA
	Models},
  journal = {International Journal of Business Process Integration and Management},
  year = {2007},
  volume = {2},
  pages = {109-119},
  number = {2},
  abstract = {Service-Oriented Architectures (SOA) are increasingly used in the
	context of business processes. However, the modelling approaches
	for process-driven SOAs do not yet sufficiently integrate the various
	kinds of models relevant for a process-driven SOA ? ranging from
	process models to software architectural models to software design
	models. We propose to integrate process-driven SOA models via a model-driven
	software development approach that is based on proven practices documented
	as software patterns. We introduce pattern primitives as an intermediate
	abstraction to precisely model the participants in the solutions
	that patterns convey. To enable model-driven development, we develop
	domain-specific modelling languages for each kind of process-driven
	SOA model ? based on meta-models that are extended with the pattern
	primitives. The various process-driven SOA models are integrated
	in a model-driven tool chain via the meta-models. Our tool chain
	validates the process-driven SOA models with regard to the constraints
	given by the meta-models and primitives.},
  file = {:./literature/soaMT.pdf:PDF},
  keywords = {service-oriented architecture, SOA models, process-driven SOA, software
	patterns, services modelling, metamodels, primitives},
  owner = {Stephan},
  timestamp = {2008.05.05},
  url = {http://www.infosys.tuwien.ac.at/Staff/zdun/publications/soaMT.pdf}
}

@ARTICLE{Zelkowitz1998,
  author = {Zelkowitz, M. V. and Wallace, D. R.},
  title = {Experimental models for validating technology},
  journal = {Computer},
  year = {1998},
  volume = {31},
  pages = {23-31},
  number = {5},
  file = {:./literature/Paper_264.pdf:PDF},
  owner = {Steffen},
  timestamp = {2013.05.01}
}

@INPROCEEDINGS{Zeng2002,
  author = {Zeng, D.D. and Zhao, J.L.},
  title = {Achieving software flexibility via intelligent workflow techniques},
  booktitle = {Proceedings of the 35th Annual Hawaii International Conference on
	System Sciences, (HICSS)},
  year = {2002},
  pages = { 606-615},
  month = {Jan},
  publisher = {IEEE},
  abstract = {In this paper, we investigate innovative techniques of achieving software
	flexibility in a workflow environment. We believe that, by incorporating
	workflow technology and intelligent agent techniques into modern
	information systems, the software can be made more robust, more cost-effective
	to maintain and easier to change. In this paper, we present: (1)
	an in-depth investigation of software flexibility issues, (2) an
	integrated system architecture that combines workflow coordination
	mechanisms and agent-based decision-making capabilities, and (3)
	a framework to evaluate software architectures with an emphasis on
	the cost implications of system flexibility. A prototype system illustrating
	the implementation of intelligent workflow concepts is also reported.},
  doi = {http://doi.ieeecomputersociety.org/10.1109/HICSS.2002.993941},
  file = {:./literature/CLUSR17.pdf:PDF},
  keywords = {computer aided software engineering, decision support systems, software
	agents, software architecture, software cost estimation, software
	maintenance, workflow management software agent-based decision-making
	capabilities, cost implications, cost-effective software maintenance,
	information systems, integrated system architecture, intelligent
	agent techniques, intelligent workflow techniques, software architecture
	evaluation framework, software changes, software flexibility, software
	robustness, workflow coordination mechanisms},
  owner = {Stephan},
  timestamp = {2008.10.09},
  url = {http://www.hicss.hawaii.edu/HICSS_35/HICSSpapers/PDFdocuments/CLUSR17.pdf}
}

@INPROCEEDINGS{Zhang2011a,
  author = {Zhang, Lei and Sun, Yanchun and Peng, Yuehui and Cui, Xiaofeng and
	Mei, Hong},
  title = {Towards quality based solution recommendation in decision-centric
	architecture design},
  booktitle = {SEKE 2011 - Proceedings of the 23rd International Conference on Software
	Engineering and Knowledge Engineering},
  year = {2011},
  pages = {776 - 781},
  address = {Miami, FL, United states},
  organization = {Knowledge Systems Institute Graduate School},
  publisher = {Knowledge Systems Institute Graduate School, 3420 Main Street, Skokie,
	IL 60076, United States},
  note = {This effort is sponsored by the National Basic Research
	
	Program of China (973) under Grant No. 2009CB320703, the
	
	Science Fund for Creative Research Groups of China under
	
	Grant No. 60821003. , and the National High-Tech Research
	
	and Development Program (863) of China under Grant No.
	
	2007AA01Z127, 2008AA01Z139.},
  abstract = {Designing software architecture is an important and complex activity.
	To design a high quality architecture, architects need to make decisions
	on a number of inter-dependent design issues, each of which usually
	has a set of viable alternative solutions. Moreover, each viable
	solution often has diverse impact on different quality attributes
	which often conflict with each other. Existing methods for architecture
	design still face the challenge of bridging the gap between software
	requirements and high quality architecture. To alleviate the complexity
	of architectural design, we propose a decision-centric approach:
	ABC/DD. We attempt to provide pragmatic assistance for practitioners
	to narrow this gap, and also ensure the quality of target architecture.
	This approach transits from requirements to architectures through
	a five-step process including requirement refining, solution exploiting,
	relation identifying, solutions and quality attributes synthesizing,
	and architecture deciding. Finally we illustrate the applicability
	of this approach using a case study.},
  file = {:./literature/zhang2011a.pdf:PDF},
  isbn = {9781891706295},
  owner = {Sebastian},
  timestamp = {2013.07.26}
}

@TECHREPORT{Zhang2005,
  author = {Xiaofang Zhang},
  title = {Analysis techniques for Program Comprehension},
  institution = {Computer and Information Science Department, University of Oregon,
	USA},
  year = {2005},
  file = {:./literature/position.pdf:PDF},
  keywords = {program comprehension},
  owner = {Robert},
  timestamp = {2007.03.02},
  url = {http://www.cs.uoregon.edu/~xzhang/documents/AreaExam-final/position.pdf}
}

@ARTICLE{Zhao2002,
  author = {Zhao, Jianjun and Yang, Hongji and Xiang, Liming and Xu, Baowen},
  title = {Change impact analysis to support architectural evolution},
  journal = {Journal of Software Maintenance},
  year = {2002},
  volume = {14},
  pages = {317-333},
  number = {5},
  booktitle = {Journal of Software Maintenance},
  file = {:./literature/Paper_17.PDF:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- changes do not only occur in code, also in architecture and other
	design documents / models
	
	- need to adress IA on that aspect to expand tool & method support
	and to make modification easier
	
	- however, "recent" approaches only focus on source code
	
	
	Research Questions:
	
	- IA of software planning phase (i.e. the architecture development)
	
	- obtain IA information from ADL (WRIGHT, in this case)
	
	- find means for forward and backward slicing of architectures
	
	
	Contribution:
	
	- automated change effect assessment based on formal architecture
	specification through ADLs
	
	- definition of new slicing and chopping methods for architectures
	
	
	Solution:
	
	- infer information flow within components from ADL(WRIGHT) descriptions
	
	- use this to construct architectural flow graph to compute architectural
	slices & chops
	
	- define several sclicing criteria to either extract components or
	their connections
	
	-> granularity of entities: entire WRIGHT architectural specification
	
	-> granularity of changes: atomic changes to components
	
	-> granularity of results: entire WRIGHT architectural specification
	
	
	Open Issues:
	
	- integration of other ADLs next to WRIGHT
	
	- not yet evaluated},
  timestamp = {2011.01.05}
}

@INPROCEEDINGS{Zhao2007,
  author = {Xulin Zhao and Ying Zou},
  title = {A Framework for Incorporating Usability into Model Transformations},
  booktitle = {Proceedings of the MoDELS'07 Workshop on Model Driven Development
	of Advanced User Interfaces},
  year = {2007},
  address = {Nashville, Tennessee, USA},
  abstract = {The usability of user interfaces is crucial for the success of an
	application. Model driven user interface (UI) development speeds
	up the production of UIs and improves the maintainability of UIs.
	However, the usability evaluation of UIs is usually conducted by
	end-users or experts after UIs are generated. Such a user centric
	evaluation is usually time consuming and expensive, especially when
	the usability problems are detected in the last phase of the software
	development. In this paper, we propose a framework that incorporates
	the usability evaluation as an integral part of automatic processes
	for UI generation. To link the usability goal into the UI generation
	process, we model the usability using a goal graph for each intermediate
	UI model and associate the usability goals to the attributes of the
	models. Our proposed framework detects and addresses usability problems
	in the early phase of the software development.},
  file = {:./literature/paper8.pdf:PDF},
  keywords = {usability, model transformation},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://sunsite.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-297/paper8.pdf}
}

@INPROCEEDINGS{Zheng2006,
  author = {Zheng, Jiang and Robinson, Brian and Williams, Laurie and Smiley,
	Karen},
  title = {Applying regression test selection for COTS-based applications},
  booktitle = {Proceedings of the 28th international conference on Software engineering},
  year = {2006},
  series = {ICSE '06},
  pages = {512--522},
  address = {New York, NY, USA},
  publisher = {ACM},
  __markedentry = {[qurat:]},
  acmid = {1134357},
  doi = {http://doi.acm.org/10.1145/1134285.1134357},
  file = {:/literature/RegressionTesting/Applying regression test selection for COTS based applications.pdf:PDF},
  isbn = {1-59593-375-1},
  keywords = {COTS, commercial-off-the-shelf, regression testing, software testing,
	component binary code baseds},
  location = {Shanghai, China},
  numpages = {11},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://doi.acm.org/10.1145/1134285.1134357}
}

@INPROCEEDINGS{Zheng2007,
  author = {Zheng, Jiang and Williams, Laurie and Robinson, Brian and Smiley,
	Karen},
  title = {Regression Test Selection for Black-box Dynamic Link Library Components},
  booktitle = {Proceedings of the Second International Workshop on Incorporating
	COTS Software into Software Systems: Tools and Techniques},
  year = {2007},
  series = {IWICSS '07},
  pages = {9--},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  __markedentry = {[qurat:]},
  acmid = {1270288},
  doi = {http://dx.doi.org/10.1109/IWICSS.2007.8},
  file = {:/literature/RegressionTesting/Regression Test Selection for Black-box Dynamic Link Library Components.pdf:PDF},
  isbn = {0-7695-2966-6},
  keywords = {RegressionTesting, Read, CodeBased, Relevant, approach, component
	binary code baseds},
  owner = {Annie},
  timestamp = {2011.10.20},
  url = {http://dx.doi.org/10.1109/IWICSS.2007.8}
}

@INPROCEEDINGS{Zhou2008,
  author = {Zhou,Yu and Wuersch, Michael and Giger, Emanuel and Gall, Harald
	and Lue, Jian},
  title = {A Bayesian Network Based Approach for Change Coupling Prediction},
  booktitle = {Proceedings of the 15th Working Conference on Reverse Engineering
	2008},
  year = {2008},
  pages = {27-36},
  month = {October},
  file = {:./literature/Paper_62.pdf:PDF},
  journal = {Reverse Engineering, Working Conference on},
  owner = {Steffen},
  review = {Problem:
	
	- most historical approaches (e.g. MSR) neglect two facts:
	
	* the author resposible for a change (-> other code of this author
	is likely to be affected)
	
	* the exact time when a change happended (-> recent changes indicate
	that it is under development and therefore likely to change again)
	
	
	Research Questions:
	
	- inspect the differen dimensions of software change
	
	- inspect siginifance of changes and different levels of source code
	dependencies
	
	
	Contribution:
	
	- approach utilizing bayesian belief networks for change coupling
	prediction
	
	- infer possible change couplings between entities in future
	
	- taxonomy of source code changes for more differentiated view on
	source code changes
	
	- define significance levels for changes (e.g. low, crucial)
	
	
	Solution:
	
	- changes classified into 2 gross categories:
	
	* body-part changes (method body changes, statement changes etc.)
	
	* declaration-part changes (attribute declarations, final modfiers,
	method declarations)
	
	- map this changes on different significance levels based on complexity
	indicators (nesting depth) or whether the modify or preserve functionality
	
	- approach comprised of 3 major steps:
	
	* data import & preprocessing
	
	 - extraction of change history
	
	 - reconstruction of transactions from version control repository
	
	 - extracting fine grained source change information
	
	 * use sliding window to extract co-changes
	
	 * perepare static source code dependency model
	
	 * classifiy changes according to taxonomy
	
	* feature extraction and instance generation
	
	 - select features that influence whethter entities might co-change:
	
	 * source code dependency level (e.g. message passing, inheritance)
	
	 - count their number to classify them into low, middle, high, uncertain
	
	 * change siginifance level
	
	 * co-change frequency (how often did they change in the past)
	
	 * age of change (old = stable, middle, new, latest = most likely
	to change)
	
	 * author
	
	* traning and validation
	
	 - use selected entities and their instances to build up the network
	structure
	
	 - use K2 algorithm (greedy) to build up the network
	
	 - use SimpleEstimator algorithm for learning (calculate feature frequencies
	to produce probabilities)
	
	-> granularity of entities: class, method, attribute
	
	-> granularity of changes: atomic changes to classes, methods and
	attributes
	
	-> granularity of results: class, method, attribute
	
	
	Open Issues:
	
	- include other features into consideration (e.g. strict code ownerships)},
  timestamp = {2011.02.10}
}

@INPROCEEDINGS{Zhu2007,
  author = {Zhu, Liming and Gorton, Ian},
  title = {UML Profiles for Design Decisions and Non-Functional Requirements},
  booktitle = {Second Workshop on Sharing and Reusing Architectural Knowledge -
	Architecture, Rationale, and Design Intent, 2007. SHARK/ADI '07:
	ICSE Workshops 2007},
  year = {2007},
  volume = {00},
  pages = {8},
  address = {Los Alamitos, CA, USA},
  publisher = {IEEE Computer Society},
  abstract = {A software architecture is composed of a collection of design decisions.
	Each design decision helps or hinders certain Non-Functional Requirements
	(NFR). Current software architecture views focus on expressing components
	and connectors in the system. Design decisions and their relationships
	with non-functional requirements are often captured in separate design
	documentation, not explicitly expressed in any views. This disassociation
	makes architecture comprehension and architecture evolution harder.
	In this paper, we propose a UML profile for modeling design decisions
	and an associated UML profile for modeling non-functional requirements
	in a generic way. The two UML profiles treat design decisions and
	nonfunctional requirements as first-class elements. Modeled design
	decisions always refer to existing architectural elements and thus
	maintain traceability between the two. We provide a mechanism for
	checking consistency over this traceability. An exemplar is given
	as a way to demonstrate the feasibility of our approach.},
  doi = {http://doi.ieeecomputersociety.org/10.1109/SHARK-ADI.2007.14},
  file = {:./literature/ICSE2007_SHARK_Zhu.pdf:PDF},
  isbn = {0-7695-2951-8},
  keywords = {UML profile, design decisions, non-functional requirements},
  owner = {Stephan},
  review = {generic UML profile for non-funcitonal requirements proposed
	
	UML profile for design decisions
	
	
	design decisions and NFR treated as first-class entities},
  timestamp = {2008.04.11},
  url = {http://www.cse.unsw.edu.au/~limingz/publication/ICSE2007_SHARK_Zhu.pdf}
}

@PHDTHESIS{Zimmermann2009a,
  author = {Zimmermann, Olaf},
  title = {An Architectural Decision Modeling Framework for Service-Oriented
	Architecture Design},
  school = {Universität Stuttgart},
  year = {2009},
  file = {:./literature/SOAD_ArchitecturalDecisionModeling_PhDThesisOlafZimmermann.pdf:PDF},
  owner = {Sebastian},
  timestamp = {2014.01.09}
}

@ARTICLE{Zimmermann2007,
  author = {Zimmermann, Olaf and Gschwind, Thomas},
  title = {{Reusable architectural decision models for enterprise application
	development}},
  journal = {Software Architectures, Components, and Applications, LNCS},
  year = {2007},
  volume = {4880},
  pages = {15--32},
  doi = {10.1007/978-3-540-77619-2\_2},
  file = {:./literature/Zimmermann2007.pdf:PDF},
  keywords = {architectural decision,architectural knowledge,mda,soa},
  mendeley-groups = {Architecture Knowledge/Models/ADkwik},
  owner = {Sebastian},
  timestamp = {2014.03.18},
  url = {http://link.springer.com/chapter/10.1007/978-3-540-77619-2\_2}
}

@incollection{Soliman2014,
year={2014},
isbn={978-3-319-09969-9},
booktitle={Software Architecture},
volume={8627},
series={Lecture Notes in Computer Science},
editor={Avgeriou, Paris and Zdun, Uwe},
doi={10.1007/978-3-319-09970-5_3},
title={Modeling the Interactions between Decisions within Software Architecture Knowledge},
url={http://dx.doi.org/10.1007/978-3-319-09970-5_3},
publisher={Springer International Publishing},
keywords={Software architecture; design decision; architecture knowledge; design reasoning},
author={Soliman, Mohamed and Riebisch, Matthias},
pages={33-40},
language={English}
}

@ARTICLE{Zimmermann2009,
  author = {Olaf Zimmermann and Jana Koehler and Frank Leymann and Ronny Polley
	and Nelly Schuster},
  title = {Managing architectural decision models with dependency relations,
	integrity constraints, and production rules},
  journal = {Journal of Systems and Software},
  year = {2009},
  volume = {82},
  pages = {1249-1267},
  number = {8},
  file = {:./literature/zimmermann2009.pdf:PDF},
  owner = {matthias},
  review = {Comment MR: The term concern is used similar to motivation or reason},
  timestamp = {2013.11.05},
  url = {http://dx.doi.org/10.1016/j.jss.2009.01.039}
}

@INPROCEEDINGS{Zimmermann2004,
  author = {Zimmermann, Thomas and Weissgerber, Peter},
  title = {Preprocessing {CVS} Data for Fine-Grained Analysis},
  booktitle = {Proceedings of the 1st International Workshop on Mining Software
	Repositories},
  year = {2004},
  pages = {2-6},
  file = {:./literature/Paper_84.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	- all history-based IA approaches must extract and analyse data from
	CVS repositories
	
	- this preprocessing has direct impact on quality of analysis
	
	
	Research Questions:
	
	- what is required prior to utilizing CVS repositories for any kind
	of analysis
	
	
	Contribution:
	
	- discussion of 4 basic steps of preprocessing
	
	- concept of sliding time window for preprocessing
	
	- 2 approaches for mapping changes to affected parts of file
	
	
	Solution:
	
	- preprocessing includes 4 steps
	
	* data extraction
	
	 -> fast access to stored information as CVS is slow
	
	 - mirror information in local database
	
	 - only extract required files (i.e. things the analysis is interested
	in)
	
	 - extract commit messages as they contain (sometimes) valuable information
	
	* transaction recovery
	
	 - sort checkins by author, time stamp und log message
	
	 - apply fixed- or sliding- window techniques to uncover what belongs
	to a certain change event
	
	 -> sliding windows performed better than fixed windows
	
	* mapping changes to entities
	
	 - compare each revision with its predecessor to map changes to syntactic
	components of the files
	
	 - apply any diff-tools (based on the content, i.e. source diff, text
	diff etc.)
	
	 -> however, inprecise (depends on diff tool)
	
	 - better approach: determine entities that appear in both versions
	and then compare their source code
	
	 -> instead of diff on file-level, perform diff on entity-level
	
	* data cleaning, required due to large transactions or noise (e.g.
	renaming of libraries affects all, but is no real change)
	
	
	Open Issues:},
  timestamp = {2011.02.23}
}

@ARTICLE{Zimmermann2005,
  author = {Zimmermann, Thomas and Weissgerber, Peter and Diehl, Stephan and
	Zeller, Andreas},
  title = {Mining Version Histories to Guide Software Changes},
  journal = {IEEE Transactions on Software Engineering},
  year = {2005},
  volume = {31},
  pages = {429-445},
  number = {6},
  month = {June},
  booktitle = {Proceedings of the IEEE TRANSACTIONS ON SOFTWARE ENGINEERING},
  file = {:./literature/Paper_58.pdf:PDF},
  owner = {Steffen},
  review = {Problem:
	
	
	Research Questions:
	
	- suggesting and predicting likely changes
	
	- prevent errors due to incomplete changes
	
	- detect couplings missed by program analysis
	
	
	Contribution:
	
	- applying data mining techniques to guide programmers among related
	changes
	
	- detection of couplings between fine-grained entities
	
	
	Solution:
	
	- approach implemented in ROSE tool, consisting of two parts:
	
	* preprocessing: extract data from CVS and map changes to entities
	
	* mining: create association rules
	
	- each entity consists of 3 attributes:
	
	* category (e.g. file, method)
	
	* identifier / name
	
	* parent entity (can be NULL)
	
	- distinguish between different kinds of changes (e.g. added, removed,
	altered)
	
	- association rules have probalistic interpretation based 2 measures:
	
	* support count: number of transactions this rule has been derived
	from
	
	* confidence: how often did the rule cover changes successfully
	
	- use Apriori-algorithm to compute rules from data sets
	
	* adjust this to run on the fly only considering the current situation
	(due to time & space) [Apriori otherwise would precompute all rules,
	which takes days according to paper]
	
	- perform mining on two levels:
	
	* fained-grained for source code
	
	* coarse-grained for entire files
	
	-> granularity of entities: methods and variables
	
	-> granularity of changes: adaptable (variable up to file)
	
	-> granularity of results: methods and variables
	
	
	Open Issues:
	
	- ROSE ignores changes affecting more than 30 entities (why 30? +
	important data can be missed!)
	
	- ROSE relies on "good" transactions, i.e. programmers never make
	"bad" transactions},
  timestamp = {2011.02.10}
}

@INPROCEEDINGS{Zisman2000,
  author = {Zisman, Andrea and Emmerich, Wolfgang and Finkelstein, Anthony},
  title = {Using {XML} to Build Consistency Rules for Distributed Specifications},
  booktitle = {Proceedings of the 10th International Workshop on Software Specification
	and Design, (IWSSD '00)},
  year = {2000},
  pages = {141-150},
  address = {Washington, DC, USA},
  publisher = {IEEE},
  acmid = {857212},
  file = {:./literature/Zisman2000.pdf:PDF},
  isbn = {0-7695-0884-7},
  keywords = {Inconsistency, consistency rules, XML, XPointer},
  owner = {Stephan},
  timestamp = {2011.01.29},
  url = {http://portal.acm.org/citation.cfm?id=857171.857212}
}

@INPROCEEDINGS{Zou2006,
  author = {Joe Zou and Christopher J. Pavlovski},
  title = {Modeling Architectural Non Functional Requirements: From Use Case
	to Control Case},
  booktitle = {IEEE International Conference on e-Business Engineering, 2006. ICEBE
	'06},
  year = {2006},
  pages = {315-322},
  month = {Oct.},
  publisher = {IEEE Computer Society},
  abstract = {While the functional requirements of a system can be effectively modeled
	through the use case driven approach, there is no standard or de
	facto method for modeling non-functional requirements of the system
	architecture. Often such requirements are dealt with in a reactive
	manner rather than proactively. Yet increasingly a contributing factor
	in project difficulty and failure are the non-functional requirements
	imposed on the solution architecture. This paper proposes a control
	case approach to record and model non-functional requirements. This
	technique enables the control case to represent the nonfunctional
	requirements from different perspectives, most typically the various
	operating conditions. Furthermore, we propose an extension to the
	"4+1" view model for depicting software architecture by adding the
	control case view. The combination of both the use case and control
	case views thus reflects the complete requirements across the collective
	system life cycle views: design, process, implementation and deployment.},
  doi = {10.1109/ICEBE.2006.71},
  file = {:./literature/04031668.pdf:PDF},
  keywords = {control system analysis computing, software architecture, systems
	analysisarchitectural nonfunctional requirement modeling, collective
	system life cycle view, control case view, software architecture,
	system architecture, system functional requirement, use case view},
  owner = {Stephan},
  timestamp = {2008.04.11},
  url = {http://ieeexplore.ieee.org/iel5/4031613/4031614/04031668.pdf?tp=&isnumber=&arnumber=4031668}
}

@INPROCEEDINGS{Zschaler2004,
  author = {Zschaler, S.},
  title = {Towards a semantic framework for non-functional specifications of
	component-based systems},
  booktitle = {Proceedings 30th Euromicro Conference},
  year = {2004},
  pages = { 92-99},
  month = {Aug.-3 Sept.},
  publisher = {IEEE Computer Society},
  abstract = {It is now widely recognized that the so-called nonfunctional or extra-functional
	properties of a software system are at least as important as its
	somewhat more classical functional properties and that they must
	be considered as early as possible in the development cycle in order
	to avoid costly failures. We define elements of a semantic framework
	for nonfunctional specifications of component-based systems. We focus
	on how the runtime environment uses components, whose nonfunctional
	properties have been specified, and the available system resources
	to provide a service with specified nonfunctional properties.},
  doi = {10.1109/EURMIC.2004.1333360},
  file = {:./literature/CBSE04_33_zschalers.pdf:PDF},
  issn = {1089-6503 },
  keywords = { formal specification, object-oriented programming, software metrics
	component-based systems, nonfunctional specifications, semantic framework},
  owner = {Stephan},
  timestamp = {2008.06.13},
  url = {http://www-st.inf.tu-dresden.de/comquad/CBSE04_33_zschalers.pdf}
}

@BOOK{Allen1997,
  title = {Handbook of Usability Principles},
  publisher = {San Diego State University Foundation \& The California State Employment
	Development Department},
  year = {1997},
  editor = {Brock S. Allen and Steven L. Eckols},
  file = {:./literature/posit.pdf:PDF},
  keywords = {usability principles},
  owner = {Stephan},
  timestamp = {2009.05.12},
  url = {http://www.luckydogarts.com/dm158/docs/posit.pdf}
}

@PROCEEDINGS{Atzmueller2010,
  title = {Proceedings of the IWK2010 Workshops: International Workshop on Design,
	Evaluation and Refinement of Intelligent Systems (DERIS2010) and
	the First International Workshop on Evolution Support for Model-Based
	Development and Testing (EMDT2010)},
  year = {2010},
  editor = {Martin Atzm{\"{u}}ller and Rainer Knauf and Stephan Bode and Qurat-Ul-Ann
	Farooq and Matthias Riebisch},
  volume = {646},
  series = {CEUR-WS.org},
  publisher = {CEUR-WS.org},
  file = {:./literature/DERIS2010_EMDT2010Proceedings.pdf:PDF},
  owner = {Stephan},
  timestamp = {2011.02.10}
}

@BOOK{Harmelen2001,
  title = {Object Modeling and User Interface Design: Designing Interactive
	Systems},
  publisher = {Addison-Wesley},
  year = {2001},
  editor = {Mark van Harmelen},
  pages = {452},
  address = {Boston, MA, USA},
  isbn = {0-201-65789-9},
  keywords = {object modeling, user interface design, use case based design, task
	modeling, usage-centered design, human-computer interaction},
  owner = {Stephan},
  timestamp = {2008.08.01},
  url = {http://www.amazon.com/exec/obidos/ASIN/0201657899/acmorg-20}
}

@BOOK{Leite2004,
  title = {Perspectives on Software Requirements},
  publisher = {Kluwer},
  year = {2004},
  editor = {Leite, J. and Doorn, J.},
  address = {Norwell, MA, USA},
  keywords = {software requirements, non-functional requirements, traceability},
  owner = {Stephan},
  timestamp = {2009.05.13},
  url = {http://books.google.de/books?id=LHvIXetZiFwC&dq=perspectives+on+software+requirements&printsec=frontcover&source=bn&hl=de&ei=RYwKSvRexZb8Boi9sZgL&sa=X&oi=book_result&ct=result&resnum=5}
}

@BOOK{Madhavji2006,
  title = {Software Evolution and Feedback: Theory and Practice},
  publisher = {John Wiley \& Sons},
  year = {2006},
  editor = {Madhavji, Nazim H. and Fernandez-Ramil, Juan and Perry, Dewayne E.},
  isbn = {0470871806},
  owner = {Stephan},
  timestamp = {2010.11.19}
}

@BOOK{Mens2008,
  title = {Software Evolution},
  publisher = {Springer},
  year = {2008},
  editor = {Tom Mens and Serge Demeyer},
  file = {:./literature/SoftwareEvolution.pdf:PDF},
  keywords = {software evolution, software maintenance, evolvability, maintainability},
  owner = {Stephan},
  timestamp = {2009.04.28},
  url = {http://www.springer.com/computer/programming/book/978-3-540-76439-7}
}

@BOOK{cocome2008,
  title = {The Common Component Modeling Example: Comparing Software Component
	Models},
  publisher = {Springer Berlin Heidelberg},
  year = {2008},
  editor = {Rausch, Andreas and Reussner, Ralf and Mirandola, Raffaela and Plasil,
	Frantisek},
  number = {5153},
  series = {Lecture Notes in Computer Science},
  edition = {1st},
  abstract = {This volume defines a common example for modelling approaches of component
	based systems. It is based on the Dagstuhl research seminar CoCoME
	(Common Component Modelling Example), which was held from August
	1-3, 2007, at Schloss Dagstuhl, Germany. The Common Component Modelling
	Example makes it possible to compare different approaches and to
	validate existing models. It serves as a platform for the classification
	of existing models and approaches and the interchange of research
	ideas, enabling researchers to focus and to tackle aspects less frequently
	dealt with. The CoCoME project is an ongoing venture, one of the
	aims of which is the adoption of the Common Component Modelling Example
	by the entire component community as a means of comparing and validating
	their approaches.},
  file = {:./literature/cocome2007.pdf:PDF},
  isbn = {3540852883, 9783540852889},
  owner = {matthias},
  timestamp = {2013.09.19}
}

@PROCEEDINGS{Vanderdonckt2005,
  title = {International COST 294 Workshop on User Interface Quality Models},
  year = {2005},
  editor = {Jean Vanderdonckt and Effie Lai-Chong Law and Ebba Thora Hvannberg},
  address = {Rome, Italy},
  month = {September},
  file = {:./literature/395.pdf:PDF},
  keywords = {quality models},
  owner = {Stephan},
  timestamp = {2008.04.02},
  url = {http://www.irit.fr/cost294/upload/395.pdf}
}

@MISC{Aagedal,
  title = {Summary of IEEE 1471},
  file = {:./literature/SummaryOfIEEE1471.pdf:PDF},
  keywords = {IEEE standard, summary, view, viewpoint},
  owner = {Stephan},
  timestamp = {2009.02.10}
}

@ELECTRONIC{CMMI_Forum,
  title = {{Xing-Forum der Gruppe: CMMI (Capability Maturity Model Integration)
	- Best Practices}},
  howpublished = {https://www.xing.com/net/pri6ca937x/cmmi_bestpractices/forums},
  owner = {elkeb},
  timestamp = {2012.01.04}
}

@MISC{EMF,
  title = {{Eclipse Modeling Framework (EMF).}},
  owner = {Steffen},
  timestamp = {2012.03.15},
  url = {http://www.eclipse.org/modeling/emf/}
}

@MISC{EMFStore,
  title = {{EMFStore Eclipse Project Website.}},
  owner = {Steffen},
  timestamp = {2012.03.15},
  url = {http://www.eclipse.org/emfstore/}
}

@MISC{EMFTrace,
  title = {{EMFTrace - Sourceforge Project Website.}},
  owner = {Steffen},
  timestamp = {2012.03.15},
  url = {https://sourceforge.net/projects/emftrace/}
}

@MISC{ISA-95,
  title = {{ANSI/ISA-95.00.05-2007 Enterprise-Control System Integration, Part
	5: Business-to-Manufacturing Transactions}},
  address = {North Carolina, USA},
  institution = {ANSI/ISA},
  key = {ANSI/ISA-95.00.05-2007},
  organization = {International Society of Information (ISA)},
  owner = {Stephan},
  timestamp = {2010.10.29}
}

@STANDARD{ISO_12207-2008,
  title = {Systems and software engineering - Software life cycle processes
	(ISO/IEC 12207:2008)},
  organization = {International Organization for Standardization (ISO) and International
	Electrotechnical Commission (IEC)},
  institution = {IEEE},
  file = {ISO_12207-2008.pdf:literature/ISO_12207-2008.pdf:PDF},
  owner = {patrickr},
  timestamp = {2012.08.06}
}

@MISC{MoDisco,
  title = {{MoDisco - Eclipse Project Website.}},
  owner = {Steffen},
  timestamp = {2012.03.15},
  url = {http://www.eclipse.org/MoDisco/}
}

@OTHER{Morgan2007,
  abstract = {Build high-quality software, leverage industry practices, and plan
	to build quality into your solution but be sure to prioritize carefully.},
  file = {:./literature/ImplementingSystemQualityAttributes.pdf:PDF},
  keywords = {quality attributes, architectural design, flexibility},
  owner = {Stephan},
  timestamp = {2008.10.09},
  url = {http://www.iasahome.org/c/portal/layout?p_l_id=PUB.1.269&p_p_id=20&p_p_action=1&p_p_state=exclusive&p_p_col_id=null&p_p_col_pos=3&p_p_col_count=4&_20_struts_action=%2Fdocument_library%2Fget_file&_20_folderId=61&_20_name=01-Implementing.pdf}
}

@ELECTRONIC{qm_forum,
  title = {{Xing-Forum der Gruppe: Qualit\"atsmanagement f\"ur Software-Projekte}},
  howpublished = {https://www.xing.com/net/pri6ca937x/qmsoftware/forums},
  url = {https://www.xing.com/net/pri6ca937x/qmsoftware/forums},
  owner = {elkeb},
  timestamp = {2012.01.04}
}

@ELECTRONIC{re_forum,
  title = {{Xing-Forum der Gruppe: Requirements Engineering}},
  howpublished = {https://www.xing.com/net/pri6ca937x/re/forums},
  url = {https://www.xing.com/net/pri6ca937x/re/forums},
  owner = {elkeb},
  timestamp = {2012.01.04}
}

@TECHREPORT{AutomationML2012.1,
  title = {AutomationML Architecture},
  institution = {AutomationML consortium},
  year = {2012},
  type = {Whitepaper},
  file = {:./literature/1338989510-AutomationML Whitepaper Part 1 - AutomationML Architecture v2.pdf:PDF},
  owner = {gerlach},
  quality = {1},
  timestamp = {2013.02.01},
  url = {https://www.automationml.org/o.red.c/dateien.html}
}

@TECHREPORT{AutomationML2012.2,
  title = {AutomationML Role Libraries},
  institution = {AutomationML consortium},
  year = {2012},
  type = {Whitepaper},
  file = {:./literature/1338989569-AutomationML Whitepaper Part 2 - AutomationML Role Libraries v2.pdf:PDF},
  owner = {gerlach},
  quality = {1},
  timestamp = {2013.02.01},
  url = {https://www.automationml.org/o.red.c/dateien.html}
}

@MISC{JGoodies,
  title = {{JGoodies}},
  howpublished = {http://www.jgoodies.com/},
  year = {2010},
  key = {JGoodies},
  keywords = {user interface design, java, swing},
  owner = {Stephan},
  timestamp = {2008.08.04},
  url = {http://www.jgoodies.com/}
}

@MISC{GRL,
  title = {{Goal-oriented Requirements Language (GRL)}},
  howpublished = {http://www.cs.toronto.edu/km/GRL/},
  year = {2008},
  key = {GRL},
  keywords = {GRL, goal-oriented modeling},
  owner = {Stephan},
  timestamp = {2009.03.25},
  url = {http://www.cs.toronto.edu/km/GRL/}
}

@MANUAL{2007,
  title = {Begriff Wissensdatenbank in Wikipedia},
  month = {03},
  year = {2007},
  owner = {Robert},
  timestamp = {2007.03.02},
  url = {http://de.wikipedia.org/wiki/Wissensdatenbank}
}

@MANUAL{2007a,
  title = {Begriff Onotologie in Wikipedia},
  month = {03},
  year = {2007},
  owner = {Robert},
  timestamp = {2007.03.02},
  url = {http://de.wikipedia.org/wiki/Ontologie_%28Informatik%29}
}

@MISC{2007b,
  title = {{UML} 2.0 Superstructure Specification},
  howpublished = {OMG document formal/2007-02-03, Object Management Group, http://www.omg.org/docs/formal/07-02-03.pdf},
  year = {2007},
  file = {:./literature/UML2_07-02-03.pdf:PDF},
  keywords = {UML},
  owner = {Robert},
  timestamp = {2008.07.16},
  url = {http://www.omg.org/docs/formal/07-02-03.pdf}
}

@MISC{2002,
  title = {Maintainability Index Technique for Measuring Program Maintainability},
  howpublished = {Carnegie Mellon University, SEI; published online at http://www.sei.cmu.edu/str/descriptions//mitmpm\_body.html},
  month = {March},
  year = {2002},
  owner = {Matthias},
  timestamp = {2008.07.16},
  url = {http://www.sei.cmu.edu/str/descriptions/mitmpm_body.html}
}

@MISC{1997,
  title = {Maintenance of Operational Systems -- An Overview},
  howpublished = {Carnegie Mellon University, SEI; published online at http://www.sei.cmu.edu/str/descriptions/mos.html},
  month = {01},
  year = {1997},
  owner = {Matthias},
  timestamp = {2008.07.16},
  url = {http://www.sei.cmu.edu/str/descriptions/mos.html}
}

@comment{jabref-meta: selector_publisher:}

@comment{jabref-meta: selector_author:}

@comment{jabref-meta: selector_journal:}

@comment{jabref-meta: selector_keywords:}

@comment{jabref-meta: groupsversion:3;}

@comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:Impact Analysis\;2\;Abdi2006a\;Abdi2006b\;Abdi2009a\;A
bdi2009b\;Antoniol2000\;Antoniol2005\;Apiwattanapong2005\;Arisholm2004
\;Arnold1993a\;Arnold1993b\;Aryani2009\;Aryani2010\;Askari2006\;Badri2
005\;Barros1995\;Beszedes2007a\;Beszedes2007b\;Beyer2005\;Bilal2006\;B
inkley2005\;Binkley2010\;Bishop2004\;Black2001\;Bohner1995\;Bohner1996
a\;Bohner1996b\;Bohner2002a\;Bohner2002b\;Bohner2003\;Borg2013a\;Boukt
if2006\;Breech2004\;Breech2005\;Breech2006\;Briand1999a\;Briand1999b\;
Briand2002\;Briand2003a\;Briand2006\;Briand2009\;Buckley2005a\;Buckner
2005\;Canfora2005\;Canfora2006\;Canfora2010\;Ceccarelli2010\;Chaumun19
99\;Chen2001\;Dantas2007\;DeLucia2008\;Ducasse2004\;Fasching2009\;Feng
2006\;Fluri2005\;Fluri2006\;Gall2003\;Gallagher1991\;German2009\;Gethe
rs2010\;Girba2004a\;Girba2004b\;Girba2005\;Girba2006\;Girba2007\;Gokni
l2008\;Gupta2009\;Gupta2010\;Gwizdala2003\;Hammad2009\;Han1996\;Hassai
ne2011\;Hassan2004\;Hassan2010\;Hassine2005\;Hattori2008a\;Hattori2008
b\;Herrmann2012\;Hewitt2005\;Hoffman2000a\;Hoffman2000b\;Hoffman2003\;
Huang2006\;Huang2007\;Huang2008\;Hutchins1998\;Hutchinson2003\;Ibrahim
2005a\;Ibrahim2005b\;Ibrahim2006\;Imtiaz2008\;Jashki2008\;Jasz2008\;Jo
ensson2005\;Kabaili2001\;Kagdi2005\;Kagdi2006\;Kagdi2007a\;Kagdi2007b\
;Kagdi2007c\;Kagdi2008\;Kagdi2010\;Keller2009\;Keller2011\;Khan2009\;K
homh2009\;Kilpinen2008\;Kim2010\;Kobayashi2011\;Korpi2007\;Kotonya2005
\;Kung1994\;Law2003a\;Law2003b\;Lee1998\;Lee2000\;Lee2010\;Lehnert2011
a\;Lehnert2011b\;Lehnert2012a\;Lehnert2012b\;Lehnert2013a\;Li1996\;Li2
012a\;Lindvall1997\;Lindvall1998b\;Lock1999\;Looman2009\;Maia2010\;McN
air2007\;Mellegard2010\;Mens2003\;Mirarab2007\;Mohamad2010\;Moonen2002
\;Nadi2010\;Nurmuliani2006\;ONeal2001\;ONeal2003\;Omerovic2011\;Orso20
03\;Orso2004b\;Petrenko2009\;Pirklbauer2010\;Popescu2010a\;Popescu2010
b\;Poshyvanyk2009\;Qu2012\;Queille1994\;Rajlich1997\;Rajlich2004\;Ren2
003\;Ren2004\;Ren2005\;Ren2007\;Robbes2007a\;Robbes2007b\;Robbes2008a\
;Robbes2008b\;Robbes2008c\;Rochimah2007\;Rungta2012\;Ryder2001\;Santel
ices2010\;Schrettner2012\;Sharafat2007\;Sharafat2008\;Sherriff2007\;Sp
ijkerman2010\;Sridharan2007\;Stoerzer2006\;Sun2010\;Sun2011\;Tang2007\
;Tang2011\;Tip1994\;Tonella2003\;Toth2010a\;Toth2010b\;Tsantalis2005\;
Vanciu2010\;Vaucher2008\;Vidacs2007\;Vora2010\;Walker2006\;Wilkerson20
12\;Wong2009\;Wong2011\;Xia2004\;Xiao2007\;Xing2004a\;Xing2004b\;Xing2
005\;Yau1978\;Yazdanshenas2012\;Ying2004\;Yoo2004\;Yu\;Zalewski2006\;Z
hao2002\;Zhou2008\;Zimmermann2004\;Zimmermann2005\;deBoer2005\;tenHove
2009\;vandenBerg2006\;vonKnethen2003\;;
2 ExplicitGroup:History Mining / MSR\;2\;Antoniol2005\;Beyer2005\;Bouk
tif2006\;Canfora2005\;Canfora2006\;Canfora2010\;Ceccarelli2010\;Dantas
2007\;Ducasse2004\;Fluri2005\;Fluri2006\;Gall2003\;Girba2004a\;Girba20
04b\;Girba2005\;Girba2006\;Girba2007\;Hassan2004\;Hattori2008a\;Jashki
2008\;Kagdi2005\;Kagdi2006\;Kagdi2007a\;Kagdi2007b\;Kagdi2007c\;Kagdi2
008\;Kagdi2010\;McNair2007\;Nadi2010\;Sherriff2007\;Wong2009\;Xing2004
a\;Xing2004b\;Xing2005\;Ying2004\;Zimmermann2004\;Zimmermann2005\;;
2 ExplicitGroup:Information Retrieval\;2\;Antoniol2000\;Binkley2010\;G
ethers2010\;Gethers2012\;Joensson2005\;Poshyvanyk2009\;Vaucher2008\;va
nHeesch2012\;;
2 ExplicitGroup:Rule-based\;2\;Barros1995\;Briand2002\;Briand2003a\;Br
iand2006\;Feng2006\;Keller2009\;Keller2011\;Lehnert2012a\;Lehnert2012b
\;Lehnert2013a\;Queille1994\;deBoer2005\;tenHove2009\;;
2 ExplicitGroup:Dependency Analysis\;2\;Bilal2006\;Binkley2005\;Bishop
2004\;Black2001\;Bohner1996b\;Bohner2002a\;Bohner2002b\;Bohner2003\;Bu
ckner2005\;Chaumun1999\;Chen2001\;Fasching2009\;German2009\;Gupta2009\
;Gupta2010\;Gwizdala2003\;Han1996\;Hewitt2005\;Hoffman2003\;Hutchins19
98\;Kabaili2001\;Khan2009\;Kim2010\;Kotonya2005\;Kung1994\;Lee1998\;Le
e2000\;Li1996\;Maia2010\;Mohamad2010\;Petrenko2009\;Pirklbauer2010\;Po
pescu2010a\;Popescu2010b\;Rajlich1997\;Sun2010\;Vanciu2010\;Xiao2007\;
Yau1978\;Yoo2004\;Yu\;Zalewski2006\;Zhao2002\;vandenBerg2006\;;
3 ExplicitGroup:Slicing\;2\;Gallagher1991\;Korpi2007\;Santelices2010\;
Sridharan2007\;Sun2011\;Tonella2003\;Vidacs2007\;;
3 ExplicitGroup:Call Graphs\;2\;Badri2005\;Ren2003\;Ren2004\;Ren2005\;
Ren2007\;Ryder2001\;Stoerzer2006\;;
3 ExplicitGroup:Execution Traces\;2\;Apiwattanapong2005\;Beszedes2007a
\;Beszedes2007b\;Breech2005\;Huang2006\;Huang2007\;Huang2008\;Jasz2008
\;Law2003a\;Law2003b\;Orso2003\;;
3 ExplicitGroup:Traceability\;2\;DeLucia2008\;Goknil2008\;Hammad2009\;
Hutchinson2003\;Ibrahim2005a\;Ibrahim2005b\;Ibrahim2006\;Imtiaz2008\;L
ee2010\;Lindvall1998b\;Looman2009\;ONeal2001\;ONeal2003\;Omerovic2011\
;Rochimah2007\;Spijkerman2010\;Tang2011\;vonKnethen2003\;;
2 ExplicitGroup:Probabilistic\;2\;Abdi2009a\;Abdi2009b\;Canfora2010\;C
eccarelli2010\;Lock1999\;Mirarab2007\;Santelices2010\;Sharafat2007\;Sh
arafat2008\;Tang2007\;Tsantalis2005\;Walker2006\;Wong2009\;Wong2011\;Z
hou2008\;;
2 ExplicitGroup:IA Classifications\;2\;Arnold1993b\;Kilpinen2008\;Lehn
ert2011a\;Lehnert2011b\;Wilkerson2012\;;
2 ExplicitGroup:Multiperspective IA\;2\;Hammad2009\;Ibrahim2005a\;Ibra
him2005b\;Ibrahim2006\;Imtiaz2008\;Lehnert2012b\;Lehnert2013a\;Tang201
1\;;
2 ExplicitGroup:IA Comparisons / Experiments\;2\;Breech2005\;Hattori20
08b\;Herrmann2012\;Li2012a\;Lindvall1997\;Mellegard2010\;Nurmuliani200
6\;Orso2004b\;Robbes2008b\;Rochimah2007\;Toth2010a\;;
1 ExplicitGroup:Regression Testing\;2\;2002\;Abramson1996\;Agrawal1993
\;Ali2007a\;Ash1994\;Bates1993\;Benedusi1998\;Beydeda2000\;Bible2001\;
Binkley1992\;Binkley1995\;Biswas2009\;Briand2002\;Briand2003b\;Briand2
009a\;Chakrabarti2006\;Chen1994\;Chen2002\;Chen2002a\;Chen2003\;Chen20
07\;Chen2009\;Chittimalli2008\;Chittimalli2009\;Cibulski2011\;Clarke20
03\;Delamare2008\;Deng2004a\;Engstroem2010\;Engstrom2008\;Fahad2008\;F
arooq2007\;Farooq2010\;Farooq2010b\;Gorthi2008\;Graves2001\;Gupta1992\
;Harrold1993\;Harrold1998\;Harrold2001\;Hartmann1988\;Hartmann1989\;Ha
rtmann1990\;Hassan\;Hassan2004\;Hsia1997\;JAÂ©ron1999\;Jeske2000\;Juer
gens2011\;Khan2011\;Korel2002\;Kung1993\;Kung1994\;Kung1995\;Kung1996\
;Laski1992\;Laski1992a\;LeTraon2000\;Leung1989\;Liang2005\;Lindvall199
8a\;Lindvall1998b\;Mahdian2009\;Malishevsky2002\;Mansour2010\;Mansour2
011\;Mao2005\;Martins2005\;Mayrhauser1993\;Mayrhauser1999a\;Mayrhauser
1999b\;Mehta2001\;Memon2003\;Memon2005\;Muccini2005\;Muccini2005a\;Muc
cini2006\;Muccini2007\;Naslavsky2007\;Naslavsky2009\;Naslavsky2010\;On
oma1998\;Orso2004a\;Orso2004b\;Orso2007\;P.G.2010\;Paul2001\;Pilskalns
2006\;Pretschner2001\;Rosenblum1996\;Rosenblum1997\;Rothermel1993\;Rot
hermel1994\;Rothermel1996\;Rothermel1997\;Rothermel1997a\;S2011\;Sajee
v2003\;Sajeev2003a\;Santelices2008\;Shiri2007\;Skoglund2005\;Sneed2004
\;Sneed2006a\;Sneed2006b\;Stallbaum2008\;Stanek2006\;Traon2000\;WalidS
.AbdEl-hamid2010\;Weide\;White1993\;White1996\;Wilde1992\;Wilde1993\;W
inter1998\;Wissink2006\;Wloka2009\;Wong1997\;Wu1999\;Wu1999a\;Wu2003\;
Xu2004\;Yoo2010\;Yu2008\;Zaidman2008\;Zheng2006\;Zheng2007\;;
1 ExplicitGroup:DependencyTypes\;2\;Adamer2012\;Aizenbud-Reshef2005\;A
izenbud-Reshef2006\;Briand2009\;Cleland-Huang2003\;Constantopoulos1995
\;Espinoza2006\;Espinoza2011\;Filho2003\;Galvao2007\;Jirapanthong2009\
;Knethen2002a\;Lamb2011\;Letelier2002\;Maeder2007a\;Marcus2005\;Olsson
2002\;Paige2008\;Paige2011\;Ramesh2001\;Seibel2010\;Sherba2003\;Sherba
2003a\;Spanoudakis2004\;Spanoudakis2005\;Tang2011\;Tang2011a\;Tang2011
b\;Walderhaug2006\;Winkler2010\;;
1 ExplicitGroup:Software Visualization\;2\;Falke2005\;Fasching2009\;Gh
anam2008\;Hegedues2010\;Koschke2003\;Langelier2005\;Li2012\;Pacione200
4\;Wettel2007\;Wettel2007a\;;
1 ExplicitGroup:Change Identification\;2\;2009\;Bergmann2009\;Bowring0
1astudy\;Brosch\;Brun2008\;Buckley2005\;Clarke2003\;Gerth2010\;Gerth:2
009:LCM:1691319.1691336\;Groher2009\;Groher2010\;Hearnden2006\;Hunt199
8\;Koenemann2009\;Kofman2003\;Kolovos2006a\;Kolovos2006b\;Kolovos2009\
;Kolovos2009a\;Konemann2009\;Konemann2009a\;Konemann2010\;Konemann:201
0:CIM:1929101.1929114\;Lin2004\;Lindvall1998a\;Lindvall1998b\;Maoz:201
1:ASD:2025113.2025140\;MarcusAlanen2003\;Ohst2003\;Rath2008\;Rath2009\
;Scharf2011\;Soto2008\;Toulme2006\;Tratt_2008\;Tun2009\;Xing2006\;;
1 ExplicitGroup:Multiperspective Modeling\;2\;Egyed2002\;Eramo2008\;Fr
adet1999\;Imtiaz2008\;Kolovos2008\;Lehnert2012b\;Mens2003b\;Murphy1995
\;Murphy2001\;Muskens2005\;Olsson2002\;Seibel2010\;Sunetnanta2001\;Tan
g2011\;VanDerStraeten2003\;Yie2009\;;
2 ExplicitGroup:Consistency Checking\;2\;Demuth2011\;Fradet1999\;Kolov
os2008\;Mens2003b\;Muskens2005\;Olsson2002\;Reder2012\;Sunetnanta2001\
;;
1 ExplicitGroup:Software Development Process (SDP)\;2\;;
2 ExplicitGroup:Patterns\;2\;;
2 ExplicitGroup:Process Tailoring\;2\;Anacleto2004\;Armbrust2008\;Bala
subramaniam2007\;Baldassarre2002\;Biffl2006\;Blowers2006\;Bowers2002\;
Budlong1996\;Bustard2005\;Cao2004\;Cass2002\;Cheng2009\;Dai2007\;Demir
ors2000\;Fitzgerald2000\;Fitzgerald2003\;Giese2007\;Ginsberg1995\;Hans
sen2005\;Henninger2001\;Hesse1999\;Hikichi2006\;Hollenbach1996\;Huang2
006a\;Ibarguengoitia2003\;Jaccheri1993\;Jaufman2005\;Johansson2005\;Ke
enan2004\;Kim2005\;Lazovik2007\;Lobsitz1996\;Madhavji1991\;Martinez-Ru
iz2008\;Martinez-Ruiz2012\;Mnkandla2005\;Ocampo2003\;Ocampo2005\;Oshan
a1998\;Oshana1998a\;Pedreira2007\;Pikkarainen2006\;Schnieders2006\;Sec
hser2009\;Seo2000\;Simidchieva2007\;SuttonJr1996\;Welzel1995\;Westerhe
im2005\;Xu2003\;Xu2005a\;Xu2008\;Yoon2001\;team2011standard\;;
2 ExplicitGroup:Process Improvement\;2\;Bjerknes2000\;Calvo-Manzano200
6\;Casey2004\;Cater-Steel2004\;Cater-Steel2006\;Dangle2005\;Demirors19
98\;Dingsoyr2004\;Florac1999\;Gorschek2004\;Grunbacher1997\;Guerrero20
04\;Haase1998\;Harjumaa2005\;Harjumaa2005a\;Herndon2006\;Kautz2000\;Ke
lly1999\;Kulpa2008\;Kurniawati2004\;Meehan2002\;Nikula2005\;Oktaba2006
\;Otoya1999\;Pino2008\;Rautiainen2003\;Richardson2006\;Scott2001\;Scot
t2002\;Scott2002a\;Serrano2003\;Wangenheim2006\;Wiegers1999\;team2011s
tandard\;;
2 ExplicitGroup:Statistical Process Control (SPC)\;2\;Florac1999\;;
2 ExplicitGroup:Process Models\;2\;Acuna2001\;CMMI2002Continuous\;Cepe
da2005\;Hug2009\;OMG2008\;SEI2002stagedCMMI\;team2010cmmi\;team2011sta
ndard\;;
2 ExplicitGroup:Process Lines / Process Variability\;2\;Martinez-Ruiz2
008\;;
2 ExplicitGroup:Process Metamodels\;2\;Dowson1987\;Hug2009\;Jarke1992\
;Jarke1993\;Jarke1993a\;Pohl1994a\;Rolland1997\;Rolland1998\;Rolland19
99\;;
1 ExplicitGroup:SWE Guidelines\;2\;Basili1994\;Biolchi2005\;Fuchs2009\
;Glass2002\;Kitchenham2001-2003\;Kitchenham2002\;Kitchenham2002a\;Kitc
henham2002b\;Kitchenham2002c\;Kitchenham2002d\;Kitchenham2003\;Kitchen
ham2004\;Kitchenham2004a\;Kitchenham2008\;Pfleeger2001\;Runeson2009\;Z
elkowitz1998\;;
1 ExplicitGroup:ToolWebsites\;2\;EMF\;EMFStore\;EMFTrace\;MoDisco\;;
1 ExplicitGroup:Traceability\;2\;Adamer2012\;Aizenbud-Reshef2005\;Aize
nbud-Reshef2006\;Antoniol2002\;Berg2006\;Borg2013a\;Briand2009\;Consta
ntopoulos1995\;DeLucia2007\;DeLucia2008\;Egyed2002\;Espinoza2006\;Espi
noza2011\;Filho2003\;Galvao2007\;Goknil2008\;Gupta2013\;Imtiaz2008\;Ja
rke1998\;Jirapanthong2009\;Knethen2002a\;Lago2004\;Lamb2011\;Letelier2
002\;Li2012\;Maeder2007a\;Marcus2003\;Marcus2005\;Olsson2002\;Paige200
8\;Paige2011\;Pohl1996a\;Pohl1996b\;Protsyk2007\;Ramesh2001\;Rempel201
2\;Riebisch2011\;Rochimah2007\;Seibel2010\;Sherba2003\;Sherba2003a\;Sp
anoudakis2004\;Spanoudakis2005\;Tang2011\;Tang2011a\;Tang2011b\;Walder
haug2006\;Winkler2010\;;
2 ExplicitGroup:Traceability Classifications\;2\;DeLucia2008\;Espinoza
2006\;Paige2008\;Protsyk2007\;Sherba2003\;;
2 ExplicitGroup:Traceability Metamodel\;2\;Drivalos2009\;Limon2005\;Li
mon2009\;Sharif2007\;;
2 ExplicitGroup:Traceability Detection\;2\;Antoniol2001\;Antoniol2002\
;Bode2011a\;DeLucia2007\;DiPenta2002\;Egyed2007\;Filho2003\;Gupta2013\
;HuffmanHayes2007\;Jirapanthong2009\;Lehnert2010\;Marcus2003\;Oliveto2
010\;Paige2011\;Riebisch2011\;Spanoudakis2003\;Spanoudakis2004\;;
2 ExplicitGroup:Traceability Benchmarks\;2\;Charrada2011\;Cleland-Huan
g2011\;Dekhtyar2007\;Gotel2012\;Rochimah2007\;Shin2012\;;
2 ExplicitGroup:Traceability Surveys/Reviews\;2\;Adamer2012\;DeLucia20
08\;Galvao2007\;Knethen2002a\;Spanoudakis2005\;Winkler2010\;;
2 ExplicitGroup:Tool survey\;2\;Djebbi2007\;Rempel2012\;;
2 ExplicitGroup:Traceability study\;2\;Alexander2002\;Arkley2006\;Gote
l1994\;Mader2009b\;Ramesh1995\;;
2 ExplicitGroup:Adapting traceability\;2\;Cleland-Huang2012\;Doemges19
98\;Doemges1998a\;;
1 ExplicitGroup:Mega-Models\;2\;Assmann2006\;Barbero2008\;Bezivin2004a
\;Bezivin2004b\;Favre2004\;Favre2005\;Reiter2005\;Seibel2010\;;
1 ExplicitGroup:Qualitative Content Analysis\;2\;Curtis2000\;Elo2008\;
Kohlbacher2006\;Kromrey2006\;Kuckartz2007\;Mayring2000\;Mayring2008\;M
ayring2010\;Pallmer2012\;;
1 ExplicitGroup:Software Project\;2\;;
2 ExplicitGroup:Dimensions\;2\;Alter1999\;Baccarini1996\;Jugdev2005\;J
urison1999\;Midler1995\;Turner1993\;Turner2004\;Ward2007\;Wateridge199
8\;Williams1999\;Winter2006\;Xia2004a\;;
2 ExplicitGroup:Inter-organizational\;2\;Chiu2004\;Colombo2002\;Grefen
2000\;Kafeza2001\;Klingemann1999\;Klingemann1999a\;Koetsier2000\;Luo20
03\;Weigand2002\;;
3 ExplicitGroup:Organizational relationships\;2\;Bensaou1996\;Blumenbe
rg2008\;Brunard1994\;DiRomualdo1998\;Halvey2005\;Heeks2001\;Herbsleb20
01\;Kern2000\;Klepper1998\;Krishna2004\;Lacity1994\;Mueller2003\;Sneho
ta1995\;;
3 ExplicitGroup:Dimensions\;2\;Bakker2010\;Bakker2011\;Bechky2006\;Ber
ggren2001\;Bigley2001\;Brady2004\;Bresnen2004\;Bryman1987\;Bryman1987a
\;DeFillippi1998\;Engwall2004\;Gann2000\;Gersick1988\;Grabher2004\;Gra
bher2006\;Hobday2000\;Ibert2004\;Jones2008\;Keegan2001\;Kernaghan1990\
;Lowendahl1995\;Lundin1995\;Manning2008\;Meyerson1996\;Miles1964\;Morr
is1987\;Palisi1970\;Perretti2006\;Pitsis2003\;Prencipe2001\;Saunders20
06\;Scarbrough2004\;Scarbrough2004a\;Shenhar2001\;Soderlund2005\;Sydow
2004\;Terrion2002\;Weick1993\;Whitley2006\;Xu2007\;;
3 ExplicitGroup:Rough set theory\;2\;;
3 ExplicitGroup:Traceability\;2\;Cleland-Huang2007\;Damian2006\;Gotel1
995\;Lormans2004\;Rabade2006\;;
3 ExplicitGroup:Stratefic goals\;2\;VonKrogh2001\;;
3 ExplicitGroup:IT Governance\;2\;VanGrembergen2004\;;
2 ExplicitGroup:Success criteria\;2\;Lim1999\;;
3 ExplicitGroup:Software costs\;0\;Boehm1988\;Jones1998\;;
3 ExplicitGroup:Software quality\;0\;Boehm1976\;Boehm1978\;ISOIEC25010
\;ISOIEC9126\;;
3 ExplicitGroup:Software development time\;0\;Blackburn1996\;;
1 ExplicitGroup:WF\;2\;;
2 ExplicitGroup:Studies\;2\;;
2 ExplicitGroup:WF Perspectives\;0\;Jablonski1996\;VanDerAalst2004\;;
3 ExplicitGroup:Control Flow\;2\;DerAalst2003\;Russell2006\;;
3 ExplicitGroup:Data Flow\;2\;Russell2004\;Russell2005\;;
3 ExplicitGroup:Resources\;2\;Russell2004a\;Russell2005a\;;
4 ExplicitGroup:Roles\;0\;Crook2003\;;
3 ExplicitGroup:Exception Handling\;2\;Russel2006\;Russell2006a\;;
2 ExplicitGroup:BPMN\;0\;;
3 ExplicitGroup:BPMN Extensions\;0\;Rodriguez2007\;Wolter2007\;;
2 ExplicitGroup:Modelling\;2\;;
3 ExplicitGroup:Strategy oriented\;2\;Essafi2007\;Nurcan2005\;Rolland1
999\;;
3 ExplicitGroup:Goals\;2\;Anton1998\;Dardenne1993\;Prat1997\;Rolland19
98a\;Rolland2010\;Vendler1957\;;
}

